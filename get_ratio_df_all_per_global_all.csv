,ds_count,task,ds,date,model_label,value,percent_of_max_sota,gain,ratio,max_sota,percent_of_max_metric,top_level_class,class_label,merge
0,1,BIRL: Benchmark on Image Registration methods with Landmark validations,CIMA-10k,2006-05,bUnwarpJ,2.82,100.0,2.82,1.0,2.82,1.0,ito:ITO_00101,Vision process,AMrTRE
0,1,BIRL: Benchmark on Image Registration methods with Landmark validations,CIMA-10k,2006-05,bUnwarpJ,3.0,100.0,3.0,1.0,3.0,1.0,ito:ITO_00101,Vision process,MMrTRE
0,1,Diffeomorphic Medical Image Registration,CUMC12,2008-02,SyN,0.514,98.85,0.514,0.99,0.52,0.99,ito:ITO_00101,Vision process,Mean\\ target\\ overlap\\ ratio
1,1,Diffeomorphic Medical Image Registration,CUMC12,2018-09,VoxelMorph,0.517,99.42,0.0,0.0,0.52,0.99,ito:ITO_00101,Vision process,Mean\\ target\\ overlap\\ ratio
2,1,Diffeomorphic Medical Image Registration,CUMC12,2019-04,Metric Net (Local Reg),0.52,100.0,0.0,0.0,0.52,1.0,ito:ITO_00101,Vision process,Mean\\ target\\ overlap\\ ratio
0,1,Monocular Depth Estimation,NYU-Depth V2,2014-06,Eigen et al.,0.907,100.0,0.907,1.0,0.907,0.0,ito:ITO_00101,Vision process,RMSE
1,1,Object Counting,CARPK,2015-06,Faster R-CNN (2015),47.67,23.79,47.67,0.24,200.42,0.03,ito:ITO_00101,Vision process,RMSE
2,1,Object Counting,CARPK,2015-06,YOLO (2016),200.42,100.0,152.8,0.76,200.42,0.13,ito:ITO_00101,Vision process,RMSE
3,1,Monocular Depth Estimation,Mid-Air Dataset,2016-09,Monodepth,13.595,18.24,13.595,0.18,74.552,0.01,ito:ITO_00101,Vision process,RMSE
4,1,Monocular Depth Estimation,Mid-Air Dataset,2018-06,Monodepth2,74.552,100.0,61.0,0.82,74.552,0.05,ito:ITO_00101,Vision process,RMSE
5,1,Depth Completion,KITTI Depth Completion,2017-08,SparseConvs,1601.0,100.0,1601.0,1.0,1601.0,1.0,ito:ITO_00101,Vision process,RMSE
6,1,Monocular Depth Estimation,Make3D,2018-06,Monodepth2,7.417,100.0,7.417,1.0,7.417,0.0,ito:ITO_00101,Vision process,RMSE
7,1,Depth Completion,VOID,2019-05,VOICED,169.79,100.0,169.79,1.0,169.79,0.11,ito:ITO_00101,Vision process,RMSE
8,1,Trajectory Prediction,TRAF,2019-06,TraPHic,0.78,100.0,0.78,1.0,0.78,0.0,ito:ITO_00101,Vision process,RMSE
9,1,Trajectory Prediction,NGSIM,2019-06,TraPHic,5.63,100.0,5.63,1.0,5.63,0.0,ito:ITO_00101,Vision process,RMSE
10,1,Stereo-LiDAR Fusion,KITTI Depth Completion Validation,2019-08,GuideNet,777.78,100.0,777.78,1.0,777.78,0.49,ito:ITO_00101,Vision process,RMSE
0,1,Medical Image Segmentation,RITE,2015-05,U-Net,55.24,100.0,55.24,1.0,55.24,0.61,ito:ITO_00101,Vision process,Dice
1,1,Nuclear Segmentation,Cell17,2016-03,FnsNet,0.6165,82.13,0.6165,0.82,0.7506,0.01,ito:ITO_00101,Vision process,Dice
2,1,Nuclear Segmentation,Cell17,2016-11,Pix2Pix,0.6351,84.61,0.0,0.0,0.7506,0.01,ito:ITO_00101,Vision process,Dice
3,1,Nuclear Segmentation,Cell17,2017-03,Mask R-CNN,0.707,94.19,0.1,0.13,0.7506,0.01,ito:ITO_00101,Vision process,Dice
4,1,Nuclear Segmentation,Cell17,2018-09,Cell R-CNN,0.7088,94.43,0.0,0.0,0.7506,0.01,ito:ITO_00101,Vision process,Dice
5,1,Nuclear Segmentation,Cell17,2019-08,Deep Panoptic Model with Semantic Feature Fusion,0.7506,100.0,0.0,0.0,0.7506,0.01,ito:ITO_00101,Vision process,Dice
6,1,Medical Image Segmentation,2018 Data Science Bowl,2018-07,Unet++,0.8974,100.0,0.8974,1.0,0.8974,0.01,ito:ITO_00101,Vision process,Dice
7,1,Image Registration,Osteoarthritis Initiative,2019-03,vSVF-net [shen2019networks],67.59,99.13,67.59,0.99,68.18,0.74,ito:ITO_00101,Vision process,Dice
8,1,Image Registration,Osteoarthritis Initiative,2019-06,Region-specific Diffeomorphic Metric Mapping,68.18,100.0,0.6,0.01,68.18,0.75,ito:ITO_00101,Vision process,Dice
9,1,Liver Segmentation,LiTS2017,2019-08,ModelGenesis,91.13,100.0,91.13,1.0,91.13,1.0,ito:ITO_00101,Vision process,Dice
10,1,Lung Nodule Segmentation,LIDC-IDRI,2019-08,ModelGenesis,75.86,100.0,75.86,1.0,75.86,0.83,ito:ITO_00101,Vision process,Dice
0,1,3D Human Pose Estimation,HumanEva-I,2010-03,TGP,48.7,100.0,48.7,1.0,48.7,1.0,ito:ITO_00101,Vision process,Mean\\ Reconstruction\\ Error\\ \\(mm\\)
1,1,3D Face Reconstruction,NoW Benchmark,2016-12,3DMM-CNN,2.33,100.0,2.33,1.0,2.33,0.05,ito:ITO_00101,Vision process,Mean\\ Reconstruction\\ Error\\ \\(mm\\)
0,1,Multivariate Time Series Imputation,KDD CUP Challenge 2018,2010-11,MICE,0.468,100.0,0.468,1.0,0.468,1.0,ito:ITO_00101,Vision process,MSE\\ \\(10%\\ missing\\)
0,1,Multivariate Time Series Imputation,UCI localization data,2010-11,MICE,0.477,100.0,0.477,1.0,0.477,1.0,ito:ITO_00101,Vision process,MAE\\ \\(10%\\ missing\\)
0,1,Multivariate Time Series Imputation,PhysioNet Challenge 2012,2010-11,MICE,0.634,100.0,0.634,1.0,0.634,1.0,ito:ITO_00101,Vision process,MAE\\ \\(10%\\ of\\ data\\ as\\ GT\\)
0,1,Multivariate Time Series Imputation,Beijing Air Quality,2010-11,MICE,27.42,100.0,27.42,1.0,27.42,1.0,ito:ITO_00101,Vision process,MAE\\ \\(PM2\\.5\\)
0,1,Traffic Sign Recognition,GTSRB,2012-02,MCDNN,11.21,100.0,11.21,1.0,11.21,1.0,ito:ITO_00101,Vision process,Error\\ rate
1,1,Face Alignment,AFLW2000,2014-06,Dlib  (68 points),10.545,100.0,10.545,1.0,10.545,0.94,ito:ITO_00101,Vision process,Error\\ rate
2,1,Gesture Recognition,Montalbano,2015-06,Temp Conv + LSTM,2.77,100.0,2.77,1.0,2.77,0.25,ito:ITO_00101,Vision process,Error\\ rate
0,1,Image Classification,MNIST,2012-02,MCDNN,0.23,4.6,0.23,0.05,5.0,0.0,ito:ITO_00101,Vision process,Percentage\\ error
1,1,Image Classification,MNIST,2013-02,Maxout Networks,0.5,10.0,0.3,0.06,5.0,0.01,ito:ITO_00101,Vision process,Percentage\\ error
2,1,Image Classification,MNIST,2014-04,PCANet,0.6,12.0,0.1,0.02,5.0,0.01,ito:ITO_00101,Vision process,Percentage\\ error
3,1,Image Classification,MNIST,2014-12,Explaining and Harnessing Adversarial Examples,0.8,16.0,0.2,0.04,5.0,0.01,ito:ITO_00101,Vision process,Percentage\\ error
4,1,Image Classification,MNIST,2015-06,Zhao et al. (2015) (auto-encoder),4.76,95.2,4.0,0.8,5.0,0.06,ito:ITO_00101,Vision process,Percentage\\ error
5,1,Image Classification,MNIST,2017-08,ProjectionNet,5.0,100.0,0.2,0.04,5.0,0.06,ito:ITO_00101,Vision process,Percentage\\ error
6,1,Image Classification,SVHN,2013-01,Stochastic Pooling,2.8,3.59,2.8,0.04,77.93,0.04,ito:ITO_00101,Vision process,Percentage\\ error
7,1,Image Classification,SVHN,2014-06,M1+TSVM,54.33,69.72,51.5,0.66,77.93,0.7,ito:ITO_00101,Vision process,Percentage\\ error
8,1,Image Classification,SVHN,2014-06,M1+KNN,65.63,84.22,11.3,0.15,77.93,0.84,ito:ITO_00101,Vision process,Percentage\\ error
9,1,Image Classification,SVHN,2015-11,TSVM,66.55,85.4,0.9,0.01,77.93,0.85,ito:ITO_00101,Vision process,Percentage\\ error
10,1,Image Classification,SVHN,2015-11,KNN,77.93,100.0,11.4,0.15,77.93,1.0,ito:ITO_00101,Vision process,Percentage\\ error
11,1,Image Classification,CIFAR-100,2013-02,Maxout Network (k=2),38.57,100.0,38.57,1.0,38.57,0.49,ito:ITO_00101,Vision process,Percentage\\ error
12,1,Image Classification,CIFAR-10,2013-02,Maxout Network (k=2),9.38,100.0,9.38,1.0,9.38,0.12,ito:ITO_00101,Vision process,Percentage\\ error
13,1,Image Classification,Fashion-MNIST,2017-08,Random Erasing,3.65,48.03,3.65,0.48,7.6,0.05,ito:ITO_00101,Vision process,Percentage\\ error
14,1,Image Classification,Fashion-MNIST,2019-01,VGG8B(2x) + LocalLearning + CO,4.14,54.47,0.5,0.07,7.6,0.05,ito:ITO_00101,Vision process,Percentage\\ error
15,1,Image Classification,Fashion-MNIST,2019-04,TextCaps,6.29,82.76,2.2,0.29,7.6,0.08,ito:ITO_00101,Vision process,Percentage\\ error
16,1,Image Classification,Fashion-MNIST,2019-08,NeuPDE,7.6,100.0,1.3,0.17,7.6,0.1,ito:ITO_00101,Vision process,Percentage\\ error
17,1,Image Classification,MultiMNIST,2017-10,CapsNet,5.2,100.0,5.2,1.0,5.2,0.07,ito:ITO_00101,Vision process,Percentage\\ error
18,1,Semi-Supervised Image Classification,"CIFAR-10, 40 Labels",2018-05,UL-Hopfield (ULH),16.9,88.48,16.9,0.88,19.1,0.22,ito:ITO_00101,Vision process,Percentage\\ error
19,1,Semi-Supervised Image Classification,"CIFAR-10, 40 Labels",2019-11,ReMixMatch,19.1,100.0,2.2,0.12,19.1,0.25,ito:ITO_00101,Vision process,Percentage\\ error
20,1,Image Classification,Kuzushiji-MNIST,2019-01,VGG8B(2x) + LocalLearning + CO,0.99,100.0,0.99,1.0,0.99,0.01,ito:ITO_00101,Vision process,Percentage\\ error
21,1,Semi-Supervised Image Classification,"CIFAR-100, 400 Labels",2020-01,FixMatch (CTA),49.95,100.0,49.95,1.0,49.95,0.64,ito:ITO_00101,Vision process,Percentage\\ error
22,1,Semi-Supervised Image Classification,"SVHN, 40 Labels",2020-01,FixMatch (CTA),7.65,100.0,7.65,1.0,7.65,0.1,ito:ITO_00101,Vision process,Percentage\\ error
23,1,Semi-Supervised Image Classification,"CIFAR-100, 2500 Labels",2020-01,FixMatch (CTA),28.64,100.0,28.64,1.0,28.64,0.37,ito:ITO_00101,Vision process,Percentage\\ error
0,1,Traffic Sign Recognition,GTSRB,2012-02,MCDNN,99.5,100.0,99.5,1.0,99.5,1.0,ito:ITO_00101,Vision process,Accuracy
1,1,Image Clustering,Extended Yale-B,2012-03,SSC,0.706,71.17,0.706,0.71,0.992,0.01,ito:ITO_00101,Vision process,Accuracy
2,1,Image Clustering,Extended Yale-B,2017-09,DSC-2,0.973,98.08,0.3,0.3,0.992,0.01,ito:ITO_00101,Vision process,Accuracy
3,1,Image Clustering,Extended Yale-B,2018-04,DMSC,0.992,100.0,0.0,0.0,0.992,0.01,ito:ITO_00101,Vision process,Accuracy
4,1,Skeleton Based Action Recognition,UWA3D,2012-07,HOJ3D,17.7,21.74,17.7,0.22,81.4,0.18,ito:ITO_00101,Vision process,Accuracy
5,1,Skeleton Based Action Recognition,UWA3D,2017-08,ESV (Synthesized + Pre-trained),73.8,90.66,56.1,0.69,81.4,0.74,ito:ITO_00101,Vision process,Accuracy
6,1,Skeleton Based Action Recognition,UWA3D,2018-04,VA-fusion (aug.),81.4,100.0,7.6,0.09,81.4,0.81,ito:ITO_00101,Vision process,Accuracy
7,1,Image Clustering,Coil-20,2012-08,AGDL,0.858,100.0,0.858,1.0,0.858,0.01,ito:ITO_00101,Vision process,Accuracy
8,1,Image Clustering,MNIST-full,2012-08,GDL,0.964,97.67,0.964,0.98,0.987,0.01,ito:ITO_00101,Vision process,Accuracy
9,1,Image Clustering,MNIST-full,2018-12,DDC-DA,0.969,98.18,0.0,0.0,0.987,0.01,ito:ITO_00101,Vision process,Accuracy
10,1,Image Clustering,MNIST-full,2019-01,DynAE,0.987,100.0,0.0,0.0,0.987,0.01,ito:ITO_00101,Vision process,Accuracy
11,1,Image Clustering,Fashion-MNIST,2012-08,GDL,0.627,93.3,0.627,0.93,0.672,0.01,ito:ITO_00101,Vision process,Accuracy
12,1,Image Clustering,Fashion-MNIST,2019-08,N2D (UMAP),0.672,100.0,0.0,0.0,0.672,0.01,ito:ITO_00101,Vision process,Accuracy
13,1,Image Clustering,MNIST-test,2012-08,GDL,0.964,97.67,0.964,0.98,0.987,0.01,ito:ITO_00101,Vision process,Accuracy
14,1,Image Clustering,MNIST-test,2018-12,DDC-DA,0.97,98.28,0.0,0.0,0.987,0.01,ito:ITO_00101,Vision process,Accuracy
15,1,Image Clustering,MNIST-test,2019-01,DynAE,0.987,100.0,0.0,0.0,0.987,0.01,ito:ITO_00101,Vision process,Accuracy
16,1,Image Clustering,coil-100,2012-08,GDL,0.731,94.32,0.731,0.94,0.775,0.01,ito:ITO_00101,Vision process,Accuracy
17,1,Image Clustering,coil-100,2017-03,DBC,0.775,100.0,0.0,0.0,0.775,0.01,ito:ITO_00101,Vision process,Accuracy
18,1,Skeleton Based Action Recognition,CAD-120,2012-10,KGS,86.0,96.3,86.0,0.96,89.3,0.86,ito:ITO_00101,Vision process,Accuracy
19,1,Skeleton Based Action Recognition,CAD-120,2013-02,All Features (w ground truth),89.3,100.0,3.3,0.04,89.3,0.89,ito:ITO_00101,Vision process,Accuracy
20,1,Trajectory Prediction,GPS,2012-11,Support Vector Machines,88.0,100.0,88,1.0,88,0.88,ito:ITO_00101,Vision process,Accuracy
21,1,Unsupervised Domain Adaptation,Office-Home,2012-12,AlexNet [cite:NIPS12CNN],54.9,71.48,54.9,0.71,76.8,0.55,ito:ITO_00101,Vision process,Accuracy
22,1,Unsupervised Domain Adaptation,Office-Home,2015-02,DAN [cite:ICML15DAN],74.3,96.74,19.4,0.25,76.8,0.74,ito:ITO_00101,Vision process,Accuracy
23,1,Unsupervised Domain Adaptation,Office-Home,2015-05,DANN [cite:JMLR16RevGrad],76.8,100.0,2.5,0.03,76.8,0.77,ito:ITO_00101,Vision process,Accuracy
24,1,Image Classification,ImageNet ReaL,2012-12,AlexNet,62.88,69.45,62.88,0.69,90.54,0.63,ito:ITO_00101,Vision process,Accuracy
25,1,Image Classification,ImageNet ReaL,2014-09,VGG-16 BN,80.6,89.02,17.7,0.2,90.54,0.81,ito:ITO_00101,Vision process,Accuracy
26,1,Image Classification,ImageNet ReaL,2015-12,ResNet-50,82.94,91.61,2.3,0.03,90.54,0.83,ito:ITO_00101,Vision process,Accuracy
27,1,Image Classification,ImageNet ReaL,2015-12,ResNet-152,84.79,93.65,1.9,0.02,90.54,0.85,ito:ITO_00101,Vision process,Accuracy
28,1,Image Classification,ImageNet ReaL,2017-07,NASNet-A Large,87.56,96.71,2.8,0.03,90.54,0.88,ito:ITO_00101,Vision process,Accuracy
29,1,Image Classification,ImageNet ReaL,2019-06,FixResNeXt-101 32x48d,89.73,99.11,2.2,0.02,90.54,0.9,ito:ITO_00101,Vision process,Accuracy
30,1,Image Classification,ImageNet ReaL,2019-12,BiT-L,90.54,100.0,0.8,0.01,90.54,0.91,ito:ITO_00101,Vision process,Accuracy
31,1,Hand Gesture Recognition,Cambridge,2013-03,Sanin et al. [sanin2013spatio],93.0,94.68,93.0,0.95,98.23,0.93,ito:ITO_00101,Vision process,Accuracy
32,1,Hand Gesture Recognition,Cambridge,2019-01,Key Frames + Feature Fusion,98.23,100.0,5.2,0.05,98.23,0.98,ito:ITO_00101,Vision process,Accuracy
33,1,Human Interaction Recognition,UT,2013-06,Raptis et al.,93.3,94.88,93.3,0.95,98.33,0.93,ito:ITO_00101,Vision process,Accuracy
34,1,Human Interaction Recognition,UT,2017-06,Co-LSTSM,95.0,96.61,1.7,0.02,98.33,0.95,ito:ITO_00101,Vision process,Accuracy
35,1,Human Interaction Recognition,UT,2018-11,H-LSTCM,98.33,100.0,3.3,0.03,98.33,0.98,ito:ITO_00101,Vision process,Accuracy
36,1,Image Classification,MNIST,2013-06,DropConnect,99.79,99.95,99.79,1.0,99.84,1.0,ito:ITO_00101,Vision process,Accuracy
37,1,Image Classification,MNIST,2018-05,RMDL (30 RDLs),99.82,99.98,0.0,0.0,99.84,1.0,ito:ITO_00101,Vision process,Accuracy
38,1,Image Classification,MNIST,2020-01,Branching/Merging CNN + Homogeneous Filter Capsules,99.84,100.0,0.0,0.0,99.84,1.0,ito:ITO_00101,Vision process,Accuracy
39,1,Facial Expression Recognition,FER2013,2013-07,Ensemble ResMaskingNet with 6 other CNNs,76.82,100.0,76.82,1.0,76.82,0.77,ito:ITO_00101,Vision process,Accuracy
40,1,Few-Shot Image Classification,ImageNet,2013-12,ConSE,1.4,93.33,1.4,0.93,1.5,0.01,ito:ITO_00101,Vision process,Accuracy
41,1,Few-Shot Image Classification,ImageNet,2016-03,Synthesised Classifier,1.5,100.0,0.1,0.07,1.5,0.02,ito:ITO_00101,Vision process,Accuracy
42,1,Image Clustering,CIFAR-10,2013-12,VAE,0.291,46.71,0.291,0.47,0.623,0.0,ito:ITO_00101,Vision process,Accuracy
43,1,Image Clustering,CIFAR-10,2015-11,GAN,0.315,50.56,0.0,0.0,0.623,0.0,ito:ITO_00101,Vision process,Accuracy
44,1,Image Clustering,CIFAR-10,2017-10,DAC,0.522,83.79,0.2,0.32,0.623,0.01,ito:ITO_00101,Vision process,Accuracy
45,1,Image Clustering,CIFAR-10,2018-07,IIC,0.617,99.04,0.1,0.16,0.623,0.01,ito:ITO_00101,Vision process,Accuracy
46,1,Image Clustering,CIFAR-10,2019-04,DCCM,0.623,100.0,0.0,0.0,0.623,0.01,ito:ITO_00101,Vision process,Accuracy
47,1,Image Clustering,Imagenet-dog-15,2013-12,VAE,0.179,46.74,0.179,0.47,0.383,0.0,ito:ITO_00101,Vision process,Accuracy
48,1,Image Clustering,Imagenet-dog-15,2015-11,DEC,0.195,50.91,0.0,0.0,0.383,0.0,ito:ITO_00101,Vision process,Accuracy
49,1,Image Clustering,Imagenet-dog-15,2017-10,DAC,0.275,71.8,0.1,0.26,0.383,0.0,ito:ITO_00101,Vision process,Accuracy
50,1,Image Clustering,Imagenet-dog-15,2019-04,DCCM,0.383,100.0,0.1,0.26,0.383,0.0,ito:ITO_00101,Vision process,Accuracy
51,1,Image Clustering,STL-10,2013-12,VAE,0.282,58.51,0.282,0.59,0.482,0.0,ito:ITO_00101,Vision process,Accuracy
52,1,Image Clustering,STL-10,2015-11,DEC,0.359,74.48,0.1,0.21,0.482,0.0,ito:ITO_00101,Vision process,Accuracy
53,1,Image Clustering,STL-10,2017-10,DAC,0.47,97.51,0.1,0.21,0.482,0.0,ito:ITO_00101,Vision process,Accuracy
54,1,Image Clustering,STL-10,2019-04,DCCM,0.482,100.0,0.0,0.0,0.482,0.0,ito:ITO_00101,Vision process,Accuracy
55,1,Image Clustering,ImageNet-10,2013-12,VAE,0.334,47.04,0.334,0.47,0.71,0.0,ito:ITO_00101,Vision process,Accuracy
56,1,Image Clustering,ImageNet-10,2015-11,DEC,0.381,53.66,0.0,0.0,0.71,0.0,ito:ITO_00101,Vision process,Accuracy
57,1,Image Clustering,ImageNet-10,2017-10,DAC,0.527,74.23,0.1,0.14,0.71,0.01,ito:ITO_00101,Vision process,Accuracy
58,1,Image Clustering,ImageNet-10,2019-04,DCCM,0.71,100.0,0.2,0.28,0.71,0.01,ito:ITO_00101,Vision process,Accuracy
59,1,Image Clustering,CIFAR-100,2013-12,VAE,0.152,46.48,0.152,0.46,0.327,0.0,ito:ITO_00101,Vision process,Accuracy
60,1,Image Clustering,CIFAR-100,2015-11,DEC,0.185,56.57,0.0,0.0,0.327,0.0,ito:ITO_00101,Vision process,Accuracy
61,1,Image Clustering,CIFAR-100,2017-10,DAC,0.238,72.78,0.1,0.31,0.327,0.0,ito:ITO_00101,Vision process,Accuracy
62,1,Image Clustering,CIFAR-100,2019-04,DCCM,0.327,100.0,0.1,0.31,0.327,0.0,ito:ITO_00101,Vision process,Accuracy
63,1,Image Clustering,Tiny-ImageNet,2013-12,VAE,0.036,33.33,0.036,0.33,0.108,0.0,ito:ITO_00101,Vision process,Accuracy
64,1,Image Clustering,Tiny-ImageNet,2015-11,GAN,0.041,37.96,0.0,0.0,0.108,0.0,ito:ITO_00101,Vision process,Accuracy
65,1,Image Clustering,Tiny-ImageNet,2017-10,DAC,0.066,61.11,0.0,0.0,0.108,0.0,ito:ITO_00101,Vision process,Accuracy
66,1,Image Clustering,Tiny-ImageNet,2019-04,DCCM,0.108,100.0,0.0,0.0,0.108,0.0,ito:ITO_00101,Vision process,Accuracy
67,1,Multimodal Activity Recognition,MSR Daily Activity3D dataset,2014-03,DL-GSGC (RGB+D),95.0,97.44,95.0,0.97,97.5,0.95,ito:ITO_00101,Vision process,Accuracy
68,1,Multimodal Activity Recognition,MSR Daily Activity3D dataset,2016-03,DSSCA-SSLM (RGB+D),97.5,100.0,2.5,0.03,97.5,0.98,ito:ITO_00101,Vision process,Accuracy
69,1,Face Verification,Labeled Faces in the Wild,2014-04,GaussianFace,98.52,98.67,98.52,0.99,99.85,0.99,ito:ITO_00101,Vision process,Accuracy
70,1,Face Verification,Labeled Faces in the Wild,2014-06,DeepId2,99.15,99.3,0.6,0.01,99.85,0.99,ito:ITO_00101,Vision process,Accuracy
71,1,Face Verification,Labeled Faces in the Wild,2014-12,DeepId2+,99.47,99.62,0.3,0.0,99.85,0.99,ito:ITO_00101,Vision process,Accuracy
72,1,Face Verification,Labeled Faces in the Wild,2015-02,DeepID3,99.53,99.68,0.1,0.0,99.85,1.0,ito:ITO_00101,Vision process,Accuracy
73,1,Face Verification,Labeled Faces in the Wild,2015-03,FaceNet,99.63,99.78,0.1,0.0,99.85,1.0,ito:ITO_00101,Vision process,Accuracy
74,1,Face Verification,Labeled Faces in the Wild,2018-01,"ArcFace + MS1MV2 + R100, ",99.83,99.98,0.2,0.0,99.85,1.0,ito:ITO_00101,Vision process,Accuracy
75,1,Face Verification,Labeled Faces in the Wild,2019-10,VarGFaceNet,99.85,100.0,0.0,0.0,99.85,1.0,ito:ITO_00101,Vision process,Accuracy
76,1,Action Classification,HMDB51,2014-05,IDT with higher-dimensional encodings,87.9,99.89,87.9,1.0,88.0,0.88,ito:ITO_00101,Vision process,Accuracy
77,1,Action Classification,HMDB51,2014-06,Two-stream model (fusion by SVM),88.0,100.0,0.1,0.0,88.0,0.88,ito:ITO_00101,Vision process,Accuracy
78,1,Domain Adaptation,UCF-to-Olympic,2014-06,W. Sultani et al.,33.33,33.96,33.33,0.34,98.15,0.33,ito:ITO_00101,Vision process,Accuracy
79,1,Domain Adaptation,UCF-to-Olympic,2014-09,TemPooling + RevGrad,98.15,100.0,64.8,0.66,98.15,0.98,ito:ITO_00101,Vision process,Accuracy
80,1,Domain Adaptation,UCF-to-HMDBsmall,2014-06,W. Sultani et al.,68.7,69.16,68.7,0.69,99.33,0.69,ito:ITO_00101,Vision process,Accuracy
81,1,Domain Adaptation,UCF-to-HMDBsmall,2014-09,TemPooling + RevGrad,99.33,100.0,30.6,0.31,99.33,0.99,ito:ITO_00101,Vision process,Accuracy
82,1,Domain Adaptation,Olympic-to-HMDBsmall,2014-06,W. Sultani et al.,47.91,51.56,47.91,0.52,92.92,0.48,ito:ITO_00101,Vision process,Accuracy
83,1,Domain Adaptation,Olympic-to-HMDBsmall,2014-09,TemPooling + RevGrad,90.0,96.86,42.1,0.45,92.92,0.9,ito:ITO_00101,Vision process,Accuracy
84,1,Domain Adaptation,Olympic-to-HMDBsmall,2019-05,TA3N,92.92,100.0,2.9,0.03,92.92,0.93,ito:ITO_00101,Vision process,Accuracy
85,1,Domain Adaptation,HMDBsmall-to-UCF,2014-06,W. Sultani et al.,68.67,69.04,68.67,0.69,99.47,0.69,ito:ITO_00101,Vision process,Accuracy
86,1,Domain Adaptation,HMDBsmall-to-UCF,2014-09,TemPooling + RevGrad,98.41,98.93,29.7,0.3,99.47,0.98,ito:ITO_00101,Vision process,Accuracy
87,1,Domain Adaptation,HMDBsmall-to-UCF,2019-05,TA3N,99.47,100.0,1.1,0.01,99.47,0.99,ito:ITO_00101,Vision process,Accuracy
88,1,Object Detection,Caltech Lanes Cordova,2014-06,ca,92.0,100.0,92,1.0,92,0.92,ito:ITO_00101,Vision process,Accuracy
89,1,Hand Gesture Recognition,VIVA Hand Gestures Dataset,2014-06,Two Stream CNNs,68.0,79.0,68.0,0.79,86.08,0.68,ito:ITO_00101,Vision process,Accuracy
90,1,Hand Gesture Recognition,VIVA Hand Gestures Dataset,2017-05,I3D,83.1,96.54,15.1,0.18,86.08,0.83,ito:ITO_00101,Vision process,Accuracy
91,1,Hand Gesture Recognition,VIVA Hand Gestures Dataset,2018-12,MTUT,86.08,100.0,3.0,0.03,86.08,0.86,ito:ITO_00101,Vision process,Accuracy
92,1,Skeleton Based Action Recognition,Florence 3D,2014-06,Lie Group,90.9,91.73,90.9,0.92,99.1,0.91,ito:ITO_00101,Vision process,Accuracy
93,1,Skeleton Based Action Recognition,Florence 3D,2016-06,Rolling Rotations (FTP),91.4,92.23,0.5,0.01,99.1,0.91,ito:ITO_00101,Vision process,Accuracy
94,1,Skeleton Based Action Recognition,Florence 3D,2018-02,Deep STGC_K,99.1,100.0,7.7,0.08,99.1,0.99,ito:ITO_00101,Vision process,Accuracy
95,1,Skeleton Based Action Recognition,UT-Kinect,2014-06,Lie Group,97.1,98.58,97.1,0.99,98.5,0.97,ito:ITO_00101,Vision process,Accuracy
96,1,Skeleton Based Action Recognition,UT-Kinect,2018-06,DPRL,98.5,100.0,1.4,0.01,98.5,0.99,ito:ITO_00101,Vision process,Accuracy
97,1,Fine-Grained Image Classification,CUB-200-2011,2014-07,Part RCNN,76.4,84.51,76.4,0.85,90.4,0.76,ito:ITO_00101,Vision process,Accuracy
98,1,Fine-Grained Image Classification,CUB-200-2011,2015-12,Bilinear-CNN,85.1,94.14,8.7,0.1,90.4,0.85,ito:ITO_00101,Vision process,Accuracy
99,1,Fine-Grained Image Classification,CUB-200-2011,2016-11,DFB,87.4,96.68,2.3,0.03,90.4,0.87,ito:ITO_00101,Vision process,Accuracy
100,1,Fine-Grained Image Classification,CUB-200-2011,2017-12,MPN-COV,88.7,98.12,1.3,0.01,90.4,0.89,ito:ITO_00101,Vision process,Accuracy
101,1,Fine-Grained Image Classification,CUB-200-2011,2018-01,PAIRS,89.2,98.67,0.5,0.01,90.4,0.89,ito:ITO_00101,Vision process,Accuracy
102,1,Fine-Grained Image Classification,CUB-200-2011,2018-06,Inception-V3,89.6,99.12,0.4,0.0,90.4,0.9,ito:ITO_00101,Vision process,Accuracy
103,1,Fine-Grained Image Classification,CUB-200-2011,2019-03,Stacked LSTM,90.4,100.0,0.8,0.01,90.4,0.9,ito:ITO_00101,Vision process,Accuracy
104,1,Activity Recognition In Videos,DogCentric,2014-09,VGG [[Simonyan and Zisserman2015]],59.9,73.59,59.9,0.74,81.4,0.6,ito:ITO_00101,Vision process,Accuracy
105,1,Activity Recognition In Videos,DogCentric,2014-12,"PoT [[Ryoo, Rothrock, and Matthies2015]]",73.0,89.68,13.1,0.16,81.4,0.73,ito:ITO_00101,Vision process,Accuracy
106,1,Activity Recognition In Videos,DogCentric,2015-05,"TDD [[Wang, Qiao, and Tang2015]]",76.6,94.1,3.6,0.04,81.4,0.77,ito:ITO_00101,Vision process,Accuracy
107,1,Activity Recognition In Videos,DogCentric,2016-05,Sub-events (temporal filters + LSTM),81.4,100.0,4.8,0.06,81.4,0.81,ito:ITO_00101,Vision process,Accuracy
108,1,Face Verification,Oulu-CASIA,2014-09,VGGFace,93.5,94.31,93.5,0.94,99.14,0.94,ito:ITO_00101,Vision process,Accuracy
109,1,Face Verification,Oulu-CASIA,2014-12,DeepId2+,96.5,97.34,3.0,0.03,99.14,0.97,ito:ITO_00101,Vision process,Accuracy
110,1,Face Verification,Oulu-CASIA,2015-03,FaceNet,97.5,98.35,1.0,0.01,99.14,0.98,ito:ITO_00101,Vision process,Accuracy
111,1,Face Verification,Oulu-CASIA,2019-11,Dynamic MTL,99.14,100.0,1.6,0.02,99.14,0.99,ito:ITO_00101,Vision process,Accuracy
112,1,Domain Adaptation,UCF-to-HMDBfull,2014-09,RevGrad,74.44,95.03,74.44,0.95,78.33,0.74,ito:ITO_00101,Vision process,Accuracy
113,1,Domain Adaptation,UCF-to-HMDBfull,2016-05,JAN,74.72,95.39,0.3,0.0,78.33,0.75,ito:ITO_00101,Vision process,Accuracy
114,1,Domain Adaptation,UCF-to-HMDBfull,2019-05,TA3N,78.33,100.0,3.6,0.05,78.33,0.78,ito:ITO_00101,Vision process,Accuracy
115,1,Domain Adaptation,HMDBfull-to-UCF,2014-09,RevGrad,74.44,91.01,74.44,0.91,81.79,0.74,ito:ITO_00101,Vision process,Accuracy
116,1,Domain Adaptation,HMDBfull-to-UCF,2016-05,JAN,79.69,97.43,5.2,0.06,81.79,0.8,ito:ITO_00101,Vision process,Accuracy
117,1,Domain Adaptation,HMDBfull-to-UCF,2019-05,TA3N,81.79,100.0,2.1,0.03,81.79,0.82,ito:ITO_00101,Vision process,Accuracy
118,1,Multi-target Domain Adaptation,Office-31,2014-09,RevGrad,73.4,100.0,73.4,1.0,73.4,0.73,ito:ITO_00101,Vision process,Accuracy
119,1,Multi-target Domain Adaptation,Office-Home,2014-09,RevGrad,57.9,100.0,57.9,1.0,57.9,0.58,ito:ITO_00101,Vision process,Accuracy
120,1,Few-Shot Image Classification,CUB-200,2014-09,SJE,50.1,88.05,50.1,0.88,56.9,0.5,ito:ITO_00101,Vision process,Accuracy
121,1,Few-Shot Image Classification,CUB-200,2019-04,TAFE-Net,56.9,100.0,6.8,0.12,56.9,0.57,ito:ITO_00101,Vision process,Accuracy
122,1,Human Interaction Recognition,BIT,2014-11,Donahue et al.,80.13,85.22,80.13,0.85,94.03,0.8,ito:ITO_00101,Vision process,Accuracy
123,1,Human Interaction Recognition,BIT,2017-06,Co-LSTSM,92.88,98.78,12.8,0.14,94.03,0.93,ito:ITO_00101,Vision process,Accuracy
124,1,Human Interaction Recognition,BIT,2018-11,H-LSTCM,94.03,100.0,1.2,0.01,94.03,0.94,ito:ITO_00101,Vision process,Accuracy
125,1,Face Verification,YouTube Faces DB,2014-12,DeepId2+,93.2,94.99,93.2,0.95,98.12,0.93,ito:ITO_00101,Vision process,Accuracy
126,1,Face Verification,YouTube Faces DB,2015-03,FaceNet,95.12,96.94,1.9,0.02,98.12,0.95,ito:ITO_00101,Vision process,Accuracy
127,1,Face Verification,YouTube Faces DB,2015-11,Light CNN-29,95.54,97.37,0.4,0.0,98.12,0.96,ito:ITO_00101,Vision process,Accuracy
128,1,Face Verification,YouTube Faces DB,2017-04,QAN,96.17,98.01,0.6,0.01,98.12,0.96,ito:ITO_00101,Vision process,Accuracy
129,1,Face Verification,YouTube Faces DB,2018-01,"ArcFace + MS1MV2 + R100, ",98.02,99.9,1.8,0.02,98.12,0.98,ito:ITO_00101,Vision process,Accuracy
130,1,Face Verification,YouTube Faces DB,2018-03,"SeqFace, 1 ResNet-64",98.12,100.0,0.1,0.0,98.12,0.98,ito:ITO_00101,Vision process,Accuracy
131,1,Domain Adaptation,Synth Digits-to-SVHN,2015-02,MMD [tzeng2015ddc]; [long2015learning],88.0,96.49,88.0,0.96,91.2,0.88,ito:ITO_00101,Vision process,Accuracy
132,1,Domain Adaptation,Synth Digits-to-SVHN,2015-05,DANN [ganin2016domain],90.3,99.01,2.3,0.03,91.2,0.9,ito:ITO_00101,Vision process,Accuracy
133,1,Domain Adaptation,Synth Digits-to-SVHN,2016-08,DSN (DANN),91.2,100.0,0.9,0.01,91.2,0.91,ito:ITO_00101,Vision process,Accuracy
134,1,Domain Adaptation,SYNSIG-to-GTSRB,2015-02,DAN,91.1,96.5,91.1,0.97,94.4,0.91,ito:ITO_00101,Vision process,Accuracy
135,1,Domain Adaptation,SYNSIG-to-GTSRB,2017-12,MCD,94.4,100.0,3.3,0.03,94.4,0.94,ito:ITO_00101,Vision process,Accuracy
136,1,Domain Adaptation,Synth Signs-to-GTSRB,2015-02,MMD [tzeng2015ddc]; [long2015learning],91.1,97.85,91.1,0.98,93.1,0.91,ito:ITO_00101,Vision process,Accuracy
137,1,Domain Adaptation,Synth Signs-to-GTSRB,2016-08,DSN (DANN),93.1,100.0,2.0,0.02,93.1,0.93,ito:ITO_00101,Vision process,Accuracy
138,1,Domain Adaptation,MNIST-to-MNIST-M,2015-02,MMD [tzeng2015ddc]; [long2015learning],76.9,92.43,76.9,0.92,83.2,0.77,ito:ITO_00101,Vision process,Accuracy
139,1,Domain Adaptation,MNIST-to-MNIST-M,2015-05,DANN [ganin2016domain],77.4,93.03,0.5,0.01,83.2,0.77,ito:ITO_00101,Vision process,Accuracy
140,1,Domain Adaptation,MNIST-to-MNIST-M,2016-08,DSN (DANN),83.2,100.0,5.8,0.07,83.2,0.83,ito:ITO_00101,Vision process,Accuracy
141,1,Domain Adaptation,ImageCLEF-DA,2015-02,DAN,76.9,85.16,76.9,0.85,90.3,0.77,ito:ITO_00101,Vision process,Accuracy
142,1,Domain Adaptation,ImageCLEF-DA,2018-11,IAFN+ENT,88.9,98.45,12.0,0.13,90.3,0.89,ito:ITO_00101,Vision process,Accuracy
143,1,Domain Adaptation,ImageCLEF-DA,2019-11,SPL,90.3,100.0,1.4,0.02,90.3,0.9,ito:ITO_00101,Vision process,Accuracy
144,1,Domain Adaptation,SVNH-to-MNIST,2015-02,MMD [tzeng2015ddc]; [long2015learning],71.1,71.88,71.1,0.72,98.91,0.71,ito:ITO_00101,Vision process,Accuracy
145,1,Domain Adaptation,SVNH-to-MNIST,2016-08,DSN (DANN),82.7,83.61,11.6,0.12,98.91,0.83,ito:ITO_00101,Vision process,Accuracy
146,1,Domain Adaptation,SVNH-to-MNIST,2019-03,rRevGrad+CAT,98.8,99.89,16.1,0.16,98.91,0.99,ito:ITO_00101,Vision process,Accuracy
147,1,Domain Adaptation,SVNH-to-MNIST,2019-05,SRDA (RAN),98.91,100.0,0.1,0.0,98.91,0.99,ito:ITO_00101,Vision process,Accuracy
148,1,Document Image Classification,RVL-CDIP,2015-02,Document section-based models + AlexNet transfer learning,89.8,95.11,89.8,0.95,94.42,0.9,ito:ITO_00101,Vision process,Accuracy
149,1,Document Image Classification,RVL-CDIP,2017-04,"Transfer Learning from AlexNet, VGG-16, GoogLeNet and ResNet50",90.97,96.35,1.2,0.01,94.42,0.91,ito:ITO_00101,Vision process,Accuracy
150,1,Document Image Classification,RVL-CDIP,2018-01,Transfer Learning from VGG16 trained on Imagenet,92.21,97.66,1.2,0.01,94.42,0.92,ito:ITO_00101,Vision process,Accuracy
151,1,Document Image Classification,RVL-CDIP,2019-12,Pre-trained LayoutLM,94.42,100.0,2.2,0.02,94.42,0.94,ito:ITO_00101,Vision process,Accuracy
152,1,Face Identification,MegaFace,2015-03,FaceNet,70.49,71.67,70.49,0.72,98.35,0.71,ito:ITO_00101,Vision process,Accuracy
153,1,Face Identification,MegaFace,2015-11,Light CNN-29,73.749,74.99,3.3,0.03,98.35,0.74,ito:ITO_00101,Vision process,Accuracy
154,1,Face Identification,MegaFace,2017-04,SphereFace (3-patch ensemble),75.766,77.04,2.0,0.02,98.35,0.76,ito:ITO_00101,Vision process,Accuracy
155,1,Face Identification,MegaFace,2018-01,ArcFace + MS1MV2 + R100 + R,98.35,100.0,22.6,0.23,98.35,0.98,ito:ITO_00101,Vision process,Accuracy
156,1,Face Verification,MegaFace,2015-03,FaceNet,86.47,86.57,86.47,0.87,99.88,0.86,ito:ITO_00101,Vision process,Accuracy
157,1,Face Verification,MegaFace,2017-04,SphereFace (3-patch ensemble),89.142,89.25,2.7,0.03,99.88,0.89,ito:ITO_00101,Vision process,Accuracy
158,1,Face Verification,MegaFace,2018-01,ArcFace + MS1MV2 + R100 + R,98.48,98.6,9.3,0.09,99.88,0.99,ito:ITO_00101,Vision process,Accuracy
159,1,Face Verification,MegaFace,2019-05,Dynamic AdaCos,99.88,100.0,1.4,0.01,99.88,1.0,ito:ITO_00101,Vision process,Accuracy
160,1,Disguised Face Verification,MegaFace,2015-03,FaceNet,86.47,100.0,86.47,1.0,86.47,0.86,ito:ITO_00101,Vision process,Accuracy
161,1,Facial Expression Recognition,JAFFE,2015-05,Salient Facial Patch,91.8,98.92,91.8,0.99,92.8,0.92,ito:ITO_00101,Vision process,Accuracy
162,1,Facial Expression Recognition,JAFFE,2019-02,DeepEmotion,92.8,100.0,1.0,0.01,92.8,0.93,ito:ITO_00101,Vision process,Accuracy
163,1,Synthetic-to-Real Translation,Syn2Real-C,2015-05,DANN,57.4,71.93,57.4,0.72,79.8,0.57,ito:ITO_00101,Vision process,Accuracy
164,1,Synthetic-to-Real Translation,Syn2Real-C,2017-11,ADR,74.8,93.73,17.4,0.22,79.8,0.75,ito:ITO_00101,Vision process,Accuracy
165,1,Synthetic-to-Real Translation,Syn2Real-C,2019-11,DADA,79.8,100.0,5.0,0.06,79.8,0.8,ito:ITO_00101,Vision process,Accuracy
166,1,Semi-Supervised Image Classification,"STL-10, 1000 Labels",2015-06,SWWAE,74.3,78.35,74.3,0.78,94.83,0.74,ito:ITO_00101,Vision process,Accuracy
167,1,Semi-Supervised Image Classification,"STL-10, 1000 Labels",2016-11,CC-GAN²,77.8,82.04,3.5,0.04,94.83,0.78,ito:ITO_00101,Vision process,Accuracy
168,1,Semi-Supervised Image Classification,"STL-10, 1000 Labels",2019-05,MixMatch,89.82,94.72,12.0,0.13,94.83,0.9,ito:ITO_00101,Vision process,Accuracy
169,1,Semi-Supervised Image Classification,"STL-10, 1000 Labels",2019-11,ReMixMatch,93.82,98.93,4.0,0.04,94.83,0.94,ito:ITO_00101,Vision process,Accuracy
170,1,Semi-Supervised Image Classification,"STL-10, 1000 Labels",2020-01,FixMatch (CTA),94.83,100.0,1.0,0.01,94.83,0.95,ito:ITO_00101,Vision process,Accuracy
171,1,Fine-Grained Image Classification,CompCars,2015-06,GoogLeNet,91.2,95.6,91.2,0.96,95.4,0.91,ito:ITO_00101,Vision process,Accuracy
172,1,Fine-Grained Image Classification,CompCars,2019-01,A3M,95.4,100.0,4.2,0.04,95.4,0.95,ito:ITO_00101,Vision process,Accuracy
173,1,Semi-Supervised Image Classification,"CIFAR-10, 4000 Labels",2015-07,Γ-model,79.6,83.07,79.6,0.83,95.82,0.8,ito:ITO_00101,Vision process,Accuracy
174,1,Semi-Supervised Image Classification,"CIFAR-10, 4000 Labels",2016-06,GAN,84.41,88.09,4.8,0.05,95.82,0.84,ito:ITO_00101,Vision process,Accuracy
175,1,Semi-Supervised Image Classification,"CIFAR-10, 4000 Labels",2016-10,Pi Model,87.84,91.67,3.4,0.04,95.82,0.88,ito:ITO_00101,Vision process,Accuracy
176,1,Semi-Supervised Image Classification,"CIFAR-10, 4000 Labels",2017-03,Mean Teacher,93.72,97.81,5.9,0.06,95.82,0.94,ito:ITO_00101,Vision process,Accuracy
177,1,Semi-Supervised Image Classification,"CIFAR-10, 4000 Labels",2018-06,SWSA,95.0,99.14,1.3,0.01,95.82,0.95,ito:ITO_00101,Vision process,Accuracy
178,1,Semi-Supervised Image Classification,"CIFAR-10, 4000 Labels",2019-11,EnAET,95.82,100.0,0.8,0.01,95.82,0.96,ito:ITO_00101,Vision process,Accuracy
179,1,One-Shot Learning,MNIST,2015-07,Siamese Neural Network,97.5,100.0,97.5,1.0,97.5,0.98,ito:ITO_00101,Vision process,Accuracy
180,1,Scene Text Recognition,ICDAR 2003,2015-07,CRNN,89.4,100.0,89.4,1.0,89.4,0.89,ito:ITO_00101,Vision process,Accuracy
181,1,Scene Text Recognition,ICDAR2013,2015-07,CRNN,86.7,100.0,86.7,1.0,86.7,0.87,ito:ITO_00101,Vision process,Accuracy
182,1,Scene Text Recognition,SVT,2015-07,CRNN,80.8,100.0,80.8,1.0,80.8,0.81,ito:ITO_00101,Vision process,Accuracy
183,1,Satellite Image Classification,SAT-4,2015-09,DeepSat,97.95,98.05,97.95,0.98,99.9,0.98,ito:ITO_00101,Vision process,Accuracy
184,1,Satellite Image Classification,SAT-4,2015-12,Contrastive loss,98.74,98.84,0.8,0.01,99.9,0.99,ito:ITO_00101,Vision process,Accuracy
185,1,Satellite Image Classification,SAT-4,2019-11,DeepSat V2,99.9,100.0,1.2,0.01,99.9,1.0,ito:ITO_00101,Vision process,Accuracy
186,1,Satellite Image Classification,SAT-6,2015-09,DeepSat,93.92,94.07,93.92,0.94,99.84,0.94,ito:ITO_00101,Vision process,Accuracy
187,1,Satellite Image Classification,SAT-6,2015-12,Contrastive loss,98.55,98.71,4.6,0.05,99.84,0.99,ito:ITO_00101,Vision process,Accuracy
188,1,Satellite Image Classification,SAT-6,2019-11,DeepSat V2,99.84,100.0,1.3,0.01,99.84,1.0,ito:ITO_00101,Vision process,Accuracy
189,1,Facial Expression Recognition,MMI,2015-09,DeXpression,98.63,100.0,98.63,1.0,98.63,0.99,ito:ITO_00101,Vision process,Accuracy
190,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2015-09,GCN-FP,61.5,82.0,61.5,0.82,75.0,0.62,ito:ITO_00101,Vision process,Accuracy
191,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2015-11,DCNN,69.4,92.53,7.9,0.11,75.0,0.69,ito:ITO_00101,Vision process,Accuracy
192,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2016-06,ChebyNet,70.1,93.47,0.7,0.01,75.0,0.7,ito:ITO_00101,Vision process,Accuracy
193,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2017-10,GAT,72.5,96.67,2.4,0.03,75.0,0.73,ito:ITO_00101,Vision process,Accuracy
194,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2019-02,H-GCN,72.8,97.07,0.3,0.0,75.0,0.73,ito:ITO_00101,Vision process,Accuracy
195,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2019-03,LDS-GNN,75.0,100.0,2.2,0.03,75.0,0.75,ito:ITO_00101,Vision process,Accuracy
196,1,Trajectory Forecasting,Trajectory Forecasting,2015-09,GCN-FP,61.5,82.0,61.5,0.82,75.0,0.62,ito:ITO_00101,Vision process,Accuracy
197,1,Trajectory Forecasting,Trajectory Forecasting,2015-11,DCNN,69.4,92.53,7.9,0.11,75.0,0.69,ito:ITO_00101,Vision process,Accuracy
198,1,Trajectory Forecasting,Trajectory Forecasting,2016-06,ChebyNet,70.1,93.47,0.7,0.01,75.0,0.7,ito:ITO_00101,Vision process,Accuracy
199,1,Trajectory Forecasting,Trajectory Forecasting,2017-10,GAT,72.5,96.67,2.4,0.03,75.0,0.73,ito:ITO_00101,Vision process,Accuracy
200,1,Trajectory Forecasting,Trajectory Forecasting,2019-02,H-GCN,72.8,97.07,0.3,0.0,75.0,0.73,ito:ITO_00101,Vision process,Accuracy
201,1,Trajectory Forecasting,Trajectory Forecasting,2019-03,LDS-GNN,75.0,100.0,2.2,0.03,75.0,0.75,ito:ITO_00101,Vision process,Accuracy
202,1,Speaker-Specific Lip to Speech Synthesis,Speaker-Specific Lip to Speech Synthesis,2015-09,GCN-FP,71.7,87.52,71.7,0.88,81.92,0.72,ito:ITO_00101,Vision process,Accuracy
203,1,Speaker-Specific Lip to Speech Synthesis,Speaker-Specific Lip to Speech Synthesis,2015-11,DCNN,76.7,93.63,5.0,0.06,81.92,0.77,ito:ITO_00101,Vision process,Accuracy
204,1,Speaker-Specific Lip to Speech Synthesis,Speaker-Specific Lip to Speech Synthesis,2019-01,AdaLanczosNet,77.7,94.85,1.0,0.01,81.92,0.78,ito:ITO_00101,Vision process,Accuracy
205,1,Speaker-Specific Lip to Speech Synthesis,Speaker-Specific Lip to Speech Synthesis,2019-06,Truncated Krylov,81.92,100.0,4.2,0.05,81.92,0.82,ito:ITO_00101,Vision process,Accuracy
206,1,Constrained Lip-synchronization,Constrained Lip-synchronization,2015-09,GCN-FP,70.3,91.05,70.3,0.91,77.21,0.7,ito:ITO_00101,Vision process,Accuracy
207,1,Constrained Lip-synchronization,Constrained Lip-synchronization,2015-11,DCNN,73.1,94.68,2.8,0.04,77.21,0.73,ito:ITO_00101,Vision process,Accuracy
208,1,Constrained Lip-synchronization,Constrained Lip-synchronization,2019-01,LanczosNet,73.4,95.07,0.3,0.0,77.21,0.73,ito:ITO_00101,Vision process,Accuracy
209,1,Constrained Lip-synchronization,Constrained Lip-synchronization,2019-06,Truncated Krylov,77.21,100.0,3.8,0.05,77.21,0.77,ito:ITO_00101,Vision process,Accuracy
210,1,Lip to Speech Synthesis,Lip to Speech Synthesis,2015-09,GCN-FP,54.3,78.66,54.3,0.79,69.03,0.54,ito:ITO_00101,Vision process,Accuracy
211,1,Lip to Speech Synthesis,Lip to Speech Synthesis,2015-11,DCNN,62.2,90.11,7.9,0.11,69.03,0.62,ito:ITO_00101,Vision process,Accuracy
212,1,Lip to Speech Synthesis,Lip to Speech Synthesis,2019-01,AdaLanczosNet,63.3,91.7,1.1,0.02,69.03,0.63,ito:ITO_00101,Vision process,Accuracy
213,1,Lip to Speech Synthesis,Lip to Speech Synthesis,2019-06,Truncated Krylov,69.03,100.0,5.7,0.08,69.03,0.69,ito:ITO_00101,Vision process,Accuracy
214,1,Micro-Expression Spotting,Micro-Expression Spotting,2015-09,GCN-FP,43.9,67.91,43.9,0.68,64.64,0.44,ito:ITO_00101,Vision process,Accuracy
215,1,Micro-Expression Spotting,Micro-Expression Spotting,2015-11,DCNN,53.1,82.15,9.2,0.14,64.64,0.53,ito:ITO_00101,Vision process,Accuracy
216,1,Micro-Expression Spotting,Micro-Expression Spotting,2019-01,AdaLanczosNet,53.8,83.23,0.7,0.01,64.64,0.54,ito:ITO_00101,Vision process,Accuracy
217,1,Micro-Expression Spotting,Micro-Expression Spotting,2019-06,Snowball (linear + tanh),61.99,95.9,8.2,0.13,64.64,0.62,ito:ITO_00101,Vision process,Accuracy
218,1,Micro-Expression Spotting,Micro-Expression Spotting,2019-06,Truncated Krylov,64.64,100.0,2.6,0.04,64.64,0.65,ito:ITO_00101,Vision process,Accuracy
219,1,Multimodal Activity Recognition,EV-Action,2015-11,WHDMM (Depth),40.2,50.19,40.2,0.5,80.1,0.4,ito:ITO_00101,Vision process,Accuracy
220,1,Multimodal Activity Recognition,EV-Action,2016-08,TSN (RGB),73.6,91.89,33.4,0.42,80.1,0.74,ito:ITO_00101,Vision process,Accuracy
221,1,Multimodal Activity Recognition,EV-Action,2017-04,TCN (Skeleton Kinect),80.1,100.0,6.5,0.08,80.1,0.8,ito:ITO_00101,Vision process,Accuracy
222,1,Visual Question Answering,VQA v1 test-std,2015-11,SAN (VGG),58.9,91.18,58.9,0.91,64.6,0.59,ito:ITO_00101,Vision process,Accuracy
223,1,Visual Question Answering,VQA v1 test-std,2016-03,DMN+,60.4,93.5,1.5,0.02,64.6,0.6,ito:ITO_00101,Vision process,Accuracy
224,1,Visual Question Answering,VQA v1 test-std,2016-05,HieCoAtt (ResNet),62.1,96.13,1.7,0.03,64.6,0.62,ito:ITO_00101,Vision process,Accuracy
225,1,Visual Question Answering,VQA v1 test-std,2016-06,RAU (ResNet),63.2,97.83,1.1,0.02,64.6,0.63,ito:ITO_00101,Vision process,Accuracy
226,1,Visual Question Answering,VQA v1 test-std,2017-04,SAAA (ResNet),64.6,100.0,1.4,0.02,64.6,0.65,ito:ITO_00101,Vision process,Accuracy
227,1,Visual Question Answering,VQA v1 test-dev,2015-11,NMN+LSTM+FT,58.6,90.85,58.6,0.91,64.5,0.59,ito:ITO_00101,Vision process,Accuracy
228,1,Visual Question Answering,VQA v1 test-dev,2016-03,DMN+,60.3,93.49,1.7,0.03,64.5,0.6,ito:ITO_00101,Vision process,Accuracy
229,1,Visual Question Answering,VQA v1 test-dev,2016-05,HieCoAtt (ResNet),61.8,95.81,1.5,0.02,64.5,0.62,ito:ITO_00101,Vision process,Accuracy
230,1,Visual Question Answering,VQA v1 test-dev,2016-06,MCB (ResNet),64.2,99.53,2.4,0.04,64.5,0.64,ito:ITO_00101,Vision process,Accuracy
231,1,Visual Question Answering,VQA v1 test-dev,2016-11,DAN (ResNet),64.3,99.69,0.1,0.0,64.5,0.64,ito:ITO_00101,Vision process,Accuracy
232,1,Visual Question Answering,VQA v1 test-dev,2017-04,SAAA (ResNet),64.5,100.0,0.2,0.0,64.5,0.65,ito:ITO_00101,Vision process,Accuracy
233,1,Age-Invariant Face Recognition,CAFR,2015-11,Light CNN,73.56,86.74,73.56,0.87,84.81,0.74,ito:ITO_00101,Vision process,Accuracy
234,1,Age-Invariant Face Recognition,CAFR,2018-09,AIM,84.81,100.0,11.2,0.13,84.81,0.85,ito:ITO_00101,Vision process,Accuracy
235,1,Age-Invariant Face Recognition,CACDVS,2015-11,MFM-CNN,97.95,98.19,97.95,0.98,99.76,0.98,ito:ITO_00101,Vision process,Accuracy
236,1,Age-Invariant Face Recognition,CACDVS,2017-03,DeepVisage,99.13,99.37,1.2,0.01,99.76,0.99,ito:ITO_00101,Vision process,Accuracy
237,1,Age-Invariant Face Recognition,CACDVS,2018-09,AIM + CAFR,99.76,100.0,0.6,0.01,99.76,1.0,ito:ITO_00101,Vision process,Accuracy
238,1,Group Activity Recognition,Collective Activity,2015-11,Deng et al.,81.2,89.23,81.2,0.89,91.0,0.81,ito:ITO_00101,Vision process,Accuracy
239,1,Group Activity Recognition,Collective Activity,2018-11,H-LSTCM,83.75,92.03,2.5,0.03,91.0,0.84,ito:ITO_00101,Vision process,Accuracy
240,1,Group Activity Recognition,Collective Activity,2019-04,GT (Inception-v3),91.0,100.0,7.2,0.08,91.0,0.91,ito:ITO_00101,Vision process,Accuracy
241,1,Unsupervised Image Classification,MNIST,2015-11,Adversarial AE,95.9,96.58,95.9,0.97,99.3,0.96,ito:ITO_00101,Vision process,Accuracy
242,1,Unsupervised Image Classification,MNIST,2018-02,ACOL + GAR + k-means,98.32,99.01,2.4,0.02,99.3,0.98,ito:ITO_00101,Vision process,Accuracy
243,1,Unsupervised Image Classification,MNIST,2019-03,IIC,99.3,100.0,1.0,0.01,99.3,0.99,ito:ITO_00101,Vision process,Accuracy
244,1,Image Clustering,CMU-PIE,2015-11,DEC (KL based),0.801,88.8,0.801,0.89,0.902,0.01,ito:ITO_00101,Vision process,Accuracy
245,1,Image Clustering,CMU-PIE,2017-04,DEPICT,0.85,94.24,0.0,0.0,0.902,0.01,ito:ITO_00101,Vision process,Accuracy
246,1,Image Clustering,CMU-PIE,2018-10,SR-K-means,0.902,100.0,0.1,0.11,0.902,0.01,ito:ITO_00101,Vision process,Accuracy
247,1,Image Clustering,YouTube Faces DB,2015-11,DEC (KL based),0.371,60.72,0.371,0.61,0.611,0.0,ito:ITO_00101,Vision process,Accuracy
248,1,Image Clustering,YouTube Faces DB,2017-04,DEPICT,0.611,100.0,0.2,0.33,0.611,0.01,ito:ITO_00101,Vision process,Accuracy
249,1,Aesthetics Quality Assessment,AVA,2015-12,DMA-Net,75.4,90.84,75.4,0.91,83.0,0.75,ito:ITO_00101,Vision process,Accuracy
250,1,Aesthetics Quality Assessment,AVA,2016-04,MTRLCNN,79.1,95.3,3.7,0.04,83.0,0.79,ito:ITO_00101,Vision process,Accuracy
251,1,Aesthetics Quality Assessment,AVA,2017-04,A-Lamp,82.5,99.4,3.4,0.04,83.0,0.83,ito:ITO_00101,Vision process,Accuracy
252,1,Aesthetics Quality Assessment,AVA,2018-10,MP_{ada},83.0,100.0,0.5,0.01,83.0,0.83,ito:ITO_00101,Vision process,Accuracy
253,1,Visual Object Tracking,TrackingNet,2015-12,STAPLE_CA,53.59,72.42,53.59,0.72,74.0,0.54,ito:ITO_00101,Vision process,Accuracy
254,1,Visual Object Tracking,TrackingNet,2016-11,ECO,56.13,75.85,2.5,0.03,74.0,0.56,ito:ITO_00101,Vision process,Accuracy
255,1,Visual Object Tracking,TrackingNet,2018-11,ATOM,70.34,95.05,14.2,0.19,74.0,0.7,ito:ITO_00101,Vision process,Accuracy
256,1,Visual Object Tracking,TrackingNet,2018-12,SiamRPN++,73.3,99.05,3.0,0.04,74.0,0.73,ito:ITO_00101,Vision process,Accuracy
257,1,Visual Object Tracking,TrackingNet,2019-04,DiMP-50,74.0,100.0,0.7,0.01,74.0,0.74,ito:ITO_00101,Vision process,Accuracy
258,1,Fine-Grained Image Classification,Stanford Dogs,2015-12,ResNet-101,70.4,76.44,70.4,0.76,92.1,0.7,ito:ITO_00101,Vision process,Accuracy
259,1,Fine-Grained Image Classification,Stanford Dogs,2016-08,Inception V3,71.2,77.31,0.8,0.01,92.1,0.71,ito:ITO_00101,Vision process,Accuracy
260,1,Fine-Grained Image Classification,Stanford Dogs,2017-05,PC-DenseNet-161,83.75,90.93,12.5,0.14,92.1,0.84,ito:ITO_00101,Vision process,Accuracy
261,1,Fine-Grained Image Classification,Stanford Dogs,2019-01,WS-DAN,92.1,100.0,8.3,0.09,92.1,0.92,ito:ITO_00101,Vision process,Accuracy
262,1,Fine-Grained Image Classification,Stanford Cars,2015-12,ResNet-101,91.2,94.8,91.2,0.95,96.2,0.91,ito:ITO_00101,Vision process,Accuracy
263,1,Fine-Grained Image Classification,Stanford Cars,2016-11,DFL-CNN,93.8,97.51,2.6,0.03,96.2,0.94,ito:ITO_00101,Vision process,Accuracy
264,1,Fine-Grained Image Classification,Stanford Cars,2018-05,AutoAugment,94.8,98.54,1.0,0.01,96.2,0.95,ito:ITO_00101,Vision process,Accuracy
265,1,Fine-Grained Image Classification,Stanford Cars,2018-11,DAT,96.2,100.0,1.4,0.01,96.2,0.96,ito:ITO_00101,Vision process,Accuracy
266,1,Smile Recognition,DISFA,2016-01,Deep CNN,99.45,100.0,99.45,1.0,99.45,0.99,ito:ITO_00101,Vision process,Accuracy
267,1,Few-Shot Image Classification,AWA,2016-03,Synthesised Classifier,72.9,100.0,72.9,1.0,72.9,0.73,ito:ITO_00101,Vision process,Accuracy
268,1,Few-Shot Image Classification,SUN,2016-03,Synthesised Classifier,62.7,100.0,62.7,1.0,62.7,0.63,ito:ITO_00101,Vision process,Accuracy
269,1,Image Classification,Kuzushiji-MNIST,2016-03,PreActResNet-18,97.82,98.8,97.82,0.99,99.01,0.98,ito:ITO_00101,Vision process,Accuracy
270,1,Image Classification,Kuzushiji-MNIST,2017-10,PreActResNet-18 + Input Mixup,98.41,99.39,0.6,0.01,99.01,0.98,ito:ITO_00101,Vision process,Accuracy
271,1,Image Classification,Kuzushiji-MNIST,2019-01,VGG8B(2x) + LocalLearning + CO,99.01,100.0,0.6,0.01,99.01,0.99,ito:ITO_00101,Vision process,Accuracy
272,1,Face Verification,Trillion Pairs Dataset,2016-04,HM-Softmax,34.46,47.39,34.46,0.47,72.71,0.34,ito:ITO_00101,Vision process,Accuracy
273,1,Face Verification,Trillion Pairs Dataset,2017-04,A-Softmax,43.76,60.18,9.3,0.13,72.71,0.44,ito:ITO_00101,Vision process,Accuracy
274,1,Face Verification,Trillion Pairs Dataset,2018-01,AM-Softmax,61.61,84.73,17.8,0.24,72.71,0.62,ito:ITO_00101,Vision process,Accuracy
275,1,Face Verification,Trillion Pairs Dataset,2018-12,SV-AM-Softmax,72.71,100.0,11.1,0.15,72.71,0.73,ito:ITO_00101,Vision process,Accuracy
276,1,Face Identification,Trillion Pairs Dataset,2016-04,HM-Softmax,36.75,49.96,36.75,0.5,73.56,0.37,ito:ITO_00101,Vision process,Accuracy
277,1,Face Identification,Trillion Pairs Dataset,2017-04,A-Softmax,43.89,59.67,7.1,0.1,73.56,0.44,ito:ITO_00101,Vision process,Accuracy
278,1,Face Identification,Trillion Pairs Dataset,2018-01,AM-Softmax,61.8,84.01,17.9,0.24,73.56,0.62,ito:ITO_00101,Vision process,Accuracy
279,1,Face Identification,Trillion Pairs Dataset,2018-12,SV-AM-Softmax,73.56,100.0,11.8,0.16,73.56,0.74,ito:ITO_00101,Vision process,Accuracy
280,1,3D Object Recognition,ModelNet40,2016-04,MVCNN-MultiRes,93.8,100.0,93.8,1.0,93.8,0.94,ito:ITO_00101,Vision process,Accuracy
281,1,3D Object Classification,ModelNet10,2016-04,ORION,93.8,100.0,93.8,1.0,93.8,0.94,ito:ITO_00101,Vision process,Accuracy
282,1,Image Clustering,Stanford Cars,2016-04,JULE,0.046,58.97,0.046,0.59,0.078,0.0,ito:ITO_00101,Vision process,Accuracy
283,1,Image Clustering,Stanford Cars,2017-04,DEPICT,0.063,80.77,0.0,0.0,0.078,0.0,ito:ITO_00101,Vision process,Accuracy
284,1,Image Clustering,Stanford Cars,2018-11,FineGAN,0.078,100.0,0.0,0.0,0.078,0.0,ito:ITO_00101,Vision process,Accuracy
285,1,Image Clustering,CUB Birds,2016-04,JULE,0.044,34.92,0.044,0.35,0.126,0.0,ito:ITO_00101,Vision process,Accuracy
286,1,Image Clustering,CUB Birds,2017-04,DEPICT-Large,0.061,48.41,0.0,0.0,0.126,0.0,ito:ITO_00101,Vision process,Accuracy
287,1,Image Clustering,CUB Birds,2018-11,FineGAN,0.126,100.0,0.1,0.79,0.126,0.0,ito:ITO_00101,Vision process,Accuracy
288,1,Image Clustering,Stanford Dogs,2016-04,JULE,0.043,54.43,0.043,0.54,0.079,0.0,ito:ITO_00101,Vision process,Accuracy
289,1,Image Clustering,Stanford Dogs,2017-04,DEPICT-Large,0.054,68.35,0.0,0.0,0.079,0.0,ito:ITO_00101,Vision process,Accuracy
290,1,Image Clustering,Stanford Dogs,2018-11,FineGAN,0.079,100.0,0.0,0.0,0.079,0.0,ito:ITO_00101,Vision process,Accuracy
291,1,Few-Shot Image Classification,Flowers-102,2016-05,Word CNN-RNN (DS-SJE Embedding),65.6,100.0,65.6,1.0,65.6,0.66,ito:ITO_00101,Vision process,Accuracy
292,1,Domain Adaptation,VisDA2017,2016-05,JAN,58.3,66.86,58.3,0.67,87.2,0.58,ito:ITO_00101,Vision process,Accuracy
293,1,Domain Adaptation,VisDA2017,2017-05,CDAN,73.7,84.52,15.4,0.18,87.2,0.74,ito:ITO_00101,Vision process,Accuracy
294,1,Domain Adaptation,VisDA2017,2018-11,IAFN,76.1,87.27,2.4,0.03,87.2,0.76,ito:ITO_00101,Vision process,Accuracy
295,1,Domain Adaptation,VisDA2017,2019-01,Contrastive Adaptation Network,87.2,100.0,11.1,0.13,87.2,0.87,ito:ITO_00101,Vision process,Accuracy
296,1,Video Classification,COIN,2016-05,Ours (temporal filters),68.4,100.0,68.4,1.0,68.4,0.68,ito:ITO_00101,Vision process,Accuracy
297,1,Visual Question Answering,VQA v2 test-dev,2016-06,MCB,64.7,88.34,64.7,0.88,73.24,0.65,ito:ITO_00101,Vision process,Accuracy
298,1,Visual Question Answering,VQA v2 test-dev,2017-04,"N2NMN (ResNet-152, policy search)",64.9,88.61,0.2,0.0,73.24,0.65,ito:ITO_00101,Vision process,Accuracy
299,1,Visual Question Answering,VQA v2 test-dev,2017-05,MUTAN,67.42,92.05,2.5,0.03,73.24,0.67,ito:ITO_00101,Vision process,Accuracy
300,1,Visual Question Answering,VQA v2 test-dev,2017-08,"Image features from bottom-up attention (adaptive K, ensemble)",69.87,95.4,2.5,0.03,73.24,0.7,ito:ITO_00101,Vision process,Accuracy
301,1,Visual Question Answering,VQA v2 test-dev,2018-05,BAN+Glove+Counter,70.04,95.63,0.2,0.0,73.24,0.7,ito:ITO_00101,Vision process,Accuracy
302,1,Visual Question Answering,VQA v2 test-dev,2019-06,MCANed-6,70.63,96.44,0.6,0.01,73.24,0.71,ito:ITO_00101,Vision process,Accuracy
303,1,Visual Question Answering,VQA v2 test-dev,2019-08,VisualBERT,70.8,96.67,0.2,0.0,73.24,0.71,ito:ITO_00101,Vision process,Accuracy
304,1,Visual Question Answering,VQA v2 test-dev,2019-08,VL-BERTBASE,71.16,97.16,0.4,0.01,73.24,0.71,ito:ITO_00101,Vision process,Accuracy
305,1,Visual Question Answering,VQA v2 test-dev,2019-08,VL-BERTLARGE,71.79,98.02,0.6,0.01,73.24,0.72,ito:ITO_00101,Vision process,Accuracy
306,1,Visual Question Answering,VQA v2 test-dev,2019-09,UNITER (Large),73.24,100.0,1.4,0.02,73.24,0.73,ito:ITO_00101,Vision process,Accuracy
307,1,Phrase Grounding,Flickr30k Entities Test,2016-06,MCB,48.69,100.0,48.69,1.0,48.69,0.49,ito:ITO_00101,Vision process,Accuracy
308,1,Phrase Grounding,ReferIt,2016-06,MCB,28.91,100.0,28.91,1.0,28.91,0.29,ito:ITO_00101,Vision process,Accuracy
309,1,Few-Shot Image Classification,OMNIGLOT,2016-06,Neural Statistician,98.1,98.13,98.1,0.98,99.97,0.98,ito:ITO_00101,Vision process,Accuracy
310,1,Few-Shot Image Classification,OMNIGLOT,2017-03,ConvNet with Memory Module,98.4,98.43,0.3,0.0,99.97,0.98,ito:ITO_00101,Vision process,Accuracy
311,1,Few-Shot Image Classification,OMNIGLOT,2017-03,MAML,98.7,98.73,0.3,0.0,99.97,0.99,ito:ITO_00101,Vision process,Accuracy
312,1,Few-Shot Image Classification,OMNIGLOT,2017-03,Prototypical Networks,98.8,98.83,0.1,0.0,99.97,0.99,ito:ITO_00101,Vision process,Accuracy
313,1,Few-Shot Image Classification,OMNIGLOT,2017-11,Relation Net,99.6,99.63,0.8,0.01,99.97,1.0,ito:ITO_00101,Vision process,Accuracy
314,1,Few-Shot Image Classification,OMNIGLOT,2019-02,MC2+,99.97,100.0,0.4,0.0,99.97,1.0,ito:ITO_00101,Vision process,Accuracy
315,1,Few-Shot Image Classification,OMNIGLOT,2016-06,Neural Statistician,99.5,99.58,99.5,1.0,99.92,1.0,ito:ITO_00101,Vision process,Accuracy
316,1,Few-Shot Image Classification,OMNIGLOT,2017-03,ConvNet with Memory Module,99.6,99.68,0.1,0.0,99.92,1.0,ito:ITO_00101,Vision process,Accuracy
317,1,Few-Shot Image Classification,OMNIGLOT,2017-03,MAML,99.9,99.98,0.3,0.0,99.92,1.0,ito:ITO_00101,Vision process,Accuracy
318,1,Few-Shot Image Classification,OMNIGLOT,2019-08,DCN6-E,99.92,100.0,0.0,0.0,99.92,1.0,ito:ITO_00101,Vision process,Accuracy
319,1,Few-Shot Image Classification,OMNIGLOT,2016-06,Neural Statistician,93.2,93.55,93.2,0.94,99.63,0.93,ito:ITO_00101,Vision process,Accuracy
320,1,Few-Shot Image Classification,OMNIGLOT,2016-06,Matching Nets,93.8,94.15,0.6,0.01,99.63,0.94,ito:ITO_00101,Vision process,Accuracy
321,1,Few-Shot Image Classification,OMNIGLOT,2017-03,ConvNet with Memory Module,95.0,95.35,1.2,0.01,99.63,0.95,ito:ITO_00101,Vision process,Accuracy
322,1,Few-Shot Image Classification,OMNIGLOT,2017-03,Prototypical Networks,96.0,96.36,1.0,0.01,99.63,0.96,ito:ITO_00101,Vision process,Accuracy
323,1,Few-Shot Image Classification,OMNIGLOT,2017-11,Relation Net,97.6,97.96,1.6,0.02,99.63,0.98,ito:ITO_00101,Vision process,Accuracy
324,1,Few-Shot Image Classification,OMNIGLOT,2018-10,MAML++,97.65,98.01,0.1,0.0,99.63,0.98,ito:ITO_00101,Vision process,Accuracy
325,1,Few-Shot Image Classification,OMNIGLOT,2019-05,TapNet,98.07,98.43,0.4,0.0,99.63,0.98,ito:ITO_00101,Vision process,Accuracy
326,1,Few-Shot Image Classification,OMNIGLOT,2019-08,GCR,99.63,100.0,1.6,0.02,99.63,1.0,ito:ITO_00101,Vision process,Accuracy
327,1,Few-Shot Image Classification,OMNIGLOT,2016-06,Neural Statistician,98.1,98.44,98.1,0.98,99.65,0.98,ito:ITO_00101,Vision process,Accuracy
328,1,Few-Shot Image Classification,OMNIGLOT,2016-06,Matching Nets,98.5,98.85,0.4,0.0,99.65,0.99,ito:ITO_00101,Vision process,Accuracy
329,1,Few-Shot Image Classification,OMNIGLOT,2017-03,ConvNet with Memory Module,98.6,98.95,0.1,0.0,99.65,0.99,ito:ITO_00101,Vision process,Accuracy
330,1,Few-Shot Image Classification,OMNIGLOT,2017-03,Prototypical Networks,98.9,99.25,0.3,0.0,99.65,0.99,ito:ITO_00101,Vision process,Accuracy
331,1,Few-Shot Image Classification,OMNIGLOT,2017-11,Relation Net,99.1,99.45,0.2,0.0,99.65,0.99,ito:ITO_00101,Vision process,Accuracy
332,1,Few-Shot Image Classification,OMNIGLOT,2018-10,MAML++,99.33,99.68,0.2,0.0,99.65,0.99,ito:ITO_00101,Vision process,Accuracy
333,1,Few-Shot Image Classification,OMNIGLOT,2019-02,MC2+,99.65,100.0,0.3,0.0,99.65,1.0,ito:ITO_00101,Vision process,Accuracy
334,1,Semi-Supervised Image Classification,"SVHN, 1000 labels",2016-06,GAN,91.89,94.11,91.89,0.94,97.64,0.92,ito:ITO_00101,Vision process,Accuracy
335,1,Semi-Supervised Image Classification,"SVHN, 1000 labels",2016-10,Pi Model,95.58,97.89,3.7,0.04,97.64,0.96,ito:ITO_00101,Vision process,Accuracy
336,1,Semi-Supervised Image Classification,"SVHN, 1000 labels",2017-03,Mean Teacher,96.05,98.37,0.5,0.01,97.64,0.96,ito:ITO_00101,Vision process,Accuracy
337,1,Semi-Supervised Image Classification,"SVHN, 1000 labels",2017-04,VAT+EntMin,96.14,98.46,0.1,0.0,97.64,0.96,ito:ITO_00101,Vision process,Accuracy
338,1,Semi-Supervised Image Classification,"SVHN, 1000 labels",2019-04,UDA,97.54,99.9,1.4,0.01,97.64,0.98,ito:ITO_00101,Vision process,Accuracy
339,1,Semi-Supervised Image Classification,"SVHN, 1000 labels",2019-11,EnAET,97.58,99.94,0.0,0.0,97.64,0.98,ito:ITO_00101,Vision process,Accuracy
340,1,Semi-Supervised Image Classification,"SVHN, 1000 labels",2020-01,FixMatch (CTA),97.64,100.0,0.1,0.0,97.64,0.98,ito:ITO_00101,Vision process,Accuracy
341,1,Few-Shot Image Classification,Meta-Dataset,2016-06,Matching Networks,56.247,92.86,56.247,0.93,60.573,0.56,ito:ITO_00101,Vision process,Accuracy
342,1,Few-Shot Image Classification,Meta-Dataset,2017-03,fo-MAML,57.024,94.14,0.8,0.01,60.573,0.57,ito:ITO_00101,Vision process,Accuracy
343,1,Few-Shot Image Classification,Meta-Dataset,2017-03,Prototypical Networks,60.573,100.0,3.5,0.06,60.573,0.61,ito:ITO_00101,Vision process,Accuracy
344,1,Semi-Supervised Image Classification,"cifar-100, 10000 Labels",2016-06,Ⅱ-Model,60.81,78.89,60.81,0.79,77.08,0.61,ito:ITO_00101,Vision process,Accuracy
345,1,Semi-Supervised Image Classification,"cifar-100, 10000 Labels",2016-10,Temporal ensembling,61.35,79.59,0.5,0.01,77.08,0.61,ito:ITO_00101,Vision process,Accuracy
346,1,Semi-Supervised Image Classification,"cifar-100, 10000 Labels",2019-09,Dual Student (480),67.23,87.22,5.9,0.08,77.08,0.67,ito:ITO_00101,Vision process,Accuracy
347,1,Semi-Supervised Image Classification,"cifar-100, 10000 Labels",2019-11,EnAET,77.08,100.0,9.8,0.13,77.08,0.77,ito:ITO_00101,Vision process,Accuracy
348,1,Semi-Supervised Image Classification,"SVHN, 250 Labels",2016-06,Ⅱ-model,82.35,85.08,82.35,0.85,96.79,0.82,ito:ITO_00101,Vision process,Accuracy
349,1,Semi-Supervised Image Classification,"SVHN, 250 Labels",2017-03,MeanTeacher,93.55,96.65,11.2,0.12,96.79,0.94,ito:ITO_00101,Vision process,Accuracy
350,1,Semi-Supervised Image Classification,"SVHN, 250 Labels",2019-05,MixMatch,96.22,99.41,2.7,0.03,96.79,0.96,ito:ITO_00101,Vision process,Accuracy
351,1,Semi-Supervised Image Classification,"SVHN, 250 Labels",2019-11,EnAET,96.79,100.0,0.6,0.01,96.79,0.97,ito:ITO_00101,Vision process,Accuracy
352,1,Surgical Skills Evaluation,JIGSAWS,2016-06,Bidir. LSTM,0.833,85.0,0.833,0.85,0.98,0.01,ito:ITO_00101,Vision process,Accuracy
353,1,Surgical Skills Evaluation,JIGSAWS,2018-06,CNN,0.98,100.0,0.1,0.1,0.98,0.01,ito:ITO_00101,Vision process,Accuracy
354,1,Zero-Shot Text-to-Image Generation,Zero-Shot Text-to-Image Generation,2016-06,Bidir. LSTM,0.833,85.0,0.833,0.85,0.98,0.01,ito:ITO_00101,Vision process,Accuracy
355,1,Zero-Shot Text-to-Image Generation,Zero-Shot Text-to-Image Generation,2018-06,CNN,0.98,100.0,0.1,0.1,0.98,0.01,ito:ITO_00101,Vision process,Accuracy
356,1,Surgical Skills Evaluation,MISTIC-SIL,2016-06,Bidir. LSTM,0.895,100.0,0.895,1.0,0.895,0.01,ito:ITO_00101,Vision process,Accuracy
357,1,Handwritten Word Generation,Handwritten Word Generation,2016-06,Bidir. LSTM,0.895,100.0,0.895,1.0,0.895,0.01,ito:ITO_00101,Vision process,Accuracy
358,1,Skeleton Based Action Recognition,SBU,2016-06,ChebyNet,96.0,96.95,96.0,0.97,99.02,0.96,ito:ITO_00101,Vision process,Accuracy
359,1,Skeleton Based Action Recognition,SBU,2017-03,Joint Line Distance,99.02,100.0,3.0,0.03,99.02,0.99,ito:ITO_00101,Vision process,Accuracy
360,1,Facial Expression Recognition,FERPlus,2016-08,*,85.1,95.45,85.1,0.95,89.16,0.85,ito:ITO_00101,Vision process,Accuracy
361,1,Facial Expression Recognition,FERPlus,2018-08,*,88.8,99.6,3.7,0.04,89.16,0.89,ito:ITO_00101,Vision process,Accuracy
362,1,Facial Expression Recognition,FERPlus,2019-05,RAN (VGG-16),89.16,100.0,0.4,0.0,89.16,0.89,ito:ITO_00101,Vision process,Accuracy
363,1,Node Classification,Europe Air-Traffic,2016-09,"GCN_cheby (Kipf and Welling, 2017)",46.0,100.0,46.0,1.0,46.0,0.46,ito:ITO_00101,Vision process,Accuracy
364,1,Stereo-LiDAR Fusion,Stereo-LiDAR Fusion,2016-09,"GCN_cheby (Kipf and Welling, 2017)",46.0,100.0,46.0,1.0,46.0,0.46,ito:ITO_00101,Vision process,Accuracy
365,1,Node Classification,Wiki-Vote,2016-09,"GCN (Kipf and Welling, 2017)",32.9,32.97,32.9,0.33,99.8,0.33,ito:ITO_00101,Vision process,Accuracy
366,1,Node Classification,Wiki-Vote,2016-09,"GCN_cheby (Kipf and Welling, 2017)",49.5,49.6,16.6,0.17,99.8,0.5,ito:ITO_00101,Vision process,Accuracy
367,1,Node Classification,Wiki-Vote,2017-10,"GAT (Velickovic et al., 2018)",59.4,59.52,9.9,0.1,99.8,0.59,ito:ITO_00101,Vision process,Accuracy
368,1,Node Classification,Wiki-Vote,2019-06,DEMO-Net(weight),99.8,100.0,40.4,0.4,99.8,1.0,ito:ITO_00101,Vision process,Accuracy
369,1,Transparent Object Depth Estimation,Transparent Object Depth Estimation,2016-09,"GCN_cheby (Kipf and Welling, 2017)",49.5,49.6,49.5,0.5,99.8,0.5,ito:ITO_00101,Vision process,Accuracy
370,1,Transparent Object Depth Estimation,Transparent Object Depth Estimation,2017-10,"GAT (Velickovic et al., 2018)",59.4,59.52,9.9,0.1,99.8,0.59,ito:ITO_00101,Vision process,Accuracy
371,1,Transparent Object Depth Estimation,Transparent Object Depth Estimation,2019-06,DEMO-Net(weight),99.8,100.0,40.4,0.4,99.8,1.0,ito:ITO_00101,Vision process,Accuracy
372,1,Facial Expression Recognition,Static Facial Expressions in the Wild,2016-10,VGG-VD-16,54.82,94.29,54.82,0.94,58.14,0.55,ito:ITO_00101,Vision process,Accuracy
373,1,Facial Expression Recognition,Static Facial Expressions in the Wild,2018-05,Covariance Pooling,58.14,100.0,3.3,0.06,58.14,0.58,ito:ITO_00101,Vision process,Accuracy
374,1,Semi-Supervised Image Classification,"CIFAR-10, 250 Labels",2016-10,Ⅱ-Model,46.88,49.38,46.88,0.49,94.93,0.47,ito:ITO_00101,Vision process,Accuracy
375,1,Semi-Supervised Image Classification,"CIFAR-10, 250 Labels",2017-03,MeanTeacher,52.68,55.49,5.8,0.06,94.93,0.53,ito:ITO_00101,Vision process,Accuracy
376,1,Semi-Supervised Image Classification,"CIFAR-10, 250 Labels",2017-04,VAT,63.97,67.39,11.3,0.12,94.93,0.64,ito:ITO_00101,Vision process,Accuracy
377,1,Semi-Supervised Image Classification,"CIFAR-10, 250 Labels",2019-05,MixMatch,88.92,93.67,25.0,0.26,94.93,0.89,ito:ITO_00101,Vision process,Accuracy
378,1,Semi-Supervised Image Classification,"CIFAR-10, 250 Labels",2019-11,ReMixMatch,93.73,98.74,4.8,0.05,94.93,0.94,ito:ITO_00101,Vision process,Accuracy
379,1,Semi-Supervised Image Classification,"CIFAR-10, 250 Labels",2020-01,FixMatch,94.93,100.0,1.2,0.01,94.93,0.95,ito:ITO_00101,Vision process,Accuracy
380,1,Action Recognition,Volleyball,2016-11,GTT (VGG19),82.6,100.0,82.6,1.0,82.6,0.83,ito:ITO_00101,Vision process,Accuracy
381,1,Action Recognition In Videos,Volleyball,2016-11,SSU (GT),81.8,99.03,81.8,0.99,82.6,0.82,ito:ITO_00101,Vision process,Accuracy
382,1,Action Recognition In Videos,Volleyball,2019-04,GTT (VGG19),82.6,100.0,0.8,0.01,82.6,0.83,ito:ITO_00101,Vision process,Accuracy
383,1,Fine-Grained Image Classification,FGVC Aircraft,2016-11,DFB-CNN,92.0,97.35,92.0,0.97,94.5,0.92,ito:ITO_00101,Vision process,Accuracy
384,1,Fine-Grained Image Classification,FGVC Aircraft,2018-05,AutoAugment,92.67,98.06,0.7,0.01,94.5,0.93,ito:ITO_00101,Vision process,Accuracy
385,1,Fine-Grained Image Classification,FGVC Aircraft,2019-01,WS-DAN,93.0,98.41,0.3,0.0,94.5,0.93,ito:ITO_00101,Vision process,Accuracy
386,1,Fine-Grained Image Classification,FGVC Aircraft,2019-10,BCN,93.5,98.94,0.5,0.01,94.5,0.94,ito:ITO_00101,Vision process,Accuracy
387,1,Fine-Grained Image Classification,FGVC Aircraft,2020-02,API-Net,93.9,99.37,0.4,0.0,94.5,0.94,ito:ITO_00101,Vision process,Accuracy
388,1,Fine-Grained Image Classification,FGVC Aircraft,2020-03,TBMSL-Net,94.5,100.0,0.6,0.01,94.5,0.95,ito:ITO_00101,Vision process,Accuracy
389,1,Visual Question Answering,VQA v2 test-std,2016-12,"MCB [11, 12]",62.27,84.84,62.27,0.85,73.4,0.62,ito:ITO_00101,Vision process,Accuracy
390,1,Visual Question Answering,VQA v2 test-std,2017-05,MUTAN,67.4,91.83,5.1,0.07,73.4,0.67,ito:ITO_00101,Vision process,Accuracy
391,1,Visual Question Answering,VQA v2 test-std,2017-07,Up-Down,70.34,95.83,2.9,0.04,73.4,0.7,ito:ITO_00101,Vision process,Accuracy
392,1,Visual Question Answering,VQA v2 test-std,2018-05,BAN+Glove+Counter,70.4,95.91,0.1,0.0,73.4,0.7,ito:ITO_00101,Vision process,Accuracy
393,1,Visual Question Answering,VQA v2 test-std,2019-06,MCANed-6,70.9,96.59,0.5,0.01,73.4,0.71,ito:ITO_00101,Vision process,Accuracy
394,1,Visual Question Answering,VQA v2 test-std,2019-08,VisualBERT,71.0,96.73,0.1,0.0,73.4,0.71,ito:ITO_00101,Vision process,Accuracy
395,1,Visual Question Answering,VQA v2 test-std,2019-08,LXMERT,72.5,98.77,1.5,0.02,73.4,0.73,ito:ITO_00101,Vision process,Accuracy
396,1,Visual Question Answering,VQA v2 test-std,2019-09,UNITER (Large),73.4,100.0,0.9,0.01,73.4,0.73,ito:ITO_00101,Vision process,Accuracy
397,1,Visual Question Answering,VQA v2,2016-12,MCB,62.27,84.35,62.27,0.84,73.82,0.62,ito:ITO_00101,Vision process,Accuracy
398,1,Visual Question Answering,VQA v2,2018-07,Pythia v0.1,70.24,95.15,8.0,0.11,73.82,0.7,ito:ITO_00101,Vision process,Accuracy
399,1,Visual Question Answering,VQA v2,2019-06,DFAF,70.34,95.29,0.1,0.0,73.82,0.7,ito:ITO_00101,Vision process,Accuracy
400,1,Visual Question Answering,VQA v2,2020-04,Oscar,73.82,100.0,3.5,0.05,73.82,0.74,ito:ITO_00101,Vision process,Accuracy
401,1,Skeleton Based Action Recognition,SYSU 3D,2016-12,Dynamic Skeletons,75.5,86.88,75.5,0.87,86.9,0.76,ito:ITO_00101,Vision process,Accuracy
402,1,Skeleton Based Action Recognition,SYSU 3D,2017-03,VA-LSTM,77.5,89.18,2.0,0.02,86.9,0.78,ito:ITO_00101,Vision process,Accuracy
403,1,Skeleton Based Action Recognition,SYSU 3D,2018-04,VA-fusion (aug.),86.7,99.77,9.2,0.11,86.9,0.87,ito:ITO_00101,Vision process,Accuracy
404,1,Skeleton Based Action Recognition,SYSU 3D,2019-04,SGN,86.9,100.0,0.2,0.0,86.9,0.87,ito:ITO_00101,Vision process,Accuracy
405,1,Hand Gesture Recognition,ChaLearn val,2017-01,Wang et al.,39.23,68.34,39.23,0.68,57.4,0.39,ito:ITO_00101,Vision process,Accuracy
406,1,Hand Gesture Recognition,ChaLearn val,2018-04,8-MFFs-3f1c (5 crop),57.4,100.0,18.2,0.32,57.4,0.57,ito:ITO_00101,Vision process,Accuracy
407,1,Facial Expression Recognition,Cohn-Kanade,2017-01,Sequential forward selection,88.7,100.0,88.7,1.0,88.7,0.89,ito:ITO_00101,Vision process,Accuracy
408,1,Domain Adaptation,SVHN-to-MNIST,2017-02,ADDN,80.1,82.15,80.1,0.82,97.5,0.8,ito:ITO_00101,Vision process,Accuracy
409,1,Domain Adaptation,SVHN-to-MNIST,2017-05,CDAN,89.2,91.49,9.1,0.09,97.5,0.89,ito:ITO_00101,Vision process,Accuracy
410,1,Domain Adaptation,SVHN-to-MNIST,2017-11,CYCADA,90.4,92.72,1.2,0.01,97.5,0.9,ito:ITO_00101,Vision process,Accuracy
411,1,Domain Adaptation,SVHN-to-MNIST,2017-12,MCD,95.8,98.26,5.4,0.06,97.5,0.96,ito:ITO_00101,Vision process,Accuracy
412,1,Domain Adaptation,SVHN-to-MNIST,2019-11,CyCleGAN (Light-weight Calibrator),97.5,100.0,1.7,0.02,97.5,0.98,ito:ITO_00101,Vision process,Accuracy
413,1,Domain Adaptation,MNIST-to-USPS,2017-02,ADDN,90.1,92.79,90.1,0.93,97.1,0.9,ito:ITO_00101,Vision process,Accuracy
414,1,Domain Adaptation,MNIST-to-USPS,2017-12,MCD,93.8,96.6,3.7,0.04,97.1,0.94,ito:ITO_00101,Vision process,Accuracy
415,1,Domain Adaptation,MNIST-to-USPS,2019-03,rRevGrad+CAT,96.0,98.87,2.2,0.02,97.1,0.96,ito:ITO_00101,Vision process,Accuracy
416,1,Domain Adaptation,MNIST-to-USPS,2019-09,3CATN,96.1,98.97,0.1,0.0,97.1,0.96,ito:ITO_00101,Vision process,Accuracy
417,1,Domain Adaptation,MNIST-to-USPS,2019-11,CyCleGAN (Light-weight Calibrator),97.1,100.0,1.0,0.01,97.1,0.97,ito:ITO_00101,Vision process,Accuracy
418,1,Node Classification,AIFB,2017-03,R-GCN,95.83,100.0,95.83,1.0,95.83,0.96,ito:ITO_00101,Vision process,Accuracy
419,1,Unconstrained Lip-synchronization,Unconstrained Lip-synchronization,2017-03,R-GCN,95.83,100.0,95.83,1.0,95.83,0.96,ito:ITO_00101,Vision process,Accuracy
420,1,Image Clustering,USPS,2017-03,DBC,0.743,75.74,0.743,0.76,0.981,0.01,ito:ITO_00101,Vision process,Accuracy
421,1,Image Clustering,USPS,2018-04,DMSC,0.951,96.94,0.2,0.2,0.981,0.01,ito:ITO_00101,Vision process,Accuracy
422,1,Image Clustering,USPS,2018-10,SR-K-means,0.974,99.29,0.0,0.0,0.981,0.01,ito:ITO_00101,Vision process,Accuracy
423,1,Image Clustering,USPS,2018-12,DDC-DA,0.977,99.59,0.0,0.0,0.981,0.01,ito:ITO_00101,Vision process,Accuracy
424,1,Image Clustering,USPS,2019-01,DynAE,0.981,100.0,0.0,0.0,0.981,0.01,ito:ITO_00101,Vision process,Accuracy
425,1,6D Pose Estimation using RGB,LineMOD,2017-03,BB8,83.9,84.57,83.9,0.85,99.21,0.84,ito:ITO_00101,Vision process,Accuracy
426,1,6D Pose Estimation using RGB,LineMOD,2017-11,Single-shot Deep CNN,90.37,91.09,6.5,0.07,99.21,0.9,ito:ITO_00101,Vision process,Accuracy
427,1,6D Pose Estimation using RGB,LineMOD,2018-03,PoseCNN + DeepIM,97.5,98.28,7.1,0.07,99.21,0.98,ito:ITO_00101,Vision process,Accuracy
428,1,6D Pose Estimation using RGB,LineMOD,2018-12,PVNet,99.0,99.79,1.5,0.02,99.21,0.99,ito:ITO_00101,Vision process,Accuracy
429,1,6D Pose Estimation using RGB,LineMOD,2019-09,HRNet+DSNT+BPnP,99.21,100.0,0.2,0.0,99.21,0.99,ito:ITO_00101,Vision process,Accuracy
430,1,Group Activity Recognition,Volleyball,2017-04,Shu et al.,83.6,90.28,83.6,0.9,92.6,0.84,ito:ITO_00101,Vision process,Accuracy
431,1,Group Activity Recognition,Volleyball,2018-11,H-LSTCM,88.4,95.46,4.8,0.05,92.6,0.88,ito:ITO_00101,Vision process,Accuracy
432,1,Group Activity Recognition,Volleyball,2019-04,GTT (VGG19),92.6,100.0,4.2,0.05,92.6,0.93,ito:ITO_00101,Vision process,Accuracy
433,1,3D Object Classification,ModelNet40,2017-04,ECC (12 votes),83.2,100.0,83.2,1.0,83.2,0.83,ito:ITO_00101,Vision process,Accuracy
434,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2017-04,Res-TCN,20.3,52.59,20.3,0.53,38.6,0.2,ito:ITO_00101,Vision process,Accuracy
435,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2018-01,ST-GCN,30.7,79.53,10.4,0.27,38.6,0.31,ito:ITO_00101,Vision process,Accuracy
436,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2018-05,2s-AGCN,36.1,93.52,5.4,0.14,38.6,0.36,ito:ITO_00101,Vision process,Accuracy
437,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2018-11,SLnL-rFA,36.6,94.82,0.5,0.01,38.6,0.37,ito:ITO_00101,Vision process,Accuracy
438,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-06,DGNN,36.9,95.6,0.3,0.01,38.6,0.37,ito:ITO_00101,Vision process,Accuracy
439,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-11,GCN-NAS,37.1,96.11,0.2,0.01,38.6,0.37,ito:ITO_00101,Vision process,Accuracy
440,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-12,JB-AAGCN,37.4,96.89,0.3,0.01,38.6,0.37,ito:ITO_00101,Vision process,Accuracy
441,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-12,MS-AAGCN,37.8,97.93,0.4,0.01,38.6,0.38,ito:ITO_00101,Vision process,Accuracy
442,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2020-03,2s-AGCN+TEM,38.6,100.0,0.8,0.02,38.6,0.39,ito:ITO_00101,Vision process,Accuracy
443,1,Visual Question Answering,MSVD-QA,2017-04,ST-VQA,0.313,86.7,0.313,0.87,0.361,0.0,ito:ITO_00101,Vision process,Accuracy
444,1,Visual Question Answering,MSVD-QA,2018-03,Co-Mem,0.317,87.81,0.0,0.0,0.361,0.0,ito:ITO_00101,Vision process,Accuracy
445,1,Visual Question Answering,MSVD-QA,2019-04,HMEMA,0.337,93.35,0.0,0.0,0.361,0.0,ito:ITO_00101,Vision process,Accuracy
446,1,Visual Question Answering,MSVD-QA,2020-02,HCRN,0.361,100.0,0.0,0.0,0.361,0.0,ito:ITO_00101,Vision process,Accuracy
447,1,Visual Question Answering,MSRVTT-QA,2017-04,ST-VQA,0.309,86.8,0.309,0.87,0.356,0.0,ito:ITO_00101,Vision process,Accuracy
448,1,Visual Question Answering,MSRVTT-QA,2018-03,Co-Mem,0.32,89.89,0.0,0.0,0.356,0.0,ito:ITO_00101,Vision process,Accuracy
449,1,Visual Question Answering,MSRVTT-QA,2019-04,HMEMA,0.33,92.7,0.0,0.0,0.356,0.0,ito:ITO_00101,Vision process,Accuracy
450,1,Visual Question Answering,MSRVTT-QA,2020-02,HCRN,0.356,100.0,0.0,0.0,0.356,0.0,ito:ITO_00101,Vision process,Accuracy
451,1,Image Clustering,FRGC,2017-04,DEPICT,0.432,100.0,0.432,1.0,0.432,0.0,ito:ITO_00101,Vision process,Accuracy
452,1,Hand Gesture Recognition,EgoGesture,2017-05,I3D,92.78,98.67,92.78,0.99,94.03,0.93,ito:ITO_00101,Vision process,Accuracy
453,1,Hand Gesture Recognition,EgoGesture,2018-12,MTUT,93.87,99.83,1.1,0.01,94.03,0.94,ito:ITO_00101,Vision process,Accuracy
454,1,Hand Gesture Recognition,EgoGesture,2019-01,ResNeXt-101,94.03,100.0,0.2,0.0,94.03,0.94,ito:ITO_00101,Vision process,Accuracy
455,1,Fine-Grained Image Classification,Oxford 102 Flowers,2017-05,PC Bilinear CNN,93.65,93.93,93.65,0.94,99.7,0.94,ito:ITO_00101,Vision process,Accuracy
456,1,Fine-Grained Image Classification,Oxford 102 Flowers,2018-05,AutoAugment,95.36,95.65,1.7,0.02,99.7,0.95,ito:ITO_00101,Vision process,Accuracy
457,1,Fine-Grained Image Classification,Oxford 102 Flowers,2019-06,FixInceptionResNet-V2,95.7,95.99,0.3,0.0,99.7,0.96,ito:ITO_00101,Vision process,Accuracy
458,1,Fine-Grained Image Classification,Oxford 102 Flowers,2019-12,BiT-L (ResNet),99.7,100.0,4.0,0.04,99.7,1.0,ito:ITO_00101,Vision process,Accuracy
459,1,Fine-Grained Image Classification,NABirds,2017-05,PC-DenseNet-161,82.79,92.81,82.79,0.93,89.2,0.83,ito:ITO_00101,Vision process,Accuracy
460,1,Fine-Grained Image Classification,NABirds,2018-01,PAIRS,87.9,98.54,5.1,0.06,89.2,0.88,ito:ITO_00101,Vision process,Accuracy
461,1,Fine-Grained Image Classification,NABirds,2019-06,FixSENet-154,89.2,100.0,1.3,0.01,89.2,0.89,ito:ITO_00101,Vision process,Accuracy
462,1,Domain Adaptation,USPS-to-MNIST,2017-05,CDAN,98.0,99.69,98.0,1.0,98.3,0.98,ito:ITO_00101,Vision process,Accuracy
463,1,Domain Adaptation,USPS-to-MNIST,2019-09,3CATN,98.3,100.0,0.3,0.0,98.3,0.98,ito:ITO_00101,Vision process,Accuracy
464,1,Semantic Segmentation,S3DIS,2017-06,PointNet++,91.9,100.0,91.9,1.0,91.9,0.92,ito:ITO_00101,Vision process,Accuracy
465,1,Multimodal Emotion Recognition,Monologue,2017-07,bc-LSTM,74.1,100.0,74.1,1.0,74.1,0.74,ito:ITO_00101,Vision process,Accuracy
466,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,bc-LSTM+Att,56.32,86.31,56.32,0.86,65.25,0.56,ito:ITO_00101,Vision process,Accuracy
467,1,Emotion Recognition in Conversation,IEMOCAP,2018-06,CMN,56.56,86.68,0.2,0.0,65.25,0.57,ito:ITO_00101,Vision process,Accuracy
468,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,ICON,59.09,90.56,2.5,0.04,65.25,0.59,ito:ITO_00101,Vision process,Accuracy
469,1,Emotion Recognition in Conversation,IEMOCAP,2018-11,DialogueRNN,63.4,97.16,4.3,0.07,65.25,0.63,ito:ITO_00101,Vision process,Accuracy
470,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,DialogueGCN,65.25,100.0,1.9,0.03,65.25,0.65,ito:ITO_00101,Vision process,Accuracy
471,1,Emotion Recognition in Conversation,MELD,2017-07,bc-LSTM+Att,57.5,96.57,57.5,0.97,59.54,0.58,ito:ITO_00101,Vision process,Accuracy
472,1,Emotion Recognition in Conversation,MELD,2018-11,DialogueRNN,59.54,100.0,2.0,0.03,59.54,0.6,ito:ITO_00101,Vision process,Accuracy
473,1,Hand Gesture Recognition,MGB,2017-07,F-BLSTM,98.04,100.0,98.04,1.0,98.04,0.98,ito:ITO_00101,Vision process,Accuracy
474,1,Hand Gesture Recognition,BUAA,2017-07,F-BGRU,99.25,100.0,99.25,1.0,99.25,0.99,ito:ITO_00101,Vision process,Accuracy
475,1,Hand Gesture Recognition,SmartWatch,2017-07,F-BGRU,97.4,100.0,97.4,1.0,97.4,0.97,ito:ITO_00101,Vision process,Accuracy
476,1,Visual Question Answering,GQA Test2019,2017-07,BottomUp,49.74,79.32,49.74,0.79,62.71,0.5,ito:ITO_00101,Vision process,Accuracy
477,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Single Model",60.33,96.2,10.6,0.17,62.71,0.6,ito:ITO_00101,Vision process,Accuracy
478,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Ensemble",62.71,100.0,2.4,0.04,62.71,0.63,ito:ITO_00101,Vision process,Accuracy
479,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2017-07,CRN,68.8,82.99,68.8,0.83,82.9,0.69,ito:ITO_00101,Vision process,Accuracy
480,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2017-11,pix2pixHD,69.2,83.47,0.4,0.0,82.9,0.69,ito:ITO_00101,Vision process,Accuracy
481,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2019-03,SPADE,79.9,96.38,10.7,0.13,82.9,0.8,ito:ITO_00101,Vision process,Accuracy
482,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2019-10,CC-FPSE,82.9,100.0,3.0,0.04,82.9,0.83,ito:ITO_00101,Vision process,Accuracy
483,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2017-07,CRN,68.6,82.75,68.6,0.83,82.9,0.69,ito:ITO_00101,Vision process,Accuracy
484,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2017-11,pix2pixHD,71.6,86.37,3.0,0.04,82.9,0.72,ito:ITO_00101,Vision process,Accuracy
485,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2018-04,SIMS,74.7,90.11,3.1,0.04,82.9,0.75,ito:ITO_00101,Vision process,Accuracy
486,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2019-03,SPADE,82.9,100.0,8.2,0.1,82.9,0.83,ito:ITO_00101,Vision process,Accuracy
487,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2017-07,CRN,40.4,57.14,40.4,0.57,70.7,0.4,ito:ITO_00101,Vision process,Accuracy
488,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2017-11,pix2pixHD,45.8,64.78,5.4,0.08,70.7,0.46,ito:ITO_00101,Vision process,Accuracy
489,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2019-03,SPADE,67.9,96.04,22.1,0.31,70.7,0.68,ito:ITO_00101,Vision process,Accuracy
490,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2019-10,CC-FPSE,70.7,100.0,2.8,0.04,70.7,0.71,ito:ITO_00101,Vision process,Accuracy
491,1,Lane Detection,TuSimple,2017-08,Discriminative loss function,96.4,99.69,96.4,1.0,96.7,0.96,ito:ITO_00101,Vision process,Accuracy
492,1,Lane Detection,TuSimple,2017-12,Spatial CNN,96.53,99.82,0.1,0.0,96.7,0.97,ito:ITO_00101,Vision process,Accuracy
493,1,Lane Detection,TuSimple,2019-08,ENet-SAD,96.64,99.94,0.1,0.0,96.7,0.97,ito:ITO_00101,Vision process,Accuracy
494,1,Lane Detection,TuSimple,2020-02,PINet,96.7,100.0,0.1,0.0,96.7,0.97,ito:ITO_00101,Vision process,Accuracy
495,1,Visual Question Answering,VizWiz,2017-08,Pythia v0.3,54.72,98.77,54.72,0.99,55.4,0.55,ito:ITO_00101,Vision process,Accuracy
496,1,Visual Question Answering,VizWiz,2019-08,LXMERT,55.4,100.0,0.7,0.01,55.4,0.55,ito:ITO_00101,Vision process,Accuracy
497,1,Facial Expression Recognition,AffectNet,2017-08,Weighted-Loss,58.0,94.28,58.0,0.94,61.52,0.58,ito:ITO_00101,Vision process,Accuracy
498,1,Facial Expression Recognition,AffectNet,2018-04,CNNs and BOVW + local SVM,59.58,96.85,1.6,0.03,61.52,0.6,ito:ITO_00101,Vision process,Accuracy
499,1,Facial Expression Recognition,AffectNet,2019-02,Facial Motion Prior Network,61.52,100.0,1.9,0.03,61.52,0.62,ito:ITO_00101,Vision process,Accuracy
500,1,Semi-Supervised Image Classification,STL-10,2017-08,CutOut,87.26,91.39,87.26,0.91,95.48,0.87,ito:ITO_00101,Vision process,Accuracy
501,1,Semi-Supervised Image Classification,STL-10,2018-07,IIC,88.8,93.0,1.5,0.02,95.48,0.89,ito:ITO_00101,Vision process,Accuracy
502,1,Semi-Supervised Image Classification,STL-10,2019-11,EnAET,95.48,100.0,6.7,0.07,95.48,0.96,ito:ITO_00101,Vision process,Accuracy
503,1,Face Identification,IJB-B,2017-08,FPN,91.1,100.0,91.1,1.0,91.1,0.91,ito:ITO_00101,Vision process,Accuracy
504,1,Face Identification,IJB-A,2017-08,FPN,91.4,96.62,91.4,0.97,94.6,0.91,ito:ITO_00101,Vision process,Accuracy
505,1,Face Identification,IJB-A,2018-03,Deep Residual Equivariant Mapping,94.6,100.0,3.2,0.03,94.6,0.95,ito:ITO_00101,Vision process,Accuracy
506,1,Video Story QA,MovieQA,2017-09,RWMN,36.25,85.23,36.25,0.85,42.53,0.36,ito:ITO_00101,Vision process,Accuracy
507,1,Video Story QA,MovieQA,2019-04,PAMN,42.53,100.0,6.3,0.15,42.53,0.43,ito:ITO_00101,Vision process,Accuracy
508,1,Pedestrian Attribute Recognition,PETA,2017-09,HP-net,76.13,95.74,76.13,0.96,79.52,0.76,ito:ITO_00101,Vision process,Accuracy
509,1,Pedestrian Attribute Recognition,PETA,2019-10,Attribute-Specific Localization,79.52,100.0,3.4,0.04,79.52,0.8,ito:ITO_00101,Vision process,Accuracy
510,1,Pedestrian Attribute Recognition,PA-100K,2017-09,HP-net,72.19,93.66,72.19,0.94,77.08,0.72,ito:ITO_00101,Vision process,Accuracy
511,1,Pedestrian Attribute Recognition,PA-100K,2019-10,Attribute-Specific Localization,77.08,100.0,4.9,0.06,77.08,0.77,ito:ITO_00101,Vision process,Accuracy
512,1,Pedestrian Attribute Recognition,RAP,2017-09,HP-net,65.39,95.92,65.39,0.96,68.17,0.65,ito:ITO_00101,Vision process,Accuracy
513,1,Pedestrian Attribute Recognition,RAP,2019-10,Attribute-Specific Localization,68.17,100.0,2.8,0.04,68.17,0.68,ito:ITO_00101,Vision process,Accuracy
514,1,Facial Expression Recognition,SFEW,2017-10,Island Loss,52.52,93.12,52.52,0.93,56.4,0.53,ito:ITO_00101,Vision process,Accuracy
515,1,Facial Expression Recognition,SFEW,2019-05,RAN (VGG16+ResNet18),56.4,100.0,3.9,0.07,56.4,0.56,ito:ITO_00101,Vision process,Accuracy
516,1,Image Classification,EMNIST-Balanced,2017-10,TextCaps,90.46,100.0,90.46,1.0,90.46,0.9,ito:ITO_00101,Vision process,Accuracy
517,1,Few-Shot Image Classification,CUB 200 5-way 5-shot,2017-11,Relation Net,65.32,70.89,65.32,0.71,92.14,0.65,ito:ITO_00101,Vision process,Accuracy
518,1,Few-Shot Image Classification,CUB 200 5-way 5-shot,2018-12,feat (ProtoNet),83.03,90.11,17.7,0.19,92.14,0.83,ito:ITO_00101,Vision process,Accuracy
519,1,Few-Shot Image Classification,CUB 200 5-way 5-shot,2019-05,Self-Critique and Adapt + High-End MAML++,85.63,92.93,2.6,0.03,92.14,0.86,ito:ITO_00101,Vision process,Accuracy
520,1,Few-Shot Image Classification,CUB 200 5-way 5-shot,2019-07,S2M2R,90.85,98.6,5.2,0.06,92.14,0.91,ito:ITO_00101,Vision process,Accuracy
521,1,Few-Shot Image Classification,CUB 200 5-way 5-shot,2020-01,Transfer+SGC,92.14,100.0,1.3,0.01,92.14,0.92,ito:ITO_00101,Vision process,Accuracy
522,1,Few-Shot Image Classification,CUB 200 5-way 1-shot,2017-11,Relation Net,50.44,57.09,50.44,0.57,88.35,0.5,ito:ITO_00101,Vision process,Accuracy
523,1,Few-Shot Image Classification,CUB 200 5-way 1-shot,2018-06,Delta-encoder,69.8,79.0,19.4,0.22,88.35,0.7,ito:ITO_00101,Vision process,Accuracy
524,1,Few-Shot Image Classification,CUB 200 5-way 1-shot,2019-05,Self-Critique and Adapt + High-End MAML++,70.46,79.75,0.7,0.01,88.35,0.7,ito:ITO_00101,Vision process,Accuracy
525,1,Few-Shot Image Classification,CUB 200 5-way 1-shot,2019-07,S2M2R,80.68,91.32,10.2,0.12,88.35,0.81,ito:ITO_00101,Vision process,Accuracy
526,1,Few-Shot Image Classification,CUB 200 5-way 1-shot,2020-01,Transfer+SGC,88.35,100.0,7.7,0.09,88.35,0.88,ito:ITO_00101,Vision process,Accuracy
527,1,Image Classification,Clothing1M,2017-11,"CLeanNet, w_{soft}",74.69,99.91,74.69,1.0,74.76,0.75,ito:ITO_00101,Vision process,Accuracy
528,1,Image Classification,Clothing1M,2020-01,DividedMix,74.76,100.0,0.1,0.0,74.76,0.75,ito:ITO_00101,Vision process,Accuracy
529,1,Image Classification,Food-101N,2017-11,CleanNet,90.39,100.0,90.39,1.0,90.39,0.9,ito:ITO_00101,Vision process,Accuracy
530,1,Gesture Recognition,Chalearn 2014,2017-12,3D-CNN + LSTM,93.2,100.0,93.2,1.0,93.2,0.93,ito:ITO_00101,Vision process,Accuracy
531,1,Action Recognition,IRD,2018-01,ST-GCN,74.03,92.41,74.03,0.92,80.11,0.74,ito:ITO_00101,Vision process,Accuracy
532,1,Action Recognition,IRD,2019-01,OHA-GCN (Two stream; HP + OHP-hands + informative samples),80.11,100.0,6.1,0.08,80.11,0.8,ito:ITO_00101,Vision process,Accuracy
533,1,Action Recognition In Videos,ICVL-4,2018-01,ST-GCN,80.23,87.34,80.23,0.87,91.86,0.8,ito:ITO_00101,Vision process,Accuracy
534,1,Action Recognition In Videos,ICVL-4,2019-01,OHA-GCN (Two stream; HP + OHP-hands + informative samples),91.86,100.0,11.6,0.13,91.86,0.92,ito:ITO_00101,Vision process,Accuracy
535,1,Action Recognition In Videos,IRD,2018-01,ST-GCN,74.03,92.41,74.03,0.92,80.11,0.74,ito:ITO_00101,Vision process,Accuracy
536,1,Action Recognition In Videos,IRD,2019-01,OHA-GCN (Two stream; HP + OHP-hands + informative samples),80.11,100.0,6.1,0.08,80.11,0.8,ito:ITO_00101,Vision process,Accuracy
537,1,Action Recognition,ICVL-4,2018-01,ST-GCN,80.23,87.34,80.23,0.87,91.86,0.8,ito:ITO_00101,Vision process,Accuracy
538,1,Action Recognition,ICVL-4,2019-01,OHA-GCN (Two stream; HP + OHP-hands + informative samples),91.86,100.0,11.6,0.13,91.86,0.92,ito:ITO_00101,Vision process,Accuracy
539,1,Skeleton Based Action Recognition,N-UCLA,2018-02,Glimpse Clouds,87.6,94.7,87.6,0.95,92.5,0.88,ito:ITO_00101,Vision process,Accuracy
540,1,Skeleton Based Action Recognition,N-UCLA,2018-04,VA-fusion (aug.),88.1,95.24,0.5,0.01,92.5,0.88,ito:ITO_00101,Vision process,Accuracy
541,1,Skeleton Based Action Recognition,N-UCLA,2018-12,Action Machine,92.3,99.78,4.2,0.05,92.5,0.92,ito:ITO_00101,Vision process,Accuracy
542,1,Skeleton Based Action Recognition,N-UCLA,2019-04,SGN,92.5,100.0,0.2,0.0,92.5,0.93,ito:ITO_00101,Vision process,Accuracy
543,1,Click-Through Rate Prediction,MovieLens 1M,2018-03,RippleNet,84.4,100.0,84.4,1.0,84.4,0.84,ito:ITO_00101,Vision process,Accuracy
544,1,Weakly-Supervised Action Recognition,Weakly-Supervised Action Recognition,2018-03,RippleNet,84.4,100.0,84.4,1.0,84.4,0.84,ito:ITO_00101,Vision process,Accuracy
545,1,Click-Through Rate Prediction,Bing News,2018-03,RippleNet,63.2,100.0,63.2,1.0,63.2,0.63,ito:ITO_00101,Vision process,Accuracy
546,1,Replay Grounding,Replay Grounding,2018-03,RippleNet,63.2,100.0,63.2,1.0,63.2,0.63,ito:ITO_00101,Vision process,Accuracy
547,1,6D Pose Estimation using RGB,Occlusion LineMOD,2018-03,PoseCNN + DeepIM,56.6,92.7,56.6,0.93,61.06,0.57,ito:ITO_00101,Vision process,Accuracy
548,1,6D Pose Estimation using RGB,Occlusion LineMOD,2018-12,PVNet,61.06,100.0,4.5,0.07,61.06,0.61,ito:ITO_00101,Vision process,Accuracy
549,1,Image Clustering,ARL Polarimetric Thermal Face Dataset,2018-04,DMSC,0.983,100.0,0.983,1.0,0.983,0.01,ito:ITO_00101,Vision process,Accuracy
550,1,Multi-view Subspace Clustering,ARL Polarimetric Thermal Face Dataset,2018-04,DMSC,0.988,100.0,0.988,1.0,0.988,0.01,ito:ITO_00101,Vision process,Accuracy
551,1,Multi-view Subspace Clustering,ORL,2018-04,DMSC,0.833,95.75,0.833,0.96,0.87,0.01,ito:ITO_00101,Vision process,Accuracy
552,1,Multi-view Subspace Clustering,ORL,2019-08,MvDSCN,0.87,100.0,0.0,0.0,0.87,0.01,ito:ITO_00101,Vision process,Accuracy
553,1,Hand Gesture Recognition,ChaLean test,2018-04,8-MFFs-3f1c,56.7,100.0,56.7,1.0,56.7,0.57,ito:ITO_00101,Vision process,Accuracy
554,1,Hand Gesture Recognition,NVGesture,2018-04,8-MFFs-3f1c,84.7,97.43,84.7,0.97,86.93,0.85,ito:ITO_00101,Vision process,Accuracy
555,1,Hand Gesture Recognition,NVGesture,2018-12,MTUT,86.93,100.0,2.2,0.03,86.93,0.87,ito:ITO_00101,Vision process,Accuracy
556,1,Semi-Supervised Image Classification,"Caltech-256, 1024 Labels",2018-05,UL-Hopfield (ULH),77.4,100.0,77.4,1.0,77.4,0.77,ito:ITO_00101,Vision process,Accuracy
557,1,Semi-Supervised Image Classification,Caltech-101,2018-05,UL-Hopfield (ULH),91.0,100.0,91,1.0,91,0.91,ito:ITO_00101,Vision process,Accuracy
558,1,Semi-Supervised Image Classification,"Caltech-101, 202 Labels",2018-05,UL-Hopfield (ULH),91.0,100.0,91,1.0,91,0.91,ito:ITO_00101,Vision process,Accuracy
559,1,Semi-Supervised Image Classification,Caltech-256,2018-05,UL-Hopfield (ULH),77.4,100.0,77.4,1.0,77.4,0.77,ito:ITO_00101,Vision process,Accuracy
560,1,Image Classification,CIFAR-10,2018-05,UL-Hopfield (ULH),83.1,100.0,83.1,1.0,83.1,0.83,ito:ITO_00101,Vision process,Accuracy
561,1,Fine-Grained Image Classification,Caltech-101,2018-05,UL-Hopfield (ULH),91.0,100.0,91,1.0,91,0.91,ito:ITO_00101,Vision process,Accuracy
562,1,Facial Expression Recognition,Real-World Affective Faces,2018-05,Covariance Pooling,87.0,100.0,87,1.0,87,0.87,ito:ITO_00101,Vision process,Accuracy
563,1,Fine-Grained Image Classification,Oxford-IIIT Pets,2018-05,AutoAugment,88.98,91.96,88.98,0.92,96.76,0.89,ito:ITO_00101,Vision process,Accuracy
564,1,Fine-Grained Image Classification,Oxford-IIIT Pets,2019-05,EfficientNet-B7,95.4,98.59,6.4,0.07,96.76,0.95,ito:ITO_00101,Vision process,Accuracy
565,1,Fine-Grained Image Classification,Oxford-IIIT Pets,2019-12,BiT-L (ResNet),96.76,100.0,1.4,0.01,96.76,0.97,ito:ITO_00101,Vision process,Accuracy
566,1,Few-Shot Image Classification,Mini-ImageNet,2018-06,PLATIPUS,50.13,64.02,50.13,0.64,78.3,0.5,ito:ITO_00101,Vision process,Accuracy
567,1,Few-Shot Image Classification,Mini-ImageNet,2019-03,DivCoop,63.73,81.39,13.6,0.17,78.3,0.64,ito:ITO_00101,Vision process,Accuracy
568,1,Few-Shot Image Classification,Mini-ImageNet,2019-06,Multiple-semantics,67.2,85.82,3.5,0.04,78.3,0.67,ito:ITO_00101,Vision process,Accuracy
569,1,Few-Shot Image Classification,Mini-ImageNet,2019-11,AmdimNet,76.82,98.11,9.6,0.12,78.3,0.77,ito:ITO_00101,Vision process,Accuracy
570,1,Few-Shot Image Classification,Mini-ImageNet,2020-02,DFMN+MCT,78.3,100.0,1.5,0.02,78.3,0.78,ito:ITO_00101,Vision process,Accuracy
571,1,Document Image Classification,Noisy Bangla Numeral,2018-06,Pixel-level RC,95.46,98.74,95.46,0.99,96.68,0.95,ito:ITO_00101,Vision process,Accuracy
572,1,Document Image Classification,Noisy Bangla Numeral,2019-08,PCGAN-CHAR,96.68,100.0,1.2,0.01,96.68,0.97,ito:ITO_00101,Vision process,Accuracy
573,1,Document Image Classification,Noisy Bangla Characters,2018-06,Pixel-level RC,77.22,86.24,77.22,0.86,89.54,0.77,ito:ITO_00101,Vision process,Accuracy
574,1,Document Image Classification,Noisy Bangla Characters,2019-08,PCGAN-CHAR,89.54,100.0,12.3,0.14,89.54,0.9,ito:ITO_00101,Vision process,Accuracy
575,1,Document Image Classification,Noisy MNIST,2018-06,Pixel-level RC,97.62,99.18,97.62,0.99,98.43,0.98,ito:ITO_00101,Vision process,Accuracy
576,1,Document Image Classification,Noisy MNIST,2019-08,PCGAN-CHAR,98.43,100.0,0.8,0.01,98.43,0.98,ito:ITO_00101,Vision process,Accuracy
577,1,Document Image Classification,n-MNIST,2018-06,Pixel-level RC,97.62,99.18,97.62,0.99,98.43,0.98,ito:ITO_00101,Vision process,Accuracy
578,1,Document Image Classification,n-MNIST,2019-08,PCGAN-CHAR,98.43,100.0,0.8,0.01,98.43,0.98,ito:ITO_00101,Vision process,Accuracy
579,1,License Plate Recognition,Chinese License Plates,2018-06,LPRNet basic,95.0,100.0,95.0,1.0,95.0,0.95,ito:ITO_00101,Vision process,Accuracy
580,1,Unsupervised Semantic Segmentation,COCO-Stuff-15,2018-07,IIC,27.7,100.0,27.7,1.0,27.7,0.28,ito:ITO_00101,Vision process,Accuracy
581,1,Unsupervised Semantic Segmentation,Potsdam,2018-07,IIC,65.1,100.0,65.1,1.0,65.1,0.65,ito:ITO_00101,Vision process,Accuracy
582,1,Unsupervised Image Classification,CIFAR-20,2018-07,IIC,25.7,100.0,25.7,1.0,25.7,0.26,ito:ITO_00101,Vision process,Accuracy
583,1,Unsupervised Semantic Segmentation,Potsdam-3,2018-07,IIC,45.4,100.0,45.4,1.0,45.4,0.45,ito:ITO_00101,Vision process,Accuracy
584,1,Unsupervised Image Classification,STL-10,2018-07,IIC,61.0,100.0,61,1.0,61,0.61,ito:ITO_00101,Vision process,Accuracy
585,1,Unsupervised Image Classification,CIFAR-10,2018-07,IIC,61.7,100.0,61.7,1.0,61.7,0.62,ito:ITO_00101,Vision process,Accuracy
586,1,Unsupervised Semantic Segmentation,COCO-Stuff-3,2018-07,IIC,72.3,100.0,72.3,1.0,72.3,0.72,ito:ITO_00101,Vision process,Accuracy
587,1,Classification Of Hyperspectral Images,Pavia University,2018-07,WCRN,99.43,100.0,99.43,1.0,99.43,0.99,ito:ITO_00101,Vision process,Accuracy
588,1,Visual Question Answering,CLEVR,2018-08,CNN + LSTM + RN + HAN,98.8,100.0,98.8,1.0,98.8,0.99,ito:ITO_00101,Vision process,Accuracy
589,1,Age-Invariant Face Recognition,FG-NET,2018-09,AIM,93.2,100.0,93.2,1.0,93.2,0.93,ito:ITO_00101,Vision process,Accuracy
590,1,Image Classification,CINIC-10,2018-10,ResNeXt29_2x64d,91.45,100.0,91.45,1.0,91.45,0.91,ito:ITO_00101,Vision process,Accuracy
591,1,Action Classification,Kinetics-400,2018-10,RepFlow-50,77.9,93.18,77.9,0.93,83.6,0.78,ito:ITO_00101,Vision process,Accuracy
592,1,Action Classification,Kinetics-400,2018-12,"SlowFast, R101 + NL",79.8,95.45,1.9,0.02,83.6,0.8,ito:ITO_00101,Vision process,Accuracy
593,1,Action Classification,Kinetics-400,2019-05,irCSN-152 (IG-Kinetics-65M pretrain),82.8,99.04,3.0,0.04,83.6,0.83,ito:ITO_00101,Vision process,Accuracy
594,1,Action Classification,Kinetics-400,2020-03,OmniSource irCSN-152 (IG-Kinetics-65M pretrain),83.6,100.0,0.8,0.01,83.6,0.84,ito:ITO_00101,Vision process,Accuracy
595,1,Visual Question Answering,TallyQA,2018-10,RCN (Ours),71.8,100.0,71.8,1.0,71.8,0.72,ito:ITO_00101,Vision process,Accuracy
596,1,Visual Question Answering,HowmanyQA,2018-10,RCN (Ours),60.3,100.0,60.3,1.0,60.3,0.6,ito:ITO_00101,Vision process,Accuracy
597,1,Steering Control,BDD100K,2018-11,FM-Net,85.03,100.0,85.03,1.0,85.03,0.85,ito:ITO_00101,Vision process,Accuracy
598,1,Steering Control,BDD100k,2018-11,FM-Net,85.03,100.0,85.03,1.0,85.03,0.85,ito:ITO_00101,Vision process,Accuracy
599,1,Fine-Grained Image Classification,Birdsnap,2018-11,GPIPE,83.6,99.17,83.6,0.99,84.3,0.84,ito:ITO_00101,Vision process,Accuracy
600,1,Fine-Grained Image Classification,Birdsnap,2019-05,EfficientNet-B7,84.3,100.0,0.7,0.01,84.3,0.84,ito:ITO_00101,Vision process,Accuracy
601,1,Gesture Recognition,ChaLearn 2013,2018-11,3S Net TTM,92.08,100.0,92.08,1.0,92.08,0.92,ito:ITO_00101,Vision process,Accuracy
602,1,Gesture Recognition,ChaLearn 2016,2018-11,3S Net TTM,39.95,100.0,39.95,1.0,39.95,0.4,ito:ITO_00101,Vision process,Accuracy
603,1,Gesture Recognition,MSRC-12,2018-11,3S Net TTM,99.01,100.0,99.01,1.0,99.01,0.99,ito:ITO_00101,Vision process,Accuracy
604,1,Domain Adaptation,Office-Home,2018-11,IAFN (ResNet-50),71.83,98.67,71.83,0.99,72.8,0.72,ito:ITO_00101,Vision process,Accuracy
605,1,Domain Adaptation,Office-Home,2019-04,MDAIR,72.8,100.0,1.0,0.01,72.8,0.73,ito:ITO_00101,Vision process,Accuracy
606,1,Action Recognition,Diving-48,2018-12,SlowFast,77.6,100.0,77.6,1.0,77.6,0.78,ito:ITO_00101,Vision process,Accuracy
607,1,Image Clustering,LetterA-J,2018-12,DDC-DA,0.691,100.0,0.691,1.0,0.691,0.01,ito:ITO_00101,Vision process,Accuracy
608,1,Action Recognition In Videos,UTD-MHAD,2018-12,Action Machine (RGB only),92.5,100.0,92.5,1.0,92.5,0.93,ito:ITO_00101,Vision process,Accuracy
609,1,Action Recognition,UTD-MHAD,2018-12,Action Machine (RGB only),92.5,100.0,92.5,1.0,92.5,0.93,ito:ITO_00101,Vision process,Accuracy
610,1,Multimodal Activity Recognition,LboroHAR,2019-01,Bagged Trees,92.5,94.48,92.5,0.94,97.9,0.93,ito:ITO_00101,Vision process,Accuracy
611,1,Multimodal Activity Recognition,LboroHAR,2019-01,Deep Neural Net,95.0,97.04,2.5,0.03,97.9,0.95,ito:ITO_00101,Vision process,Accuracy
612,1,Multimodal Activity Recognition,LboroHAR,2019-01,Cubic SVM,97.9,100.0,2.9,0.03,97.9,0.98,ito:ITO_00101,Vision process,Accuracy
613,1,Image Retrieval,street2shop,2019-01,Ranknet,94.98,100.0,94.98,1.0,94.98,0.95,ito:ITO_00101,Vision process,Accuracy
614,1,Hand Gesture Recognition,Northwestern University,2019-01,Key Frames + Feature Fusion,96.89,100.0,96.89,1.0,96.89,0.97,ito:ITO_00101,Vision process,Accuracy
615,1,Gesture Recognition,Ninapro DB-1 12 gestures,2019-01,2SRNN,84.7,100.0,84.7,1.0,84.7,0.85,ito:ITO_00101,Vision process,Accuracy
616,1,Gesture Recognition,CapgMyo DB-b,2019-01,2SRNN,97.1,100.0,97.1,1.0,97.1,0.97,ito:ITO_00101,Vision process,Accuracy
617,1,Gesture Recognition,CapgMyo DB-a,2019-01,2SRNN,97.1,100.0,97.1,1.0,97.1,0.97,ito:ITO_00101,Vision process,Accuracy
618,1,Gesture Recognition,CapgMyo DB-c,2019-01,2SRNN,96.8,100.0,96.8,1.0,96.8,0.97,ito:ITO_00101,Vision process,Accuracy
619,1,Gesture Recognition,Ninapro DB-1 8 gestures,2019-01,2SRNN,90.7,100.0,90.7,1.0,90.7,0.91,ito:ITO_00101,Vision process,Accuracy
620,1,Click-Through Rate Prediction,Children's Book Test Common noun,2019-01,MKR,70.4,100.0,70.4,1.0,70.4,0.7,ito:ITO_00101,Vision process,Accuracy
621,1,Generalized Zero Shot skeletal action recognition,Generalized Zero Shot skeletal action recognition,2019-01,MKR,70.4,100.0,70.4,1.0,70.4,0.7,ito:ITO_00101,Vision process,Accuracy
622,1,Facial Expression Recognition,FERG,2019-02,DeepEmotion,99.3,100.0,99.3,1.0,99.3,0.99,ito:ITO_00101,Vision process,Accuracy
623,1,Few-Shot Image Classification,OMNIGLOT,2019-02,APL,73.5,100.0,73.5,1.0,73.5,0.74,ito:ITO_00101,Vision process,Accuracy
624,1,Few-Shot Image Classification,OMNIGLOT,2019-02,APL,88.0,100.0,88,1.0,88,0.88,ito:ITO_00101,Vision process,Accuracy
625,1,Few-Shot Image Classification,OMNIGLOT,2019-02,APL,68.9,100.0,68.9,1.0,68.9,0.69,ito:ITO_00101,Vision process,Accuracy
626,1,Few-Shot Image Classification,OMNIGLOT,2019-02,APL,78.9,100.0,78.9,1.0,78.9,0.79,ito:ITO_00101,Vision process,Accuracy
627,1,Safety Perception Recognition,Google Street Images,2019-02,CNN,81.0,100.0,81,1.0,81,0.81,ito:ITO_00101,Vision process,Accuracy
628,1,Visual Question Answering,TDIUC,2019-02,Accuracy,88.2,100.0,88.2,1.0,88.2,0.88,ito:ITO_00101,Vision process,Accuracy
629,1,Visual Question Answering,GQA test-std,2019-02,MAC,54.06,85.58,54.06,0.86,63.17,0.54,ito:ITO_00101,Vision process,Accuracy
630,1,Visual Question Answering,GQA test-std,2019-07,NSM,63.17,100.0,9.1,0.14,63.17,0.63,ito:ITO_00101,Vision process,Accuracy
631,1,Retinal Vessel Segmentation,DRIVE,2019-03,CE-Net,0.9545,99.84,0.9545,1.0,0.956,0.01,ito:ITO_00101,Vision process,Accuracy
632,1,Retinal Vessel Segmentation,DRIVE,2019-07,ET-Net,0.956,100.0,0.0,0.0,0.956,0.01,ito:ITO_00101,Vision process,Accuracy
633,1,Lung Nodule Segmentation,LUNA,2019-03,CE-Net,0.99,100.0,0.99,1.0,0.99,0.01,ito:ITO_00101,Vision process,Accuracy
634,1,Action Recognition In Videos,miniSports,2019-04,IF+MD+RGB-R (ResNet-18),74.9,100.0,74.9,1.0,74.9,0.75,ito:ITO_00101,Vision process,Accuracy
635,1,Action Recognition,miniSports,2019-04,IF+MD+RGB-R (ResNet-18),74.9,100.0,74.9,1.0,74.9,0.75,ito:ITO_00101,Vision process,Accuracy
636,1,Few-Shot Image Classification,AWA2,2019-04,TAFE-Net,69.3,100.0,69.3,1.0,69.3,0.69,ito:ITO_00101,Vision process,Accuracy
637,1,Few-Shot Image Classification,AWA1,2019-04,TAFE-Net,70.8,100.0,70.8,1.0,70.8,0.71,ito:ITO_00101,Vision process,Accuracy
638,1,Few-Shot Image Classification,aPY,2019-04,TAFE-Net,42.2,100.0,42.2,1.0,42.2,0.42,ito:ITO_00101,Vision process,Accuracy
639,1,Image Classification,EMNIST-Letters,2019-04,TextCaps,95.39,100.0,95.39,1.0,95.39,0.95,ito:ITO_00101,Vision process,Accuracy
640,1,Visual Question Answering,TextVQA Val,2019-04,Pythia + LoRRA,26.56,100.0,26.56,1.0,26.56,0.27,ito:ITO_00101,Vision process,Accuracy
641,1,Visual Question Answering,TextVQA Test,2019-04,Pythia + LoRRA,27.63,100.0,27.63,1.0,27.63,0.28,ito:ITO_00101,Vision process,Accuracy
642,1,Sparse Representation-based Classification,SVHN,2019-04,DSRC,67.75,100.0,67.75,1.0,67.75,0.68,ito:ITO_00101,Vision process,Accuracy
643,1,Semi-Supervised Image Classification,"CIFAR-10, 500 Labels",2019-05,MixMatch,91.35,100.0,91.35,1.0,91.35,0.91,ito:ITO_00101,Vision process,Accuracy
644,1,Semi-Supervised Image Classification,"SVHN, 4000 Labels",2019-05,MixMatch,97.11,100.0,97.11,1.0,97.11,0.97,ito:ITO_00101,Vision process,Accuracy
645,1,Semi-Supervised Image Classification,"CIFAR-10, 2000 Labels",2019-05,MixMatch,92.97,100.0,92.97,1.0,92.97,0.93,ito:ITO_00101,Vision process,Accuracy
646,1,Semi-Supervised Image Classification,"CIFAR-10, 1000 Labels",2019-05,MixMatch,92.25,100.0,92.25,1.0,92.25,0.92,ito:ITO_00101,Vision process,Accuracy
647,1,Semi-Supervised Image Classification,"SVHN, 2000 Labels",2019-05,MixMatch,96.96,100.0,96.96,1.0,96.96,0.97,ito:ITO_00101,Vision process,Accuracy
648,1,Semi-Supervised Image Classification,"SVHN, 500 Labels",2019-05,MixMatch,96.36,100.0,96.36,1.0,96.36,0.96,ito:ITO_00101,Vision process,Accuracy
649,1,Semi-Supervised Image Classification,"STL-10, 5000 Labels",2019-05,MixMatch,94.41,100.0,94.41,1.0,94.41,0.94,ito:ITO_00101,Vision process,Accuracy
650,1,Facial Expression Recognition,RAF-DB,2019-05,RAN (ResNet-18),86.9,100.0,86.9,1.0,86.9,0.87,ito:ITO_00101,Vision process,Accuracy
651,1,Emotion Recognition,MPED,2019-05,BiHDM,40.34,100.0,40.34,1.0,40.34,0.4,ito:ITO_00101,Vision process,Accuracy
652,1,Object Classification,Pubmed,2019-05,GMNN,81.8,100.0,81.8,1.0,81.8,0.82,ito:ITO_00101,Vision process,Accuracy
653,1,Object Classification,Cora,2019-05,GMNN,83.7,100.0,83.7,1.0,83.7,0.84,ito:ITO_00101,Vision process,Accuracy
654,1,Object Classification,Citeseer,2019-05,GMNN,72.9,100.0,72.9,1.0,72.9,0.73,ito:ITO_00101,Vision process,Accuracy
655,1,Image Classification,Flowers-102,2019-05,EfficientNet-B7,98.8,99.1,98.8,0.99,99.7,0.99,ito:ITO_00101,Vision process,Accuracy
656,1,Image Classification,Flowers-102,2019-12,BiT-L (ResNet),99.7,100.0,0.9,0.01,99.7,1.0,ito:ITO_00101,Vision process,Accuracy
657,1,Fine-Grained Image Classification,Food-101,2019-05,EfficientNet-B7,93.0,100.0,93.0,1.0,93.0,0.93,ito:ITO_00101,Vision process,Accuracy
658,1,Skeleton Based Action Recognition,MSR Action3D,2019-06,HDM-BG,86.1,100.0,86.1,1.0,86.1,0.86,ito:ITO_00101,Vision process,Accuracy
659,1,Skeleton Based Action Recognition,UPenn Action,2019-06,HDM-BG,93.4,94.06,93.4,0.94,99.3,0.93,ito:ITO_00101,Vision process,Accuracy
660,1,Skeleton Based Action Recognition,UPenn Action,2020-01,UniPose-LSTM,99.3,100.0,5.9,0.06,99.3,0.99,ito:ITO_00101,Vision process,Accuracy
661,1,Visual Question Answering,GQA test-dev,2019-07,NSM,62.95,100.0,62.95,1.0,62.95,0.63,ito:ITO_00101,Vision process,Accuracy
662,1,Face Verification,CFP-FP,2019-07,VarGNet,0.89829,91.2,0.89829,0.91,0.985,0.01,ito:ITO_00101,Vision process,Accuracy
663,1,Face Verification,CFP-FP,2019-08,Seesaw-shuffleFaceNet (mobi),0.9307,94.49,0.0,0.0,0.985,0.01,ito:ITO_00101,Vision process,Accuracy
664,1,Face Verification,CFP-FP,2019-10,VarGFaceNet,0.985,100.0,0.1,0.1,0.985,0.01,ito:ITO_00101,Vision process,Accuracy
665,1,Face Verification,AgeDB-30,2019-07,VarGNet,0.97333,99.17,0.97333,0.99,0.9815,0.01,ito:ITO_00101,Vision process,Accuracy
666,1,Face Verification,AgeDB-30,2019-10,VarGFaceNet,0.9815,100.0,0.0,0.0,0.9815,0.01,ito:ITO_00101,Vision process,Accuracy
667,1,Emotion Recognition,SEED-IV,2019-07,RGNN,79.37,100.0,79.37,1.0,79.37,0.79,ito:ITO_00101,Vision process,Accuracy
668,1,Hand Gesture Recognition,DHG-14,2019-07,DG-STA,91.9,100.0,91.9,1.0,91.9,0.92,ito:ITO_00101,Vision process,Accuracy
669,1,Hand Gesture Recognition,DHG-28,2019-07,DG-STA,88.0,100.0,88,1.0,88,0.88,ito:ITO_00101,Vision process,Accuracy
670,1,Lung Nodule Segmentation,Montgomery County,2019-07,ET-Net,0.9865,100.0,0.9865,1.0,0.9865,0.01,ito:ITO_00101,Vision process,Accuracy
671,1,Lane Detection,BDD100k,2019-08,ENet-SAD,36.56,100.0,36.56,1.0,36.56,0.37,ito:ITO_00101,Vision process,Accuracy
672,1,Lane Detection,BDD100K,2019-08,ENet-SAD,36.56,100.0,36.56,1.0,36.56,0.37,ito:ITO_00101,Vision process,Accuracy
673,1,Visual Reasoning,NLVR2 Dev,2019-08,VisualBERT,66.7,89.05,66.7,0.89,74.9,0.67,ito:ITO_00101,Vision process,Accuracy
674,1,Visual Reasoning,NLVR2 Dev,2019-08,LXMERT (Pre-train + scratch),74.9,100.0,8.2,0.11,74.9,0.75,ito:ITO_00101,Vision process,Accuracy
675,1,Few-Shot Image Classification,mini-ImageNet,2019-08,GCR,39.14,100.0,39.14,1.0,39.14,0.39,ito:ITO_00101,Vision process,Accuracy
676,1,Image Clustering,pendigits,2019-08,N2D (UMAP),0.885,100.0,0.885,1.0,0.885,0.01,ito:ITO_00101,Vision process,Accuracy
677,1,Image Clustering,HAR,2019-08,N2D (UMAP),0.801,100.0,0.801,1.0,0.801,0.01,ito:ITO_00101,Vision process,Accuracy
678,1,Visual Reasoning,NLVR2 Test,2019-08,LXMERT,76.2,95.85,76.2,0.96,79.5,0.76,ito:ITO_00101,Vision process,Accuracy
679,1,Visual Reasoning,NLVR2 Test,2019-09,UNITER (Large),79.5,100.0,3.3,0.04,79.5,0.8,ito:ITO_00101,Vision process,Accuracy
680,1,Multimodal Activity Recognition,Nurse Care Activity Recognition Challenge,2019-09,KNN,80.2,100.0,80.2,1.0,80.2,0.8,ito:ITO_00101,Vision process,Accuracy
681,1,Node Classification,Coauthor CS,2019-09,GraphMix,91.83,96.87,91.83,0.97,94.8,0.92,ito:ITO_00101,Vision process,Accuracy
682,1,Node Classification,Coauthor CS,2019-10,GCN (PPR Diffusion),93.01,98.11,1.2,0.01,94.8,0.93,ito:ITO_00101,Vision process,Accuracy
683,1,Node Classification,Coauthor CS,2020-02,GCN-LPA,94.8,100.0,1.8,0.02,94.8,0.95,ito:ITO_00101,Vision process,Accuracy
684,1,Face Age Editing,Face Age Editing,2019-09,GraphMix,91.83,96.87,91.83,0.97,94.8,0.92,ito:ITO_00101,Vision process,Accuracy
685,1,Face Age Editing,Face Age Editing,2019-10,GCN (PPR Diffusion),93.01,98.11,1.2,0.01,94.8,0.93,ito:ITO_00101,Vision process,Accuracy
686,1,Face Age Editing,Face Age Editing,2020-02,GCN-LPA,94.8,100.0,1.8,0.02,94.8,0.95,ito:ITO_00101,Vision process,Accuracy
687,1,Domain Generalization,PACS,2019-11,AlexNet,73.55,88.25,73.55,0.88,83.34,0.74,ito:ITO_00101,Vision process,Accuracy
688,1,Domain Generalization,PACS,2019-11,ResNet18,83.34,100.0,9.8,0.12,83.34,0.83,ito:ITO_00101,Vision process,Accuracy
689,1,Image Classification,Imbalanced CUB-200-2011,2019-11,PC-Softmax,89.73,100.0,89.73,1.0,89.73,0.9,ito:ITO_00101,Vision process,Accuracy
690,1,Fine-Grained Image Classification,Imbalanced CUB-200-2011,2019-11,PC-Softmax,89.73,100.0,89.73,1.0,89.73,0.9,ito:ITO_00101,Vision process,Accuracy
691,1,Few-Shot Image Classification,Mini-ImageNet to CUB,2020-03,Neg-Margin,69.3,100.0,69.3,1.0,69.3,0.69,ito:ITO_00101,Vision process,Accuracy
692,1,Event data classification,CIFAR10-DVS,2020-03,DeepResidualSNN,68.3,100.0,68.3,1.0,68.3,0.68,ito:ITO_00101,Vision process,Accuracy
693,1,Small Data,"CIFAR-100, 1000 Labels",2020-03,cGLO,28.55,100.0,28.55,1.0,28.55,0.29,ito:ITO_00101,Vision process,Accuracy
694,1,Small Data,"CUB-200-2011, 5 samples per class",2020-03,cGLO,51.52,100.0,51.52,1.0,51.52,0.52,ito:ITO_00101,Vision process,Accuracy
695,1,Small Data,"CUB-200-2011, 30 samples per class",2020-03,cGLO,77.75,100.0,77.75,1.0,77.75,0.78,ito:ITO_00101,Vision process,Accuracy
696,1,Handwritten Digit Recognition,MNIST,2020-04,CNN,96.95,100.0,96.95,1.0,96.95,0.97,ito:ITO_00101,Vision process,Accuracy
0,1,Image Classification,CIFAR-10,2012-02,MCDNN,88.8,89.36,88.8,0.89,99.37,0.89,ito:ITO_00101,Vision process,Percentage\\ correct
1,1,Image Classification,CIFAR-10,2012-12,GP EI,90.5,91.07,1.7,0.02,99.37,0.91,ito:ITO_00101,Vision process,Percentage\\ correct
2,1,Image Classification,CIFAR-10,2013-02,Maxout Network (k=2),90.65,91.22,0.2,0.0,99.37,0.91,ito:ITO_00101,Vision process,Percentage\\ correct
3,1,Image Classification,CIFAR-10,2013-12,Network in Network,91.2,91.78,0.5,0.01,99.37,0.92,ito:ITO_00101,Vision process,Percentage\\ correct
4,1,Image Classification,CIFAR-10,2014-09,DSN,91.8,92.38,0.6,0.01,99.37,0.92,ito:ITO_00101,Vision process,Percentage\\ correct
5,1,Image Classification,CIFAR-10,2014-09,SSCNN,93.7,94.29,1.9,0.02,99.37,0.94,ito:ITO_00101,Vision process,Percentage\\ correct
6,1,Image Classification,CIFAR-10,2014-12,Fractional MP,96.5,97.11,2.8,0.03,99.37,0.97,ito:ITO_00101,Vision process,Percentage\\ correct
7,1,Image Classification,CIFAR-10,2016-08,DenseNet (DenseNet-BC-190),96.54,97.15,0.0,0.0,99.37,0.97,ito:ITO_00101,Vision process,Percentage\\ correct
8,1,Image Classification,CIFAR-10,2016-10,Deep pyramidal residual network,96.69,97.3,0.1,0.0,99.37,0.97,ito:ITO_00101,Vision process,Percentage\\ correct
9,1,Image Classification,CIFAR-10,2017-09,SENet + ShakeShake + Cutout,97.88,98.5,1.2,0.01,99.37,0.99,ito:ITO_00101,Vision process,Percentage\\ correct
10,1,Image Classification,CIFAR-10,2018-11,GPIPE + transfer learning,99.0,99.63,1.1,0.01,99.37,1.0,ito:ITO_00101,Vision process,Percentage\\ correct
11,1,Image Classification,CIFAR-10,2019-12,BiT-L (ResNet),99.37,100.0,0.4,0.0,99.37,1.0,ito:ITO_00101,Vision process,Percentage\\ correct
12,1,Image Classification,CIFAR-100,2013-01,Stochastic Pooling,57.5,61.43,57.5,0.61,93.6,0.58,ito:ITO_00101,Vision process,Percentage\\ correct
13,1,Image Classification,CIFAR-100,2013-02,Maxout Network (k=2),61.43,65.63,3.9,0.04,93.6,0.62,ito:ITO_00101,Vision process,Percentage\\ correct
14,1,Image Classification,CIFAR-100,2013-12,Tree Priors,63.2,67.52,1.8,0.02,93.6,0.64,ito:ITO_00101,Vision process,Percentage\\ correct
15,1,Image Classification,CIFAR-100,2013-12,NiN,64.3,68.7,1.1,0.01,93.6,0.65,ito:ITO_00101,Vision process,Percentage\\ correct
16,1,Image Classification,CIFAR-100,2014-09,DSN,65.4,69.87,1.1,0.01,93.6,0.66,ito:ITO_00101,Vision process,Percentage\\ correct
17,1,Image Classification,CIFAR-100,2014-09,SSCNN,75.7,80.88,10.3,0.11,93.6,0.76,ito:ITO_00101,Vision process,Percentage\\ correct
18,1,Image Classification,CIFAR-100,2016-03,ResNet-1001,77.3,82.59,1.6,0.02,93.6,0.78,ito:ITO_00101,Vision process,Percentage\\ correct
19,1,Image Classification,CIFAR-100,2016-05,Wide ResNet,81.15,86.7,3.9,0.04,93.6,0.82,ito:ITO_00101,Vision process,Percentage\\ correct
20,1,Image Classification,CIFAR-100,2016-08,DenseNet-BC,82.82,88.48,1.7,0.02,93.6,0.83,ito:ITO_00101,Vision process,Percentage\\ correct
21,1,Image Classification,CIFAR-100,2017-09,SENet + ShakeEven + Cutout,84.59,90.37,1.8,0.02,93.6,0.85,ito:ITO_00101,Vision process,Percentage\\ correct
22,1,Image Classification,CIFAR-100,2018-05,PyramidNet+ShakeDrop,89.3,95.41,4.7,0.05,93.6,0.9,ito:ITO_00101,Vision process,Percentage\\ correct
23,1,Image Classification,CIFAR-100,2018-11,GPIPE,91.3,97.54,2.0,0.02,93.6,0.92,ito:ITO_00101,Vision process,Percentage\\ correct
24,1,Image Classification,CIFAR-100,2019-05,EfficientNet-B7,91.7,97.97,0.4,0.0,93.6,0.92,ito:ITO_00101,Vision process,Percentage\\ correct
25,1,Image Classification,CIFAR-100,2019-12,BiT-M (ResNet),92.17,98.47,0.5,0.01,93.6,0.93,ito:ITO_00101,Vision process,Percentage\\ correct
26,1,Image Classification,CIFAR-100,2019-12,BiT-L (ResNet),93.6,100.0,1.4,0.01,93.6,0.94,ito:ITO_00101,Vision process,Percentage\\ correct
27,1,Image Classification,STL-10,2013-12,Multi-Task Bayesian Optimization,70.1,73.42,70.1,0.73,95.48,0.71,ito:ITO_00101,Vision process,Percentage\\ correct
28,1,Image Classification,STL-10,2014-12,Discriminative Unsupervised Feature Learning with Convolutional Neural Networks,72.8,76.25,2.7,0.03,95.48,0.73,ito:ITO_00101,Vision process,Percentage\\ correct
29,1,Image Classification,STL-10,2015-06,SWWAE,74.3,77.82,1.5,0.02,95.48,0.75,ito:ITO_00101,Vision process,Percentage\\ correct
30,1,Image Classification,STL-10,2016-11,CC-GAN²,77.8,81.48,3.5,0.04,95.48,0.78,ito:ITO_00101,Vision process,Percentage\\ correct
31,1,Image Classification,STL-10,2017-08,Cutout,87.26,91.39,9.5,0.1,95.48,0.88,ito:ITO_00101,Vision process,Percentage\\ correct
32,1,Image Classification,STL-10,2018-07,IIC,88.8,93.0,1.5,0.02,95.48,0.89,ito:ITO_00101,Vision process,Percentage\\ correct
33,1,Image Classification,STL-10,2019-04,Harmonic WRN-16-8,90.45,94.73,1.7,0.02,95.48,0.91,ito:ITO_00101,Vision process,Percentage\\ correct
34,1,Image Classification,STL-10,2019-05,MixMatch,94.41,98.88,4.0,0.04,95.48,0.95,ito:ITO_00101,Vision process,Percentage\\ correct
35,1,Image Classification,STL-10,2019-06,AMDIM,94.5,98.97,0.1,0.0,95.48,0.95,ito:ITO_00101,Vision process,Percentage\\ correct
36,1,Image Classification,STL-10,2019-11,EnAET,95.48,100.0,1.0,0.01,95.48,0.96,ito:ITO_00101,Vision process,Percentage\\ correct
37,1,Visual Question Answering,Visual7W,2016-06,MCB+Att.,62.2,85.76,62.2,0.86,72.53,0.63,ito:ITO_00101,Vision process,Percentage\\ correct
38,1,Visual Question Answering,Visual7W,2016-11,CMN,72.53,100.0,10.3,0.14,72.53,0.73,ito:ITO_00101,Vision process,Percentage\\ correct
39,1,Semi-Supervised Image Classification,"cifar10, 250 Labels",2017-04,VAT,63.97,68.25,63.97,0.68,93.73,0.64,ito:ITO_00101,Vision process,Percentage\\ correct
40,1,Semi-Supervised Image Classification,"cifar10, 250 Labels",2019-11,ReMixMatch,93.73,100.0,29.8,0.32,93.73,0.94,ito:ITO_00101,Vision process,Percentage\\ correct
41,1,Semi-Supervised Image Classification,"CIFAR-100, 5000Labels",2019-11,EnAET,68.17,100.0,68.17,1.0,68.17,0.69,ito:ITO_00101,Vision process,Percentage\\ correct
42,1,Semi-Supervised Image Classification,"CIFAR-100, 1000 Labels",2019-11,EnAET,41.27,100.0,41.27,1.0,41.27,0.42,ito:ITO_00101,Vision process,Percentage\\ correct
0,1,Motion Segmentation,Hopkins155,2012-03,SSC,2.18,100.0,2.18,1.0,2.18,0.25,ito:ITO_00101,Vision process,Classification\\ Error
1,1,Image-to-Image Translation,RaFD,2016-10,DIA,4.1,50.81,4.1,0.51,8.07,0.46,ito:ITO_00101,Vision process,Classification\\ Error
2,1,Image-to-Image Translation,RaFD,2016-11,IcGAN,8.07,100.0,4.0,0.5,8.07,0.91,ito:ITO_00101,Vision process,Classification\\ Error
3,1,Superpixel Image Classification,75 Superpixel MNIST,2016-11,Monet,8.89,100.0,8.89,1.0,8.89,1.0,ito:ITO_00101,Vision process,Classification\\ Error
4,1,Image Classification,smallNORB,2017-10,CapsNet,3.77,100.0,3.77,1.0,3.77,0.42,ito:ITO_00101,Vision process,Classification\\ Error
5,1,Motion Segmentation,MTPV62,2018-04,MVC,0.65,100.0,0.65,1.0,0.65,0.07,ito:ITO_00101,Vision process,Classification\\ Error
0,1,Image Clustering,MNIST-test,2012-08,GDL,0.91,94.5,0.91,0.94,0.963,0.91,ito:ITO_00101,Vision process,NMI
1,1,Image Clustering,MNIST-test,2016-04,OURS-RC,0.915,95.02,0.0,0.0,0.963,0.92,ito:ITO_00101,Vision process,NMI
2,1,Image Clustering,MNIST-test,2018-12,DDC-DA,0.927,96.26,0.0,0.0,0.963,0.93,ito:ITO_00101,Vision process,NMI
3,1,Image Clustering,MNIST-test,2019-01,DynAE,0.963,100.0,0.0,0.0,0.963,0.96,ito:ITO_00101,Vision process,NMI
4,1,Image Clustering,Extended Yale-B,2012-08,GDL-U,0.91,92.11,0.91,0.92,0.988,0.91,ito:ITO_00101,Vision process,NMI
5,1,Image Clustering,Extended Yale-B,2017-09,DSC-2,0.97,98.18,0.1,0.1,0.988,0.97,ito:ITO_00101,Vision process,NMI
6,1,Image Clustering,Extended Yale-B,2018-04,DMSC,0.988,100.0,0.0,0.0,0.988,0.99,ito:ITO_00101,Vision process,NMI
7,1,Image Clustering,coil-100,2012-08,AGDL,0.933,94.72,0.933,0.95,0.985,0.93,ito:ITO_00101,Vision process,NMI
8,1,Image Clustering,coil-100,2016-04,JULE-RC,0.985,100.0,0.1,0.1,0.985,0.98,ito:ITO_00101,Vision process,NMI
9,1,Image Clustering,Coil-20,2012-08,AGDL,0.937,93.7,0.937,0.94,1.0,0.94,ito:ITO_00101,Vision process,NMI
10,1,Image Clustering,Coil-20,2016-04,JULE-RC,1.0,100.0,0.1,0.1,1.0,1.0,ito:ITO_00101,Vision process,NMI
11,1,Image Clustering,Fashion-MNIST,2012-08,GDL,0.66,96.49,0.66,0.96,0.684,0.66,ito:ITO_00101,Vision process,NMI
12,1,Image Clustering,Fashion-MNIST,2018-12,DDC,0.682,99.71,0.0,0.0,0.684,0.68,ito:ITO_00101,Vision process,NMI
13,1,Image Clustering,Fashion-MNIST,2019-08,N2D (UMAP),0.684,100.0,0.0,0.0,0.684,0.68,ito:ITO_00101,Vision process,NMI
14,1,Image Clustering,USPS,2012-08,GDL-U,0.824,86.92,0.824,0.87,0.948,0.82,ito:ITO_00101,Vision process,NMI
15,1,Image Clustering,USPS,2016-04,JULE-RC,0.913,96.31,0.1,0.11,0.948,0.91,ito:ITO_00101,Vision process,NMI
16,1,Image Clustering,USPS,2018-04,DMSC,0.929,98.0,0.0,0.0,0.948,0.93,ito:ITO_00101,Vision process,NMI
17,1,Image Clustering,USPS,2018-10,SR-K-means,0.936,98.73,0.0,0.0,0.948,0.94,ito:ITO_00101,Vision process,NMI
18,1,Image Clustering,USPS,2018-12,DDC-DA,0.939,99.05,0.0,0.0,0.948,0.94,ito:ITO_00101,Vision process,NMI
19,1,Image Clustering,USPS,2019-01,DynAE,0.948,100.0,0.0,0.0,0.948,0.95,ito:ITO_00101,Vision process,NMI
20,1,Image Clustering,MNIST-full,2012-08,GDL,0.91,94.4,0.91,0.94,0.964,0.91,ito:ITO_00101,Vision process,NMI
21,1,Image Clustering,MNIST-full,2016-04,JULE-RC,0.913,94.71,0.0,0.0,0.964,0.91,ito:ITO_00101,Vision process,NMI
22,1,Image Clustering,MNIST-full,2017-03,DBC,0.917,95.12,0.0,0.0,0.964,0.92,ito:ITO_00101,Vision process,NMI
23,1,Image Clustering,MNIST-full,2018-12,DDC-DA,0.941,97.61,0.0,0.0,0.964,0.94,ito:ITO_00101,Vision process,NMI
24,1,Image Clustering,MNIST-full,2019-01,DynAE,0.964,100.0,0.0,0.0,0.964,0.96,ito:ITO_00101,Vision process,NMI
25,1,Image Clustering,STL-10,2013-12,VAE,0.2,53.19,0.2,0.53,0.376,0.2,ito:ITO_00101,Vision process,NMI
26,1,Image Clustering,STL-10,2015-11,DEC,0.276,73.4,0.1,0.27,0.376,0.28,ito:ITO_00101,Vision process,NMI
27,1,Image Clustering,STL-10,2017-10,DAC,0.366,97.34,0.1,0.27,0.376,0.37,ito:ITO_00101,Vision process,NMI
28,1,Image Clustering,STL-10,2019-04,DCCM,0.376,100.0,0.0,0.0,0.376,0.38,ito:ITO_00101,Vision process,NMI
29,1,Image Clustering,Tiny-ImageNet,2013-12,VAE,0.113,50.45,0.113,0.5,0.224,0.11,ito:ITO_00101,Vision process,NMI
30,1,Image Clustering,Tiny-ImageNet,2015-11,GAN,0.135,60.27,0.0,0.0,0.224,0.14,ito:ITO_00101,Vision process,NMI
31,1,Image Clustering,Tiny-ImageNet,2017-10,DAC,0.19,84.82,0.1,0.45,0.224,0.19,ito:ITO_00101,Vision process,NMI
32,1,Image Clustering,Tiny-ImageNet,2019-04,DCCM,0.224,100.0,0.0,0.0,0.224,0.22,ito:ITO_00101,Vision process,NMI
33,1,Image Clustering,ImageNet-10,2013-12,VAE,0.193,31.74,0.193,0.32,0.608,0.19,ito:ITO_00101,Vision process,NMI
34,1,Image Clustering,ImageNet-10,2015-11,DEC,0.282,46.38,0.1,0.16,0.608,0.28,ito:ITO_00101,Vision process,NMI
35,1,Image Clustering,ImageNet-10,2017-10,DAC,0.394,64.8,0.1,0.16,0.608,0.39,ito:ITO_00101,Vision process,NMI
36,1,Image Clustering,ImageNet-10,2019-04,DCCM,0.608,100.0,0.2,0.33,0.608,0.61,ito:ITO_00101,Vision process,NMI
37,1,Image Clustering,CIFAR-10,2013-12,VAE,0.245,47.95,0.245,0.48,0.511,0.24,ito:ITO_00101,Vision process,NMI
38,1,Image Clustering,CIFAR-10,2015-11,GAN,0.265,51.86,0.0,0.0,0.511,0.26,ito:ITO_00101,Vision process,NMI
39,1,Image Clustering,CIFAR-10,2017-10,DAC,0.396,77.5,0.1,0.2,0.511,0.4,ito:ITO_00101,Vision process,NMI
40,1,Image Clustering,CIFAR-10,2017-10,DAC,0.4,78.28,0.0,0.0,0.511,0.4,ito:ITO_00101,Vision process,NMI
41,1,Image Clustering,CIFAR-10,2018-07,IIC,0.511,100.0,0.1,0.2,0.511,0.51,ito:ITO_00101,Vision process,NMI
42,1,Image Clustering,CIFAR-100,2013-12,VAE,0.108,37.89,0.108,0.38,0.285,0.11,ito:ITO_00101,Vision process,NMI
43,1,Image Clustering,CIFAR-100,2015-11,DEC,0.136,47.72,0.0,0.0,0.285,0.14,ito:ITO_00101,Vision process,NMI
44,1,Image Clustering,CIFAR-100,2017-10,DAC,0.185,64.91,0.0,0.0,0.285,0.18,ito:ITO_00101,Vision process,NMI
45,1,Image Clustering,CIFAR-100,2019-04,DCCM,0.285,100.0,0.1,0.35,0.285,0.28,ito:ITO_00101,Vision process,NMI
46,1,Image Clustering,Imagenet-dog-15,2013-12,VAE,0.107,33.33,0.107,0.33,0.321,0.11,ito:ITO_00101,Vision process,NMI
47,1,Image Clustering,Imagenet-dog-15,2015-11,DEC,0.122,38.01,0.0,0.0,0.321,0.12,ito:ITO_00101,Vision process,NMI
48,1,Image Clustering,Imagenet-dog-15,2017-10,DAC,0.219,68.22,0.1,0.31,0.321,0.22,ito:ITO_00101,Vision process,NMI
49,1,Image Clustering,Imagenet-dog-15,2019-04,DCCM,0.321,100.0,0.1,0.31,0.321,0.32,ito:ITO_00101,Vision process,NMI
50,1,Image Clustering,CMU-PIE,2015-11,DEC (KL based),0.924,92.4,0.924,0.92,1.0,0.92,ito:ITO_00101,Vision process,NMI
51,1,Image Clustering,CMU-PIE,2016-04,JULE-RC,1.0,100.0,0.1,0.1,1.0,1.0,ito:ITO_00101,Vision process,NMI
52,1,Image Clustering,YouTube Faces DB,2015-11,DEC (KL based),0.446,52.59,0.446,0.53,0.848,0.45,ito:ITO_00101,Vision process,NMI
53,1,Image Clustering,YouTube Faces DB,2016-04,JULE-RC,0.848,100.0,0.4,0.47,0.848,0.85,ito:ITO_00101,Vision process,NMI
54,1,Image Clustering,CUB Birds,2016-04,JULE,0.203,50.37,0.203,0.5,0.403,0.2,ito:ITO_00101,Vision process,NMI
55,1,Image Clustering,CUB Birds,2017-04,DEPICT-Large,0.297,73.7,0.1,0.25,0.403,0.3,ito:ITO_00101,Vision process,NMI
56,1,Image Clustering,CUB Birds,2018-11,FineGAN,0.403,100.0,0.1,0.25,0.403,0.4,ito:ITO_00101,Vision process,NMI
57,1,Image Clustering,UMist,2016-04,JULE-RC,0.877,100.0,0.877,1.0,0.877,0.88,ito:ITO_00101,Vision process,NMI
58,1,Image Clustering,Stanford Cars,2016-04,JULE,0.232,65.54,0.232,0.66,0.354,0.23,ito:ITO_00101,Vision process,NMI
59,1,Image Clustering,Stanford Cars,2017-04,DEPICT,0.329,92.94,0.1,0.28,0.354,0.33,ito:ITO_00101,Vision process,NMI
60,1,Image Clustering,Stanford Cars,2017-04,DEPICT-Large,0.33,93.22,0.0,0.0,0.354,0.33,ito:ITO_00101,Vision process,NMI
61,1,Image Clustering,Stanford Cars,2018-11,FineGAN,0.354,100.0,0.0,0.0,0.354,0.35,ito:ITO_00101,Vision process,NMI
62,1,Image Clustering,FRGC,2016-04,JULE-RC,0.574,98.46,0.574,0.98,0.583,0.57,ito:ITO_00101,Vision process,NMI
63,1,Image Clustering,FRGC,2017-04,DEPICT,0.583,100.0,0.0,0.0,0.583,0.58,ito:ITO_00101,Vision process,NMI
64,1,Image Clustering,Stanford Dogs,2016-04,JULE,0.142,60.94,0.142,0.61,0.233,0.14,ito:ITO_00101,Vision process,NMI
65,1,Image Clustering,Stanford Dogs,2017-04,DEPICT-Large,0.183,78.54,0.0,0.0,0.233,0.18,ito:ITO_00101,Vision process,NMI
66,1,Image Clustering,Stanford Dogs,2018-11,FineGAN,0.233,100.0,0.1,0.43,0.233,0.23,ito:ITO_00101,Vision process,NMI
67,1,Image Clustering,LetterA-J,2018-12,DDC-DA,0.629,100.0,0.629,1.0,0.629,0.63,ito:ITO_00101,Vision process,NMI
68,1,Image Clustering,pendigits,2019-08,N2D (UMAP),0.863,100.0,0.863,1.0,0.863,0.86,ito:ITO_00101,Vision process,NMI
69,1,Image Clustering,HAR,2019-08,N2D (UMAP),0.683,100.0,0.683,1.0,0.683,0.68,ito:ITO_00101,Vision process,NMI
0,1,Image Classification,ImageNet,2012-12,AlexNet,63.3,71.53,63.3,0.72,88.5,0.66,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
1,1,Image Classification,ImageNet,2013-11,"ZFNet (ensemble, 6 convnets)",64.0,72.32,0.7,0.01,88.5,0.66,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
2,1,Image Classification,ImageNet,2013-12,Five Base + Five HiRes,66.3,74.92,2.3,0.03,88.5,0.69,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
3,1,Image Classification,ImageNet,2014-06,MSRA,71.32,80.59,5.0,0.06,88.5,0.74,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
4,1,Image Classification,ImageNet,2014-06,SPPNet,72.14,81.51,0.8,0.01,88.5,0.75,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
5,1,Image Classification,ImageNet,2014-09,VGG-19,74.5,84.18,2.4,0.03,88.5,0.77,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
6,1,Image Classification,ImageNet,2015-02,PReLU-Net,75.73,85.57,1.2,0.01,88.5,0.78,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
7,1,Image Classification,ImageNet,2015-12,Inception V3,78.8,89.04,3.1,0.04,88.5,0.82,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
8,1,Image Classification,ImageNet,2015-12,ResNet-152,80.62,91.1,1.8,0.02,88.5,0.83,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
9,1,Image Classification,ImageNet,2016-11,ResNeXt-101  64x4,80.9,91.41,0.3,0.0,88.5,0.84,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
10,1,Image Classification,ImageNet,2017-07,DPN-131 (320x320),81.38,91.95,0.5,0.01,88.5,0.84,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
11,1,Image Classification,ImageNet,2017-07,NASNET-A(6),82.7,93.45,1.3,0.01,88.5,0.86,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
12,1,Image Classification,ImageNet,2017-12,PNASNet-5,82.9,93.67,0.2,0.0,88.5,0.86,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
13,1,Image Classification,ImageNet,2018-02,AmoebaNet-A,83.9,94.8,1.0,0.01,88.5,0.87,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
14,1,Image Classification,ImageNet,2018-05,ResNeXt-101 32×16d,84.2,95.14,0.3,0.0,88.5,0.87,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
15,1,Image Classification,ImageNet,2018-05,ResNeXt-101 32x48d,85.4,96.5,1.2,0.01,88.5,0.88,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
16,1,Image Classification,ImageNet,2019-06,FixResNeXt-101 32x48d,86.4,97.63,1.0,0.01,88.5,0.89,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
17,1,Image Classification,ImageNet,2019-11,NoisyStudent (EfficientNet-L2),88.4,99.89,2.0,0.02,88.5,0.92,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
18,1,Image Classification,ImageNet,2020-03,FixEfficientNet-L2,88.5,100.0,0.1,0.0,88.5,0.92,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
19,1,Self-Supervised Image Classification,ImageNet,2016-03,Colorization [zhang2016colorful],35.2,46.01,35.2,0.46,76.5,0.36,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
20,1,Self-Supervised Image Classification,ImageNet,2018-06,InstDisc (ResNet-50),54.0,70.59,18.8,0.25,76.5,0.56,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
21,1,Self-Supervised Image Classification,ImageNet,2019-01,Revisited Rotation (RevNet-50 ×4),55.4,72.42,1.4,0.02,76.5,0.57,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
22,1,Self-Supervised Image Classification,ImageNet,2019-06,AMDIM (small),63.5,83.01,8.1,0.11,76.5,0.66,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
23,1,Self-Supervised Image Classification,ImageNet,2019-06,AMDIM (large),68.1,89.02,4.6,0.06,76.5,0.7,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
24,1,Self-Supervised Image Classification,ImageNet,2019-06,CMC (ResNet-50 x2),70.6,92.29,2.5,0.03,76.5,0.73,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
25,1,Self-Supervised Image Classification,ImageNet,2020-01,CPC v2 (ResNet-161),71.5,93.46,0.9,0.01,76.5,0.74,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
26,1,Self-Supervised Image Classification,ImageNet,2020-02,SimCLR (ResNet-50 4x),76.5,100.0,5.0,0.07,76.5,0.79,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
27,1,Action Classification,Moments in Time,2017-05,I3D,29.51,86.11,29.51,0.86,34.27,0.31,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
28,1,Action Classification,Moments in Time,2018-11,EvaNet,31.8,92.79,2.3,0.07,34.27,0.33,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
29,1,Action Classification,Moments in Time,2019-05,AssembleNet,34.27,100.0,2.5,0.07,34.27,0.35,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
30,1,Image Classification,iNaturalist,2017-07,IncResNetV2 SE,67.3,89.26,67.3,0.89,75.4,0.7,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
31,1,Image Classification,iNaturalist,2019-06,FixSENet-154,75.4,100.0,8.1,0.11,75.4,0.78,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
32,1,Action Recognition,Something-Something V1,2017-11,NL I3D,44.4,80.49,44.4,0.8,55.16,0.46,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
33,1,Action Recognition,Something-Something V1,2017-12,S3D-G (ImageNet pretrained),48.2,87.38,3.8,0.07,55.16,0.5,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
34,1,Action Recognition,Something-Something V1,2018-01,ResNet50 I3D (Moments pretrained),50.0,90.65,1.8,0.03,55.16,0.52,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
35,1,Action Recognition,Something-Something V1,2018-11,TSM (RGB + Flow),50.7,91.91,0.7,0.01,55.16,0.52,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
36,1,Action Recognition,Something-Something V1,2019-04,R(2+1)D-152 (IG-65M pretraining),51.6,93.55,0.9,0.02,55.16,0.53,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
37,1,Action Recognition,Something-Something V1,2019-04,ip-CSN-152 (IG-65M pretraining),53.3,96.63,1.7,0.03,55.16,0.55,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
38,1,Action Recognition,Something-Something V1,2019-08,"GB + DF + LB (ResNet152, ImageNet pretrained)",53.4,96.81,0.1,0.0,55.16,0.55,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
39,1,Action Recognition,Something-Something V1,2019-12,GSM Ensemble InceptionV3 (ImageNet pretrained),55.16,100.0,1.8,0.03,55.16,0.57,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
40,1,Action Recognition In Videos,Something-Something V1,2017-11,2-Stream TRN,42.01,76.16,42.01,0.76,55.16,0.43,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
41,1,Action Recognition In Videos,Something-Something V1,2017-12,S3D-G (ImageNet pretrained),48.2,87.38,6.2,0.11,55.16,0.5,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
42,1,Action Recognition In Videos,Something-Something V1,2018-01,ResNet50 I3D (Moments pretrained),50.0,90.65,1.8,0.03,55.16,0.52,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
43,1,Action Recognition In Videos,Something-Something V1,2018-11,TSM (RGB + Flow),50.7,91.91,0.7,0.01,55.16,0.52,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
44,1,Action Recognition In Videos,Something-Something V1,2019-06,"MARS+RGB+Flow (64 frames, Kinetics pretrained)",53.0,96.08,2.3,0.04,55.16,0.55,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
45,1,Action Recognition In Videos,Something-Something V1,2019-08,"GB + DF + LB (ResNet152, ImageNet pretrained)",53.4,96.81,0.4,0.01,55.16,0.55,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
46,1,Action Recognition In Videos,Something-Something V1,2019-12,GSM Ensemble InceptionV3 (ImageNet pretrained),55.16,100.0,1.8,0.03,55.16,0.57,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
47,1,Hand Gesture Recognition,Jester test,2017-11,Multiscale TRN,94.78,98.12,94.78,0.98,96.6,0.98,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
48,1,Hand Gesture Recognition,Jester test,2018-04,DRX3D,96.6,100.0,1.8,0.02,96.6,1.0,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
49,1,Hand Gesture Recognition,Jester val,2018-04,8-MFFs-3f1c (5 crop),96.33,100.0,96.33,1.0,96.33,1.0,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
50,1,Fine-Grained Image Classification,iNaturalist,2019-03,TASN,68.2,100.0,68.2,1.0,68.2,0.71,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
51,1,Semi-Supervised Image Classification,ImageNet,2019-05,S4L-MOAM (ResNet-50 4×),73.21,100.0,73.21,1.0,73.21,0.76,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
52,1,Semi-Supervised Image Classification,ImageNet,2020-01,CPC v2 (ResNet-161),52.7,100.0,52.7,1.0,52.7,0.55,ito:ITO_00101,Vision process,Top\\ 1\\ Accuracy
0,1,Image Classification,ImageNet,2012-12,AlexNet,84.6,85.71,84.6,0.86,98.7,0.85,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
1,1,Image Classification,ImageNet,2013-11,"ZFNet (ensemble, 6 convnets)",85.3,86.42,0.7,0.01,98.7,0.85,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
2,1,Image Classification,ImageNet,2013-12,Five Base + Five HiRes,86.3,87.44,1.0,0.01,98.7,0.86,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
3,1,Image Classification,ImageNet,2013-12,OverFeat,86.76,87.9,0.5,0.01,98.7,0.87,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
4,1,Image Classification,ImageNet,2014-06,SPPNet,91.86,93.07,5.1,0.05,98.7,0.92,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
5,1,Image Classification,ImageNet,2014-09,VGG-16,91.9,93.11,0.0,0.0,98.7,0.92,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
6,1,Image Classification,ImageNet,2014-09,VGG-19,92.0,93.21,0.1,0.0,98.7,0.92,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
7,1,Image Classification,ImageNet,2015-02,PReLU-Net,92.62,93.84,0.6,0.01,98.7,0.93,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
8,1,Image Classification,ImageNet,2015-12,ResNet-50,93.29,94.52,0.7,0.01,98.7,0.93,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
9,1,Image Classification,ImageNet,2015-12,ResNet-152 (60M),94.29,95.53,1.0,0.01,98.7,0.94,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
10,1,Image Classification,ImageNet,2015-12,ResNet-152,95.51,96.77,1.2,0.01,98.7,0.96,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
11,1,Image Classification,ImageNet,2016-11,ResNeXt-101  64x4,95.6,96.86,0.1,0.0,98.7,0.96,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
12,1,Image Classification,ImageNet,2017-07,DPN-131 (320x320),95.77,97.03,0.2,0.0,98.7,0.96,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
13,1,Image Classification,ImageNet,2017-07,NASNET-A(6),96.2,97.47,0.4,0.0,98.7,0.96,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
14,1,Image Classification,ImageNet,2018-02,AmoebaNet-A,96.6,97.87,0.4,0.0,98.7,0.97,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
15,1,Image Classification,ImageNet,2018-05,ResNeXt-101 32×16d,97.2,98.48,0.6,0.01,98.7,0.97,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
16,1,Image Classification,ImageNet,2018-05,ResNeXt-101 32x48d,97.6,98.89,0.4,0.0,98.7,0.98,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
17,1,Image Classification,ImageNet,2019-06,FixResNeXt-101 32x48d,98.0,99.29,0.4,0.0,98.7,0.98,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
18,1,Image Classification,ImageNet,2019-11,NoisyStudent (EfficientNet-B7),98.1,99.39,0.1,0.0,98.7,0.98,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
19,1,Image Classification,ImageNet,2019-11,NoisyStudent (EfficientNet-L2),98.7,100.0,0.6,0.01,98.7,0.99,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
20,1,Semi-Supervised Image Classification,ImageNet,2017-03,Mean Teacher (ResNeXt-152),90.89,98.15,90.89,0.98,92.6,0.91,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
21,1,Semi-Supervised Image Classification,ImageNet,2019-05,S4L-MOAM (ResNet-50 4×),91.23,98.52,0.3,0.0,92.6,0.91,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
22,1,Semi-Supervised Image Classification,ImageNet,2020-02,SimCLR (ResNet-50 4×),92.6,100.0,1.4,0.02,92.6,0.93,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
23,1,Action Classification,Moments in Time,2017-05,TSN-2Stream,50.1,79.89,50.1,0.8,62.71,0.5,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
24,1,Action Classification,Moments in Time,2017-05,I3D,56.06,89.4,6.0,0.1,62.71,0.56,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
25,1,Action Classification,Moments in Time,2019-05,AssembleNet,62.71,100.0,6.6,0.11,62.71,0.63,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
26,1,Image Classification,iNaturalist,2017-07,IncResNetV2 SE,87.5,100.0,87.5,1.0,87.5,0.88,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
27,1,Action Recognition,Something-Something V1,2017-12,S3D-G (ImageNet pretrained),78.7,91.41,78.7,0.91,86.1,0.79,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
28,1,Action Recognition,Something-Something V1,2019-08,TRG (ResNet-50),86.1,100.0,7.4,0.09,86.1,0.86,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
29,1,Hand Gesture Recognition,Jester val,2018-04,8-MFFs-3f1c (5 crop),99.86,100.0,99.86,1.0,99.86,1.0,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
30,1,Semi-Supervised Image Classification,ImageNet,2018-06,Instance Discrimination,39.2,45.69,39.2,0.46,85.8,0.39,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
31,1,Semi-Supervised Image Classification,ImageNet,2018-07,CPC,64.03,74.63,24.8,0.29,85.8,0.64,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
32,1,Semi-Supervised Image Classification,ImageNet,2020-01,CPC v2 (ResNet-161),77.9,90.79,13.9,0.16,85.8,0.78,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
33,1,Semi-Supervised Image Classification,ImageNet,2020-02,SimCLR (ResNet-50 4×),85.8,100.0,7.9,0.09,85.8,0.86,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
34,1,Self-Supervised Image Classification,ImageNet,2018-07,CPC (ResNet-V2),73.6,78.97,73.6,0.79,93.2,0.74,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
35,1,Self-Supervised Image Classification,ImageNet,2019-01,Revisited Rotation (RevNet-50 ×4),77.9,83.58,4.3,0.05,93.2,0.78,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
36,1,Self-Supervised Image Classification,ImageNet,2019-06,CMC (ResNet-101)-deprecated,86.0,92.27,8.1,0.09,93.2,0.86,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
37,1,Self-Supervised Image Classification,ImageNet,2019-06,CMC (ResNet-50 x2),89.7,96.24,3.7,0.04,93.2,0.9,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
38,1,Self-Supervised Image Classification,ImageNet,2020-01,CPC v2 (ResNet-161),90.1,96.67,0.4,0.0,93.2,0.9,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
39,1,Self-Supervised Image Classification,ImageNet,2020-02,SimCLR (ResNet-50 4x),93.2,100.0,3.1,0.03,93.2,0.93,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
40,1,Action Recognition In Videos,Something-Something V1,2019-08,TRG (ResNet-50),86.1,100.0,86.1,1.0,86.1,0.86,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
41,1,Image Classification,ObjectNet,2019-12,NASNet-A,56.4,70.5,56.4,0.7,80.0,0.56,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
42,1,Image Classification,ObjectNet,2019-12,BiT-L (ResNet-152x4),80.0,100.0,23.6,0.3,80.0,0.8,ito:ITO_00101,Vision process,Top\\ 5\\ Accuracy
0,1,Image Classification,ImageNet,2012-12,AlexNet,60000000.0,6.47,60000000,0.06,928000000,0.06,ito:ITO_00101,Vision process,Number\\ of\\ params
1,1,Image Classification,ImageNet,2014-09,VGG-19,144000000.0,15.52,84000000,0.09,928000000,0.16,ito:ITO_00101,Vision process,Number\\ of\\ params
2,1,Image Classification,ImageNet,2018-02,AmoebaNet-A,469000000.0,50.54,325000000,0.35,928000000,0.51,ito:ITO_00101,Vision process,Number\\ of\\ params
3,1,Image Classification,ImageNet,2018-05,ResNeXt-101 32x48d,829000000.0,89.33,360000000,0.39,928000000,0.89,ito:ITO_00101,Vision process,Number\\ of\\ params
4,1,Image Classification,ImageNet,2019-12,BiT-M (ResNet),928000000.0,100.0,99000000,0.11,928000000,1.0,ito:ITO_00101,Vision process,Number\\ of\\ params
0,1,Action Recognition In Videos,UCF101,2012-12,Baseline UCF101,43.9,44.7,43.9,0.45,98.2,0.45,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
1,1,Action Recognition In Videos,UCF101,2014-05,iDT+HSV,87.9,89.51,44.0,0.45,98.2,0.9,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
2,1,Action Recognition In Videos,UCF101,2014-06,Two-stream,88.0,89.61,0.1,0.0,98.2,0.9,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
3,1,Action Recognition In Videos,UCF101,2015-03,Two-stream+LSTM,88.6,90.22,0.6,0.01,98.2,0.9,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
4,1,Action Recognition In Videos,UCF101,2015-07,Very deep two-stream ConvNet,91.4,93.08,2.8,0.03,98.2,0.93,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
5,1,Action Recognition In Videos,UCF101,2016-04,LTC,91.7,93.38,0.3,0.0,98.2,0.93,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
6,1,Action Recognition In Videos,UCF101,2016-04,"S:VGG-16, T:VGG-16",92.5,94.2,0.8,0.01,98.2,0.94,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
7,1,Action Recognition In Videos,UCF101,2017-03,TS-LSTM,94.1,95.82,1.6,0.02,98.2,0.96,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
8,1,Action Recognition In Videos,UCF101,2017-04,Hidden Two-Stream,97.1,98.88,3.0,0.03,98.2,0.99,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
9,1,Action Recognition In Videos,UCF101,2017-05,Two-stream I3D (on pre-trained),98.0,99.8,0.9,0.01,98.2,1.0,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
10,1,Action Recognition In Videos,UCF101,2019-06,LGD-3D Two-stream,98.2,100.0,0.2,0.0,98.2,1.0,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
11,1,Action Recognition,UCF101,2012-12,Baseline UCF101,43.9,44.7,43.9,0.45,98.2,0.45,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
12,1,Action Recognition,UCF101,2014-06,Two-Stream (ImageNet pretrained),88.0,89.61,44.1,0.45,98.2,0.9,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
13,1,Action Recognition,UCF101,2015-03,Two-stream+LSTM,88.6,90.22,0.6,0.01,98.2,0.9,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
14,1,Action Recognition,UCF101,2015-05,TDD + IDT,91.5,93.18,2.9,0.03,98.2,0.93,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
15,1,Action Recognition,UCF101,2016-04,LTC,91.7,93.38,0.2,0.0,98.2,0.93,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
16,1,Action Recognition,UCF101,2016-04,"S:VGG-16, T:VGG-16 (ImageNet pretrain)",92.5,94.2,0.8,0.01,98.2,0.94,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
17,1,Action Recognition,UCF101,2016-08,Temporal Segment Networks,94.2,95.93,1.7,0.02,98.2,0.96,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
18,1,Action Recognition,UCF101,2017-04,Hidden Two-Stream,97.1,98.88,2.9,0.03,98.2,0.99,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
19,1,Action Recognition,UCF101,2017-05,Two-Stream I3D (Imagenet+Kinetics pre-training),98.0,99.8,0.9,0.01,98.2,1.0,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
20,1,Action Recognition,UCF101,2019-06,LGD-3D Two-stream,98.2,100.0,0.2,0.0,98.2,1.0,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
21,1,Self-Supervised Action Recognition,UCF101,2016-09,VideoGan (C3D),52.1,88.61,52.1,0.89,58.8,0.53,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
22,1,Self-Supervised Action Recognition,UCF101,2019-04,Motion & Appearance (C3D),58.8,100.0,6.7,0.11,58.8,0.6,ito:ITO_00101,Vision process,3\\-fold\\ Accuracy
0,1,Few-Shot Image Classification,CUB-200-2011,2013-06,ALE,18.0,31.69,18.0,0.32,56.8,0.19,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
1,1,Few-Shot Image Classification,CUB-200-2011,2014-09,SJE,50.1,88.2,32.1,0.57,56.8,0.53,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
2,1,Few-Shot Image Classification,CUB-200-2011,2016-03,Synthesised Classifier,54.7,96.3,4.6,0.08,56.8,0.58,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
3,1,Few-Shot Image Classification,CUB-200-2011,2016-05,Word CNN-RNN (DS-SJE Embedding),56.8,100.0,2.1,0.04,56.8,0.6,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
4,1,Action Recognition,Something-Something V2,2017-06,model3D_1 with left-right augmentation and fps jitter,51.33,77.07,51.33,0.77,66.6,0.54,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
5,1,Action Recognition,Something-Something V2,2017-11,2-Stream TRN,55.52,83.36,4.2,0.06,66.6,0.59,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
6,1,Action Recognition,Something-Something V2,2018-11,TSM (RGB + Flow),66.6,100.0,11.1,0.17,66.6,0.71,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
7,1,Action Recognition In Videos,Something-Something V2,2017-06,model3D_1 with left-right augmentation and fps jitter,51.33,77.07,51.33,0.77,66.6,0.54,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
8,1,Action Recognition In Videos,Something-Something V2,2017-11,2-Stream TRN,55.52,83.36,4.2,0.06,66.6,0.59,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
9,1,Action Recognition In Videos,Something-Something V2,2018-11,TSM (RGB + Flow),66.6,100.0,11.1,0.17,66.6,0.71,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
10,1,Image Classification,iNaturalist 2018,2017-07,Inception-V3,60.2,100.0,60.2,1.0,60.2,0.64,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
11,1,Action Classification,Kinetics-600,2017-12,S3D-G (Flow),69.7,83.87,69.7,0.84,83.1,0.74,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
12,1,Action Classification,Kinetics-600,2017-12,S3D-G (RGB),76.6,92.18,6.9,0.08,83.1,0.81,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
13,1,Action Classification,Kinetics-600,2017-12,S3D-G (RGB+Flow),78.6,94.58,2.0,0.02,83.1,0.83,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
14,1,Action Classification,Kinetics-600,2018-12,SlowFast 16x8 (ResNet-101),81.1,97.59,2.5,0.03,83.1,0.86,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
15,1,Action Classification,Kinetics-600,2018-12,SlowFast 16x8 (ResNet-101 + NL),81.8,98.44,0.7,0.01,83.1,0.87,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
16,1,Action Classification,Kinetics-600,2019-06,LGD-3D Two-stream* (ResNet-101),82.7,99.52,0.9,0.01,83.1,0.88,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
17,1,Action Classification,Kinetics-600,2019-06,LGD-3D Two-stream,83.1,100.0,0.4,0.0,83.1,0.88,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
18,1,Action Recognition,Something-Something V1,2017-12,S3D,47.3,100.0,47.3,1.0,47.3,0.5,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
19,1,Self-Supervised Action Recognition,HMDB51,2019-04,Motion & Appearance (C3D),20.3,100.0,20.3,1.0,20.3,0.22,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
20,1,Action Classification,MiniKinetics,2019-06,MARS+RGB+Flow (16 frames),73.5,100.0,73.5,1.0,73.5,0.78,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
21,1,Image Classification,VTAB-1k,2019-10,S4L-10%-Exemplar-ResNet50,63.9,81.17,63.9,0.81,78.72,0.68,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
22,1,Image Classification,VTAB-1k,2019-10,S4L-10%-Rotation-ResNet50,64.8,82.32,0.9,0.01,78.72,0.69,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
23,1,Image Classification,VTAB-1k,2019-10,S4L-Rotation-ResNet50,67.5,85.75,2.7,0.03,78.72,0.72,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
24,1,Image Classification,VTAB-1k,2019-10,S4L-Exemplar-ResNet50-LargeHyperSweep,72.7,92.35,5.2,0.07,78.72,0.77,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
25,1,Image Classification,VTAB-1k,2019-12,BiT-L,76.3,96.93,3.6,0.05,78.72,0.81,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
26,1,Image Classification,VTAB-1k,2019-12,BiT-L (50 hypers/task),78.72,100.0,2.4,0.03,78.72,0.83,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
27,1,Image Classification,ObjectNet,2019-12,BiT-L (ResNet-152x4),58.7,100.0,58.7,1.0,58.7,0.62,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
28,1,Action Recognition,EPIC-KITCHENS-55,2020-04,TSM+W3,34.2,100.0,34.2,1.0,34.2,0.36,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
29,1,Action Recognition,EgoGesture,2020-04,TSM+W3,94.3,100.0,94.3,1.0,94.3,1.0,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
30,1,Action Recognition In Videos,EPIC-Kitchens,2020-04,TSM+W3,34.2,100.0,34.2,1.0,34.2,0.36,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
31,1,Action Recognition In Videos,EgoGesture,2020-04,TSM+W3,94.3,100.0,94.3,1.0,94.3,1.0,ito:ITO_00101,Vision process,Top\\-1\\ Accuracy
0,1,3D Human Pose Estimation,Human3.6M,2013-12,LinKDE,162.14,100.0,162.14,1.0,162.14,1.0,ito:ITO_00101,Vision process,Average\\ MPJPE\\ \\(mm\\)
1,1,Monocular 3D Human Pose Estimation,Human3.6M,2015-11,Sparseness Meets Deepness,113.0,98.18,113.0,0.98,115.1,0.7,ito:ITO_00101,Vision process,Average\\ MPJPE\\ \\(mm\\)
2,1,Monocular 3D Human Pose Estimation,Human3.6M,2018-05,Ordinal Depth Supervision,115.1,100.0,2.1,0.02,115.1,0.71,ito:ITO_00101,Vision process,Average\\ MPJPE\\ \\(mm\\)
3,1,3D Human Pose Estimation,Total Capture,2016-01,Tri-CPM,99.0,92.52,99.0,0.93,107.0,0.61,ito:ITO_00101,Vision process,Average\\ MPJPE\\ \\(mm\\)
4,1,3D Human Pose Estimation,Total Capture,2017-09,PVH,107.0,100.0,8.0,0.07,107.0,0.66,ito:ITO_00101,Vision process,Average\\ MPJPE\\ \\(mm\\)
5,1,Weakly-supervised 3D Human Pose Estimation,Human3.6M,2017-01,Tome et al.,88.4,74.66,88.4,0.75,118.4,0.55,ito:ITO_00101,Vision process,Average\\ MPJPE\\ \\(mm\\)
6,1,Weakly-supervised 3D Human Pose Estimation,Human3.6M,2017-04,Pavlakos et al.,118.4,100.0,30.0,0.25,118.4,0.73,ito:ITO_00101,Vision process,Average\\ MPJPE\\ \\(mm\\)
0,1,Image Clustering,CIFAR-10,2013-12,VAE,0.168,40.88,0.168,0.41,0.411,0.0,ito:ITO_00101,Vision process,ARI
1,1,Image Clustering,CIFAR-10,2015-11,GAN,0.176,42.82,0.0,0.0,0.411,0.0,ito:ITO_00101,Vision process,ARI
2,1,Image Clustering,CIFAR-10,2017-10,DAC,0.301,73.24,0.1,0.24,0.411,0.01,ito:ITO_00101,Vision process,ARI
3,1,Image Clustering,CIFAR-10,2018-07,IIC,0.411,100.0,0.1,0.24,0.411,0.01,ito:ITO_00101,Vision process,ARI
4,1,3D Object Detection,nuScenes-FB,2019-05,RRPN + R101,51.4,100.0,51.4,1.0,51.4,0.88,ito:ITO_00101,Vision process,ARI
5,1,3D Object Detection,nuScenes-F,2019-05,RRPN + R101,58.2,100.0,58.2,1.0,58.2,1.0,ito:ITO_00101,Vision process,ARI
0,1,Object Detection,ImageNet Detection,2013-12,OverFeat,24.3,55.35,24.3,0.55,43.9,0.25,ito:ITO_00101,Vision process,MAP
1,1,Object Detection,ImageNet Detection,2014-09,Inception V1,43.9,100.0,19.6,0.45,43.9,0.46,ito:ITO_00101,Vision process,MAP
2,1,Weakly Supervised Object Detection,PASCAL VOC 2007,2014-03,Cover + SLSVM,22.7,41.35,22.7,0.41,54.9,0.24,ito:ITO_00101,Vision process,MAP
3,1,Weakly Supervised Object Detection,PASCAL VOC 2007,2015-11,WSDDN-Ens,39.3,71.58,16.6,0.3,54.9,0.41,ito:ITO_00101,Vision process,MAP
4,1,Weakly Supervised Object Detection,PASCAL VOC 2007,2016-11,WCCN,42.8,77.96,3.5,0.06,54.9,0.44,ito:ITO_00101,Vision process,MAP
5,1,Weakly Supervised Object Detection,PASCAL VOC 2007,2017-04,OICR-Ens + FRCNN,47.0,85.61,4.2,0.08,54.9,0.49,ito:ITO_00101,Vision process,MAP
6,1,Weakly Supervised Object Detection,PASCAL VOC 2007,2018-02,pipeline method,51.2,93.26,4.2,0.08,54.9,0.53,ito:ITO_00101,Vision process,MAP
7,1,Weakly Supervised Object Detection,PASCAL VOC 2007,2018-06,WSD+PGE+PGA+FSD2,52.4,95.45,1.2,0.02,54.9,0.54,ito:ITO_00101,Vision process,MAP
8,1,Weakly Supervised Object Detection,PASCAL VOC 2007,2018-11,Pred Net (Ens),53.6,97.63,1.2,0.02,54.9,0.56,ito:ITO_00101,Vision process,MAP
9,1,Weakly Supervised Object Detection,PASCAL VOC 2007,2019-11,Our-Ens,54.5,99.27,0.9,0.02,54.9,0.57,ito:ITO_00101,Vision process,MAP
10,1,Weakly Supervised Object Detection,PASCAL VOC 2007,2020-04,wetectron(single-model),54.9,100.0,0.4,0.01,54.9,0.57,ito:ITO_00101,Vision process,MAP
11,1,Action Classification,Charades,2014-06,2-Strm,18.6,31.74,18.6,0.32,58.6,0.19,ito:ITO_00101,Vision process,MAP
12,1,Action Classification,Charades,2016-12,Asyn-TF,22.4,38.23,3.8,0.06,58.6,0.23,ito:ITO_00101,Vision process,MAP
13,1,Action Classification,Charades,2017-05,I3D,32.9,56.14,10.5,0.18,58.6,0.34,ito:ITO_00101,Vision process,MAP
14,1,Action Classification,Charades,2018-06,PoTion + (GCN + I3D + NL I3D),40.8,69.62,7.9,0.13,58.6,0.42,ito:ITO_00101,Vision process,MAP
15,1,Action Classification,Charades,2018-12,SlowFast (Kinetics-600 pretraining),42.1,71.84,1.3,0.02,58.6,0.44,ito:ITO_00101,Vision process,MAP
16,1,Action Classification,Charades,2018-12,"SlowFast (Kinetics-600 pretraining, NL)",45.2,77.13,3.1,0.05,58.6,0.47,ito:ITO_00101,Vision process,MAP
17,1,Action Classification,Charades,2019-05,AssembleNet,58.6,100.0,13.4,0.23,58.6,0.61,ito:ITO_00101,Vision process,MAP
18,1,Person Re-Identification,Market-1501,2014-06,LOMO + XQDA,22.22,23.27,22.22,0.23,95.5,0.23,ito:ITO_00101,Vision process,MAP
19,1,Person Re-Identification,Market-1501,2016-03,DNS,35.68,37.36,13.5,0.14,95.5,0.37,ito:ITO_00101,Vision process,MAP
20,1,Person Re-Identification,Market-1501,2016-07,S-CNN,39.55,41.41,3.9,0.04,95.5,0.41,ito:ITO_00101,Vision process,MAP
21,1,Person Re-Identification,Market-1501,2016-10,IDE,46.0,48.17,6.5,0.07,95.5,0.48,ito:ITO_00101,Vision process,MAP
22,1,Person Re-Identification,Market-1501,2016-11,DLCE,59.9,62.72,13.9,0.15,95.5,0.62,ito:ITO_00101,Vision process,MAP
23,1,Person Re-Identification,Market-1501,2017-01,GAN,66.07,69.18,6.2,0.06,95.5,0.69,ito:ITO_00101,Vision process,MAP
24,1,Person Re-Identification,Market-1501,2017-03,TriNet,69.14,72.4,3.1,0.03,95.5,0.72,ito:ITO_00101,Vision process,MAP
25,1,Person Re-Identification,Market-1501,2017-07,PartLoss,69.3,72.57,0.2,0.0,95.5,0.72,ito:ITO_00101,Vision process,MAP
26,1,Person Re-Identification,Market-1501,2017-09,GLAD*,73.9,77.38,4.6,0.05,95.5,0.77,ito:ITO_00101,Vision process,MAP
27,1,Person Re-Identification,Market-1501,2017-11,AlignedReID (RK),90.7,94.97,16.8,0.18,95.5,0.94,ito:ITO_00101,Vision process,MAP
28,1,Person Re-Identification,Market-1501,2018-07,SSP-ReID (RR),90.8,95.08,0.1,0.0,95.5,0.94,ito:ITO_00101,Vision process,MAP
29,1,Person Re-Identification,Market-1501,2018-11,Parameter-Free Spatial Attention,91.7,96.02,0.9,0.01,95.5,0.95,ito:ITO_00101,Vision process,MAP
30,1,Person Re-Identification,Market-1501,2018-12,"st-ReID(RE, RK)",95.5,100.0,3.8,0.04,95.5,0.99,ito:ITO_00101,Vision process,MAP
31,1,Person Re-Identification,DukeMTMC-reID,2014-06,LOMO + XQDA,17.04,18.38,17.04,0.18,92.7,0.18,ito:ITO_00101,Vision process,MAP
32,1,Person Re-Identification,DukeMTMC-reID,2016-04,OIM,47.4,51.13,30.4,0.33,92.7,0.49,ito:ITO_00101,Vision process,MAP
33,1,Person Re-Identification,DukeMTMC-reID,2016-11,DLCE,49.3,53.18,1.9,0.02,92.7,0.51,ito:ITO_00101,Vision process,MAP
34,1,Person Re-Identification,DukeMTMC-reID,2017-03,SVDNet,56.8,61.27,7.5,0.08,92.7,0.59,ito:ITO_00101,Vision process,MAP
35,1,Person Re-Identification,DukeMTMC-reID,2017-08,SVDNet + Random Erasing,62.4,67.31,5.6,0.06,92.7,0.65,ito:ITO_00101,Vision process,MAP
36,1,Person Re-Identification,DukeMTMC-reID,2017-11,PCB (RPP),69.2,74.65,6.8,0.07,92.7,0.72,ito:ITO_00101,Vision process,MAP
37,1,Person Re-Identification,DukeMTMC-reID,2017-11,PSE+ ECN (rank-dist),79.8,86.08,10.6,0.11,92.7,0.83,ito:ITO_00101,Vision process,MAP
38,1,Person Re-Identification,DukeMTMC-reID,2018-05,DaRe(De)+RE+RR [wang2018resource],80.0,86.3,0.2,0.0,92.7,0.83,ito:ITO_00101,Vision process,MAP
39,1,Person Re-Identification,DukeMTMC-reID,2018-07,SSP-ReID (RR),83.7,90.29,3.7,0.04,92.7,0.87,ito:ITO_00101,Vision process,MAP
40,1,Person Re-Identification,DukeMTMC-reID,2018-11,Parameter-Free Spatial Attention,85.9,92.66,2.2,0.02,92.7,0.89,ito:ITO_00101,Vision process,MAP
41,1,Person Re-Identification,DukeMTMC-reID,2018-12,"st-ReID(RE, RK,Cam)",92.7,100.0,6.8,0.07,92.7,0.96,ito:ITO_00101,Vision process,MAP
42,1,Object Detection,PASCAL VOC 2007,2014-06,SPP (Overfeat-7),82.44,94.87,82.44,0.95,86.9,0.86,ito:ITO_00101,Vision process,MAP
43,1,Object Detection,PASCAL VOC 2007,2017-08,CoupleNet,82.7,95.17,0.3,0.0,86.9,0.86,ito:ITO_00101,Vision process,MAP
44,1,Object Detection,PASCAL VOC 2007,2017-11,RefineDet512+,83.8,96.43,1.1,0.01,86.9,0.87,ito:ITO_00101,Vision process,MAP
45,1,Object Detection,PASCAL VOC 2007,2018-05,SNIPER,86.9,100.0,3.1,0.04,86.9,0.9,ito:ITO_00101,Vision process,MAP
46,1,Object Detection,PASCAL VOC 2012,2014-07,SDS,50.7,63.38,50.7,0.63,80.0,0.53,ito:ITO_00101,Vision process,MAP
47,1,Object Detection,PASCAL VOC 2012,2015-06,YOLO,57.9,72.38,7.2,0.09,80.0,0.6,ito:ITO_00101,Vision process,MAP
48,1,Object Detection,PASCAL VOC 2012,2015-12,SSD512 (07+12+COCO),80.0,100.0,22.1,0.28,80.0,0.83,ito:ITO_00101,Vision process,MAP
49,1,Weakly Supervised Object Detection,Charades,2015-05,R*CNN,0.99,9.87,0.99,0.1,10.03,0.01,ito:ITO_00101,Vision process,MAP
50,1,Weakly Supervised Object Detection,Charades,2016-09,ContextLocNet,1.12,11.17,0.1,0.01,10.03,0.01,ito:ITO_00101,Vision process,MAP
51,1,Weakly Supervised Object Detection,Charades,2017-08,TD-LSTM,1.98,19.74,0.9,0.09,10.03,0.02,ito:ITO_00101,Vision process,MAP
52,1,Weakly Supervised Object Detection,Charades,2018-07,PCL,2.83,28.22,0.8,0.08,10.03,0.03,ito:ITO_00101,Vision process,MAP
53,1,Weakly Supervised Object Detection,Charades,2019-04,Spatial Prior,10.03,100.0,7.2,0.72,10.03,0.1,ito:ITO_00101,Vision process,MAP
54,1,Weakly Supervised Object Detection,HICO-DET,2015-05,R*CNN,2.15,39.89,2.15,0.4,5.39,0.02,ito:ITO_00101,Vision process,MAP
55,1,Weakly Supervised Object Detection,HICO-DET,2015-11,WSDDN,3.27,60.67,1.1,0.2,5.39,0.03,ito:ITO_00101,Vision process,MAP
56,1,Weakly Supervised Object Detection,HICO-DET,2018-07,PCL,3.62,67.16,0.4,0.07,5.39,0.04,ito:ITO_00101,Vision process,MAP
57,1,Weakly Supervised Object Detection,HICO-DET,2019-04,Spatial Prior,5.39,100.0,1.8,0.33,5.39,0.06,ito:ITO_00101,Vision process,MAP
58,1,Real-Time Object Detection,PASCAL VOC 2007,2015-06,Faster R-CNN,73.2,89.82,73.2,0.9,81.5,0.76,ito:ITO_00101,Vision process,MAP
59,1,Real-Time Object Detection,PASCAL VOC 2007,2016-05,R-FCN,80.5,98.77,7.3,0.09,81.5,0.84,ito:ITO_00101,Vision process,MAP
60,1,Real-Time Object Detection,PASCAL VOC 2007,2017-08,BlitzNet512 (s8),81.5,100.0,1.0,0.01,81.5,0.85,ito:ITO_00101,Vision process,MAP
61,1,3D Object Detection,SUN-RGBD val,2015-11,DSS,42.1,72.96,42.1,0.73,57.7,0.44,ito:ITO_00101,Vision process,MAP
62,1,3D Object Detection,SUN-RGBD val,2016-06,COG,47.6,82.5,5.5,0.1,57.7,0.49,ito:ITO_00101,Vision process,MAP
63,1,3D Object Detection,SUN-RGBD val,2017-11,F-PointNet,54.0,93.59,6.4,0.11,57.7,0.56,ito:ITO_00101,Vision process,MAP
64,1,3D Object Detection,SUN-RGBD val,2019-04,VoteNet (Geo only),57.7,100.0,3.7,0.06,57.7,0.6,ito:ITO_00101,Vision process,MAP
65,1,Weakly Supervised Object Detection,Watercolor2k,2015-11,WSDDN,12.7,23.39,12.7,0.23,54.3,0.13,ito:ITO_00101,Vision process,MAP
66,1,Weakly Supervised Object Detection,Watercolor2k,2018-03,DT+PL,54.3,100.0,41.6,0.77,54.3,0.56,ito:ITO_00101,Vision process,MAP
67,1,Weakly Supervised Object Detection,COCO,2015-11,ProNet,43.5,76.86,43.5,0.77,56.6,0.45,ito:ITO_00101,Vision process,MAP
68,1,Weakly Supervised Object Detection,COCO,2016-03,Deep Feature Maps,47.9,84.63,4.4,0.08,56.6,0.5,ito:ITO_00101,Vision process,MAP
69,1,Weakly Supervised Object Detection,COCO,2017-06,MSLPD,56.6,100.0,8.7,0.15,56.6,0.59,ito:ITO_00101,Vision process,MAP
70,1,Image Retrieval,Oxf105k,2015-11,R-MAC,61.6,64.71,61.6,0.65,95.2,0.64,ito:ITO_00101,Vision process,MAP
71,1,Image Retrieval,Oxf105k,2015-11,R-MAC+R+QE,73.2,76.89,11.6,0.12,95.2,0.76,ito:ITO_00101,Vision process,MAP
72,1,Image Retrieval,Oxf105k,2016-04,DIR+QE*,87.8,92.23,14.6,0.15,95.2,0.91,ito:ITO_00101,Vision process,MAP
73,1,Image Retrieval,Oxf105k,2016-12,DELF+FT+ATT+DIR+QE,88.5,92.96,0.7,0.01,95.2,0.92,ito:ITO_00101,Vision process,MAP
74,1,Image Retrieval,Oxf105k,2018-11,Offline Diffusion,95.2,100.0,6.7,0.07,95.2,0.99,ito:ITO_00101,Vision process,MAP
75,1,Object Detection,Visual Genome,2015-11,AP (%),5.39,72.54,5.39,0.73,7.43,0.06,ito:ITO_00101,Vision process,MAP
76,1,Object Detection,Visual Genome,2017-07,MSDN,7.43,100.0,2.0,0.27,7.43,0.08,ito:ITO_00101,Vision process,MAP
77,1,Image Retrieval,Oxf5k,2016-04,DIR+QE*,89.0,92.52,89.0,0.93,96.2,0.93,ito:ITO_00101,Vision process,MAP
78,1,Image Retrieval,Oxf5k,2016-12,DELF+FT+ATT+DIR+QE,90.0,93.56,1.0,0.01,96.2,0.94,ito:ITO_00101,Vision process,MAP
79,1,Image Retrieval,Oxf5k,2018-11,Offline Diffusion,96.2,100.0,6.2,0.06,96.2,1.0,ito:ITO_00101,Vision process,MAP
80,1,Person Re-Identification,CUHK03,2016-04,OIM Loss 45,72.5,79.41,72.5,0.79,91.3,0.75,ito:ITO_00101,Vision process,MAP
81,1,Person Re-Identification,CUHK03,2017-01,VI+LSRO 3,87.4,95.73,14.9,0.16,91.3,0.91,ito:ITO_00101,Vision process,MAP
82,1,Person Re-Identification,CUHK03,2018-10,FD-GAN,91.3,100.0,3.9,0.04,91.3,0.95,ito:ITO_00101,Vision process,MAP
83,1,Weakly Supervised Object Detection,PASCAL VOC 2012 test,2016-09,WSDDN + context,35.3,67.75,35.3,0.68,52.1,0.37,ito:ITO_00101,Vision process,MAP
84,1,Weakly Supervised Object Detection,PASCAL VOC 2012 test,2016-11,WCCN,37.9,72.74,2.6,0.05,52.1,0.39,ito:ITO_00101,Vision process,MAP
85,1,Weakly Supervised Object Detection,PASCAL VOC 2012 test,2017-04,OICR-Ens + FRCNN,42.5,81.57,4.6,0.09,52.1,0.44,ito:ITO_00101,Vision process,MAP
86,1,Weakly Supervised Object Detection,PASCAL VOC 2012 test,2017-07,WebRelETH,42.8,82.15,0.3,0.01,52.1,0.44,ito:ITO_00101,Vision process,MAP
87,1,Weakly Supervised Object Detection,PASCAL VOC 2012 test,2018-04,ZLDN-L,42.9,82.34,0.1,0.0,52.1,0.45,ito:ITO_00101,Vision process,MAP
88,1,Weakly Supervised Object Detection,PASCAL VOC 2012 test,2018-06,WSD+PGE+PGA+FSD2,47.8,91.75,4.9,0.09,52.1,0.5,ito:ITO_00101,Vision process,MAP
89,1,Weakly Supervised Object Detection,PASCAL VOC 2012 test,2018-11,Pred Net (Ens),49.5,95.01,1.7,0.03,52.1,0.51,ito:ITO_00101,Vision process,MAP
90,1,Weakly Supervised Object Detection,PASCAL VOC 2012 test,2019-10,C-MIDN+FRCNN,50.3,96.55,0.8,0.02,52.1,0.52,ito:ITO_00101,Vision process,MAP
91,1,Weakly Supervised Object Detection,PASCAL VOC 2012 test,2020-04,wetectron(single-model),52.1,100.0,1.8,0.03,52.1,0.54,ito:ITO_00101,Vision process,MAP
92,1,Person Re-Identification,CUHK-SYSU,2016-10,Deep *,74.0,78.39,74.0,0.78,94.4,0.77,ito:ITO_00101,Vision process,MAP
93,1,Person Re-Identification,CUHK-SYSU,2017-07,Neural,77.9,82.52,3.9,0.04,94.4,0.81,ito:ITO_00101,Vision process,MAP
94,1,Person Re-Identification,CUHK-SYSU,2017-11,AlignedReID,94.4,100.0,16.5,0.17,94.4,0.98,ito:ITO_00101,Vision process,MAP
95,1,Object Detection,PeopleArt,2016-10,Fast R-CNN (VGG16),59.0,100.0,59,1.0,59,0.61,ito:ITO_00101,Vision process,MAP
96,1,Weakly Supervised Object Detection,ImageNet,2016-11,WCCN,16.3,83.16,16.3,0.83,19.6,0.17,ito:ITO_00101,Vision process,MAP
97,1,Weakly Supervised Object Detection,ImageNet,2018-07,PCL-OB-G-Ens + FRCNN,19.6,100.0,3.3,0.17,19.6,0.2,ito:ITO_00101,Vision process,MAP
98,1,Person Re-Identification,CUHK03 labeled,2017-01,IDE-C+XQDA,20.0,24.84,20.0,0.25,80.5,0.21,ito:ITO_00101,Vision process,MAP
99,1,Person Re-Identification,CUHK03 labeled,2017-01,IDE-R+XQDA,29.6,36.77,9.6,0.12,80.5,0.31,ito:ITO_00101,Vision process,MAP
100,1,Person Re-Identification,CUHK03 labeled,2017-07,"PAN(Zheng et al., [2017a])",35.0,43.48,5.4,0.07,80.5,0.36,ito:ITO_00101,Vision process,MAP
101,1,Person Re-Identification,CUHK03 labeled,2017-07,PAN+re-rank,45.8,56.89,10.8,0.13,80.5,0.48,ito:ITO_00101,Vision process,MAP
102,1,Person Re-Identification,CUHK03 labeled,2018-04,MGN (ACM MM'18),67.4,83.73,21.6,0.27,80.5,0.7,ito:ITO_00101,Vision process,MAP
103,1,Person Re-Identification,CUHK03 labeled,2018-10,Pyramid (CVPR\' 19),76.9,95.53,9.5,0.12,80.5,0.8,ito:ITO_00101,Vision process,MAP
104,1,Person Re-Identification,CUHK03 labeled,2020-01,PLR-OSNet,80.5,100.0,3.6,0.04,80.5,0.84,ito:ITO_00101,Vision process,MAP
105,1,Person Re-Identification,CUHK03 detected,2017-01,IDE-R,19.7,25.52,19.7,0.26,77.2,0.2,ito:ITO_00101,Vision process,MAP
106,1,Person Re-Identification,CUHK03 detected,2017-01,IDE-R+XQDA,28.2,36.53,8.5,0.11,77.2,0.29,ito:ITO_00101,Vision process,MAP
107,1,Person Re-Identification,CUHK03 detected,2017-03,SVDNet-ResNet50,37.3,48.32,9.1,0.12,77.2,0.39,ito:ITO_00101,Vision process,MAP
108,1,Person Re-Identification,CUHK03 detected,2018-02,HA-CNN (CVPR'18),38.6,50.0,1.3,0.02,77.2,0.4,ito:ITO_00101,Vision process,MAP
109,1,Person Re-Identification,CUHK03 detected,2018-04,MGN (ACM MM'18),66.0,85.49,27.4,0.35,77.2,0.69,ito:ITO_00101,Vision process,MAP
110,1,Person Re-Identification,CUHK03 detected,2018-10,Pyramid (CVPR'19),74.8,96.89,8.8,0.11,77.2,0.78,ito:ITO_00101,Vision process,MAP
111,1,Person Re-Identification,CUHK03 detected,2020-01,PLR-OSNet,77.2,100.0,2.4,0.03,77.2,0.8,ito:ITO_00101,Vision process,MAP
112,1,Weakly Supervised Action Localization,THUMOS 2014,2017-03,UntrimmedNets,13.7,50.74,13.7,0.51,27.0,0.14,ito:ITO_00101,Vision process,MAP
113,1,Weakly Supervised Action Localization,THUMOS 2014,2017-12,STPN,16.9,62.59,3.2,0.12,27.0,0.18,ito:ITO_00101,Vision process,MAP
114,1,Weakly Supervised Action Localization,THUMOS 2014,2018-07,W-TALC,22.8,84.44,5.9,0.22,27.0,0.24,ito:ITO_00101,Vision process,MAP
115,1,Weakly Supervised Action Localization,THUMOS 2014,2019-06,CMCS,23.1,85.56,0.3,0.01,27.0,0.24,ito:ITO_00101,Vision process,MAP
116,1,Weakly Supervised Action Localization,THUMOS 2014,2019-10,TSM,24.5,90.74,1.4,0.05,27.0,0.25,ito:ITO_00101,Vision process,MAP
117,1,Weakly Supervised Action Localization,THUMOS 2014,2019-11,BaS-Net,27.0,100.0,2.5,0.09,27.0,0.28,ito:ITO_00101,Vision process,MAP
118,1,Real-Time Object Detection,COCO minival,2017-03,Mask R-CNN X-101-FPN,37.6,100.0,37.6,1.0,37.6,0.39,ito:ITO_00101,Vision process,MAP
119,1,Real-Time Object Detection,COCO,2017-03,Mask R-CNN X-152-32x8d,45.2,93.58,45.2,0.94,48.3,0.47,ito:ITO_00101,Vision process,MAP
120,1,Real-Time Object Detection,COCO,2019-04,NAS-FPN AmoebaNet (7 @ 384) + DropBlock,48.3,100.0,3.1,0.06,48.3,0.5,ito:ITO_00101,Vision process,MAP
121,1,Video Object Detection,ImageNet VID,2017-03,FGFA + Seq-NMS,80.1,93.79,80.1,0.94,85.4,0.83,ito:ITO_00101,Vision process,MAP
122,1,Video Object Detection,ImageNet VID,2018-11,Tracklet-Conditioned Detection+DCNv2+FGFA,83.5,97.78,3.4,0.04,85.4,0.87,ito:ITO_00101,Vision process,MAP
123,1,Video Object Detection,ImageNet VID,2019-07,SELSA + Faster R-CNN,84.3,98.71,0.8,0.01,85.4,0.88,ito:ITO_00101,Vision process,MAP
124,1,Video Object Detection,ImageNet VID,2020-03,MEGA + ResNeXt101,85.4,100.0,1.1,0.01,85.4,0.89,ito:ITO_00101,Vision process,MAP
125,1,Human-Object Interaction Detection,HICO-DET,2017-04,InteractNet,9.94,43.89,9.94,0.44,22.65,0.1,ito:ITO_00101,Vision process,MAP
126,1,Human-Object Interaction Detection,HICO-DET,2018-08,GPNN,13.11,57.88,3.2,0.14,22.65,0.14,ito:ITO_00101,Vision process,MAP
127,1,Human-Object Interaction Detection,HICO-DET,2018-08,iCAN,14.84,65.52,1.7,0.08,22.65,0.15,ito:ITO_00101,Vision process,MAP
128,1,Human-Object Interaction Detection,HICO-DET,2018-11,Interactiveness,17.54,77.44,2.7,0.12,22.65,0.18,ito:ITO_00101,Vision process,MAP
129,1,Human-Object Interaction Detection,HICO-DET,2019-12,PPDM,21.92,96.78,4.4,0.19,22.65,0.23,ito:ITO_00101,Vision process,MAP
130,1,Human-Object Interaction Detection,HICO-DET,2020-04,HAKE,22.65,100.0,0.7,0.03,22.65,0.24,ito:ITO_00101,Vision process,MAP
131,1,Unsupervised Person Re-Identification,Market-1501,2017-05,PUL,20.5,28.67,20.5,0.29,71.5,0.21,ito:ITO_00101,Vision process,MAP
132,1,Unsupervised Person Re-Identification,Market-1501,2017-11,SPGAN+LMP,26.7,37.34,6.2,0.09,71.5,0.28,ito:ITO_00101,Vision process,MAP
133,1,Unsupervised Person Re-Identification,Market-1501,2018-11,Self-Similarity Grouping (one shot),71.5,100.0,44.8,0.63,71.5,0.74,ito:ITO_00101,Vision process,MAP
134,1,Unsupervised Person Re-Identification,DukeMTMC-reID,2017-05,PUL,16.4,29.34,16.4,0.29,55.9,0.17,ito:ITO_00101,Vision process,MAP
135,1,Unsupervised Person Re-Identification,DukeMTMC-reID,2017-11,SPGAN+LMP,26.2,46.87,9.8,0.18,55.9,0.27,ito:ITO_00101,Vision process,MAP
136,1,Unsupervised Person Re-Identification,DukeMTMC-reID,2018-11,Self-Similarity Grouping (one shot),55.9,100.0,29.7,0.53,55.9,0.58,ito:ITO_00101,Vision process,MAP
137,1,Person Re-Identification,CUHK03 detected,2017-01,IDE-R,19.7,25.52,19.7,0.26,77.2,0.2,ito:ITO_00101,Vision process,MAP
138,1,Person Re-Identification,CUHK03 detected,2017-01,IDE-R+XQDA,28.2,36.53,8.5,0.11,77.2,0.29,ito:ITO_00101,Vision process,MAP
139,1,Person Re-Identification,CUHK03 detected,2017-03,SVDNet-ResNet50,37.3,48.32,9.1,0.12,77.2,0.39,ito:ITO_00101,Vision process,MAP
140,1,Person Re-Identification,CUHK03 detected,2018-02,HA-CNN (CVPR'18),38.6,50.0,1.3,0.02,77.2,0.4,ito:ITO_00101,Vision process,MAP
141,1,Person Re-Identification,CUHK03 detected,2018-04,MGN (ACM MM'18),66.0,85.49,27.4,0.35,77.2,0.69,ito:ITO_00101,Vision process,MAP
142,1,Person Re-Identification,CUHK03 detected,2018-10,Pyramid (CVPR'19),74.8,96.89,8.8,0.11,77.2,0.78,ito:ITO_00101,Vision process,MAP
143,1,Person Re-Identification,CUHK03 detected,2020-01,PLR-OSNet,77.2,100.0,2.4,0.03,77.2,0.8,ito:ITO_00101,Vision process,MAP
144,1,Occluded Face Detection,MAFA,2017-09,AOFD,77.3,87.54,77.3,0.88,88.3,0.8,ito:ITO_00101,Vision process,MAP
145,1,Occluded Face Detection,MAFA,2017-11,FAN,88.3,100.0,11.0,0.12,88.3,0.92,ito:ITO_00101,Vision process,MAP
146,1,3D Object Detection,SUN-RGBD,2017-11,Frustum PointNets,54.0,85.17,54.0,0.85,63.4,0.56,ito:ITO_00101,Vision process,MAP
147,1,3D Object Detection,SUN-RGBD,2020-01,ImVoteNet,63.4,100.0,9.4,0.15,63.4,0.66,ito:ITO_00101,Vision process,MAP
148,1,Instance Segmentation,NYU Depth v2,2017-11,SGPN-CNN,43.5,100.0,43.5,1.0,43.5,0.45,ito:ITO_00101,Vision process,MAP
149,1,3D Object Detection,NYU Depth v2,2017-11,SGPN-CNN,41.3,100.0,41.3,1.0,41.3,0.43,ito:ITO_00101,Vision process,MAP
150,1,6D Pose Estimation using RGB,OCCLUSION,2017-11,Single-shot deep CNN,0.48,100.0,0.48,1.0,0.48,0.0,ito:ITO_00101,Vision process,MAP
151,1,Weakly Supervised Object Detection,Comic2k,2018-03,DT+PL,37.2,100.0,37.2,1.0,37.2,0.39,ito:ITO_00101,Vision process,MAP
152,1,Weakly Supervised Object Detection,Clipart1k,2018-03,DT+PL,46.0,100.0,46,1.0,46,0.48,ito:ITO_00101,Vision process,MAP
153,1,Traffic Sign Recognition,Tsinghua-Tencent 100K,2018-06,Background Threshold Model,0.32,100.0,0.32,1.0,0.32,0.0,ito:ITO_00101,Vision process,MAP
154,1,Traffic Sign Recognition,Bosch Small Traffic Lights,2018-06,Hierarchical + Background Threshold Model,0.46,100.0,0.46,1.0,0.46,0.0,ito:ITO_00101,Vision process,MAP
155,1,Human-Object Interaction Detection,V-COCO,2018-08,GPNN,44.0,85.01,44.0,0.85,51.76,0.46,ito:ITO_00101,Vision process,MAP
156,1,Human-Object Interaction Detection,V-COCO,2018-08,iCAN,44.7,86.36,0.7,0.01,51.76,0.46,ito:ITO_00101,Vision process,MAP
157,1,Human-Object Interaction Detection,V-COCO,2018-11,Interactiveness,49.0,94.67,4.3,0.08,51.76,0.51,ito:ITO_00101,Vision process,MAP
158,1,Human-Object Interaction Detection,V-COCO,2020-03,VSGNet,51.76,100.0,2.8,0.05,51.76,0.54,ito:ITO_00101,Vision process,MAP
159,1,Weakly Supervised Object Detection,IconArt,2018-10,MI-max-C,13.2,100.0,13.2,1.0,13.2,0.14,ito:ITO_00101,Vision process,MAP
160,1,Weakly Supervised Object Detection,PeopleArt,2018-10,MI-max,55.4,100.0,55.4,1.0,55.4,0.58,ito:ITO_00101,Vision process,MAP
161,1,Image Retrieval,NUS-WIDE,2019-02,DTQ,0.801,100.0,0.801,1.0,0.801,0.01,ito:ITO_00101,Vision process,MAP
162,1,Quantization,CIFAR-10,2019-02,DTQ,0.792,100.0,0.792,1.0,0.792,0.01,ito:ITO_00101,Vision process,MAP
163,1,Pose Tracking,PoseTrack2017,2019-02,HRNet-W48 COCO,74.9,91.68,74.9,0.92,81.7,0.78,ito:ITO_00101,Vision process,MAP
164,1,Pose Tracking,PoseTrack2017,2019-05,GT Detections,81.7,100.0,6.8,0.08,81.7,0.85,ito:ITO_00101,Vision process,MAP
165,1,Real-time Instance Segmentation,MSCOCO,2019-04,YOLACT,29.8,100.0,29.8,1.0,29.8,0.31,ito:ITO_00101,Vision process,MAP
166,1,3D Object Detection,nuScenes,2019-08,MEGVII,52.8,100.0,52.8,1.0,52.8,0.55,ito:ITO_00101,Vision process,MAP
0,1,Action Recognition In Videos,HMDB-51,2014-06,Two-stream,59.4,72.02,59.4,0.72,82.48,0.72,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
1,1,Action Recognition In Videos,HMDB-51,2016-04,LTC,64.8,78.56,5.4,0.07,82.48,0.79,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
2,1,Action Recognition In Videos,HMDB-51,2016-04,"S:VGG-16, T:VGG-16",65.4,79.29,0.6,0.01,82.48,0.79,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
3,1,Action Recognition In Videos,HMDB-51,2016-05,Sub-events,68.4,82.93,3.0,0.04,82.48,0.83,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
4,1,Action Recognition In Videos,HMDB-51,2017-03,TS-LSTM,69.0,83.66,0.6,0.01,82.48,0.84,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
5,1,Action Recognition In Videos,HMDB-51,2017-04,Hidden Two-Stream,78.7,95.42,9.7,0.12,82.48,0.95,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
6,1,Action Recognition In Videos,HMDB-51,2017-05,Two-stream I3D,80.9,98.08,2.2,0.03,82.48,0.98,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
7,1,Action Recognition In Videos,HMDB-51,2018-10,RepFlow-50,81.1,98.33,0.2,0.0,82.48,0.98,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
8,1,Action Recognition In Videos,HMDB-51,2018-11,EvaNet,82.1,99.54,1.0,0.01,82.48,1.0,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
9,1,Action Recognition In Videos,HMDB-51,2019-06,HAF+BoW/FV halluc,82.48,100.0,0.4,0.0,82.48,1.0,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
10,1,Action Recognition,HMDB-51,2014-06,Two-Stream (ImageNet pretrained),59.4,72.02,59.4,0.72,82.48,0.72,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
11,1,Action Recognition,HMDB-51,2015-05,TDD + IDT,65.9,79.9,6.5,0.08,82.48,0.8,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
12,1,Action Recognition,HMDB-51,2016-08,Temporal Segment Networks,69.4,84.14,3.5,0.04,82.48,0.84,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
13,1,Action Recognition,HMDB-51,2017-04,Hidden Two-Stream,78.7,95.42,9.3,0.11,82.48,0.95,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
14,1,Action Recognition,HMDB-51,2017-05,Two-Stream I3D (Imagenet+Kinetics pre-training),80.7,97.84,2.0,0.02,82.48,0.98,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
15,1,Action Recognition,HMDB-51,2017-05,Two-stream I3D,80.9,98.08,0.2,0.0,82.48,0.98,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
16,1,Action Recognition,HMDB-51,2018-10,"RepFlow-50 ([2+1]D CNN, FcF, Non-local block)",81.1,98.33,0.2,0.0,82.48,0.98,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
17,1,Action Recognition,HMDB-51,2019-06,HAF+BoW/FV halluc,82.48,100.0,1.4,0.02,82.48,1.0,ito:ITO_00101,Vision process,Average\\ accuracy\\ of\\ 3\\ splits
0,1,Person Re-Identification,Market-1501,2014-06,LOMO + XQDA,43.79,44.68,43.79,0.45,98.0,0.45,ito:ITO_00101,Vision process,Rank\\-1
1,1,Person Re-Identification,Market-1501,2016-03,WARCA,45.16,46.08,1.4,0.01,98.0,0.46,ito:ITO_00101,Vision process,Rank\\-1
2,1,Person Re-Identification,Market-1501,2016-03,DNS,61.02,62.27,15.9,0.16,98.0,0.62,ito:ITO_00101,Vision process,Rank\\-1
3,1,Person Re-Identification,Market-1501,2016-07,S-CNN,65.88,67.22,4.9,0.05,98.0,0.67,ito:ITO_00101,Vision process,Rank\\-1
4,1,Person Re-Identification,Market-1501,2016-10,IDE,72.54,74.02,6.7,0.07,98.0,0.74,ito:ITO_00101,Vision process,Rank\\-1
5,1,Person Re-Identification,Market-1501,2016-11,DLCE,79.5,81.12,7.0,0.07,98.0,0.81,ito:ITO_00101,Vision process,Rank\\-1
6,1,Person Re-Identification,Market-1501,2017-01,GAN,83.97,85.68,4.5,0.05,98.0,0.86,ito:ITO_00101,Vision process,Rank\\-1
7,1,Person Re-Identification,Market-1501,2017-03,LuNet (RK),84.59,86.32,0.6,0.01,98.0,0.86,ito:ITO_00101,Vision process,Rank\\-1
8,1,Person Re-Identification,Market-1501,2017-03,TriNet,84.92,86.65,0.3,0.0,98.0,0.87,ito:ITO_00101,Vision process,Rank\\-1
9,1,Person Re-Identification,Market-1501,2017-03,TriNet (RK),86.67,88.44,1.8,0.02,98.0,0.88,ito:ITO_00101,Vision process,Rank\\-1
10,1,Person Re-Identification,Market-1501,2017-07,PAN (GAN)+re-rank,88.57,90.38,1.9,0.02,98.0,0.9,ito:ITO_00101,Vision process,Rank\\-1
11,1,Person Re-Identification,Market-1501,2017-09,GLAD*,89.9,91.73,1.3,0.01,98.0,0.92,ito:ITO_00101,Vision process,Rank\\-1
12,1,Person Re-Identification,Market-1501,2017-11,AlignedReID (RK),94.4,96.33,4.5,0.05,98.0,0.96,ito:ITO_00101,Vision process,Rank\\-1
13,1,Person Re-Identification,Market-1501,2018-04,MGN,95.7,97.65,1.3,0.01,98.0,0.98,ito:ITO_00101,Vision process,Rank\\-1
14,1,Person Re-Identification,Market-1501,2018-12,"st-ReID(RE, RK)",98.0,100.0,2.3,0.02,98.0,1.0,ito:ITO_00101,Vision process,Rank\\-1
15,1,Person Re-Identification,DukeMTMC-reID,2014-06,LOMO + XQDA,30.75,32.54,30.75,0.33,94.5,0.31,ito:ITO_00101,Vision process,Rank\\-1
16,1,Person Re-Identification,DukeMTMC-reID,2016-04,OIM,68.1,72.06,37.3,0.39,94.5,0.69,ito:ITO_00101,Vision process,Rank\\-1
17,1,Person Re-Identification,DukeMTMC-reID,2016-11,DLCE,68.9,72.91,0.8,0.01,94.5,0.7,ito:ITO_00101,Vision process,Rank\\-1
18,1,Person Re-Identification,DukeMTMC-reID,2017-03,SVDNet,76.7,81.16,7.8,0.08,94.5,0.78,ito:ITO_00101,Vision process,Rank\\-1
19,1,Person Re-Identification,DukeMTMC-reID,2017-08,SVDNet + Random Erasing,79.3,83.92,2.6,0.03,94.5,0.81,ito:ITO_00101,Vision process,Rank\\-1
20,1,Person Re-Identification,DukeMTMC-reID,2017-11,PCB (UP),81.8,86.56,2.5,0.03,94.5,0.83,ito:ITO_00101,Vision process,Rank\\-1
21,1,Person Re-Identification,DukeMTMC-reID,2017-11,PCB (RPP),83.3,88.15,1.5,0.02,94.5,0.85,ito:ITO_00101,Vision process,Rank\\-1
22,1,Person Re-Identification,DukeMTMC-reID,2017-11,PSE+ ECN (rank-dist),85.2,90.16,1.9,0.02,94.5,0.87,ito:ITO_00101,Vision process,Rank\\-1
23,1,Person Re-Identification,DukeMTMC-reID,2018-04,MGN,88.7,93.86,3.5,0.04,94.5,0.91,ito:ITO_00101,Vision process,Rank\\-1
24,1,Person Re-Identification,DukeMTMC-reID,2018-10,Pyramid (CVPR\'19),89.0,94.18,0.3,0.0,94.5,0.91,ito:ITO_00101,Vision process,Rank\\-1
25,1,Person Re-Identification,DukeMTMC-reID,2018-12,"st-ReID(RE, RK,Cam)",94.5,100.0,5.5,0.06,94.5,0.96,ito:ITO_00101,Vision process,Rank\\-1
26,1,Person Re-Identification,CUHK03,2016-04,OIM Loss 45,77.5,79.24,77.5,0.79,97.8,0.79,ito:ITO_00101,Vision process,Rank\\-1
27,1,Person Re-Identification,CUHK03,2017-01,VI+LSRO 3,84.6,86.5,7.1,0.07,97.8,0.86,ito:ITO_00101,Vision process,Rank\\-1
28,1,Person Re-Identification,CUHK03,2017-03,TriNet,89.63,91.65,5.0,0.05,97.8,0.91,ito:ITO_00101,Vision process,Rank\\-1
29,1,Person Re-Identification,CUHK03,2017-11,AlignedReID (RK),97.8,100.0,8.2,0.08,97.8,1.0,ito:ITO_00101,Vision process,Rank\\-1
30,1,Person Re-Identification,CUHK-SYSU,2016-10,Deep *,76.7,80.15,76.7,0.8,95.7,0.78,ito:ITO_00101,Vision process,Rank\\-1
31,1,Person Re-Identification,CUHK-SYSU,2017-07,Neural,81.2,84.85,4.5,0.05,95.7,0.83,ito:ITO_00101,Vision process,Rank\\-1
32,1,Person Re-Identification,CUHK-SYSU,2017-11,AlignedReID,95.7,100.0,14.5,0.15,95.7,0.98,ito:ITO_00101,Vision process,Rank\\-1
33,1,Person Re-Identification,MSMT17,2016-11,DLCE,60.48,73.49,60.48,0.73,82.3,0.62,ito:ITO_00101,Vision process,Rank\\-1
34,1,Person Re-Identification,MSMT17,2019-04,DG-Net,77.2,93.8,16.7,0.2,82.3,0.79,ito:ITO_00101,Vision process,Rank\\-1
35,1,Person Re-Identification,MSMT17,2019-05,OSNet,78.7,95.63,1.5,0.02,82.3,0.8,ito:ITO_00101,Vision process,Rank\\-1
36,1,Person Re-Identification,MSMT17,2019-08,ABD-Net (ResNet-50),82.3,100.0,3.6,0.04,82.3,0.84,ito:ITO_00101,Vision process,Rank\\-1
37,1,Person Re-Identification,CUHK03 detected,2017-01,IDE-R,21.3,26.49,21.3,0.26,80.4,0.22,ito:ITO_00101,Vision process,Rank\\-1
38,1,Person Re-Identification,CUHK03 detected,2017-01,IDE-R+XQDA,31.1,38.68,9.8,0.12,80.4,0.32,ito:ITO_00101,Vision process,Rank\\-1
39,1,Person Re-Identification,CUHK03 detected,2017-03,SVDNet-ResNet50,41.5,51.62,10.4,0.13,80.4,0.42,ito:ITO_00101,Vision process,Rank\\-1
40,1,Person Re-Identification,CUHK03 detected,2018-02,HA-CNN (CVPR'18),41.7,51.87,0.2,0.0,80.4,0.43,ito:ITO_00101,Vision process,Rank\\-1
41,1,Person Re-Identification,CUHK03 detected,2018-04,MGN (ACM MM'18),68.0,84.58,26.3,0.33,80.4,0.69,ito:ITO_00101,Vision process,Rank\\-1
42,1,Person Re-Identification,CUHK03 detected,2018-10,Pyramid (CVPR'19),78.9,98.13,10.9,0.14,80.4,0.81,ito:ITO_00101,Vision process,Rank\\-1
43,1,Person Re-Identification,CUHK03 detected,2020-01,PLR-OSNet,80.4,100.0,1.5,0.02,80.4,0.82,ito:ITO_00101,Vision process,Rank\\-1
44,1,Person Re-Identification,CUHK03 labeled,2017-01,IDE-C+XQDA,21.9,25.89,21.9,0.26,84.6,0.22,ito:ITO_00101,Vision process,Rank\\-1
45,1,Person Re-Identification,CUHK03 labeled,2017-01,IDE-R+XQDA,32.0,37.83,10.1,0.12,84.6,0.33,ito:ITO_00101,Vision process,Rank\\-1
46,1,Person Re-Identification,CUHK03 labeled,2017-07,PAN+re-rank,43.9,51.89,11.9,0.14,84.6,0.45,ito:ITO_00101,Vision process,Rank\\-1
47,1,Person Re-Identification,CUHK03 labeled,2018-02,HA-CNN (CVPR'18),44.4,52.48,0.5,0.01,84.6,0.45,ito:ITO_00101,Vision process,Rank\\-1
48,1,Person Re-Identification,CUHK03 labeled,2018-04,MGN (ACM MM'18),68.0,80.38,23.6,0.28,84.6,0.69,ito:ITO_00101,Vision process,Rank\\-1
49,1,Person Re-Identification,CUHK03 labeled,2018-10,Pyramid (CVPR\' 19),78.9,93.26,10.9,0.13,84.6,0.81,ito:ITO_00101,Vision process,Rank\\-1
50,1,Person Re-Identification,CUHK03 labeled,2018-11,BDB  (ICCV'19),79.4,93.85,0.5,0.01,84.6,0.81,ito:ITO_00101,Vision process,Rank\\-1
51,1,Person Re-Identification,CUHK03 labeled,2020-01,PLR-OSNet,84.6,100.0,5.2,0.06,84.6,0.86,ito:ITO_00101,Vision process,Rank\\-1
52,1,Person Re-Identification,MARS,2017-03,LuNet,75.56,83.96,75.56,0.84,90.0,0.77,ito:ITO_00101,Vision process,Rank\\-1
53,1,Person Re-Identification,MARS,2017-03,TriNet (RK),81.21,90.23,5.6,0.06,90.0,0.83,ito:ITO_00101,Vision process,Rank\\-1
54,1,Person Re-Identification,MARS,2019-08,NVAN,90.0,100.0,8.8,0.1,90.0,0.92,ito:ITO_00101,Vision process,Rank\\-1
55,1,Unsupervised Person Re-Identification,DukeMTMC-reID,2017-05,PUL,30.0,41.44,30.0,0.41,72.4,0.31,ito:ITO_00101,Vision process,Rank\\-1
56,1,Unsupervised Person Re-Identification,DukeMTMC-reID,2017-11,SPGAN+LMP,46.4,64.09,16.4,0.23,72.4,0.47,ito:ITO_00101,Vision process,Rank\\-1
57,1,Unsupervised Person Re-Identification,DukeMTMC-reID,2018-11,Self-Similarity Grouping (one shot),72.4,100.0,26.0,0.36,72.4,0.74,ito:ITO_00101,Vision process,Rank\\-1
58,1,Unsupervised Person Re-Identification,Market-1501,2017-05,PUL,45.5,52.0,45.5,0.52,87.5,0.46,ito:ITO_00101,Vision process,Rank\\-1
59,1,Unsupervised Person Re-Identification,Market-1501,2017-11,SPGAN+LMP,57.7,65.94,12.2,0.14,87.5,0.59,ito:ITO_00101,Vision process,Rank\\-1
60,1,Unsupervised Person Re-Identification,Market-1501,2018-11,Self-Similarity Grouping (one shot),87.5,100.0,29.8,0.34,87.5,0.89,ito:ITO_00101,Vision process,Rank\\-1
61,1,Person Re-Identification,CUHK03 detected,2017-01,IDE-R,21.3,26.49,21.3,0.26,80.4,0.22,ito:ITO_00101,Vision process,Rank\\-1
62,1,Person Re-Identification,CUHK03 detected,2017-01,IDE-R+XQDA,31.1,38.68,9.8,0.12,80.4,0.32,ito:ITO_00101,Vision process,Rank\\-1
63,1,Person Re-Identification,CUHK03 detected,2017-03,SVDNet-ResNet50,41.5,51.62,10.4,0.13,80.4,0.42,ito:ITO_00101,Vision process,Rank\\-1
64,1,Person Re-Identification,CUHK03 detected,2018-02,HA-CNN (CVPR'18),41.7,51.87,0.2,0.0,80.4,0.43,ito:ITO_00101,Vision process,Rank\\-1
65,1,Person Re-Identification,CUHK03 detected,2018-04,MGN (ACM MM'18),68.0,84.58,26.3,0.33,80.4,0.69,ito:ITO_00101,Vision process,Rank\\-1
66,1,Person Re-Identification,CUHK03 detected,2018-10,Pyramid (CVPR'19),78.9,98.13,10.9,0.14,80.4,0.81,ito:ITO_00101,Vision process,Rank\\-1
67,1,Person Re-Identification,CUHK03 detected,2020-01,PLR-OSNet,80.4,100.0,1.5,0.02,80.4,0.82,ito:ITO_00101,Vision process,Rank\\-1
68,1,Person Re-Identification,PRID2011,2017-09,DGM+MLAPG+,73.1,75.67,73.1,0.76,96.6,0.75,ito:ITO_00101,Vision process,Rank\\-1
69,1,Person Re-Identification,PRID2011,2017-10,SMP*,80.9,83.75,7.8,0.08,96.6,0.83,ito:ITO_00101,Vision process,Rank\\-1
70,1,Person Re-Identification,PRID2011,2018-06,Snippet (Supervised),93.0,96.27,12.1,0.13,96.6,0.95,ito:ITO_00101,Vision process,Rank\\-1
71,1,Person Re-Identification,PRID2011,2019-11,B-BOT + Attention and CL loss*,96.6,100.0,3.6,0.04,96.6,0.99,ito:ITO_00101,Vision process,Rank\\-1
72,1,Unsupervised Person Re-Identification,MSMT17->DukeMTMC-reID,2017-11,SPGAN,46.4,66.19,46.4,0.66,70.1,0.47,ito:ITO_00101,Vision process,Rank\\-1
73,1,Unsupervised Person Re-Identification,MSMT17->DukeMTMC-reID,2019-10,OSNet-AIN,70.1,100.0,23.7,0.34,70.1,0.72,ito:ITO_00101,Vision process,Rank\\-1
74,1,Person Re-Identification,UAV-Human,2017-11,PCB,62.19,99.54,62.19,1.0,62.48,0.63,ito:ITO_00101,Vision process,Rank\\-1
75,1,Person Re-Identification,UAV-Human,2019-03,Tricks,62.48,100.0,0.3,0.0,62.48,0.64,ito:ITO_00101,Vision process,Rank\\-1
76,1,Person Re-Identification,DukeTracklet,2018-09,TAUDL,26.1,59.59,26.1,0.6,43.8,0.27,ito:ITO_00101,Vision process,Rank\\-1
77,1,Person Re-Identification,DukeTracklet,2019-03,UTAL,43.8,100.0,17.7,0.4,43.8,0.45,ito:ITO_00101,Vision process,Rank\\-1
78,1,Unsupervised Person Re-Identification,Market-1501->MSMT17,2018-11,Self-Similarity Grouping (one shot),27.6,100.0,27.6,1.0,27.6,0.28,ito:ITO_00101,Vision process,Rank\\-1
79,1,Unsupervised Person Re-Identification,DukeMTMC-reID->MSMT17,2018-11,Self-Similarity Grouping (one shot),43.6,100.0,43.6,1.0,43.6,0.44,ito:ITO_00101,Vision process,Rank\\-1
80,1,Person Re-Identification,iLIDS-VID,2019-03,UTAL,35.1,64.29,35.1,0.64,54.6,0.36,ito:ITO_00101,Vision process,Rank\\-1
81,1,Person Re-Identification,iLIDS-VID,2019-08,TKP,54.6,100.0,19.5,0.36,54.6,0.56,ito:ITO_00101,Vision process,Rank\\-1
82,1,Unsupervised Person Re-Identification,DukeMTMC-reID->Market-1501,2019-04,ECN,75.1,100.0,75.1,1.0,75.1,0.77,ito:ITO_00101,Vision process,Rank\\-1
83,1,Unsupervised Person Re-Identification,Market-1501->DukeMTMC-reID,2019-04,ECN,63.3,81.15,63.3,0.81,78.0,0.65,ito:ITO_00101,Vision process,Rank\\-1
84,1,Unsupervised Person Re-Identification,Market-1501->DukeMTMC-reID,2020-01,MMT-ResNet50,78.0,100.0,14.7,0.19,78.0,0.8,ito:ITO_00101,Vision process,Rank\\-1
85,1,Unsupervised Person Re-Identification,MSMT17->Market-1501,2019-10,OSNet-AIN,71.1,100.0,71.1,1.0,71.1,0.73,ito:ITO_00101,Vision process,Rank\\-1
0,1,Person Re-Identification,DukeMTMC-reID,2014-06,LOMO + XQDA,17.04,18.38,17.04,0.18,92.7,0.17,ito:ITO_00101,Vision process,mAP
1,1,Person Re-Identification,DukeMTMC-reID,2016-04,OIM,47.4,51.13,30.4,0.33,92.7,0.48,ito:ITO_00101,Vision process,mAP
2,1,Person Re-Identification,DukeMTMC-reID,2016-11,DLCE,49.3,53.18,1.9,0.02,92.7,0.5,ito:ITO_00101,Vision process,mAP
3,1,Person Re-Identification,DukeMTMC-reID,2017-03,SVDNet,56.8,61.27,7.5,0.08,92.7,0.58,ito:ITO_00101,Vision process,mAP
4,1,Person Re-Identification,DukeMTMC-reID,2017-07,PAN + re-rank,66.74,72.0,9.9,0.11,92.7,0.68,ito:ITO_00101,Vision process,mAP
5,1,Person Re-Identification,DukeMTMC-reID,2017-11,PCB (RPP),69.2,74.65,2.5,0.03,92.7,0.71,ito:ITO_00101,Vision process,mAP
6,1,Person Re-Identification,DukeMTMC-reID,2017-11,PSE+ ECN (rank-dist),79.8,86.08,10.6,0.11,92.7,0.82,ito:ITO_00101,Vision process,mAP
7,1,Person Re-Identification,DukeMTMC-reID,2018-05,DaRe(De)+RE+RR [wang2018resource],80.0,86.3,0.2,0.0,92.7,0.82,ito:ITO_00101,Vision process,mAP
8,1,Person Re-Identification,DukeMTMC-reID,2018-07,SSP-ReID (RR),83.7,90.29,3.7,0.04,92.7,0.86,ito:ITO_00101,Vision process,mAP
9,1,Person Re-Identification,DukeMTMC-reID,2018-11,Parameter-Free Spatial Attention,85.9,92.66,2.2,0.02,92.7,0.88,ito:ITO_00101,Vision process,mAP
10,1,Person Re-Identification,DukeMTMC-reID,2018-12,"st-ReID(RE, RK,Cam)",92.7,100.0,6.8,0.07,92.7,0.95,ito:ITO_00101,Vision process,mAP
11,1,Person Re-Identification,Market-1501,2014-06,LOMO + XQDA,22.22,23.27,22.22,0.23,95.5,0.23,ito:ITO_00101,Vision process,mAP
12,1,Person Re-Identification,Market-1501,2016-03,DNS,35.68,37.36,13.5,0.14,95.5,0.36,ito:ITO_00101,Vision process,mAP
13,1,Person Re-Identification,Market-1501,2016-07,S-CNN,39.55,41.41,3.9,0.04,95.5,0.4,ito:ITO_00101,Vision process,mAP
14,1,Person Re-Identification,Market-1501,2016-10,IDE,46.0,48.17,6.5,0.07,95.5,0.47,ito:ITO_00101,Vision process,mAP
15,1,Person Re-Identification,Market-1501,2016-11,DLCE,59.9,62.72,13.9,0.15,95.5,0.61,ito:ITO_00101,Vision process,mAP
16,1,Person Re-Identification,Market-1501,2017-01,GAN,66.07,69.18,6.2,0.06,95.5,0.68,ito:ITO_00101,Vision process,mAP
17,1,Person Re-Identification,Market-1501,2017-03,TriNet (RK),81.07,84.89,15.0,0.16,95.5,0.83,ito:ITO_00101,Vision process,mAP
18,1,Person Re-Identification,Market-1501,2017-07,PAN (GAN)+re-rank,81.53,85.37,0.5,0.01,95.5,0.83,ito:ITO_00101,Vision process,mAP
19,1,Person Re-Identification,Market-1501,2017-11,AlignedReID (RK),90.7,94.97,9.2,0.1,95.5,0.93,ito:ITO_00101,Vision process,mAP
20,1,Person Re-Identification,Market-1501,2018-07,SSP-ReID (RR),90.8,95.08,0.1,0.0,95.5,0.93,ito:ITO_00101,Vision process,mAP
21,1,Person Re-Identification,Market-1501,2018-11,Parameter-Free Spatial Attention (RK),91.7,96.02,0.9,0.01,95.5,0.94,ito:ITO_00101,Vision process,mAP
22,1,Person Re-Identification,Market-1501,2018-12,"st-ReID(RE, RK)",95.5,100.0,3.8,0.04,95.5,0.98,ito:ITO_00101,Vision process,mAP
23,1,Human-Object Interaction Detection,HICO,2015-05,R*CNN,28.5,60.51,28.5,0.61,47.1,0.29,ito:ITO_00101,Vision process,mAP
24,1,Human-Object Interaction Detection,HICO,2016-04,Mallya & Lazebnik,36.1,76.65,7.6,0.16,47.1,0.37,ito:ITO_00101,Vision process,mAP
25,1,Human-Object Interaction Detection,HICO,2018-07,Pairwise-Part,39.9,84.71,3.8,0.08,47.1,0.41,ito:ITO_00101,Vision process,mAP
26,1,Human-Object Interaction Detection,HICO,2019-04,HAKE,47.1,100.0,7.2,0.15,47.1,0.48,ito:ITO_00101,Vision process,mAP
27,1,Action Detection,Multi-THUMOS,2015-07,Two-stream + LSTM,28.1,60.56,28.1,0.61,46.4,0.29,ito:ITO_00101,Vision process,mAP
28,1,Action Detection,Multi-THUMOS,2017-12,I3D + our super-event,36.4,78.45,8.3,0.18,46.4,0.37,ito:ITO_00101,Vision process,mAP
29,1,Action Detection,Multi-THUMOS,2018-03,TGM,46.4,100.0,10.0,0.22,46.4,0.47,ito:ITO_00101,Vision process,mAP
30,1,Image Retrieval,Par6k,2015-11,R-MAC+R+QE,86.5,88.45,86.5,0.88,97.8,0.88,ito:ITO_00101,Vision process,mAP
31,1,Image Retrieval,Par6k,2016-04,DIR+QE*,93.8,95.91,7.3,0.07,97.8,0.96,ito:ITO_00101,Vision process,mAP
32,1,Image Retrieval,Par6k,2016-12,DELF+FT+ATT+DIR+QE,95.7,97.85,1.9,0.02,97.8,0.98,ito:ITO_00101,Vision process,mAP
33,1,Image Retrieval,Par6k,2018-11,Offline Diffusion,97.8,100.0,2.1,0.02,97.8,1.0,ito:ITO_00101,Vision process,mAP
34,1,Image Retrieval,Par106k,2015-11,R-MAC,75.7,78.69,75.7,0.79,96.2,0.77,ito:ITO_00101,Vision process,mAP
35,1,Image Retrieval,Par106k,2015-11,R-MAC+R+QE,79.8,82.95,4.1,0.04,96.2,0.82,ito:ITO_00101,Vision process,mAP
36,1,Image Retrieval,Par106k,2016-04,DIR+QE*,90.5,94.07,10.7,0.11,96.2,0.93,ito:ITO_00101,Vision process,mAP
37,1,Image Retrieval,Par106k,2016-12,DELF+FT+ATT+DIR+QE,92.8,96.47,2.3,0.02,96.2,0.95,ito:ITO_00101,Vision process,mAP
38,1,Image Retrieval,Par106k,2018-11,Offline Diffusion,96.2,100.0,3.4,0.04,96.2,0.98,ito:ITO_00101,Vision process,mAP
39,1,Action Recognition In Videos,ActivityNet,2015-12,VGG19 + 393K webcam images,53.8,71.16,53.8,0.71,75.6,0.55,ito:ITO_00101,Vision process,mAP
40,1,Action Recognition In Videos,ActivityNet,2016-09,LSTM + Pretrained on YT-8M,75.6,100.0,21.8,0.29,75.6,0.77,ito:ITO_00101,Vision process,mAP
41,1,Action Recognition,ActivityNet,2015-12,VGG19,52.3,97.21,52.3,0.97,53.8,0.53,ito:ITO_00101,Vision process,mAP
42,1,Action Recognition,ActivityNet,2015-12,VGG19 + 393K webcam images,53.8,100.0,1.5,0.03,53.8,0.55,ito:ITO_00101,Vision process,mAP
43,1,Temporal Action Localization,MEXaction2,2016-01,S-CNN,7.4,100.0,7.4,1.0,7.4,0.08,ito:ITO_00101,Vision process,mAP
44,1,Person Re-Identification,MSMT17,2016-11,DLCE,31.58,51.94,31.58,0.52,60.8,0.32,ito:ITO_00101,Vision process,mAP
45,1,Person Re-Identification,MSMT17,2019-04,DG-Net,52.3,86.02,20.7,0.34,60.8,0.53,ito:ITO_00101,Vision process,mAP
46,1,Person Re-Identification,MSMT17,2019-05,OSNet,52.9,87.01,0.6,0.01,60.8,0.54,ito:ITO_00101,Vision process,mAP
47,1,Person Re-Identification,MSMT17,2019-08,ABD-Net (ResNet-50),60.8,100.0,7.9,0.13,60.8,0.62,ito:ITO_00101,Vision process,mAP
48,1,Pose Estimation,UAV-Human,2016-12,AlphaPose,56.9,100.0,56.9,1.0,56.9,0.58,ito:ITO_00101,Vision process,mAP
49,1,Action Detection,Charades,2016-12,Sigurdsson et al.,9.6,43.05,9.6,0.43,22.3,0.1,ito:ITO_00101,Vision process,mAP
50,1,Action Detection,Charades,2017-03,R-C3D,12.4,55.61,2.8,0.13,22.3,0.13,ito:ITO_00101,Vision process,mAP
51,1,Action Detection,Charades,2017-12,Super-events,19.41,87.04,7.0,0.31,22.3,0.2,ito:ITO_00101,Vision process,mAP
52,1,Action Detection,Charades,2018-03,TGM,22.3,100.0,2.9,0.13,22.3,0.23,ito:ITO_00101,Vision process,mAP
53,1,Temporal Action Localization,ActivityNet-1.3,2017-03,SSN,32.26,88.58,32.26,0.89,36.42,0.33,ito:ITO_00101,Vision process,mAP
54,1,Temporal Action Localization,ActivityNet-1.3,2019-07,BMN,36.42,100.0,4.2,0.12,36.42,0.37,ito:ITO_00101,Vision process,mAP
55,1,Action Classification,ActivityNet-1.2,2017-03,UntrimmedNets,87.7,94.1,87.7,0.94,93.2,0.9,ito:ITO_00101,Vision process,mAP
56,1,Action Classification,ActivityNet-1.2,2018-07,W-TALC,93.2,100.0,5.5,0.06,93.2,0.95,ito:ITO_00101,Vision process,mAP
57,1,Action Classification,THUMOS’14,2017-03,UntrimmedNets,82.2,94.59,82.2,0.95,86.9,0.84,ito:ITO_00101,Vision process,mAP
58,1,Action Classification,THUMOS’14,2018-07,W-TALC,85.6,98.5,3.4,0.04,86.9,0.88,ito:ITO_00101,Vision process,mAP
59,1,Action Classification,THUMOS’14,2019-08,3C-Net,86.9,100.0,1.3,0.01,86.9,0.89,ito:ITO_00101,Vision process,mAP
60,1,Person Re-Identification,MARS,2017-03,LuNet (RK),73.68,83.25,73.68,0.83,88.5,0.75,ito:ITO_00101,Vision process,mAP
61,1,Person Re-Identification,MARS,2017-03,TriNet (RK),77.43,87.49,3.8,0.04,88.5,0.79,ito:ITO_00101,Vision process,mAP
62,1,Person Re-Identification,MARS,2019-08,NVAN,82.8,93.56,5.4,0.06,88.5,0.85,ito:ITO_00101,Vision process,mAP
63,1,Person Re-Identification,MARS,2019-11,B-BOT + OSM + CL Centers* (Re-rank),88.5,100.0,5.7,0.06,88.5,0.9,ito:ITO_00101,Vision process,mAP
64,1,Human-Object Interaction Detection,HICO-DET,2017-04,InteractNet,9.94,43.89,9.94,0.44,22.65,0.1,ito:ITO_00101,Vision process,mAP
65,1,Human-Object Interaction Detection,HICO-DET,2018-08,GPNN,13.11,57.88,3.2,0.14,22.65,0.13,ito:ITO_00101,Vision process,mAP
66,1,Human-Object Interaction Detection,HICO-DET,2018-08,iCAN,14.84,65.52,1.7,0.08,22.65,0.15,ito:ITO_00101,Vision process,mAP
67,1,Human-Object Interaction Detection,HICO-DET,2018-11,TIN-PAMI,17.84,78.76,3.0,0.13,22.65,0.18,ito:ITO_00101,Vision process,mAP
68,1,Human-Object Interaction Detection,HICO-DET,2019-12,PPDM,21.92,96.78,4.1,0.18,22.65,0.22,ito:ITO_00101,Vision process,mAP
69,1,Human-Object Interaction Detection,HICO-DET,2020-04,HAKE,22.65,100.0,0.7,0.03,22.65,0.23,ito:ITO_00101,Vision process,mAP
70,1,Pose Tracking,PoseTrack2017,2017-10,PoseTrack,59.22,79.01,59.22,0.79,74.95,0.61,ito:ITO_00101,Vision process,mAP
71,1,Pose Tracking,PoseTrack2017,2017-12,ProTracker,59.56,79.47,0.3,0.0,74.95,0.61,ito:ITO_00101,Vision process,mAP
72,1,Pose Tracking,PoseTrack2017,2018-02,PoseFlow,62.95,83.99,3.4,0.05,74.95,0.64,ito:ITO_00101,Vision process,mAP
73,1,Pose Tracking,PoseTrack2017,2018-04,MSRA (FlowTrack),74.57,99.49,11.6,0.15,74.95,0.76,ito:ITO_00101,Vision process,mAP
74,1,Pose Tracking,PoseTrack2017,2019-02,HRNet-W48 COCO,74.95,100.0,0.4,0.01,74.95,0.77,ito:ITO_00101,Vision process,mAP
75,1,Unsupervised Person Re-Identification,MSMT17->DukeMTMC-reID,2017-11,SPGAN,26.2,60.51,26.2,0.61,43.3,0.27,ito:ITO_00101,Vision process,mAP
76,1,Unsupervised Person Re-Identification,MSMT17->DukeMTMC-reID,2019-10,OSNet-AIN,43.3,100.0,17.1,0.39,43.3,0.44,ito:ITO_00101,Vision process,mAP
77,1,Unsupervised Domain Adaptation,Duke to Market,2017-11,SPGAN,22.8,32.02,22.8,0.32,71.2,0.23,ito:ITO_00101,Vision process,mAP
78,1,Unsupervised Domain Adaptation,Duke to Market,2018-11,SSG,58.3,81.88,35.5,0.5,71.2,0.6,ito:ITO_00101,Vision process,mAP
79,1,Unsupervised Domain Adaptation,Duke to Market,2020-01,MMT,71.2,100.0,12.9,0.18,71.2,0.73,ito:ITO_00101,Vision process,mAP
80,1,Unsupervised Domain Adaptation,Market to Duke,2017-11,SPGAN,22.3,34.25,22.3,0.34,65.1,0.23,ito:ITO_00101,Vision process,mAP
81,1,Unsupervised Domain Adaptation,Market to Duke,2018-11,SSG,53.4,82.03,31.1,0.48,65.1,0.55,ito:ITO_00101,Vision process,mAP
82,1,Unsupervised Domain Adaptation,Market to Duke,2020-01,MMT,65.1,100.0,11.7,0.18,65.1,0.67,ito:ITO_00101,Vision process,mAP
83,1,Unsupervised Domain Adaptation,Duke to MSMT,2017-11,PTGAN,3.3,14.16,3.3,0.14,23.3,0.03,ito:ITO_00101,Vision process,mAP
84,1,Unsupervised Domain Adaptation,Duke to MSMT,2018-11,SSG,13.3,57.08,10.0,0.43,23.3,0.14,ito:ITO_00101,Vision process,mAP
85,1,Unsupervised Domain Adaptation,Duke to MSMT,2020-01,MMT,23.3,100.0,10.0,0.43,23.3,0.24,ito:ITO_00101,Vision process,mAP
86,1,Unsupervised Domain Adaptation,Market to MSMT,2017-11,PTGAN,2.9,12.66,2.9,0.13,22.9,0.03,ito:ITO_00101,Vision process,mAP
87,1,Unsupervised Domain Adaptation,Market to MSMT,2018-11,SSG,13.2,57.64,10.3,0.45,22.9,0.13,ito:ITO_00101,Vision process,mAP
88,1,Unsupervised Domain Adaptation,Market to MSMT,2020-01,MMT,22.9,100.0,9.7,0.42,22.9,0.23,ito:ITO_00101,Vision process,mAP
89,1,Person Re-Identification,UAV-Human,2017-11,PCB,61.05,96.28,61.05,0.96,63.41,0.62,ito:ITO_00101,Vision process,mAP
90,1,Person Re-Identification,UAV-Human,2019-03,Tricks,63.41,100.0,2.4,0.04,63.41,0.65,ito:ITO_00101,Vision process,mAP
91,1,Image-to-Image Translation,Cityscapes-to-Foggy Cityscapes,2018-03,FRCNN in the wild,27.6,74.8,27.6,0.75,36.9,0.28,ito:ITO_00101,Vision process,mAP
92,1,Image-to-Image Translation,Cityscapes-to-Foggy Cityscapes,2019-05,Diversify & Match,34.6,93.77,7.0,0.19,36.9,0.35,ito:ITO_00101,Vision process,mAP
93,1,Image-to-Image Translation,Cityscapes-to-Foggy Cityscapes,2019-10,Progressive Domain Adaptation,36.9,100.0,2.3,0.06,36.9,0.38,ito:ITO_00101,Vision process,mAP
94,1,Zero-Shot Object Detection,ImageNet Detection,2018-03,ZSD-Rahman etal,16.4,100.0,16.4,1.0,16.4,0.17,ito:ITO_00101,Vision process,mAP
95,1,Pose Tracking,PoseTrack2018,2018-04,MSRA,74.03,100.0,74.03,1.0,74.03,0.76,ito:ITO_00101,Vision process,mAP
96,1,Object Detection In Aerial Images,DOTA,2018-07,Multi-class object detection in unconstrained RS imagery,68.16,100.0,68.16,1.0,68.16,0.7,ito:ITO_00101,Vision process,mAP
97,1,Human-Object Interaction Detection,Ambiguious-HOI,2018-08,iCAN,8.14,99.03,8.14,0.99,8.22,0.08,ito:ITO_00101,Vision process,mAP
98,1,Human-Object Interaction Detection,Ambiguious-HOI,2018-11,TIN,8.22,100.0,0.1,0.01,8.22,0.08,ito:ITO_00101,Vision process,mAP
99,1,Person Re-Identification,DukeTracklet,2018-09,TAUDL,20.8,56.83,20.8,0.57,36.6,0.21,ito:ITO_00101,Vision process,mAP
100,1,Person Re-Identification,DukeTracklet,2019-03,UTAL,36.6,100.0,15.8,0.43,36.6,0.37,ito:ITO_00101,Vision process,mAP
101,1,Zero-Shot Object Detection,MS-COCO,2018-11,ZSD-Polarity Loss,12.62,100.0,12.62,1.0,12.62,0.13,ito:ITO_00101,Vision process,mAP
102,1,Unsupervised Person Re-Identification,Market-1501->MSMT17,2018-11,Self-Similarity Grouping (one shot),11.8,51.53,11.8,0.52,22.9,0.12,ito:ITO_00101,Vision process,mAP
103,1,Unsupervised Person Re-Identification,Market-1501->MSMT17,2020-01,MMT-ResNet50,22.9,100.0,11.1,0.48,22.9,0.23,ito:ITO_00101,Vision process,mAP
104,1,Unsupervised Person Re-Identification,DukeMTMC-reID->MSMT17,2018-11,Self-Similarity Grouping (one shot),23.6,100.0,23.6,1.0,23.6,0.24,ito:ITO_00101,Vision process,mAP
105,1,Action Recognition,AVA v2.2,2018-12,"SlowFast, 8x8, R101 (Kinetics-400 pretraining)",23.8,86.55,23.8,0.87,27.5,0.24,ito:ITO_00101,Vision process,mAP
106,1,Action Recognition,AVA v2.2,2018-12,"SlowFast, 8x8 R101+NL (Kinetics-600 pretraining)",27.1,98.55,3.3,0.12,27.5,0.28,ito:ITO_00101,Vision process,mAP
107,1,Action Recognition,AVA v2.2,2018-12,"SlowFast, 16x8 R101+NL (Kinetics-600 pretraining)",27.5,100.0,0.4,0.01,27.5,0.28,ito:ITO_00101,Vision process,mAP
108,1,Activity Prediction,ActEV,2019-02,Next,0.192,100.0,0.192,1.0,0.192,0.0,ito:ITO_00101,Vision process,mAP
109,1,3D Instance Segmentation,ScanNet,2019-02,MASC,0.447,100.0,0.447,1.0,0.447,0.0,ito:ITO_00101,Vision process,mAP
110,1,Action Detection,UCF101-24,2019-04,two-in-one two stream,22.02,79.49,22.02,0.79,27.7,0.23,ito:ITO_00101,Vision process,mAP
111,1,Action Detection,UCF101-24,2020-01,Ours (MOC),27.7,100.0,5.7,0.21,27.7,0.28,ito:ITO_00101,Vision process,mAP
112,1,Unsupervised Person Re-Identification,Market-1501->DukeMTMC-reID,2019-04,ECN,40.4,62.06,40.4,0.62,65.1,0.41,ito:ITO_00101,Vision process,mAP
113,1,Unsupervised Person Re-Identification,Market-1501->DukeMTMC-reID,2020-01,MMT-ResNet50,65.1,100.0,24.7,0.38,65.1,0.67,ito:ITO_00101,Vision process,mAP
114,1,Unsupervised Person Re-Identification,DukeMTMC-reID->Market-1501,2019-04,ECN,43.0,60.39,43.0,0.6,71.2,0.44,ito:ITO_00101,Vision process,mAP
115,1,Unsupervised Person Re-Identification,DukeMTMC-reID->Market-1501,2020-01,MMT-ResNet50,71.2,100.0,28.2,0.4,71.2,0.73,ito:ITO_00101,Vision process,mAP
116,1,Action Classification,THUMOS'14,2019-08,3C-Net,86.9,100.0,86.9,1.0,86.9,0.89,ito:ITO_00101,Vision process,mAP
117,1,3D Object Detection,nuScenes,2019-08,MEGVII,0.528,100.0,0.528,1.0,0.528,0.01,ito:ITO_00101,Vision process,mAP
118,1,Depth Estimation,NYU-Depth V2,2019-08,A2J,8.61,100.0,8.61,1.0,8.61,0.09,ito:ITO_00101,Vision process,mAP
119,1,Unsupervised Person Re-Identification,MSMT17->Market-1501,2019-10,OSNet-AIN,52.7,100.0,52.7,1.0,52.7,0.54,ito:ITO_00101,Vision process,mAP
120,1,Fine-Grained Image Classification,Con-Text,2020-01,PHOC descriptor + Fisher Vector Encoding,80.2,100.0,80.2,1.0,80.2,0.82,ito:ITO_00101,Vision process,mAP
121,1,Fine-Grained Image Classification,Bottles,2020-01,PHOC descriptor + Fisher Vector Encoding,77.4,100.0,77.4,1.0,77.4,0.79,ito:ITO_00101,Vision process,mAP
0,1,Action Recognition In Videos,Sports-1M,2014-06,DeepVideo’s Slow Fusion,60.9,80.66,60.9,0.81,75.5,0.75,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-1
1,1,Action Recognition In Videos,Sports-1M,2015-03,Conv pooling,71.7,94.97,10.8,0.14,75.5,0.88,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-1
2,1,Action Recognition In Videos,Sports-1M,2017-11,R(2+1)D-Two-Stream-32frame,73.3,97.09,1.6,0.02,75.5,0.9,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-1
3,1,Action Recognition In Videos,Sports-1M,2019-04,ir-CSN-152,75.5,100.0,2.2,0.03,75.5,0.93,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-1
4,1,Action Recognition,Sports-1M,2014-06,DeepVideo’s Slow Fusion,60.9,80.66,60.9,0.81,75.5,0.75,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-1
5,1,Action Recognition,Sports-1M,2014-12,C3D,61.1,80.93,0.2,0.0,75.5,0.75,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-1
6,1,Action Recognition,Sports-1M,2015-03,Conv pooling,71.7,94.97,10.6,0.14,75.5,0.88,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-1
7,1,Action Recognition,Sports-1M,2017-11,R[2+1]D-Two-Stream-32frame,73.3,97.09,1.6,0.02,75.5,0.9,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-1
8,1,Action Recognition,Sports-1M,2019-04,ip-CSN-101 (RGB),74.9,99.21,1.6,0.02,75.5,0.92,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-1
9,1,Action Recognition,Sports-1M,2019-04,ip-CSN-152 (RGB),75.5,100.0,0.6,0.01,75.5,0.93,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-1
10,1,Action Recognition In Videos,Kinetics-400,2017-08,Inception-ResNet,73.0,89.79,73.0,0.9,81.3,0.9,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-1
11,1,Action Recognition In Videos,Kinetics-400,2018-12,SlowFast+NL,79.8,98.15,6.8,0.08,81.3,0.98,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-1
12,1,Action Recognition In Videos,Kinetics-400,2019-05,R(2+1)D-152*,81.3,100.0,1.5,0.02,81.3,1.0,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-1
13,1,Action Recognition In Videos,miniSports,2019-05,G-Blend,62.8,100.0,62.8,1.0,62.8,0.77,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-1
14,1,Action Recognition,miniSports,2019-05,G-Blend,62.8,100.0,62.8,1.0,62.8,0.77,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-1
0,1,Action Recognition In Videos,Sports-1M,2014-06,DeepVideo’s Slow Fusion,80.2,86.52,80.2,0.87,92.7,0.84,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-5
1,1,Action Recognition In Videos,Sports-1M,2014-12,C3D,84.4,91.05,4.2,0.05,92.7,0.89,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-5
2,1,Action Recognition In Videos,Sports-1M,2015-03,Conv pooling,90.4,97.52,6.0,0.06,92.7,0.95,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-5
3,1,Action Recognition In Videos,Sports-1M,2017-11,R(2+1)D-Two-Stream-32frame,91.9,99.14,1.5,0.02,92.7,0.97,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-5
4,1,Action Recognition In Videos,Sports-1M,2019-04,ir-CSN-152,92.7,100.0,0.8,0.01,92.7,0.97,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-5
5,1,Action Recognition,Sports-1M,2014-06,DeepVideo’s Slow Fusion,80.2,86.42,80.2,0.86,92.8,0.84,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-5
6,1,Action Recognition,Sports-1M,2014-12,C3D,85.5,92.13,5.3,0.06,92.8,0.9,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-5
7,1,Action Recognition,Sports-1M,2015-03,Conv pooling,90.4,97.41,4.9,0.05,92.8,0.95,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-5
8,1,Action Recognition,Sports-1M,2017-11,R[2+1]D-Two-Stream-32frame,91.9,99.03,1.5,0.02,92.8,0.97,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-5
9,1,Action Recognition,Sports-1M,2019-04,ip-CSN-101 (RGB),92.6,99.78,0.7,0.01,92.8,0.97,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-5
10,1,Action Recognition,Sports-1M,2019-04,ip-CSN-152 (RGB),92.8,100.0,0.2,0.0,92.8,0.98,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-5
11,1,Action Recognition In Videos,Kinetics-400,2017-08,Inception-ResNet,90.9,95.58,90.9,0.96,95.1,0.96,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-5
12,1,Action Recognition In Videos,Kinetics-400,2018-12,SlowFast+NL,93.9,98.74,3.0,0.03,95.1,0.99,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-5
13,1,Action Recognition In Videos,Kinetics-400,2019-05,R(2+1)D-152*,95.1,100.0,1.2,0.01,95.1,1.0,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-5
14,1,Action Recognition In Videos,miniSports,2019-05,G-Blend,85.5,100.0,85.5,1.0,85.5,0.9,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-5
15,1,Action Recognition,miniSports,2019-05,G-Blend,85.5,100.0,85.5,1.0,85.5,0.9,ito:ITO_00101,Vision process,Video\\ hit\\-at\\-5
0,1,Action Recognition,Sports-1M,2014-06,DeepVideo’s Slow Fusion,41.9,73.51,41.9,0.74,57.0,0.74,ito:ITO_00101,Vision process,Clip\\ Hit\\-at\\-1
1,1,Action Recognition,Sports-1M,2014-12,C3D,46.1,80.88,4.2,0.07,57.0,0.81,ito:ITO_00101,Vision process,Clip\\ Hit\\-at\\-1
2,1,Action Recognition,Sports-1M,2017-11,P3D,47.9,84.04,1.8,0.03,57.0,0.84,ito:ITO_00101,Vision process,Clip\\ Hit\\-at\\-1
3,1,Action Recognition,Sports-1M,2017-11,R[2+1]D-RGB-32frame,57.0,100.0,9.1,0.16,57.0,1.0,ito:ITO_00101,Vision process,Clip\\ Hit\\-at\\-1
4,1,Action Recognition In Videos,Sports-1M,2014-06,DeepVideo’s Slow Fusion,41.9,73.51,41.9,0.74,57.0,0.74,ito:ITO_00101,Vision process,Clip\\ Hit\\-at\\-1
5,1,Action Recognition In Videos,Sports-1M,2014-12,C3D,44.9,78.77,3.0,0.05,57.0,0.79,ito:ITO_00101,Vision process,Clip\\ Hit\\-at\\-1
6,1,Action Recognition In Videos,Sports-1M,2017-11,P3D,47.9,84.04,3.0,0.05,57.0,0.84,ito:ITO_00101,Vision process,Clip\\ Hit\\-at\\-1
7,1,Action Recognition In Videos,Sports-1M,2017-11,R(2+1)D-RGB-32frame ,57.0,100.0,9.1,0.16,57.0,1.0,ito:ITO_00101,Vision process,Clip\\ Hit\\-at\\-1
8,1,Action Recognition,miniSports,2019-05,G-Blend,49.7,100.0,49.7,1.0,49.7,0.87,ito:ITO_00101,Vision process,Clip\\ Hit\\-at\\-1
9,1,Action Recognition In Videos,miniSports,2019-05,G-Blend,49.7,100.0,49.7,1.0,49.7,0.87,ito:ITO_00101,Vision process,Clip\\ Hit\\-at\\-1
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,LSTM,56.0,73.68,56,0.74,76,0.59,ito:ITO_00101,Vision process,Accuracy\\ \\(CS\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,60.0,78.95,4,0.05,76,0.63,ito:ITO_00101,Vision process,Accuracy\\ \\(CS\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-04,Res-TCN,63.0,82.89,3,0.04,76,0.67,ito:ITO_00101,Vision process,Accuracy\\ \\(CS\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2018-01,ST-GCN,71.0,93.42,8,0.11,76,0.75,ito:ITO_00101,Vision process,Accuracy\\ \\(CS\\)
4,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,76.0,100.0,5,0.07,76,0.8,ito:ITO_00101,Vision process,Accuracy\\ \\(CS\\)
5,1,Multimodal Activity Recognition,UTD-MHAD,2018-06,PoseMap,94.5,100.0,94.5,1.0,94.5,1.0,ito:ITO_00101,Vision process,Accuracy\\ \\(CS\\)
0,1,Action Recognition In Videos,VIRAT Ground 2.0,2014-06,DHCM,66.45,100.0,66.45,1.0,66.45,0.71,ito:ITO_00101,Vision process,Average\\ Accuracy
1,1,Action Recognition,VIRAT Ground 2.0,2014-06,DHCM,66.45,100.0,66.45,1.0,66.45,0.71,ito:ITO_00101,Vision process,Average\\ Accuracy
2,1,Domain Adaptation,Office-Caltech,2014-12,DDC[[Tzeng et al.2014]],88.2,94.84,88.2,0.95,93.0,0.95,ito:ITO_00101,Vision process,Average\\ Accuracy
3,1,Domain Adaptation,Office-Caltech,2015-02,DAN[[Long et al.2015]],90.1,96.88,1.9,0.02,93.0,0.97,ito:ITO_00101,Vision process,Average\\ Accuracy
4,1,Domain Adaptation,Office-Caltech,2018-07,MEDA[[Wang et al.2018]],92.8,99.78,2.7,0.03,93.0,1.0,ito:ITO_00101,Vision process,Average\\ Accuracy
5,1,Domain Adaptation,Office-Caltech,2019-11,SPL,93.0,100.0,0.2,0.0,93.0,1.0,ito:ITO_00101,Vision process,Average\\ Accuracy
6,1,Domain Adaptation,Office-31,2015-12,ResNet-50,76.1,84.0,76.1,0.84,90.6,0.82,ito:ITO_00101,Vision process,Average\\ Accuracy
7,1,Domain Adaptation,Office-31,2017-04,GTA,86.5,95.47,10.4,0.11,90.6,0.93,ito:ITO_00101,Vision process,Average\\ Accuracy
8,1,Domain Adaptation,Office-31,2018-11,IAFN+ENT,87.1,96.14,0.6,0.01,90.6,0.94,ito:ITO_00101,Vision process,Average\\ Accuracy
9,1,Domain Adaptation,Office-31,2019-01,Contrastive Adaptation Network,90.6,100.0,3.5,0.04,90.6,0.97,ito:ITO_00101,Vision process,Average\\ Accuracy
10,1,3D Reconstruction,Scan2CAD,2016-03,3DMatch,10.29,32.48,10.29,0.32,31.68,0.11,ito:ITO_00101,Vision process,Average\\ Accuracy
11,1,3D Reconstruction,Scan2CAD,2018-11,Scan2CAD,31.68,100.0,21.4,0.68,31.68,0.34,ito:ITO_00101,Vision process,Average\\ Accuracy
12,1,Scene Segmentation,ScanNet,2016-12,PointNet++,60.2,80.27,60.2,0.8,75.0,0.65,ito:ITO_00101,Vision process,Average\\ Accuracy
13,1,Scene Segmentation,ScanNet,2018-03,3DMV,75.0,100.0,14.8,0.2,75.0,0.81,ito:ITO_00101,Vision process,Average\\ Accuracy
14,1,Facial Action Unit Detection,BP4D,2017-02,Baseline,56.1,68.58,56.1,0.69,81.8,0.6,ito:ITO_00101,Vision process,Average\\ Accuracy
15,1,Facial Action Unit Detection,BP4D,2017-04,Multi-View,81.8,100.0,25.7,0.31,81.8,0.88,ito:ITO_00101,Vision process,Average\\ Accuracy
16,1,Skeleton Based Action Recognition,UAV-Human,2018-01,ST-GCN,30.25,86.83,30.25,0.87,34.84,0.33,ito:ITO_00101,Vision process,Average\\ Accuracy
17,1,Skeleton Based Action Recognition,UAV-Human,2018-05,2S-AGCN,34.84,100.0,4.6,0.13,34.84,0.37,ito:ITO_00101,Vision process,Average\\ Accuracy
18,1,Egocentric Activity Recognition,EGTEA,2018-07,Ego-RNN,60.8,96.97,60.8,0.97,62.7,0.65,ito:ITO_00101,Vision process,Average\\ Accuracy
19,1,Egocentric Activity Recognition,EGTEA,2018-11,LSTA,61.9,98.72,1.1,0.02,62.7,0.67,ito:ITO_00101,Vision process,Average\\ Accuracy
20,1,Egocentric Activity Recognition,EGTEA,2020-02,SAP,62.7,100.0,0.8,0.01,62.7,0.67,ito:ITO_00101,Vision process,Average\\ Accuracy
0,1,Semantic Segmentation,PASCAL VOC 2012 test,2014-07,SDS,51.6,57.98,51.6,0.58,89.0,0.52,ito:ITO_00101,Vision process,Mean\\ IoU
1,1,Semantic Segmentation,PASCAL VOC 2012 test,2014-11,FCN (VGG-16),62.2,69.89,10.6,0.12,89.0,0.62,ito:ITO_00101,Vision process,Mean\\ IoU
2,1,Semantic Segmentation,PASCAL VOC 2012 test,2014-12,DeepLab-MSc-CRF-LargeFOV (VGG-16),71.6,80.45,9.4,0.11,89.0,0.72,ito:ITO_00101,Vision process,Mean\\ IoU
3,1,Semantic Segmentation,PASCAL VOC 2012 test,2015-02,CRF-RNN,74.7,83.93,3.1,0.03,89.0,0.75,ito:ITO_00101,Vision process,Mean\\ IoU
4,1,Semantic Segmentation,PASCAL VOC 2012 test,2016-03,CentraleSupelec Deep G-CRF,80.2,90.11,5.5,0.06,89.0,0.8,ito:ITO_00101,Vision process,Mean\\ IoU
5,1,Semantic Segmentation,PASCAL VOC 2012 test,2016-11,Multipath-RefineNet,84.2,94.61,4.0,0.04,89.0,0.84,ito:ITO_00101,Vision process,Mean\\ IoU
6,1,Semantic Segmentation,PASCAL VOC 2012 test,2016-11,ResNet-38 MS COCO,84.9,95.39,0.7,0.01,89.0,0.85,ito:ITO_00101,Vision process,Mean\\ IoU
7,1,Semantic Segmentation,PASCAL VOC 2012 test,2016-12,PSPNet,85.4,95.96,0.5,0.01,89.0,0.85,ito:ITO_00101,Vision process,Mean\\ IoU
8,1,Semantic Segmentation,PASCAL VOC 2012 test,2017-06,DeepLabv3-JFT,86.9,97.64,1.5,0.02,89.0,0.87,ito:ITO_00101,Vision process,Mean\\ IoU
9,1,Semantic Segmentation,PASCAL VOC 2012 test,2018-02,DeepLabv3+ (Xception-65-JFT),89.0,100.0,2.1,0.02,89.0,0.89,ito:ITO_00101,Vision process,Mean\\ IoU
10,1,Semantic Segmentation,SkyScapes-Dense,2014-11,FCN8s (ResNet-50),33.06,82.38,33.06,0.82,40.13,0.33,ito:ITO_00101,Vision process,Mean\\ IoU
11,1,Semantic Segmentation,SkyScapes-Dense,2018-02,DeepLabv3+,38.2,95.19,5.1,0.13,40.13,0.38,ito:ITO_00101,Vision process,Mean\\ IoU
12,1,Semantic Segmentation,SkyScapes-Dense,2019-10,SkyScapesNet-Dense,40.13,100.0,1.9,0.05,40.13,0.4,ito:ITO_00101,Vision process,Mean\\ IoU
13,1,Semantic Segmentation,SkyScapes-Lane,2014-11,FCN8s (ResNet-50),13.74,26.98,13.74,0.27,50.93,0.14,ito:ITO_00101,Vision process,Mean\\ IoU
14,1,Semantic Segmentation,SkyScapes-Lane,2019-10,SkyScapesNet-Lane,50.93,100.0,37.2,0.73,50.93,0.51,ito:ITO_00101,Vision process,Mean\\ IoU
15,1,Scene Segmentation,SUN-RGBD,2014-12,DeepLab-LargeFOV,32.08,95.82,32.08,0.96,33.48,0.32,ito:ITO_00101,Vision process,Mean\\ IoU
16,1,Scene Segmentation,SUN-RGBD,2019-08,Index Network,33.48,100.0,1.4,0.04,33.48,0.34,ito:ITO_00101,Vision process,Mean\\ IoU
17,1,Semantic Segmentation,CamVid,2014-12,DeepLab-MSc-CRF-LargeFOV,61.6,75.4,61.6,0.75,81.7,0.62,ito:ITO_00101,Vision process,Mean\\ IoU
18,1,Semantic Segmentation,CamVid,2015-11,Dilated Convolutions,65.3,79.93,3.7,0.05,81.7,0.65,ito:ITO_00101,Vision process,Mean\\ IoU
19,1,Semantic Segmentation,CamVid,2016-11,FC-DenseNet103,66.9,81.88,1.6,0.02,81.7,0.67,ito:ITO_00101,Vision process,Mean\\ IoU
20,1,Semantic Segmentation,CamVid,2016-12,PSPNet,69.1,84.58,2.2,0.03,81.7,0.69,ito:ITO_00101,Vision process,Mean\\ IoU
21,1,Semantic Segmentation,CamVid,2018-12,DeepLabV3Plus + SDCNetAug,81.7,100.0,12.6,0.15,81.7,0.82,ito:ITO_00101,Vision process,Mean\\ IoU
22,1,Cell Segmentation,DIC-HeLa,2015-05,U-Net,0.7756,100.0,0.7756,1.0,0.7756,0.01,ito:ITO_00101,Vision process,Mean\\ IoU
23,1,Cell Segmentation,PhC-U373,2015-05,U-Net,0.9203,100.0,0.9203,1.0,0.9203,0.01,ito:ITO_00101,Vision process,Mean\\ IoU
24,1,Semantic Segmentation,PASCAL VOC 2011,2016-11,DLDL-8s+CRF,67.6,100.0,67.6,1.0,67.6,0.68,ito:ITO_00101,Vision process,Mean\\ IoU
25,1,Semantic Segmentation,PASCAL VOC 2012,2016-11,DLDL-8s+CRF,67.1,100.0,67.1,1.0,67.1,0.67,ito:ITO_00101,Vision process,Mean\\ IoU
26,1,Semantic Segmentation,NYU Depth v2,2016-11,RefineNet (ResNet-101),40.6,91.44,40.6,0.91,44.4,0.41,ito:ITO_00101,Vision process,Mean\\ IoU
27,1,Semantic Segmentation,NYU Depth v2,2019-08,Asymmetric ALNN,44.4,100.0,3.8,0.09,44.4,0.44,ito:ITO_00101,Vision process,Mean\\ IoU
28,1,Semantic Segmentation,S3DIS,2016-12,PointNet,47.6,67.42,47.6,0.67,70.6,0.48,ito:ITO_00101,Vision process,Mean\\ IoU
29,1,Semantic Segmentation,S3DIS,2017-11,SPG,62.1,87.96,14.5,0.21,70.6,0.62,ito:ITO_00101,Vision process,Mean\\ IoU
30,1,Semantic Segmentation,S3DIS,2018-12,PointCNN,65.4,92.63,3.3,0.05,70.6,0.65,ito:ITO_00101,Vision process,Mean\\ IoU
31,1,Semantic Segmentation,S3DIS,2019-04,ConvPoint,68.2,96.6,2.8,0.04,70.6,0.68,ito:ITO_00101,Vision process,Mean\\ IoU
32,1,Semantic Segmentation,S3DIS,2019-04,KPConv,70.6,100.0,2.4,0.03,70.6,0.71,ito:ITO_00101,Vision process,Mean\\ IoU
33,1,Lesion Segmentation,ISIC 2017,2017-03,Automatic skin lesion segmentation with fully convolutional-deconvolutional networks,0.765,100.0,0.765,1.0,0.765,0.01,ito:ITO_00101,Vision process,Mean\\ IoU
34,1,Semantic Segmentation,ShapeNet,2017-06,PointNet++,84.6,98.6,84.6,0.99,85.8,0.85,ito:ITO_00101,Vision process,Mean\\ IoU
35,1,Semantic Segmentation,ShapeNet,2017-11,SGPN,85.8,100.0,1.2,0.01,85.8,0.86,ito:ITO_00101,Vision process,Mean\\ IoU
36,1,Semantic Segmentation,PASCAL VOC 2007,2017-07,DeepLabv3 (ImageNet+300M),81.3,97.95,81.3,0.98,83.0,0.81,ito:ITO_00101,Vision process,Mean\\ IoU
37,1,Semantic Segmentation,PASCAL VOC 2007,2019-09,GALDNet,83.0,100.0,1.7,0.02,83.0,0.83,ito:ITO_00101,Vision process,Mean\\ IoU
38,1,Scene Segmentation,NYU Depth v2,2017-07,Dilated FCN-2s RGB,32.3,100.0,32.3,1.0,32.3,0.32,ito:ITO_00101,Vision process,Mean\\ IoU
39,1,6D Pose Estimation using RGB,LineMOD,2017-11,Single-shot Deep CNN,99.92,100.0,99.92,1.0,99.92,1.0,ito:ITO_00101,Vision process,Mean\\ IoU
40,1,6D Pose Estimation using RGBD,LineMOD,2017-11,SSD-6D,96.5,100.0,96.5,1.0,96.5,0.97,ito:ITO_00101,Vision process,Mean\\ IoU
41,1,Human Part Segmentation,CIHP,2018-08,PGN + ResNet101,55.8,82.7,55.8,0.83,67.47,0.56,ito:ITO_00101,Vision process,Mean\\ IoU
42,1,Human Part Segmentation,CIHP,2018-11,Parsing R-CNN + ResNext101,61.1,90.56,5.3,0.08,67.47,0.61,ito:ITO_00101,Vision process,Mean\\ IoU
43,1,Human Part Segmentation,CIHP,2019-10,ResNet101,67.47,100.0,6.4,0.09,67.47,0.68,ito:ITO_00101,Vision process,Mean\\ IoU
44,1,Semantic Segmentation,ScanNetV2,2018-08,SSMA,57.7,100.0,57.7,1.0,57.7,0.58,ito:ITO_00101,Vision process,Mean\\ IoU
45,1,Semantic Segmentation,Freiburg Forest,2018-08,SSMA,84.18,100.0,84.18,1.0,84.18,0.84,ito:ITO_00101,Vision process,Mean\\ IoU
46,1,Semantic Segmentation,SYNTHIA-CVPR’16,2018-08,SSMA,92.1,100.0,92.1,1.0,92.1,0.92,ito:ITO_00101,Vision process,Mean\\ IoU
47,1,Semantic Segmentation,SUN-RGBD,2018-08,SSMA,45.73,100.0,45.73,1.0,45.73,0.46,ito:ITO_00101,Vision process,Mean\\ IoU
48,1,Human Part Segmentation,MHP v2.0,2018-11,Parsing R-CNN + ResNext101,41.8,100.0,41.8,1.0,41.8,0.42,ito:ITO_00101,Vision process,Mean\\ IoU
49,1,Weakly-Supervised Semantic Segmentation,PASCAL VOC 2012 val,2019-04,IRNet (ResNet-50),63.5,100.0,63.5,1.0,63.5,0.64,ito:ITO_00101,Vision process,Mean\\ IoU
50,1,Weakly-Supervised Semantic Segmentation,PASCAL VOC 2012 test,2019-04,IRNet (ResNet-50),64.8,100.0,64.8,1.0,64.8,0.65,ito:ITO_00101,Vision process,Mean\\ IoU
51,1,Semantic Segmentation,S3DIS Area5,2019-04,KPConv,67.1,100.0,67.1,1.0,67.1,0.67,ito:ITO_00101,Vision process,Mean\\ IoU
52,1,Few-Shot Semantic Segmentation,FSS-1000,2019-07,Adapted relation network,80.12,96.11,80.12,0.96,83.36,0.8,ito:ITO_00101,Vision process,Mean\\ IoU
53,1,Few-Shot Semantic Segmentation,FSS-1000,2019-12,EfficientLab,82.78,99.3,2.7,0.03,83.36,0.83,ito:ITO_00101,Vision process,Mean\\ IoU
54,1,Few-Shot Semantic Segmentation,FSS-1000,2020-03,DoG-BConvLSTM,83.36,100.0,0.6,0.01,83.36,0.83,ito:ITO_00101,Vision process,Mean\\ IoU
55,1,Scene Understanding,ADE20K val,2020-04,CPN(ResNet-101),46.3,100.0,46.3,1.0,46.3,0.46,ito:ITO_00101,Vision process,Mean\\ IoU
0,1,Pose Estimation,Leeds Sports Poses,2014-07,"Chen&Yuille, NIPS'14",73.4,77.43,73.4,0.77,94.8,0.77,ito:ITO_00101,Vision process,PCK
1,1,Pose Estimation,Leeds Sports Poses,2016-01,Convolutional Pose Machines,90.5,95.46,17.1,0.18,94.8,0.95,ito:ITO_00101,Vision process,PCK
2,1,Pose Estimation,Leeds Sports Poses,2016-09,Part heatmap regression (ResNet-152),90.7,95.68,0.2,0.0,94.8,0.96,ito:ITO_00101,Vision process,PCK
3,1,Pose Estimation,Leeds Sports Poses,2017-02,Multi-Context Attention,92.6,97.68,1.9,0.02,94.8,0.98,ito:ITO_00101,Vision process,PCK
4,1,Pose Estimation,Leeds Sports Poses,2017-05,Stacked hourglass + Inception-resnet,93.9,99.05,1.3,0.01,94.8,0.99,ito:ITO_00101,Vision process,PCK
5,1,Pose Estimation,Leeds Sports Poses,2018-05,Residual Hourglass + ASR + AHO,94.5,99.68,0.6,0.01,94.8,1.0,ito:ITO_00101,Vision process,PCK
6,1,Pose Estimation,Leeds Sports Poses,2020-02,Soft-gated Skip Connections,94.8,100.0,0.3,0.0,94.8,1.0,ito:ITO_00101,Vision process,PCK
0,1,Face Detection,FDDB,2014-08,DPM,0.864,87.18,0.864,0.87,0.991,0.01,ito:ITO_00101,Vision process,AP
1,1,Face Detection,FDDB,2016-03,HyperFace,0.901,90.92,0.0,0.0,0.991,0.01,ito:ITO_00101,Vision process,AP
2,1,Face Detection,FDDB,2017-08,FaceBoxes,0.96,96.87,0.1,0.1,0.991,0.01,ito:ITO_00101,Vision process,AP
3,1,Face Detection,FDDB,2017-08,S3FD,0.983,99.19,0.0,0.0,0.991,0.01,ito:ITO_00101,Vision process,AP
4,1,Face Detection,FDDB,2017-09,Face R-FCN,0.99,99.9,0.0,0.0,0.991,0.01,ito:ITO_00101,Vision process,AP
5,1,Face Detection,FDDB,2018-10,DSFD,0.991,100.0,0.0,0.0,0.991,0.01,ito:ITO_00101,Vision process,AP
6,1,Face Detection,PASCAL Face,2014-08,DPM,0.9029,91.12,0.9029,0.91,0.9909,0.01,ito:ITO_00101,Vision process,AP
7,1,Face Detection,PASCAL Face,2016-03,HyperFace-ResNet,0.962,97.08,0.1,0.1,0.9909,0.01,ito:ITO_00101,Vision process,AP
8,1,Face Detection,PASCAL Face,2017-08,S3FD,0.9849,99.39,0.0,0.0,0.9909,0.01,ito:ITO_00101,Vision process,AP
9,1,Face Detection,PASCAL Face,2018-09,SRN,0.9909,100.0,0.0,0.0,0.9909,0.01,ito:ITO_00101,Vision process,AP
10,1,Face Detection,Annotated Faces in the Wild,2014-08,DPM,0.9721,97.34,0.9721,0.97,0.9987,0.01,ito:ITO_00101,Vision process,AP
11,1,Face Detection,Annotated Faces in the Wild,2016-03,HyperFace-ResNet,0.994,99.53,0.0,0.0,0.9987,0.01,ito:ITO_00101,Vision process,AP
12,1,Face Detection,Annotated Faces in the Wild,2017-08,S3FD,0.9985,99.98,0.0,0.0,0.9987,0.01,ito:ITO_00101,Vision process,AP
13,1,Face Detection,Annotated Faces in the Wild,2018-09,SRN,0.9987,100.0,0.0,0.0,0.9987,0.01,ito:ITO_00101,Vision process,AP
14,1,Dense Object Detection,SKU-110K,2015-06,Faster-RCNN,0.045,6.57,0.045,0.07,0.685,0.0,ito:ITO_00101,Vision process,AP
15,1,Dense Object Detection,SKU-110K,2016-12,YOLO9000opt,0.094,13.72,0.0,0.0,0.685,0.0,ito:ITO_00101,Vision process,AP
16,1,Dense Object Detection,SKU-110K,2017-08,RetinaNet,0.455,66.42,0.4,0.58,0.685,0.0,ito:ITO_00101,Vision process,AP
17,1,Dense Object Detection,SKU-110K,2019-04,Soft-IoU + EM-Merger unit,0.492,71.82,0.0,0.0,0.685,0.01,ito:ITO_00101,Vision process,AP
18,1,Dense Object Detection,SKU-110K,2019-12,FRCNN (trained on normal scenes),0.685,100.0,0.2,0.29,0.685,0.01,ito:ITO_00101,Vision process,AP
19,1,Birds Eye View Object Detection,KITTI Cars Moderate val,2015-12,3DOP,9.49,11.19,9.49,0.11,84.81,0.1,ito:ITO_00101,Vision process,AP
20,1,Birds Eye View Object Detection,KITTI Cars Moderate val,2016-08,VeloFCN,32.08,37.83,22.6,0.27,84.81,0.34,ito:ITO_00101,Vision process,AP
21,1,Birds Eye View Object Detection,KITTI Cars Moderate val,2016-11,MV (BV+FV),77.32,91.17,45.2,0.53,84.81,0.81,ito:ITO_00101,Vision process,AP
22,1,Birds Eye View Object Detection,KITTI Cars Moderate val,2017-11,VoxelNet,84.81,100.0,7.5,0.09,84.81,0.89,ito:ITO_00101,Vision process,AP
23,1,Multi-Person Pose Estimation,MPII Multi-Person,2016-05,DeeperCut,59.4,72.35,59.4,0.72,82.1,0.63,ito:ITO_00101,Vision process,AP
24,1,Multi-Person Pose Estimation,MPII Multi-Person,2016-08,Local Joint-to-Person Association,62.2,75.76,2.8,0.03,82.1,0.65,ito:ITO_00101,Vision process,AP
25,1,Multi-Person Pose Estimation,MPII Multi-Person,2016-11,Associative Embedding,77.5,94.4,15.3,0.19,82.1,0.82,ito:ITO_00101,Vision process,AP
26,1,Multi-Person Pose Estimation,MPII Multi-Person,2016-12,Regional Multi-Person Pose Estimation,82.1,100.0,4.6,0.06,82.1,0.86,ito:ITO_00101,Vision process,AP
27,1,Object Detection,KITTI Cars Moderate,2016-08,VeloFCN,47.51,61.57,47.51,0.62,77.16,0.5,ito:ITO_00101,Vision process,AP
28,1,Object Detection,KITTI Cars Moderate,2017-11,VoxelNet,65.11,84.38,17.6,0.23,77.16,0.69,ito:ITO_00101,Vision process,AP
29,1,Object Detection,KITTI Cars Moderate,2017-12,AVOD-FPN,71.88,93.16,6.8,0.09,77.16,0.76,ito:ITO_00101,Vision process,AP
30,1,Object Detection,KITTI Cars Moderate,2018-12,PointRCNN Shi et al. (2019),75.76,98.19,3.9,0.05,77.16,0.8,ito:ITO_00101,Vision process,AP
31,1,Object Detection,KITTI Cars Moderate,2019-10,Patches,77.16,100.0,1.4,0.02,77.16,0.81,ito:ITO_00101,Vision process,AP
32,1,Object Detection,KITTI Cars Hard,2016-08,VeloFCN,42.74,62.02,42.74,0.62,68.91,0.45,ito:ITO_00101,Vision process,AP
33,1,Object Detection,KITTI Cars Hard,2017-11,VoxelNet,57.73,83.78,15.0,0.22,68.91,0.61,ito:ITO_00101,Vision process,AP
34,1,Object Detection,KITTI Cars Hard,2017-11,F-PointNet,62.19,90.25,4.5,0.07,68.91,0.65,ito:ITO_00101,Vision process,AP
35,1,Object Detection,KITTI Cars Hard,2017-12,AVOD-FPN,66.38,96.33,4.2,0.06,68.91,0.7,ito:ITO_00101,Vision process,AP
36,1,Object Detection,KITTI Cars Hard,2018-12,PointRCNN Shi et al. (2019),68.32,99.14,1.9,0.03,68.91,0.72,ito:ITO_00101,Vision process,AP
37,1,Object Detection,KITTI Cars Hard,2019-10,Patches,68.91,100.0,0.6,0.01,68.91,0.73,ito:ITO_00101,Vision process,AP
38,1,Object Detection,KITTI Cars Easy,2016-08,VeloFCN,60.34,68.67,60.34,0.69,87.87,0.64,ito:ITO_00101,Vision process,AP
39,1,Object Detection,KITTI Cars Easy,2017-11,VoxelNet,77.47,88.16,17.1,0.19,87.87,0.82,ito:ITO_00101,Vision process,AP
40,1,Object Detection,KITTI Cars Easy,2017-12,AVOD-FPN,81.94,93.25,4.5,0.05,87.87,0.86,ito:ITO_00101,Vision process,AP
41,1,Object Detection,KITTI Cars Easy,2018-11,Roarnet,83.71,95.27,1.8,0.02,87.87,0.88,ito:ITO_00101,Vision process,AP
42,1,Object Detection,KITTI Cars Easy,2018-12,PointRCNN Shi et al. (2019),85.94,97.8,2.2,0.03,87.87,0.9,ito:ITO_00101,Vision process,AP
43,1,Object Detection,KITTI Cars Easy,2019-10,Patches,87.87,100.0,1.9,0.02,87.87,0.93,ito:ITO_00101,Vision process,AP
44,1,Multi-Person Pose Estimation,COCO,2016-11,Associative Embedding,0.655,84.63,0.655,0.85,0.774,0.01,ito:ITO_00101,Vision process,AP
45,1,Multi-Person Pose Estimation,COCO,2017-01,G-RMI*,0.685,88.5,0.0,0.0,0.774,0.01,ito:ITO_00101,Vision process,AP
46,1,Multi-Person Pose Estimation,COCO,2017-11,CPN+,0.73,94.32,0.0,0.0,0.774,0.01,ito:ITO_00101,Vision process,AP
47,1,Multi-Person Pose Estimation,COCO,2019-10,DarkPose,0.774,100.0,0.0,0.0,0.774,0.01,ito:ITO_00101,Vision process,AP
48,1,Birds Eye View Object Detection,KITTI Cars Easy val,2016-11,MV (BV+FV),86.18,96.18,86.18,0.96,89.6,0.91,ito:ITO_00101,Vision process,AP
49,1,Birds Eye View Object Detection,KITTI Cars Easy val,2017-11,VoxelNet,89.6,100.0,3.4,0.04,89.6,0.94,ito:ITO_00101,Vision process,AP
50,1,Birds Eye View Object Detection,KITTI Cars Hard val,2016-11,MV (BV+FV),76.33,97.15,76.33,0.97,78.57,0.8,ito:ITO_00101,Vision process,AP
51,1,Birds Eye View Object Detection,KITTI Cars Hard val,2017-11,VoxelNet,78.57,100.0,2.2,0.03,78.57,0.83,ito:ITO_00101,Vision process,AP
52,1,3D Object Detection,KITTI Cars Easy val,2016-11,MV3D (LiDAR),71.19,84.73,71.19,0.85,84.02,0.75,ito:ITO_00101,Vision process,AP
53,1,3D Object Detection,KITTI Cars Easy val,2016-11,MV3D,71.29,84.85,0.1,0.0,84.02,0.75,ito:ITO_00101,Vision process,AP
54,1,3D Object Detection,KITTI Cars Easy val,2017-11,F-PointNet [Qi:2018fd],83.26,99.1,12.0,0.14,84.02,0.88,ito:ITO_00101,Vision process,AP
55,1,3D Object Detection,KITTI Cars Easy val,2019-07,PVCNN,84.02,100.0,0.8,0.01,84.02,0.88,ito:ITO_00101,Vision process,AP
56,1,3D Object Detection,KITTI Cars Moderate val,2016-11,MV3D,62.68,87.62,62.68,0.88,71.54,0.66,ito:ITO_00101,Vision process,AP
57,1,3D Object Detection,KITTI Cars Moderate val,2017-11,F-PointNet [Qi:2018fd],69.28,96.84,6.6,0.09,71.54,0.73,ito:ITO_00101,Vision process,AP
58,1,3D Object Detection,KITTI Cars Moderate val,2019-07,PVCNN,71.54,100.0,2.3,0.03,71.54,0.75,ito:ITO_00101,Vision process,AP
59,1,3D Object Detection,KITTI Cars Hard val,2016-11,MV3D,56.56,88.64,56.56,0.89,63.81,0.6,ito:ITO_00101,Vision process,AP
60,1,3D Object Detection,KITTI Cars Hard val,2017-11,F-PointNet [Qi:2018fd],62.56,98.04,6.0,0.09,63.81,0.66,ito:ITO_00101,Vision process,AP
61,1,3D Object Detection,KITTI Cars Hard val,2019-07,PVCNN,63.81,100.0,1.2,0.02,63.81,0.67,ito:ITO_00101,Vision process,AP
62,1,Pose Estimation,COCO test-dev,2016-11,CMU-Pose,61.8,79.84,61.8,0.8,77.4,0.65,ito:ITO_00101,Vision process,AP
63,1,Pose Estimation,COCO test-dev,2016-12,RMPE++,72.3,93.41,10.5,0.14,77.4,0.76,ito:ITO_00101,Vision process,AP
64,1,Pose Estimation,COCO test-dev,2017-11,"CPN+ [6, 9]",73.0,94.32,0.7,0.01,77.4,0.77,ito:ITO_00101,Vision process,AP
65,1,Pose Estimation,COCO test-dev,2018-04,Flow-based (ResNet-152),73.7,95.22,0.7,0.01,77.4,0.78,ito:ITO_00101,Vision process,AP
66,1,Pose Estimation,COCO test-dev,2018-12,PoseFix,74.7,96.51,1.0,0.01,77.4,0.79,ito:ITO_00101,Vision process,AP
67,1,Pose Estimation,COCO test-dev,2019-01,MSPN,76.1,98.32,1.4,0.02,77.4,0.8,ito:ITO_00101,Vision process,AP
68,1,Pose Estimation,COCO test-dev,2019-02,HRNet-W48 + extra data,77.0,99.48,0.9,0.01,77.4,0.81,ito:ITO_00101,Vision process,AP
69,1,Pose Estimation,COCO test-dev,2019-10,DARK (extra data),77.4,100.0,0.4,0.01,77.4,0.81,ito:ITO_00101,Vision process,AP
70,1,Multi-Person Pose Estimation,COCO test-dev,2016-11,CMU-Pose,61.8,87.66,61.8,0.88,70.5,0.65,ito:ITO_00101,Vision process,AP
71,1,Multi-Person Pose Estimation,COCO test-dev,2017-01,G-RMI,64.9,92.06,3.1,0.04,70.5,0.68,ito:ITO_00101,Vision process,AP
72,1,Multi-Person Pose Estimation,COCO test-dev,2018-03,PersonLab,68.7,97.45,3.8,0.05,70.5,0.72,ito:ITO_00101,Vision process,AP
73,1,Multi-Person Pose Estimation,COCO test-dev,2019-08,HigherHRNet (HR-Net-48),70.5,100.0,1.8,0.03,70.5,0.74,ito:ITO_00101,Vision process,AP
74,1,Keypoint Detection,COCO test-challenge,2017-01,G-RMI*,69.1,90.45,69.1,0.9,76.4,0.73,ito:ITO_00101,Vision process,AP
75,1,Keypoint Detection,COCO test-challenge,2017-11,CPN+,72.1,94.37,3.0,0.04,76.4,0.76,ito:ITO_00101,Vision process,AP
76,1,Keypoint Detection,COCO test-challenge,2018-04,Simple Base+*,74.5,97.51,2.4,0.03,76.4,0.78,ito:ITO_00101,Vision process,AP
77,1,Keypoint Detection,COCO test-challenge,2019-01,MSPN+*,76.4,100.0,1.9,0.02,76.4,0.8,ito:ITO_00101,Vision process,AP
78,1,Multi-Person Pose Estimation,WAF,2017-05,Generative Partition Networks,84.8,100.0,84.8,1.0,84.8,0.89,ito:ITO_00101,Vision process,AP
79,1,Edge Detection,Cityscapes test,2017-05,CASENet,70.8,100.0,70.8,1.0,70.8,0.75,ito:ITO_00101,Vision process,AP
80,1,Object Localization,KITTI Cars Moderate,2017-11,VoxelNet,79.26,94.36,79.26,0.94,84.0,0.83,ito:ITO_00101,Vision process,AP
81,1,Object Localization,KITTI Cars Moderate,2017-11,Frustum PointNets,84.0,100.0,4.7,0.06,84.0,0.88,ito:ITO_00101,Vision process,AP
82,1,Birds Eye View Object Detection,KITTI Cyclist Hard val,2017-11,VoxelNet,50.49,100.0,50.49,1.0,50.49,0.53,ito:ITO_00101,Vision process,AP
83,1,Birds Eye View Object Detection,KITTI Pedestrian Hard val,2017-11,VoxelNet,56.98,100.0,56.98,1.0,56.98,0.6,ito:ITO_00101,Vision process,AP
84,1,Birds Eye View Object Detection,KITTI Cyclist Easy val,2017-11,VoxelNet,74.41,100.0,74.41,1.0,74.41,0.78,ito:ITO_00101,Vision process,AP
85,1,Object Localization,KITTI Pedestrians Moderate,2017-11,VoxelNet,40.74,81.12,40.74,0.81,50.22,0.43,ito:ITO_00101,Vision process,AP
86,1,Object Localization,KITTI Pedestrians Moderate,2017-11,Frustum PointNets,50.22,100.0,9.5,0.19,50.22,0.53,ito:ITO_00101,Vision process,AP
87,1,Object Localization,KITTI Cyclists Hard,2017-11,VoxelNe,50.55,92.45,50.55,0.92,54.68,0.53,ito:ITO_00101,Vision process,AP
88,1,Object Localization,KITTI Cyclists Hard,2017-11,Frustum PointNets,54.68,100.0,4.1,0.07,54.68,0.58,ito:ITO_00101,Vision process,AP
89,1,Object Localization,KITTI Cars Easy,2017-11,VoxelNet,89.35,100.0,89.35,1.0,89.35,0.94,ito:ITO_00101,Vision process,AP
90,1,Birds Eye View Object Detection,KITTI Cyclists Moderate,2017-11,VoxelNet,54.76,79.49,54.76,0.79,68.89,0.58,ito:ITO_00101,Vision process,AP
91,1,Birds Eye View Object Detection,KITTI Cyclists Moderate,2017-11,F-PointNet,61.96,89.94,7.2,0.1,68.89,0.65,ito:ITO_00101,Vision process,AP
92,1,Birds Eye View Object Detection,KITTI Cyclists Moderate,2018-12,PointPillars,62.25,90.36,0.3,0.0,68.89,0.66,ito:ITO_00101,Vision process,AP
93,1,Birds Eye View Object Detection,KITTI Cyclists Moderate,2019-07,STD,65.32,94.82,3.1,0.04,68.89,0.69,ito:ITO_00101,Vision process,AP
94,1,Birds Eye View Object Detection,KITTI Cyclists Moderate,2019-12,PV-RCNN,68.89,100.0,3.6,0.05,68.89,0.73,ito:ITO_00101,Vision process,AP
95,1,Birds Eye View Object Detection,KITTI Cars Moderate,2017-11,VoxelNet,79.26,87.44,79.26,0.87,90.65,0.83,ito:ITO_00101,Vision process,AP
96,1,Birds Eye View Object Detection,KITTI Cars Moderate,2017-12,AVOD-FPN,83.79,92.43,4.5,0.05,90.65,0.88,ito:ITO_00101,Vision process,AP
97,1,Birds Eye View Object Detection,KITTI Cars Moderate,2018-12,PointPillars,86.1,94.98,2.3,0.03,90.65,0.91,ito:ITO_00101,Vision process,AP
98,1,Birds Eye View Object Detection,KITTI Cars Moderate,2019-07,STD,87.76,96.81,1.7,0.02,90.65,0.92,ito:ITO_00101,Vision process,AP
99,1,Birds Eye View Object Detection,KITTI Cars Moderate,2019-12,PV-RCNN,90.65,100.0,2.9,0.03,90.65,0.95,ito:ITO_00101,Vision process,AP
100,1,Birds Eye View Object Detection,KITTI Pedestrians Moderate,2017-11,VoxelNet,40.74,79.28,40.74,0.79,51.39,0.43,ito:ITO_00101,Vision process,AP
101,1,Birds Eye View Object Detection,KITTI Pedestrians Moderate,2017-11,F-PointNet,50.22,97.72,9.5,0.18,51.39,0.53,ito:ITO_00101,Vision process,AP
102,1,Birds Eye View Object Detection,KITTI Pedestrians Moderate,2017-12,AVOD-FPN,51.05,99.34,0.8,0.02,51.39,0.54,ito:ITO_00101,Vision process,AP
103,1,Birds Eye View Object Detection,KITTI Pedestrians Moderate,2019-07,STD,51.39,100.0,0.3,0.01,51.39,0.54,ito:ITO_00101,Vision process,AP
104,1,Object Localization,KITTI Cars Hard,2017-11,VoxelNet,77.39,100.0,77.39,1.0,77.39,0.81,ito:ITO_00101,Vision process,AP
105,1,Object Localization,KITTI Cyclists Moderate,2017-11,VoxelNet,54.76,88.38,54.76,0.88,61.96,0.58,ito:ITO_00101,Vision process,AP
106,1,Object Localization,KITTI Cyclists Moderate,2017-11,Frustum PointNets,61.96,100.0,7.2,0.12,61.96,0.65,ito:ITO_00101,Vision process,AP
107,1,Object Localization,KITTI Pedestrians Hard,2017-11,VoxelNet,38.11,80.74,38.11,0.81,47.2,0.4,ito:ITO_00101,Vision process,AP
108,1,Object Localization,KITTI Pedestrians Hard,2017-11,Frustum PointNets,47.2,100.0,9.1,0.19,47.2,0.5,ito:ITO_00101,Vision process,AP
109,1,Object Localization,KITTI Cyclists Easy,2017-11,VoxelNet,66.7,88.49,66.7,0.88,75.38,0.7,ito:ITO_00101,Vision process,AP
110,1,Object Localization,KITTI Cyclists Easy,2017-11,Frustum PointNets,75.38,100.0,8.7,0.12,75.38,0.79,ito:ITO_00101,Vision process,AP
111,1,Object Localization,KITTI Pedestrians Easy,2017-11,VoxelNet,46.13,79.41,46.13,0.79,58.09,0.49,ito:ITO_00101,Vision process,AP
112,1,Object Localization,KITTI Pedestrians Easy,2017-11,Frustum PointNets,58.09,100.0,12.0,0.21,58.09,0.61,ito:ITO_00101,Vision process,AP
113,1,Birds Eye View Object Detection,KITTI Cars Easy,2017-11,VoxelNet,89.35,94.07,89.35,0.94,94.98,0.94,ito:ITO_00101,Vision process,AP
114,1,Birds Eye View Object Detection,KITTI Cars Easy,2019-07,STD,89.66,94.4,0.3,0.0,94.98,0.94,ito:ITO_00101,Vision process,AP
115,1,Birds Eye View Object Detection,KITTI Cars Easy,2019-10,Patches,89.78,94.53,0.1,0.0,94.98,0.95,ito:ITO_00101,Vision process,AP
116,1,Birds Eye View Object Detection,KITTI Cars Easy,2019-12,PV-RCNN,94.98,100.0,5.2,0.05,94.98,1.0,ito:ITO_00101,Vision process,AP
117,1,Birds Eye View Object Detection,KITTI Cars Hard,2017-11,VoxelNet,77.39,89.07,77.39,0.89,86.89,0.81,ito:ITO_00101,Vision process,AP
118,1,Birds Eye View Object Detection,KITTI Cars Hard,2018-12,PointPillars,79.83,91.87,2.4,0.03,86.89,0.84,ito:ITO_00101,Vision process,AP
119,1,Birds Eye View Object Detection,KITTI Cars Hard,2019-07,STD,86.89,100.0,7.1,0.08,86.89,0.91,ito:ITO_00101,Vision process,AP
120,1,Birds Eye View Object Detection,KITTI Cyclist Moderate val,2017-11,VoxelNet,52.18,100.0,52.18,1.0,52.18,0.55,ito:ITO_00101,Vision process,AP
121,1,3D Object Detection,KITTI Pedestrians Easy,2017-11,VoxelNet ,39.48,69.36,39.48,0.69,56.92,0.42,ito:ITO_00101,Vision process,AP
122,1,3D Object Detection,KITTI Pedestrians Easy,2017-11,Frustum PointNets,51.21,89.97,11.7,0.21,56.92,0.54,ito:ITO_00101,Vision process,AP
123,1,3D Object Detection,KITTI Pedestrians Easy,2018-12,IPOD,56.92,100.0,5.7,0.1,56.92,0.6,ito:ITO_00101,Vision process,AP
124,1,3D Object Detection,KITTI Cyclists Hard,2017-11,VoxelNet ,44.37,76.96,44.37,0.77,57.65,0.47,ito:ITO_00101,Vision process,AP
125,1,3D Object Detection,KITTI Cyclists Hard,2017-11,Frustum PointNets,50.39,87.41,6.0,0.1,57.65,0.53,ito:ITO_00101,Vision process,AP
126,1,3D Object Detection,KITTI Cyclists Hard,2018-12,PointRCNN,53.59,92.96,3.2,0.06,57.65,0.56,ito:ITO_00101,Vision process,AP
127,1,3D Object Detection,KITTI Cyclists Hard,2019-03,F-ConvNets,57.03,98.92,3.4,0.06,57.65,0.6,ito:ITO_00101,Vision process,AP
128,1,3D Object Detection,KITTI Cyclists Hard,2019-12,PV-RCNN,57.65,100.0,0.6,0.01,57.65,0.61,ito:ITO_00101,Vision process,AP
129,1,3D Object Detection,KITTI Pedestrians Moderate,2017-11,VoxelNet,33.69,75.18,33.69,0.75,44.81,0.35,ito:ITO_00101,Vision process,AP
130,1,3D Object Detection,KITTI Pedestrians Moderate,2017-11,Frustum PointNets,42.15,94.06,8.5,0.19,44.81,0.44,ito:ITO_00101,Vision process,AP
131,1,3D Object Detection,KITTI Pedestrians Moderate,2017-12,AVOD + Feature Pyramid,42.81,95.54,0.7,0.02,44.81,0.45,ito:ITO_00101,Vision process,AP
132,1,3D Object Detection,KITTI Pedestrians Moderate,2018-12,IPOD,44.68,99.71,1.9,0.04,44.81,0.47,ito:ITO_00101,Vision process,AP
133,1,3D Object Detection,KITTI Pedestrians Moderate,2019-12,HotSpotNet,44.81,100.0,0.1,0.0,44.81,0.47,ito:ITO_00101,Vision process,AP
134,1,Birds Eye View Object Detection,KITTI Pedestrian Moderate val,2017-11,VoxelNet,61.05,100.0,61.05,1.0,61.05,0.64,ito:ITO_00101,Vision process,AP
135,1,Birds Eye View Object Detection,KITTI Pedestrian Easy val,2017-11,VoxelNet,65.95,100.0,65.95,1.0,65.95,0.69,ito:ITO_00101,Vision process,AP
136,1,3D Object Detection,KITTI Pedestrians Hard,2017-11,VoxelNet,31.51,74.33,31.51,0.74,42.39,0.33,ito:ITO_00101,Vision process,AP
137,1,3D Object Detection,KITTI Pedestrians Hard,2017-11,Frustum PointNets,40.23,94.9,8.7,0.21,42.39,0.42,ito:ITO_00101,Vision process,AP
138,1,3D Object Detection,KITTI Pedestrians Hard,2017-12,AVOD + Feature Pyramid,40.88,96.44,0.7,0.02,42.39,0.43,ito:ITO_00101,Vision process,AP
139,1,3D Object Detection,KITTI Pedestrians Hard,2018-12,IPOD,42.39,100.0,1.5,0.04,42.39,0.45,ito:ITO_00101,Vision process,AP
140,1,3D Object Detection,KITTI Cyclists Moderate,2017-11,VoxelNet,48.36,74.77,48.36,0.75,64.68,0.51,ito:ITO_00101,Vision process,AP
141,1,3D Object Detection,KITTI Cyclists Moderate,2017-11,Frustum PointNets,56.77,87.77,8.4,0.13,64.68,0.6,ito:ITO_00101,Vision process,AP
142,1,3D Object Detection,KITTI Cyclists Moderate,2018-12,PointRCNN,59.6,92.15,2.8,0.04,64.68,0.63,ito:ITO_00101,Vision process,AP
143,1,3D Object Detection,KITTI Cyclists Moderate,2019-03,F-ConvNet,64.68,100.0,5.1,0.08,64.68,0.68,ito:ITO_00101,Vision process,AP
144,1,3D Object Detection,KITTI Cars Hard,2017-11,VoxelNet ,57.73,75.15,57.73,0.75,76.82,0.61,ito:ITO_00101,Vision process,AP
145,1,3D Object Detection,KITTI Cars Hard,2017-11,Frustum PointNets,62.19,80.96,4.5,0.06,76.82,0.65,ito:ITO_00101,Vision process,AP
146,1,3D Object Detection,KITTI Cars Hard,2017-12,AVOD + Feature Pyramid,66.38,86.41,4.2,0.05,76.82,0.7,ito:ITO_00101,Vision process,AP
147,1,3D Object Detection,KITTI Cars Hard,2018-12,PointRCNN,67.86,88.34,1.5,0.02,76.82,0.71,ito:ITO_00101,Vision process,AP
148,1,3D Object Detection,KITTI Cars Hard,2019-03,F-ConvNet,68.08,88.62,0.2,0.0,76.82,0.72,ito:ITO_00101,Vision process,AP
149,1,3D Object Detection,KITTI Cars Hard,2019-06,UberATG-MMF,68.41,89.05,0.3,0.0,76.82,0.72,ito:ITO_00101,Vision process,AP
150,1,3D Object Detection,KITTI Cars Hard,2019-07,STD,76.06,99.01,7.7,0.1,76.82,0.8,ito:ITO_00101,Vision process,AP
151,1,3D Object Detection,KITTI Cars Hard,2019-12,PV-RCNN,76.82,100.0,0.8,0.01,76.82,0.81,ito:ITO_00101,Vision process,AP
152,1,3D Object Detection,KITTI Cars Easy,2017-11,VoxelNet ,77.47,85.84,77.47,0.86,90.25,0.82,ito:ITO_00101,Vision process,AP
153,1,3D Object Detection,KITTI Cars Easy,2017-11,Frustum PointNets,81.2,89.97,3.7,0.04,90.25,0.85,ito:ITO_00101,Vision process,AP
154,1,3D Object Detection,KITTI Cars Easy,2017-12,AVOD + Feature Pyramid,81.94,90.79,0.7,0.01,90.25,0.86,ito:ITO_00101,Vision process,AP
155,1,3D Object Detection,KITTI Cars Easy,2018-02,PC-CNN-V2,84.33,93.44,2.4,0.03,90.25,0.89,ito:ITO_00101,Vision process,AP
156,1,3D Object Detection,KITTI Cars Easy,2019-03,F-ConvNet,85.88,95.16,1.5,0.02,90.25,0.9,ito:ITO_00101,Vision process,AP
157,1,3D Object Detection,KITTI Cars Easy,2019-06,UberATG-MMF,86.81,96.19,0.9,0.01,90.25,0.91,ito:ITO_00101,Vision process,AP
158,1,3D Object Detection,KITTI Cars Easy,2019-12,PV-RCNN,90.25,100.0,3.4,0.04,90.25,0.95,ito:ITO_00101,Vision process,AP
159,1,3D Object Detection,KITTI Cars Moderate,2017-11,VoxelNet,65.11,79.96,65.11,0.8,81.43,0.69,ito:ITO_00101,Vision process,AP
160,1,3D Object Detection,KITTI Cars Moderate,2017-11,Frustum PointNets,70.39,86.44,5.3,0.07,81.43,0.74,ito:ITO_00101,Vision process,AP
161,1,3D Object Detection,KITTI Cars Moderate,2017-12,AVOD + Feature Pyramid,71.88,88.27,1.5,0.02,81.43,0.76,ito:ITO_00101,Vision process,AP
162,1,3D Object Detection,KITTI Cars Moderate,2018-02,PC-CNN-V2,73.8,90.63,1.9,0.02,81.43,0.78,ito:ITO_00101,Vision process,AP
163,1,3D Object Detection,KITTI Cars Moderate,2018-12,PointRCNN,75.42,92.62,1.6,0.02,81.43,0.79,ito:ITO_00101,Vision process,AP
164,1,3D Object Detection,KITTI Cars Moderate,2019-03,F-ConvNet,76.51,93.96,1.1,0.01,81.43,0.81,ito:ITO_00101,Vision process,AP
165,1,3D Object Detection,KITTI Cars Moderate,2019-06,UberATG-MMF,76.75,94.25,0.2,0.0,81.43,0.81,ito:ITO_00101,Vision process,AP
166,1,3D Object Detection,KITTI Cars Moderate,2019-07,STD,77.63,95.33,0.9,0.01,81.43,0.82,ito:ITO_00101,Vision process,AP
167,1,3D Object Detection,KITTI Cars Moderate,2019-12,PV-RCNN,81.43,100.0,3.8,0.05,81.43,0.86,ito:ITO_00101,Vision process,AP
168,1,3D Object Detection,KITTI Cyclists Easy,2017-11,VoxelNet,61.22,76.93,61.22,0.77,79.58,0.64,ito:ITO_00101,Vision process,AP
169,1,3D Object Detection,KITTI Cyclists Easy,2017-11,Frustum PointNets,71.96,90.42,10.7,0.13,79.58,0.76,ito:ITO_00101,Vision process,AP
170,1,3D Object Detection,KITTI Cyclists Easy,2018-12,PointRCNN,73.93,92.9,2.0,0.03,79.58,0.78,ito:ITO_00101,Vision process,AP
171,1,3D Object Detection,KITTI Cyclists Easy,2018-12,PointPillars,75.78,95.22,1.8,0.02,79.58,0.8,ito:ITO_00101,Vision process,AP
172,1,3D Object Detection,KITTI Cyclists Easy,2019-03,F-ConvNet,79.58,100.0,3.8,0.05,79.58,0.84,ito:ITO_00101,Vision process,AP
173,1,3D Object Detection,KITTI Cyclist Moderate val,2017-11,F-PointNet++ [Qi:2018fd],56.49,94.2,56.49,0.94,59.97,0.59,ito:ITO_00101,Vision process,AP
174,1,3D Object Detection,KITTI Cyclist Moderate val,2019-07,PVCNN,59.97,100.0,3.5,0.06,59.97,0.63,ito:ITO_00101,Vision process,AP
175,1,3D Object Detection,KITTI Pedestrian Hard val,2017-11,F-PointNet++ [Qi:2018fd],53.59,94.38,53.59,0.94,56.78,0.56,ito:ITO_00101,Vision process,AP
176,1,3D Object Detection,KITTI Pedestrian Hard val,2019-07,PVCNN,56.78,100.0,3.2,0.06,56.78,0.6,ito:ITO_00101,Vision process,AP
177,1,3D Object Detection,KITTI Pedestrian Easy val,2017-11,F-PointNet++ [Qi:2018fd],70.0,95.63,70.0,0.96,73.2,0.74,ito:ITO_00101,Vision process,AP
178,1,3D Object Detection,KITTI Pedestrian Easy val,2019-07,PVCNN,73.2,100.0,3.2,0.04,73.2,0.77,ito:ITO_00101,Vision process,AP
179,1,3D Object Detection,KITTI Pedestrian Moderate val,2017-11,F-PointNet++ [Qi:2018fd],61.32,94.76,61.32,0.95,64.71,0.65,ito:ITO_00101,Vision process,AP
180,1,3D Object Detection,KITTI Pedestrian Moderate val,2019-07,PVCNN,64.71,100.0,3.4,0.05,64.71,0.68,ito:ITO_00101,Vision process,AP
181,1,3D Object Detection,KITTI Cyclist Hard val,2017-11,F-PointNet++ [Qi:2018fd],53.37,94.9,53.37,0.95,56.24,0.56,ito:ITO_00101,Vision process,AP
182,1,3D Object Detection,KITTI Cyclist Hard val,2019-07,PVCNN,56.24,100.0,2.9,0.05,56.24,0.59,ito:ITO_00101,Vision process,AP
183,1,3D Object Detection,KITTI Cyclist Easy val,2017-11,F-PointNet++ [Qi:2018fd],77.15,94.78,77.15,0.95,81.4,0.81,ito:ITO_00101,Vision process,AP
184,1,3D Object Detection,KITTI Cyclist Easy val,2019-07,PVCNN,81.4,100.0,4.2,0.05,81.4,0.86,ito:ITO_00101,Vision process,AP
185,1,Panoptic Segmentation,Cityscapes val,2018-01,MRCNN + PSPNet (ResNet-101),36.4,83.68,36.4,0.84,43.5,0.38,ito:ITO_00101,Vision process,AP
186,1,Panoptic Segmentation,Cityscapes val,2018-12,TASCNet (ResNet-50),37.6,86.44,1.2,0.03,43.5,0.4,ito:ITO_00101,Vision process,AP
187,1,Panoptic Segmentation,Cityscapes val,2018-12,"TASCNet (ResNet-50, multi-scale)",39.0,89.66,1.4,0.03,43.5,0.41,ito:ITO_00101,Vision process,AP
188,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS,43.5,100.0,4.5,0.1,43.5,0.46,ito:ITO_00101,Vision process,AP
189,1,Pose Estimation,DensePose-COCO,2018-02,DensePose + keypoints,55.8,90.58,55.8,0.91,61.6,0.59,ito:ITO_00101,Vision process,AP
190,1,Pose Estimation,DensePose-COCO,2018-11,Parsing R-CNN + ResNext101,61.6,100.0,5.8,0.09,61.6,0.65,ito:ITO_00101,Vision process,AP
191,1,Human Instance Segmentation,OCHuman,2018-03,Pose2Seg (plus ground-truth keypoints),0.552,100.0,0.552,1.0,0.552,0.01,ito:ITO_00101,Vision process,AP
192,1,Pose Estimation,COCO minival,2019-01,MSPN,75.9,100.0,75.9,1.0,75.9,0.8,ito:ITO_00101,Vision process,AP
193,1,Keypoint Detection,COCO test-dev,2019-01,MSPN,76.1,100.0,76.1,1.0,76.1,0.8,ito:ITO_00101,Vision process,AP
194,1,Real-time Instance Segmentation,MSCOCO,2019-04,YOLACT,24.9,70.74,24.9,0.71,35.2,0.26,ito:ITO_00101,Vision process,AP
195,1,Real-time Instance Segmentation,MSCOCO,2019-04,YOLACT-550 (ResNet-101-FPN),28.2,80.11,3.3,0.09,35.2,0.3,ito:ITO_00101,Vision process,AP
196,1,Real-time Instance Segmentation,MSCOCO,2019-12,YOLACT-550++ (ResNet-101-FPN),34.6,98.3,6.4,0.18,35.2,0.36,ito:ITO_00101,Vision process,AP
197,1,Real-time Instance Segmentation,MSCOCO,2020-01,BlendMask-512 (DLA_34),35.2,100.0,0.6,0.02,35.2,0.37,ito:ITO_00101,Vision process,AP
198,1,3D Object Detection,nuScenes-F,2019-05,RRPN + R101,43.0,100.0,43,1.0,43,0.45,ito:ITO_00101,Vision process,AP
199,1,3D Object Detection,nuScenes-FB,2019-05,RRPN + R101,35.5,100.0,35.5,1.0,35.5,0.37,ito:ITO_00101,Vision process,AP
200,1,Birds Eye View Object Detection,KITTI Cyclists Hard,2019-07,STD,57.85,92.69,57.85,0.93,62.41,0.61,ito:ITO_00101,Vision process,AP
201,1,Birds Eye View Object Detection,KITTI Cyclists Hard,2019-12,PV-RCNN,62.41,100.0,4.6,0.07,62.41,0.66,ito:ITO_00101,Vision process,AP
202,1,Birds Eye View Object Detection,KITTI Pedestrians Hard,2019-07,STD,45.89,100.0,45.89,1.0,45.89,0.48,ito:ITO_00101,Vision process,AP
203,1,Birds Eye View Object Detection,KITTI Cyclists Easy,2019-07,STD,81.04,98.24,81.04,0.98,82.49,0.85,ito:ITO_00101,Vision process,AP
204,1,Birds Eye View Object Detection,KITTI Cyclists Easy,2019-12,PV-RCNN,82.49,100.0,1.4,0.02,82.49,0.87,ito:ITO_00101,Vision process,AP
205,1,Birds Eye View Object Detection,KITTI Pedestrians Easy,2019-07,STD,60.99,100.0,60.99,1.0,60.99,0.64,ito:ITO_00101,Vision process,AP
206,1,Drone navigation,University-1652,2020-02,Instance Loss,58.74,100.0,58.74,1.0,58.74,0.62,ito:ITO_00101,Vision process,AP
207,1,Drone-view target localization,University-1652,2020-02,Instance Loss,63.13,100.0,63.13,1.0,63.13,0.66,ito:ITO_00101,Vision process,AP
0,1,Unsupervised Facial Landmark Detection,MAFL,2014-08,TCDCN,7.95,100.0,7.95,1.0,7.95,0.72,ito:ITO_00101,Vision process,NME
1,1,Facial Landmark Detection,300W,2015-11,CFSS,5.76,82.17,5.76,0.82,7.01,0.52,ito:ITO_00101,Vision process,NME
2,1,Facial Landmark Detection,300W,2015-11,3DDFA,7.01,100.0,1.2,0.17,7.01,0.64,ito:ITO_00101,Vision process,NME
3,1,Unsupervised Facial Landmark Detection,AFLW-MTFL,2017-05,FSE,10.53,95.81,10.53,0.96,10.99,0.96,ito:ITO_00101,Vision process,NME
4,1,Unsupervised Facial Landmark Detection,AFLW-MTFL,2017-06,DEIL,10.99,100.0,0.5,0.05,10.99,1.0,ito:ITO_00101,Vision process,NME
5,1,Unsupervised Facial Landmark Detection,300W,2017-05,FSE,7.97,96.84,7.97,0.97,8.23,0.73,ito:ITO_00101,Vision process,NME
6,1,Unsupervised Facial Landmark Detection,300W,2017-06,DEIL,8.23,100.0,0.3,0.04,8.23,0.75,ito:ITO_00101,Vision process,NME
0,1,Face Anti-Spoofing,Replay-Attack,2014-08,Multi-Scale,2.14,100.0,2.14,1.0,2.14,0.43,ito:ITO_00101,Vision process,EER
1,1,Face Anti-Spoofing,CASIA-MFSD,2014-08,Multi-Scale,4.92,100.0,4.92,1.0,4.92,1.0,ito:ITO_00101,Vision process,EER
2,1,Semi-supervised Anomaly Detection,UBI-Fights,2017-08,Adversarial Generator,0.484,100.0,0.484,1.0,0.484,0.1,ito:ITO_00101,Vision process,EER
3,1,Abnormal Event Detection In Video,UBI-Fights,2017-08,Adversarial Generator,0.504,100.0,0.504,1.0,0.504,0.1,ito:ITO_00101,Vision process,EER
0,1,Image-to-Image Translation,GTAV-to-Cityscapes Labels,2014-09,VGG16 60.3,41.3,85.15,41.3,0.85,48.5,0.46,ito:ITO_00101,Vision process,mIoU
1,1,Image-to-Image Translation,GTAV-to-Cityscapes Labels,2015-12,ResNet101 65.1,48.5,100.0,7.2,0.15,48.5,0.54,ito:ITO_00101,Vision process,mIoU
2,1,Semantic Segmentation,PASCAL Context,2014-11,FCN-8s,37.8,64.18,37.8,0.64,58.9,0.42,ito:ITO_00101,Vision process,mIoU
3,1,Semantic Segmentation,PASCAL Context,2015-02,CRF-RNN,39.3,66.72,1.5,0.03,58.9,0.44,ito:ITO_00101,Vision process,mIoU
4,1,Semantic Segmentation,PASCAL Context,2015-03,BoxSup,40.5,68.76,1.2,0.02,58.9,0.45,ito:ITO_00101,Vision process,mIoU
5,1,Semantic Segmentation,PASCAL Context,2015-04,Piecewise,43.3,73.51,2.8,0.05,58.9,0.48,ito:ITO_00101,Vision process,mIoU
6,1,Semantic Segmentation,PASCAL Context,2016-05,VeryDeep,44.5,75.55,1.2,0.02,58.9,0.49,ito:ITO_00101,Vision process,mIoU
7,1,Semantic Segmentation,PASCAL Context,2016-06,DeepLabV2,45.7,77.59,1.2,0.02,58.9,0.51,ito:ITO_00101,Vision process,mIoU
8,1,Semantic Segmentation,PASCAL Context,2016-11,RefineNet,47.3,80.31,1.6,0.03,58.9,0.52,ito:ITO_00101,Vision process,mIoU
9,1,Semantic Segmentation,PASCAL Context,2016-11,ResNet-38,48.1,81.66,0.8,0.01,58.9,0.53,ito:ITO_00101,Vision process,mIoU
10,1,Semantic Segmentation,PASCAL Context,2018-03,EncNet (ResNet-101),51.7,87.78,3.6,0.06,58.9,0.57,ito:ITO_00101,Vision process,mIoU
11,1,Semantic Segmentation,PASCAL Context,2018-09,DANet (ResNet-101),52.6,89.3,0.9,0.02,58.9,0.58,ito:ITO_00101,Vision process,mIoU
12,1,Semantic Segmentation,PASCAL Context,2019-03,Joint Pyramid Upsampling + EncNet,53.1,90.15,0.5,0.01,58.9,0.59,ito:ITO_00101,Vision process,mIoU
13,1,Semantic Segmentation,PASCAL Context,2019-06,CFNet (ResNet-101),54.0,91.68,0.9,0.02,58.9,0.6,ito:ITO_00101,Vision process,mIoU
14,1,Semantic Segmentation,PASCAL Context,2019-09,OCR (HRNetV2-W48),56.2,95.42,2.2,0.04,58.9,0.62,ito:ITO_00101,Vision process,mIoU
15,1,Semantic Segmentation,PASCAL Context,2020-04,ResNeSt-269,58.9,100.0,2.7,0.05,58.9,0.65,ito:ITO_00101,Vision process,mIoU
16,1,Semantic Segmentation,COCO-Stuff test,2014-11,FCN (VGG-16),22.7,56.05,22.7,0.56,40.5,0.25,ito:ITO_00101,Vision process,mIoU
17,1,Semantic Segmentation,COCO-Stuff test,2015-09,DAG-RNN (VGG-16),31.2,77.04,8.5,0.21,40.5,0.35,ito:ITO_00101,Vision process,mIoU
18,1,Semantic Segmentation,COCO-Stuff test,2016-11,RefineNet (ResNet-101),33.6,82.96,2.4,0.06,40.5,0.37,ito:ITO_00101,Vision process,mIoU
19,1,Semantic Segmentation,COCO-Stuff test,2018-06,CCL (ResNet-101),35.7,88.15,2.1,0.05,40.5,0.4,ito:ITO_00101,Vision process,mIoU
20,1,Semantic Segmentation,COCO-Stuff test,2018-09,DANet (ResNet-101),39.7,98.02,4.0,0.1,40.5,0.44,ito:ITO_00101,Vision process,mIoU
21,1,Semantic Segmentation,COCO-Stuff test,2019-09,OCR (HRNetV2-W48),40.5,100.0,0.8,0.02,40.5,0.45,ito:ITO_00101,Vision process,mIoU
22,1,Real-Time Semantic Segmentation,CamVid,2014-12,DeepLab,61.6,78.47,61.6,0.78,78.5,0.68,ito:ITO_00101,Vision process,mIoU
23,1,Real-Time Semantic Segmentation,CamVid,2015-11,Dilation10,65.3,83.18,3.7,0.05,78.5,0.72,ito:ITO_00101,Vision process,mIoU
24,1,Real-Time Semantic Segmentation,CamVid,2016-12,PSPNet,69.1,88.03,3.8,0.05,78.5,0.77,ito:ITO_00101,Vision process,mIoU
25,1,Real-Time Semantic Segmentation,CamVid,2020-04,TD4-PSP18,72.6,92.48,3.5,0.04,78.5,0.8,ito:ITO_00101,Vision process,mIoU
26,1,Real-Time Semantic Segmentation,CamVid,2020-04,TD2-PSP50,76.0,96.82,3.4,0.04,78.5,0.84,ito:ITO_00101,Vision process,mIoU
27,1,Real-Time Semantic Segmentation,CamVid,2020-04,BiSeNet V2-Large(Cityscapes-Pretrained),78.5,100.0,2.5,0.03,78.5,0.87,ito:ITO_00101,Vision process,mIoU
28,1,Real-Time Semantic Segmentation,Cityscapes test,2014-12,DeepLab,63.1,83.14,63.1,0.83,75.9,0.7,ito:ITO_00101,Vision process,mIoU
29,1,Real-Time Semantic Segmentation,Cityscapes test,2015-11,Dilation10,67.1,88.41,4.0,0.05,75.9,0.74,ito:ITO_00101,Vision process,mIoU
30,1,Real-Time Semantic Segmentation,Cityscapes test,2016-11,FRRN,71.8,94.6,4.7,0.06,75.9,0.8,ito:ITO_00101,Vision process,mIoU
31,1,Real-Time Semantic Segmentation,Cityscapes test,2018-08,BiSeNet(ResNet-18),74.7,98.42,2.9,0.04,75.9,0.83,ito:ITO_00101,Vision process,mIoU
32,1,Real-Time Semantic Segmentation,Cityscapes test,2018-11,ShelfNet18,74.8,98.55,0.1,0.0,75.9,0.83,ito:ITO_00101,Vision process,mIoU
33,1,Real-Time Semantic Segmentation,Cityscapes test,2019-03,SwiftNetRN-18,75.5,99.47,0.7,0.01,75.9,0.84,ito:ITO_00101,Vision process,mIoU
34,1,Real-Time Semantic Segmentation,Cityscapes test,2019-09,U-HarDNet-70,75.9,100.0,0.4,0.01,75.9,0.84,ito:ITO_00101,Vision process,mIoU
35,1,Semantic Segmentation,Kvasir-Instrument,2015-05,UNet,0.8578,100.0,0.8578,1.0,0.8578,0.01,ito:ITO_00101,Vision process,mIoU
36,1,Human Part Segmentation,PASCAL-Person-Part,2015-11,HAZN,57.54,79.02,57.54,0.79,72.82,0.64,ito:ITO_00101,Vision process,mIoU
37,1,Human Part Segmentation,PASCAL-Person-Part,2017-08,"Joint (ResNet-101, +ms)",64.39,88.42,6.9,0.09,72.82,0.71,ito:ITO_00101,Vision process,mIoU
38,1,Human Part Segmentation,PASCAL-Person-Part,2018-05,WSHP,67.6,92.83,3.2,0.04,72.82,0.75,ito:ITO_00101,Vision process,mIoU
39,1,Human Part Segmentation,PASCAL-Person-Part,2018-09,DPC,71.34,97.97,3.7,0.05,72.82,0.79,ito:ITO_00101,Vision process,mIoU
40,1,Human Part Segmentation,PASCAL-Person-Part,2019-07,CDCL+Pascal,72.82,100.0,1.5,0.02,72.82,0.81,ito:ITO_00101,Vision process,mIoU
41,1,Human Part Segmentation,PASCAL-Part,2015-11,HAZN,57.54,80.52,57.54,0.81,71.46,0.64,ito:ITO_00101,Vision process,mIoU
42,1,Human Part Segmentation,PASCAL-Part,2017-08,"Joint (ResNet-101, +ms)",64.39,90.11,6.9,0.1,71.46,0.71,ito:ITO_00101,Vision process,mIoU
43,1,Human Part Segmentation,PASCAL-Part,2018-05,WSHP,67.6,94.6,3.2,0.04,71.46,0.75,ito:ITO_00101,Vision process,mIoU
44,1,Human Part Segmentation,PASCAL-Part,2018-09,DPC,71.34,99.83,3.7,0.05,71.46,0.79,ito:ITO_00101,Vision process,mIoU
45,1,Human Part Segmentation,PASCAL-Part,2019-10,SCHP,71.46,100.0,0.1,0.0,71.46,0.79,ito:ITO_00101,Vision process,mIoU
46,1,Semantic Segmentation,Cityscapes val,2015-12,Dilated-ResNet (Dilated-ResNet-101),75.7,91.54,75.7,0.92,82.7,0.84,ito:ITO_00101,Vision process,mIoU
47,1,Semantic Segmentation,Cityscapes val,2016-12,PSPNet (Dilated-ResNet-101),79.7,96.37,4.0,0.05,82.7,0.88,ito:ITO_00101,Vision process,mIoU
48,1,Semantic Segmentation,Cityscapes val,2019-01,Auto-DeepLab-L,80.33,97.13,0.6,0.01,82.7,0.89,ito:ITO_00101,Vision process,mIoU
49,1,Semantic Segmentation,Cityscapes val,2019-08,HRNetV2 (HRNetV2-W48),81.1,98.07,0.8,0.01,82.7,0.9,ito:ITO_00101,Vision process,mIoU
50,1,Semantic Segmentation,Cityscapes val,2019-11,Panoptic-DeepLab,81.5,98.55,0.4,0.0,82.7,0.9,ito:ITO_00101,Vision process,mIoU
51,1,Semantic Segmentation,Cityscapes val,2020-04,ResNeSt200,82.7,100.0,1.2,0.01,82.7,0.92,ito:ITO_00101,Vision process,mIoU
52,1,Semantic Segmentation,Semantic3D,2016-03,TMLC-MSR,54.2,70.03,54.2,0.7,77.4,0.6,ito:ITO_00101,Vision process,mIoU
53,1,Semantic Segmentation,Semantic3D,2017-04,SnapNet_,59.1,76.36,4.9,0.06,77.4,0.65,ito:ITO_00101,Vision process,mIoU
54,1,Semantic Segmentation,Semantic3D,2017-10,SEGCloud,61.3,79.2,2.2,0.03,77.4,0.68,ito:ITO_00101,Vision process,mIoU
55,1,Semantic Segmentation,Semantic3D,2017-11,SPGraph,73.2,94.57,11.9,0.15,77.4,0.81,ito:ITO_00101,Vision process,mIoU
56,1,Semantic Segmentation,Semantic3D,2017-11,SPG,76.2,98.45,3.0,0.04,77.4,0.84,ito:ITO_00101,Vision process,mIoU
57,1,Semantic Segmentation,Semantic3D,2019-11,RandLA-Net,77.4,100.0,1.2,0.02,77.4,0.86,ito:ITO_00101,Vision process,mIoU
58,1,Video Semantic Segmentation,Cityscapes val,2016-05,FCN-50 [14],70.1,87.73,70.1,0.88,79.9,0.78,ito:ITO_00101,Vision process,mIoU
59,1,Video Semantic Segmentation,Cityscapes val,2016-12,PSPNet-50 [20],78.1,97.75,8.0,0.1,79.9,0.86,ito:ITO_00101,Vision process,mIoU
60,1,Video Semantic Segmentation,Cityscapes val,2016-12,PSPNet-101 [20],79.7,99.75,1.6,0.02,79.9,0.88,ito:ITO_00101,Vision process,mIoU
61,1,Video Semantic Segmentation,Cityscapes val,2020-04,TDNet-50 [9],79.9,100.0,0.2,0.0,79.9,0.88,ito:ITO_00101,Vision process,mIoU
62,1,Semi-Supervised Video Object Segmentation,YouTube,2016-06,ObjFlow,0.776,94.52,0.776,0.95,0.821,0.01,ito:ITO_00101,Vision process,mIoU
63,1,Semi-Supervised Video Object Segmentation,YouTube,2016-11,OSVOS,0.783,95.37,0.0,0.0,0.821,0.01,ito:ITO_00101,Vision process,mIoU
64,1,Semi-Supervised Video Object Segmentation,YouTube,2018-03,MRFCNN,0.784,95.49,0.0,0.0,0.821,0.01,ito:ITO_00101,Vision process,mIoU
65,1,Semi-Supervised Video Object Segmentation,YouTube,2019-02,FEELVOS,0.821,100.0,0.0,0.0,0.821,0.01,ito:ITO_00101,Vision process,mIoU
66,1,Video Object Segmentation,YouTube,2016-06,ObjFlow,0.776,94.52,0.776,0.95,0.821,0.01,ito:ITO_00101,Vision process,mIoU
67,1,Video Object Segmentation,YouTube,2016-11,OSVOS,0.783,95.37,0.0,0.0,0.821,0.01,ito:ITO_00101,Vision process,mIoU
68,1,Video Object Segmentation,YouTube,2018-03,MRFCNN,0.784,95.49,0.0,0.0,0.821,0.01,ito:ITO_00101,Vision process,mIoU
69,1,Video Object Segmentation,YouTube,2019-02,FEELVOS,0.821,100.0,0.0,0.0,0.821,0.01,ito:ITO_00101,Vision process,mIoU
70,1,Semantic Segmentation,PASCAL VOC 2012 val,2016-06,DeepLab-CRF (ResNet-101),77.69,90.55,77.69,0.91,85.8,0.86,ito:ITO_00101,Vision process,mIoU
71,1,Semantic Segmentation,PASCAL VOC 2012 val,2017-03,ResNet-GCN,81.0,94.41,3.3,0.04,85.8,0.9,ito:ITO_00101,Vision process,mIoU
72,1,Semantic Segmentation,PASCAL VOC 2012 val,2017-06,DeepLabv3-JFT,82.7,96.39,1.7,0.02,85.8,0.92,ito:ITO_00101,Vision process,mIoU
73,1,Semantic Segmentation,PASCAL VOC 2012 val,2018-02,DeepLabv3+ (Xception-JFT),84.56,98.55,1.9,0.02,85.8,0.94,ito:ITO_00101,Vision process,mIoU
74,1,Semantic Segmentation,PASCAL VOC 2012 val,2018-04,ExFuse (ResNeXt-131),85.8,100.0,1.2,0.01,85.8,0.95,ito:ITO_00101,Vision process,mIoU
75,1,Semantic Segmentation,ADE20K val,2016-11,RefineNet (ResNet-152),40.7,84.16,40.7,0.84,48.36,0.45,ito:ITO_00101,Vision process,mIoU
76,1,Semantic Segmentation,ADE20K val,2016-12,PSPNet (ResNet-152),43.51,89.97,2.8,0.06,48.36,0.48,ito:ITO_00101,Vision process,mIoU
77,1,Semantic Segmentation,ADE20K val,2018-03,DSSPN (ResNet-101),43.68,90.32,0.2,0.0,48.36,0.48,ito:ITO_00101,Vision process,mIoU
78,1,Semantic Segmentation,ADE20K val,2018-03,EncNet (ResNet-101),44.65,92.33,1.0,0.02,48.36,0.49,ito:ITO_00101,Vision process,mIoU
79,1,Semantic Segmentation,ADE20K val,2019-06,CFNet (ResNet-101),44.89,92.82,0.2,0.0,48.36,0.5,ito:ITO_00101,Vision process,mIoU
80,1,Semantic Segmentation,ADE20K val,2019-08,Asymmetric ALNN,45.24,93.55,0.4,0.01,48.36,0.5,ito:ITO_00101,Vision process,mIoU
81,1,Semantic Segmentation,ADE20K val,2019-09,OCR (HRNetV2-W48),45.66,94.42,0.4,0.01,48.36,0.51,ito:ITO_00101,Vision process,mIoU
82,1,Semantic Segmentation,ADE20K val,2019-10,ACNet (ResNet-101),45.9,94.91,0.2,0.0,48.36,0.51,ito:ITO_00101,Vision process,mIoU
83,1,Semantic Segmentation,ADE20K val,2020-03,DCNAS,47.12,97.44,1.2,0.02,48.36,0.52,ito:ITO_00101,Vision process,mIoU
84,1,Semantic Segmentation,ADE20K val,2020-04,ResNeSt-200,48.36,100.0,1.2,0.02,48.36,0.54,ito:ITO_00101,Vision process,mIoU
85,1,Semantic Segmentation,S3DIS Area5,2016-12,PointNet,41.1,61.25,41.1,0.61,67.1,0.46,ito:ITO_00101,Vision process,mIoU
86,1,Semantic Segmentation,S3DIS Area5,2017-10,SegCloud,48.9,72.88,7.8,0.12,67.1,0.54,ito:ITO_00101,Vision process,mIoU
87,1,Semantic Segmentation,S3DIS Area5,2017-11,SPG,58.04,86.5,9.1,0.14,67.1,0.64,ito:ITO_00101,Vision process,mIoU
88,1,Semantic Segmentation,S3DIS Area5,2019-04,MinkowskiNet,65.4,97.47,7.4,0.11,67.1,0.72,ito:ITO_00101,Vision process,mIoU
89,1,Semantic Segmentation,S3DIS Area5,2019-04,KPConv,67.1,100.0,1.7,0.03,67.1,0.74,ito:ITO_00101,Vision process,mIoU
90,1,3D Semantic Segmentation,SemanticKITTI,2016-12,PointNet,14.6,24.83,14.6,0.25,58.8,0.16,ito:ITO_00101,Vision process,mIoU
91,1,3D Semantic Segmentation,SemanticKITTI,2017-06,PointNet++,20.1,34.18,5.5,0.09,58.8,0.22,ito:ITO_00101,Vision process,mIoU
92,1,3D Semantic Segmentation,SemanticKITTI,2017-10,SqueezeSeg,29.5,50.17,9.4,0.16,58.8,0.33,ito:ITO_00101,Vision process,mIoU
93,1,3D Semantic Segmentation,SemanticKITTI,2018-07,TangentConv,35.9,61.05,6.4,0.11,58.8,0.4,ito:ITO_00101,Vision process,mIoU
94,1,3D Semantic Segmentation,SemanticKITTI,2018-07,TagentConv,40.9,69.56,5.0,0.09,58.8,0.45,ito:ITO_00101,Vision process,mIoU
95,1,3D Semantic Segmentation,SemanticKITTI,2019-04,KPConv,58.8,100.0,17.9,0.3,58.8,0.65,ito:ITO_00101,Vision process,mIoU
96,1,Real-Time Semantic Segmentation,NYU Depth v2,2016-12,PSPNet101,43.2,99.31,43.2,0.99,43.5,0.48,ito:ITO_00101,Vision process,mIoU
97,1,Real-Time Semantic Segmentation,NYU Depth v2,2020-04,TD2-PSP50,43.5,100.0,0.3,0.01,43.5,0.48,ito:ITO_00101,Vision process,mIoU
98,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2016-12,FCNs in the wild,27.1,53.98,27.1,0.54,50.2,0.3,ito:ITO_00101,Vision process,mIoU
99,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2017-07,CDA,28.9,57.57,1.8,0.04,50.2,0.32,ito:ITO_00101,Vision process,mIoU
100,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2017-11,CyCADA pixel+feat,39.5,78.69,10.6,0.21,50.2,0.44,ito:ITO_00101,Vision process,mIoU
101,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2018-02,Multi-level Adaptation,42.4,84.46,2.9,0.06,50.2,0.47,ito:ITO_00101,Vision process,mIoU
102,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2018-08,Domain adaptation (ResNet-101),43.2,86.06,0.8,0.02,50.2,0.48,ito:ITO_00101,Vision process,mIoU
103,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2018-10,CBST-SP (ResNet-38),46.2,92.03,3.0,0.06,50.2,0.51,ito:ITO_00101,Vision process,mIoU
104,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2018-10,"CBST-SP (ResNet-38, MST)",47.0,93.63,0.8,0.02,50.2,0.52,ito:ITO_00101,Vision process,mIoU
105,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2019-04,BDL (ResNet-101),48.5,96.61,1.5,0.03,50.2,0.54,ito:ITO_00101,Vision process,mIoU
106,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2019-08,MRKLD-SP-MST (ResNet-38),49.8,99.2,1.3,0.03,50.2,0.55,ito:ITO_00101,Vision process,mIoU
107,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2019-10,CAG-UDA,50.2,100.0,0.4,0.01,50.2,0.56,ito:ITO_00101,Vision process,mIoU
108,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2016-12,FCNs in the wild,20.2,37.9,20.2,0.38,53.3,0.22,ito:ITO_00101,Vision process,mIoU
109,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2017-07,CDA,29.0,54.41,8.8,0.17,53.3,0.32,ito:ITO_00101,Vision process,mIoU
110,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2018-02,Multi-level Adaptation,46.7,87.62,17.7,0.33,53.3,0.52,ito:ITO_00101,Vision process,mIoU
111,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2018-11,ADVENT,48.0,90.06,1.3,0.02,53.3,0.53,ito:ITO_00101,Vision process,mIoU
112,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-03,SWD,48.1,90.24,0.1,0.0,53.3,0.53,ito:ITO_00101,Vision process,mIoU
113,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-08,PyCDA (ResNet-101),53.3,100.0,5.2,0.1,53.3,0.59,ito:ITO_00101,Vision process,mIoU
114,1,Image-to-Image Translation,SYNTHIA Fall-to-Winter,2016-12,FCNs in the wild,59.6,94.15,59.6,0.94,63.3,0.66,ito:ITO_00101,Vision process,mIoU
115,1,Image-to-Image Translation,SYNTHIA Fall-to-Winter,2017-11,CyCADA,63.3,100.0,3.7,0.06,63.3,0.7,ito:ITO_00101,Vision process,mIoU
116,1,Semantic Segmentation,LIP val,2017-03,Attention+SSL (ResNet-101),44.73,75.35,44.73,0.75,59.36,0.5,ito:ITO_00101,Vision process,mIoU
117,1,Semantic Segmentation,LIP val,2018-04,JPPNet (ResNet-101),51.37,86.54,6.6,0.11,59.36,0.57,ito:ITO_00101,Vision process,mIoU
118,1,Semantic Segmentation,LIP val,2018-09,CE2P (ResNet-101),53.1,89.45,1.7,0.03,59.36,0.59,ito:ITO_00101,Vision process,mIoU
119,1,Semantic Segmentation,LIP val,2019-04,HRNetV2 (HRNetV2-W48),55.9,94.17,2.8,0.05,59.36,0.62,ito:ITO_00101,Vision process,mIoU
120,1,Semantic Segmentation,LIP val,2019-09,OCR (HRNetV2-W48),56.65,95.43,0.8,0.01,59.36,0.63,ito:ITO_00101,Vision process,mIoU
121,1,Semantic Segmentation,LIP val,2019-10,SCHP (ResNet-101),59.36,100.0,2.7,0.05,59.36,0.66,ito:ITO_00101,Vision process,mIoU
122,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2017-07,CRN,52.4,80.0,52.4,0.8,65.5,0.58,ito:ITO_00101,Vision process,mIoU
123,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2017-11,pix2pixHD,58.3,89.01,5.9,0.09,65.5,0.65,ito:ITO_00101,Vision process,mIoU
124,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2019-03,SPADE,62.3,95.11,4.0,0.06,65.5,0.69,ito:ITO_00101,Vision process,mIoU
125,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2019-10,CC-FPSE,65.5,100.0,3.2,0.05,65.5,0.73,ito:ITO_00101,Vision process,mIoU
126,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2017-07,CRN,23.7,56.97,23.7,0.57,41.6,0.26,ito:ITO_00101,Vision process,mIoU
127,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2019-03,SPADE,37.4,89.9,13.7,0.33,41.6,0.41,ito:ITO_00101,Vision process,mIoU
128,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2019-10,CC-FPSE,41.6,100.0,4.2,0.1,41.6,0.46,ito:ITO_00101,Vision process,mIoU
129,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2017-07,CRN,22.4,51.26,22.4,0.51,43.7,0.25,ito:ITO_00101,Vision process,mIoU
130,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2019-03,SPADE,38.5,88.1,16.1,0.37,43.7,0.43,ito:ITO_00101,Vision process,mIoU
131,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2019-10,CC-FPSE,43.7,100.0,5.2,0.12,43.7,0.48,ito:ITO_00101,Vision process,mIoU
132,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2017-07,CRN,16.5,53.57,16.5,0.54,30.8,0.18,ito:ITO_00101,Vision process,mIoU
133,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2017-11,pix2pixHD,17.4,56.49,0.9,0.03,30.8,0.19,ito:ITO_00101,Vision process,mIoU
134,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2019-03,SPADE,30.8,100.0,13.4,0.44,30.8,0.34,ito:ITO_00101,Vision process,mIoU
135,1,3D Instance Segmentation,S3DIS,2018-01,PointCNN,65.39,100.0,65.39,1.0,65.39,0.72,ito:ITO_00101,Vision process,mIoU
136,1,Medical Image Segmentation,2018 Data Science Bowl,2018-07,Unet++,0.9255,100.0,0.9255,1.0,0.9255,0.01,ito:ITO_00101,Vision process,mIoU
137,1,Panoptic Segmentation,Cityscapes val,2018-08,Dynamically Instantiated Network (ResNet-101),79.8,88.37,79.8,0.88,90.3,0.88,ito:ITO_00101,Vision process,mIoU
138,1,Panoptic Segmentation,Cityscapes val,2019-11,Panoptic-DeepLab (X71),81.5,90.25,1.7,0.02,90.3,0.9,ito:ITO_00101,Vision process,mIoU
139,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS,82.1,90.92,0.6,0.01,90.3,0.91,ito:ITO_00101,Vision process,mIoU
140,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS (Cityscapes-fine),90.3,100.0,8.2,0.09,90.3,1.0,ito:ITO_00101,Vision process,mIoU
141,1,Domain Adaptation,SYNTHIA-to-Cityscapes,2018-11,ADVENT (ResNet-101),41.2,88.22,41.2,0.88,46.7,0.46,ito:ITO_00101,Vision process,mIoU
142,1,Domain Adaptation,SYNTHIA-to-Cityscapes,2019-08,PyCDA (ResNet-101),46.7,100.0,5.5,0.12,46.7,0.52,ito:ITO_00101,Vision process,mIoU
143,1,Iris Segmentation,UBIRIS,2019-01,IrisParseNet (ASPP),85.39,100.0,85.39,1.0,85.39,0.95,ito:ITO_00101,Vision process,mIoU
144,1,Iris Segmentation,CASIA,2019-01,IrisParseNet (ASPP) CASIA,89.4,100.0,89.4,1.0,89.4,0.99,ito:ITO_00101,Vision process,mIoU
145,1,Iris Segmentation,MICHE,2019-01,IrisParseNet (PSP),85.07,100.0,85.07,1.0,85.07,0.94,ito:ITO_00101,Vision process,mIoU
146,1,Video Object Segmentation,DAVIS-2017,2019-02,FEELVOS,81.1,100.0,81.1,1.0,81.1,0.9,ito:ITO_00101,Vision process,mIoU
147,1,Semantic Segmentation,ParisLille3D,2019-04,KPConv deform,75.9,100.0,75.9,1.0,75.9,0.84,ito:ITO_00101,Vision process,mIoU
148,1,3D Semantic Segmentation,S3DIS,2019-07,PVCNN++,58.98,100.0,58.98,1.0,58.98,0.65,ito:ITO_00101,Vision process,mIoU
149,1,Retinal Vessel Segmentation,DRIVE,2019-07,ET-Net,0.7744,100.0,0.7744,1.0,0.7744,0.01,ito:ITO_00101,Vision process,mIoU
150,1,Lung Nodule Segmentation,LUNA,2019-07,ET-Net,0.9623,100.0,0.9623,1.0,0.9623,0.01,ito:ITO_00101,Vision process,mIoU
151,1,Lung Nodule Segmentation,Montgomery County,2019-07,ET-Net,0.942,100.0,0.942,1.0,0.942,0.01,ito:ITO_00101,Vision process,mIoU
152,1,Panoptic Segmentation,Mapillary val,2019-09,AdaptIS (ResNeXt-101),56.8,100.0,56.8,1.0,56.8,0.63,ito:ITO_00101,Vision process,mIoU
153,1,Unsupervised Semantic Segmentation,PASCAL VOC 2012 val,2019-10,SegSort,55.86,100.0,55.86,1.0,55.86,0.62,ito:ITO_00101,Vision process,mIoU
154,1,Real-Time Semantic Segmentation,Cityscapes val,2019-12,LiteSeg-MobileNet,67.8,100.0,67.8,1.0,67.8,0.75,ito:ITO_00101,Vision process,mIoU
155,1,Semantic Segmentation,BDD,2019-12,FasterSeg,55.1,100.0,55.1,1.0,55.1,0.61,ito:ITO_00101,Vision process,mIoU
156,1,Semantic Segmentation,GTAV-to-Cityscapes Labels,2019-12,MRNet,48.3,96.02,48.3,0.96,50.3,0.53,ito:ITO_00101,Vision process,mIoU
157,1,Semantic Segmentation,GTAV-to-Cityscapes Labels,2020-03,MRNet+Rectifying Label,50.3,100.0,2.0,0.04,50.3,0.56,ito:ITO_00101,Vision process,mIoU
158,1,Unsupervised Video Object Segmentation,YouTube,2020-01,COSNet,0.705,100.0,0.705,1.0,0.705,0.01,ito:ITO_00101,Vision process,mIoU
159,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet-tiny,46.9,84.05,46.9,0.84,55.8,0.52,ito:ITO_00101,Vision process,mIoU
160,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet,55.8,100.0,8.9,0.16,55.8,0.62,ito:ITO_00101,Vision process,mIoU
161,1,Real-Time Semantic Segmentation,COCO-Stuff,2020-04,BiSeNet V2-Large,28.7,100.0,28.7,1.0,28.7,0.32,ito:ITO_00101,Vision process,mIoU
0,1,Unsupervised Image-To-Image Translation,SVNH-to-MNIST,2014-09,DANN,73.6,81.42,73.6,0.81,90.4,0.74,ito:ITO_00101,Vision process,Classification\\ Accuracy
1,1,Unsupervised Image-To-Image Translation,SVNH-to-MNIST,2016-11,DTN,84.4,93.36,10.8,0.12,90.4,0.84,ito:ITO_00101,Vision process,Classification\\ Accuracy
2,1,Unsupervised Image-To-Image Translation,SVNH-to-MNIST,2017-11,CyCADA pixel+feat,90.4,100.0,6.0,0.07,90.4,0.9,ito:ITO_00101,Vision process,Classification\\ Accuracy
3,1,Domain Adaptation,Synth Objects-to-LINEMOD,2016-08,DSN (DANN),100.0,100.0,100,1.0,100,1.0,ito:ITO_00101,Vision process,Classification\\ Accuracy
4,1,3D Object Classification,ModelNet40,2018-12,3D-PointCapsNet,89.3,100.0,89.3,1.0,89.3,0.89,ito:ITO_00101,Vision process,Classification\\ Accuracy
0,1,Image Generation,CIFAR-10,2014-10,NICE,4.5,100.0,4.5,1.0,4.5,1.0,ito:ITO_00101,Vision process,Model\\ Entropy
0,1,Image Generation,CIFAR-10,2014-10,NICE,4.5,100.0,4.5,1.0,4.5,1.0,ito:ITO_00101,Vision process,bits/dimension
1,1,Image Generation,MNIST,2018-11,i-ResNet,1.06,100.0,1.06,1.0,1.06,0.24,ito:ITO_00101,Vision process,bits/dimension
0,1,Image Generation,CIFAR-10,2014-10,NICE,4.5,100.0,4.5,1.0,4.5,1.0,ito:ITO_00101,Vision process,NLL\\ Test
1,1,Image Generation,ImageNet 64x64,2019-02,Flow++,3.69,98.4,3.69,0.98,3.75,0.82,ito:ITO_00101,Vision process,NLL\\ Test
2,1,Image Generation,ImageNet 64x64,2019-02,MaCow (Unf),3.75,100.0,0.1,0.03,3.75,0.83,ito:ITO_00101,Vision process,NLL\\ Test
0,1,Semantic Segmentation,ADE20K,2014-11,FCN,29.39,60.77,29.39,0.61,48.36,0.41,ito:ITO_00101,Vision process,Validation\\ mIoU
1,1,Semantic Segmentation,ADE20K,2015-11,DilatedNet,32.31,66.81,2.9,0.06,48.36,0.45,ito:ITO_00101,Vision process,Validation\\ mIoU
2,1,Semantic Segmentation,ADE20K,2016-11,RefineNet,40.7,84.16,8.4,0.17,48.36,0.57,ito:ITO_00101,Vision process,Validation\\ mIoU
3,1,Semantic Segmentation,ADE20K,2016-12,PSPNet,44.94,92.93,4.2,0.09,48.36,0.63,ito:ITO_00101,Vision process,Validation\\ mIoU
4,1,Semantic Segmentation,ADE20K,2019-11,LaU-regression-loss,45.02,93.09,0.1,0.0,48.36,0.63,ito:ITO_00101,Vision process,Validation\\ mIoU
5,1,Semantic Segmentation,ADE20K,2020-04,CPN(ResNet-101),46.27,95.68,1.2,0.02,48.36,0.65,ito:ITO_00101,Vision process,Validation\\ mIoU
6,1,Semantic Segmentation,ADE20K,2020-04,ResNeSt-269,47.6,98.43,1.3,0.03,48.36,0.67,ito:ITO_00101,Vision process,Validation\\ mIoU
7,1,Semantic Segmentation,ADE20K,2020-04,ResNeSt-200,48.36,100.0,0.8,0.02,48.36,0.68,ito:ITO_00101,Vision process,Validation\\ mIoU
8,1,Semi-Supervised Semantic Segmentation,Cityscapes 25% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),60.5,94.72,60.5,0.95,63.87,0.85,ito:ITO_00101,Vision process,Validation\\ mIoU
9,1,Semi-Supervised Semantic Segmentation,Cityscapes 25% labeled,2019-06,"CutMix (DeepLab v2, ImageNet pre-trained)",63.87,100.0,3.4,0.05,63.87,0.89,ito:ITO_00101,Vision process,Validation\\ mIoU
10,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 12.5% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),64.3,90.06,64.3,0.9,71.4,0.9,ito:ITO_00101,Vision process,Validation\\ mIoU
11,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 12.5% labeled,2019-06,CutMix (DeepLab v2 ImageNet pre-trained),67.6,94.68,3.3,0.05,71.4,0.95,ito:ITO_00101,Vision process,Validation\\ mIoU
12,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 12.5% labeled,2019-08,s4GAN+MLMT (DeepLab v3 ImageNet pre-trained),70.4,98.6,2.8,0.04,71.4,0.99,ito:ITO_00101,Vision process,Validation\\ mIoU
13,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 12.5% labeled,2019-08,s4GAN + MLMT (DeepLab v2 MSCOCO/ImageNet pre-trained),71.4,100.0,1.0,0.01,71.4,1.0,ito:ITO_00101,Vision process,Validation\\ mIoU
14,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 5% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),59.1,87.95,59.1,0.88,67.2,0.83,ito:ITO_00101,Vision process,Validation\\ mIoU
15,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 5% labeled,2019-06,CutMix (DeepLab v2 ImageNet pre-trained),66.48,98.93,7.4,0.11,67.2,0.93,ito:ITO_00101,Vision process,Validation\\ mIoU
16,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 5% labeled,2019-08,s4GAN+MLMT (DeepLab v3 ImageNet pre-trained),66.6,99.11,0.1,0.0,67.2,0.93,ito:ITO_00101,Vision process,Validation\\ mIoU
17,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 5% labeled,2019-08,s4GAN + MLMT (DeepLab v2 MSCOCO/ImageNet pre-trained),67.2,100.0,0.6,0.01,67.2,0.94,ito:ITO_00101,Vision process,Validation\\ mIoU
18,1,Semi-Supervised Semantic Segmentation,Cityscapes 12.5% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),57.1,94.63,57.1,0.95,60.34,0.8,ito:ITO_00101,Vision process,Validation\\ mIoU
19,1,Semi-Supervised Semantic Segmentation,Cityscapes 12.5% labeled,2019-06,"CutMix (DeepLab v2, ImageNet pre-trained)",60.34,100.0,3.2,0.05,60.34,0.85,ito:ITO_00101,Vision process,Validation\\ mIoU
20,1,Semi-Supervised Semantic Segmentation,Cityscapes 50% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),65.7,100.0,65.7,1.0,65.7,0.92,ito:ITO_00101,Vision process,Validation\\ mIoU
21,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 2% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),49.2,75.91,49.2,0.76,64.81,0.69,ito:ITO_00101,Vision process,Validation\\ mIoU
22,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 2% labeled,2019-06,CutMix (DeepLab v2 ImageNet pre-trained),64.81,100.0,15.6,0.24,64.81,0.91,ito:ITO_00101,Vision process,Validation\\ mIoU
23,1,Semi-Supervised Semantic Segmentation,Cityscapes 100 samples labeled,2019-06,"CutMix (DeepLab v2, ImageNet pre-trained)",51.2,100.0,51.2,1.0,51.2,0.72,ito:ITO_00101,Vision process,Validation\\ mIoU
24,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 1% labeled,2019-06,CutMix (DeepLab v2 ImageNet pre-trained),53.79,100.0,53.79,1.0,53.79,0.75,ito:ITO_00101,Vision process,Validation\\ mIoU
25,1,Semi-Supervised Semantic Segmentation,Cityscapes 2% labeled,2019-08,"S4GAN (DeepLabv2 with ResNet101, MSCOCO pre-trained)",50.48,100.0,50.48,1.0,50.48,0.71,ito:ITO_00101,Vision process,Validation\\ mIoU
26,1,Semi-Supervised Semantic Segmentation,Cityscapes 5% labeled,2019-08,"S4GAN (DeepLabv2 with ResNet101, MSCOCO pre-trained)",55.61,100.0,55.61,1.0,55.61,0.78,ito:ITO_00101,Vision process,Validation\\ mIoU
27,1,Semi-Supervised Semantic Segmentation,PASCAL Context 25% labeled,2019-08,s4GAN+MLMT (DeepLab v2 ImageNet pre-trained),37.8,100.0,37.8,1.0,37.8,0.53,ito:ITO_00101,Vision process,Validation\\ mIoU
28,1,Semi-Supervised Semantic Segmentation,PASCAL Context 12.5% labeled,2019-08,s4GAN+MLMT (DeepLab v2 ImageNet pre-trained),35.3,100.0,35.3,1.0,35.3,0.49,ito:ITO_00101,Vision process,Validation\\ mIoU
0,1,Pose Estimation,MPII Human Pose,2014-11,Tompson et al.,82.0,87.14,82.0,0.87,94.1,0.87,ito:ITO_00101,Vision process,PCKh\\-0\\.5
1,1,Pose Estimation,MPII Human Pose,2015-11,DeepCut,82.4,87.57,0.4,0.0,94.1,0.88,ito:ITO_00101,Vision process,PCKh\\-0\\.5
2,1,Pose Estimation,MPII Human Pose,2016-01,Convolutional Pose Machines,88.52,94.07,6.1,0.06,94.1,0.94,ito:ITO_00101,Vision process,PCKh\\-0\\.5
3,1,Pose Estimation,MPII Human Pose,2016-03,Stacked Hourglass Networks,90.9,96.6,2.4,0.03,94.1,0.97,ito:ITO_00101,Vision process,PCKh\\-0\\.5
4,1,Pose Estimation,MPII Human Pose,2017-02,Multi-Context Attention,91.5,97.24,0.6,0.01,94.1,0.97,ito:ITO_00101,Vision process,PCKh\\-0\\.5
5,1,Pose Estimation,MPII Human Pose,2017-04,Chen et al. ICCV\'17,91.9,97.66,0.4,0.0,94.1,0.98,ito:ITO_00101,Vision process,PCKh\\-0\\.5
6,1,Pose Estimation,MPII Human Pose,2017-08,Pyramid Residual Modules (PRMs),92.0,97.77,0.1,0.0,94.1,0.98,ito:ITO_00101,Vision process,PCKh\\-0\\.5
7,1,Pose Estimation,MPII Human Pose,2018-03,Multi-Scale Structure-Aware Network,92.1,97.87,0.1,0.0,94.1,0.98,ito:ITO_00101,Vision process,PCKh\\-0\\.5
8,1,Pose Estimation,MPII Human Pose,2019-01,MSPN,92.6,98.41,0.5,0.01,94.1,0.98,ito:ITO_00101,Vision process,PCKh\\-0\\.5
9,1,Pose Estimation,MPII Human Pose,2019-02,Cascade Feature Aggregation,93.9,99.79,1.3,0.01,94.1,1.0,ito:ITO_00101,Vision process,PCKh\\-0\\.5
10,1,Pose Estimation,MPII Human Pose,2020-02,Soft-gated Skip Connections,94.1,100.0,0.2,0.0,94.1,1.0,ito:ITO_00101,Vision process,PCKh\\-0\\.5
0,1,Skeleton Based Action Recognition,J-HMDB,2014-11,Action Tubes,62.5,69.14,62.5,0.69,90.4,0.69,ito:ITO_00101,Vision process,Accuracy\\ \\(RGB\\+pose\\)
1,1,Skeleton Based Action Recognition,J-HMDB,2016-09,MR Two-Sream R-CNN,71.1,78.65,8.6,0.1,90.4,0.79,ito:ITO_00101,Vision process,Accuracy\\ \\(RGB\\+pose\\)
2,1,Skeleton Based Action Recognition,J-HMDB,2017-04,Chained (RGB+Flow +Pose),76.1,84.18,5.0,0.06,90.4,0.84,ito:ITO_00101,Vision process,Accuracy\\ \\(RGB\\+pose\\)
3,1,Skeleton Based Action Recognition,J-HMDB,2017-05,I3D,84.1,93.03,8.0,0.09,90.4,0.93,ito:ITO_00101,Vision process,Accuracy\\ \\(RGB\\+pose\\)
4,1,Skeleton Based Action Recognition,J-HMDB,2018-06,Potion,90.4,100.0,6.3,0.07,90.4,1.0,ito:ITO_00101,Vision process,Accuracy\\ \\(RGB\\+pose\\)
0,1,Pedestrian Detection,Caltech,2014-11,TA-CNN,20.9,84.27,20.9,0.84,24.8,0.84,ito:ITO_00101,Vision process,Reasonable\\ Miss\\ Rate
1,1,Pedestrian Detection,Caltech,2014-12,LDCF,24.8,100.0,3.9,0.16,24.8,1.0,ito:ITO_00101,Vision process,Reasonable\\ Miss\\ Rate
0,1,Scene Text Detection,ICDAR 2013,2014-12,Jaderberg et al.,88.5,90.86,88.5,0.91,97.4,0.91,ito:ITO_00101,Vision process,Precision
1,1,Scene Text Detection,ICDAR 2013,2016-04,Gupta et al.,92.0,94.46,3.5,0.04,97.4,0.94,ito:ITO_00101,Vision process,Precision
2,1,Scene Text Detection,ICDAR 2013,2017-08,WordSup (VGG16-synth-icdar),93.34,95.83,1.3,0.01,97.4,0.96,ito:ITO_00101,Vision process,Precision
3,1,Scene Text Detection,ICDAR 2013,2018-07,Mask TextSpotter,95.0,97.54,1.7,0.02,97.4,0.98,ito:ITO_00101,Vision process,Precision
4,1,Scene Text Detection,ICDAR 2013,2019-04,CRAFT,97.4,100.0,2.4,0.02,97.4,1.0,ito:ITO_00101,Vision process,Precision
5,1,Pancreas Segmentation,CT-150,2015-05,U-Net,0.848,99.88,0.848,1.0,0.849,0.01,ito:ITO_00101,Vision process,Precision
6,1,Pancreas Segmentation,CT-150,2018-04,Att U-Net,0.849,100.0,0.0,0.0,0.849,0.01,ito:ITO_00101,Vision process,Precision
7,1,Gesture Recognition,Montalbano,2015-06,Temp Conv + LSTM,94.49,100.0,94.49,1.0,94.49,0.97,ito:ITO_00101,Vision process,Precision
8,1,Visual Object Tracking,TrackingNet,2015-12,STAPLE_CA,46.72,67.34,46.72,0.67,69.38,0.48,ito:ITO_00101,Vision process,Precision
9,1,Visual Object Tracking,TrackingNet,2016-11,ECO,48.86,70.42,2.1,0.03,69.38,0.5,ito:ITO_00101,Vision process,Precision
10,1,Visual Object Tracking,TrackingNet,2018-11,ATOM,64.84,93.46,16.0,0.23,69.38,0.67,ito:ITO_00101,Vision process,Precision
11,1,Visual Object Tracking,TrackingNet,2018-12,SiamRPN++,69.38,100.0,4.5,0.06,69.38,0.71,ito:ITO_00101,Vision process,Precision
12,1,Scene Text Detection,ICDAR 2015,2016-04,MCLAB_FCN,70.8,76.42,70.8,0.76,92.65,0.73,ito:ITO_00101,Vision process,Precision
13,1,Scene Text Detection,ICDAR 2015,2017-03,SegLink,73.1,78.9,2.3,0.02,92.65,0.75,ito:ITO_00101,Vision process,Precision
14,1,Scene Text Detection,ICDAR 2015,2017-04,EAST + PVANET2x RBOX (single-scale),83.6,90.23,10.5,0.11,92.65,0.86,ito:ITO_00101,Vision process,Precision
15,1,Scene Text Detection,ICDAR 2015,2017-09,FTSN + MNMS,88.6,95.63,5.0,0.05,92.65,0.91,ito:ITO_00101,Vision process,Precision
16,1,Scene Text Detection,ICDAR 2015,2018-01,FOTS,91.0,98.22,2.4,0.03,92.65,0.93,ito:ITO_00101,Vision process,Precision
17,1,Scene Text Detection,ICDAR 2015,2018-01,FOTS MS,91.85,99.14,0.8,0.01,92.65,0.94,ito:ITO_00101,Vision process,Precision
18,1,Scene Text Detection,ICDAR 2015,2019-10,CharNet H-88 (multi-scale),92.65,100.0,0.8,0.01,92.65,0.95,ito:ITO_00101,Vision process,Precision
19,1,Scene Text Detection,COCO-Text,2016-06,Yao et al.,43.23,71.02,43.23,0.71,60.87,0.44,ito:ITO_00101,Vision process,Precision
20,1,Scene Text Detection,COCO-Text,2017-04,EAST + VGG16,50.39,82.78,7.2,0.12,60.87,0.52,ito:ITO_00101,Vision process,Precision
21,1,Scene Text Detection,COCO-Text,2018-01,TextBoxes++_MS,60.87,100.0,10.5,0.17,60.87,0.62,ito:ITO_00101,Vision process,Precision
22,1,Scene Text Detection,MSRA-TD500,2017-03,SegLink,86.0,93.99,86.0,0.94,91.5,0.88,ito:ITO_00101,Vision process,Precision
23,1,Scene Text Detection,MSRA-TD500,2017-04,EAST + PVANET2x,87.28,95.39,1.3,0.01,91.5,0.9,ito:ITO_00101,Vision process,Precision
24,1,Scene Text Detection,MSRA-TD500,2017-09,FTSN + MNMS,87.6,95.74,0.3,0.0,91.5,0.9,ito:ITO_00101,Vision process,Precision
25,1,Scene Text Detection,MSRA-TD500,2019-04,CRAFT,88.2,96.39,0.6,0.01,91.5,0.91,ito:ITO_00101,Vision process,Precision
26,1,Scene Text Detection,MSRA-TD500,2019-11,DB-ResNet-50 (736),91.5,100.0,3.3,0.04,91.5,0.94,ito:ITO_00101,Vision process,Precision
27,1,Scene Text Detection,Total-Text,2017-04,EAST,50.0,55.62,50.0,0.56,89.9,0.51,ito:ITO_00101,Vision process,Precision
28,1,Scene Text Detection,Total-Text,2017-09,FTSN,84.7,94.22,34.7,0.39,89.9,0.87,ito:ITO_00101,Vision process,Precision
29,1,Scene Text Detection,Total-Text,2019-04,CRAFT,87.6,97.44,2.9,0.03,89.9,0.9,ito:ITO_00101,Vision process,Precision
30,1,Scene Text Detection,Total-Text,2019-08,PAN-640,89.3,99.33,1.7,0.02,89.9,0.92,ito:ITO_00101,Vision process,Precision
31,1,Scene Text Detection,Total-Text,2019-10,CharNet H-88,89.9,100.0,0.6,0.01,89.9,0.92,ito:ITO_00101,Vision process,Precision
32,1,Scene Text Detection,ICDAR 2017 MLT,2018-01,FOTS,80.95,95.89,80.95,0.96,84.42,0.83,ito:ITO_00101,Vision process,Precision
33,1,Scene Text Detection,ICDAR 2017 MLT,2018-01,FOTS MS,81.86,96.97,0.9,0.01,84.42,0.84,ito:ITO_00101,Vision process,Precision
34,1,Scene Text Detection,ICDAR 2017 MLT,2018-02,Corner Localization (single-scale),83.8,99.27,1.9,0.02,84.42,0.86,ito:ITO_00101,Vision process,Precision
35,1,Scene Text Detection,ICDAR 2017 MLT,2019-03,PMTD*,84.42,100.0,0.6,0.01,84.42,0.87,ito:ITO_00101,Vision process,Precision
36,1,Scene Text Detection,SCUT-CTW1500,2018-01,SLPR,80.1,92.28,80.1,0.92,86.8,0.82,ito:ITO_00101,Vision process,Precision
37,1,Scene Text Detection,SCUT-CTW1500,2018-06,PSENet-1s,82.5,95.05,2.4,0.03,86.8,0.85,ito:ITO_00101,Vision process,Precision
38,1,Scene Text Detection,SCUT-CTW1500,2018-11,PAN,86.8,100.0,4.3,0.05,86.8,0.89,ito:ITO_00101,Vision process,Precision
39,1,Object Localization,Mall,2018-06,Hausdorff Loss,88.1,100.0,88.1,1.0,88.1,0.9,ito:ITO_00101,Vision process,Precision
40,1,Lung Nodule Segmentation,NIH,2019-04,U-Net+R+A4,0.969,100.0,0.969,1.0,0.969,0.01,ito:ITO_00101,Vision process,Precision
41,1,Visual Object Tracking,OTB-2015,2019-09,GradNet,0.861,100.0,0.861,1.0,0.861,0.01,ito:ITO_00101,Vision process,Precision
0,1,Scene Text Detection,ICDAR 2013,2014-12,Jaderberg et al.,67.8,72.82,67.8,0.73,93.1,0.72,ito:ITO_00101,Vision process,Recall
1,1,Scene Text Detection,ICDAR 2013,2015-04,Neumann et al. *,72.4,77.77,4.6,0.05,93.1,0.77,ito:ITO_00101,Vision process,Recall
2,1,Scene Text Detection,ICDAR 2013,2016-04,Gupta et al.,75.5,81.1,3.1,0.03,93.1,0.8,ito:ITO_00101,Vision process,Recall
3,1,Scene Text Detection,ICDAR 2013,2017-03,SegLink,83.0,89.15,7.5,0.08,93.1,0.88,ito:ITO_00101,Vision process,Recall
4,1,Scene Text Detection,ICDAR 2013,2017-08,WordSup (VGG16-synth-icdar),87.53,94.02,4.5,0.05,93.1,0.93,ito:ITO_00101,Vision process,Recall
5,1,Scene Text Detection,ICDAR 2013,2018-07,Mask TextSpotter,88.6,95.17,1.1,0.01,93.1,0.94,ito:ITO_00101,Vision process,Recall
6,1,Scene Text Detection,ICDAR 2013,2018-11,SPCNET,90.5,97.21,1.9,0.02,93.1,0.96,ito:ITO_00101,Vision process,Recall
7,1,Scene Text Detection,ICDAR 2013,2019-04,CRAFT,93.1,100.0,2.6,0.03,93.1,0.98,ito:ITO_00101,Vision process,Recall
8,1,Pancreas Segmentation,CT-150,2015-05,U-Net,0.806,95.84,0.806,0.96,0.841,0.01,ito:ITO_00101,Vision process,Recall
9,1,Pancreas Segmentation,CT-150,2018-04,Att U-Net,0.841,100.0,0.0,0.0,0.841,0.01,ito:ITO_00101,Vision process,Recall
10,1,Gesture Recognition,Montalbano,2015-06,Temp Conv + LSTM,94.57,100.0,94.57,1.0,94.57,1.0,ito:ITO_00101,Vision process,Recall
11,1,Temporal Action Localization,CrossTask,2015-06,Alayrac,13.3,39.58,13.3,0.4,33.6,0.14,ito:ITO_00101,Vision process,Recall
12,1,Temporal Action Localization,CrossTask,2019-03,Fully-supervised upper-bound,31.6,94.05,18.3,0.54,33.6,0.33,ito:ITO_00101,Vision process,Recall
13,1,Temporal Action Localization,CrossTask,2019-06,Text-Video Embedding,33.6,100.0,2.0,0.06,33.6,0.36,ito:ITO_00101,Vision process,Recall
14,1,Point Cloud Registration,3DMatch Benchmark,2016-03,3DMatch + RANSAC,66.8,81.46,66.8,0.81,82.0,0.71,ito:ITO_00101,Vision process,Recall
15,1,Point Cloud Registration,3DMatch Benchmark,2019-10,FCGF + RANSAC,82.0,100.0,15.2,0.19,82.0,0.87,ito:ITO_00101,Vision process,Recall
16,1,Scene Text Detection,ICDAR 2015,2016-04,MCLAB_FCN,43.0,46.75,43.0,0.47,91.98,0.45,ito:ITO_00101,Vision process,Recall
17,1,Scene Text Detection,ICDAR 2015,2017-03,SegLink,76.8,83.5,33.8,0.37,91.98,0.81,ito:ITO_00101,Vision process,Recall
18,1,Scene Text Detection,ICDAR 2015,2017-04,EAST + PVANET2x RBOX (multi-scale),78.3,85.13,1.5,0.02,91.98,0.83,ito:ITO_00101,Vision process,Recall
19,1,Scene Text Detection,ICDAR 2015,2017-09,FTSN + MNMS,80.0,86.98,1.7,0.02,91.98,0.85,ito:ITO_00101,Vision process,Recall
20,1,Scene Text Detection,ICDAR 2015,2018-01,PixelLink+VGG16 2s,82.0,89.15,2.0,0.02,91.98,0.87,ito:ITO_00101,Vision process,Recall
21,1,Scene Text Detection,ICDAR 2015,2018-01,FOTS,85.17,92.6,3.2,0.03,91.98,0.9,ito:ITO_00101,Vision process,Recall
22,1,Scene Text Detection,ICDAR 2015,2018-01,FOTS MS,87.92,95.59,2.8,0.03,91.98,0.93,ito:ITO_00101,Vision process,Recall
23,1,Scene Text Detection,ICDAR 2015,2019-10,CharNet H-57 (multi-scale),88.74,96.48,0.8,0.01,91.98,0.94,ito:ITO_00101,Vision process,Recall
24,1,Scene Text Detection,ICDAR 2015,2019-10,CharNet H-88 (multi-scale),90.47,98.36,1.7,0.02,91.98,0.96,ito:ITO_00101,Vision process,Recall
25,1,Scene Text Detection,ICDAR 2015,2019-10,CharNet H-88 (single-scale),91.98,100.0,1.5,0.02,91.98,0.97,ito:ITO_00101,Vision process,Recall
26,1,Scene Text Detection,COCO-Text,2016-06,Yao et al.,27.1,42.81,27.1,0.43,63.3,0.29,ito:ITO_00101,Vision process,Recall
27,1,Scene Text Detection,COCO-Text,2017-04,EAST + VGG16,32.4,51.18,5.3,0.08,63.3,0.34,ito:ITO_00101,Vision process,Recall
28,1,Scene Text Detection,COCO-Text,2018-01,TextBoxes++_MS,56.7,89.57,24.3,0.38,63.3,0.6,ito:ITO_00101,Vision process,Recall
29,1,Scene Text Detection,COCO-Text,2018-04,Corner-based Region Proposals,63.3,100.0,6.6,0.1,63.3,0.67,ito:ITO_00101,Vision process,Recall
30,1,Scene Text Detection,MSRA-TD500,2017-03,SegLink,70.0,83.53,70.0,0.84,83.8,0.74,ito:ITO_00101,Vision process,Recall
31,1,Scene Text Detection,MSRA-TD500,2017-09,FTSN + MNMS,77.1,92.0,7.1,0.08,83.8,0.82,ito:ITO_00101,Vision process,Recall
32,1,Scene Text Detection,MSRA-TD500,2019-04,CRAFT,78.2,93.32,1.1,0.01,83.8,0.83,ito:ITO_00101,Vision process,Recall
33,1,Scene Text Detection,MSRA-TD500,2019-08,PAN,83.8,100.0,5.6,0.07,83.8,0.89,ito:ITO_00101,Vision process,Recall
34,1,Scene Text Detection,Total-Text,2017-04,EAST,36.2,42.59,36.2,0.43,85.0,0.38,ito:ITO_00101,Vision process,Recall
35,1,Scene Text Detection,Total-Text,2017-09,FTSN,78.0,91.76,41.8,0.49,85.0,0.82,ito:ITO_00101,Vision process,Recall
36,1,Scene Text Detection,Total-Text,2018-11,SPCNET,82.8,97.41,4.8,0.06,85.0,0.88,ito:ITO_00101,Vision process,Recall
37,1,Scene Text Detection,Total-Text,2019-10,CharNet H-88 (multi-scale),85.0,100.0,2.2,0.03,85.0,0.9,ito:ITO_00101,Vision process,Recall
38,1,Scene Text Detection,ICDAR 2017 MLT,2018-01,FOTS MS,62.3,81.5,62.3,0.82,76.44,0.66,ito:ITO_00101,Vision process,Recall
39,1,Scene Text Detection,ICDAR 2017 MLT,2018-02,Corner Localization (multi-scale),70.6,92.36,8.3,0.11,76.44,0.75,ito:ITO_00101,Vision process,Recall
40,1,Scene Text Detection,ICDAR 2017 MLT,2019-03,PMTD*,76.25,99.75,5.7,0.07,76.44,0.81,ito:ITO_00101,Vision process,Recall
41,1,Scene Text Detection,ICDAR 2017 MLT,2019-12,SBD,76.44,100.0,0.2,0.0,76.44,0.81,ito:ITO_00101,Vision process,Recall
42,1,Scene Text Detection,SCUT-CTW1500,2018-01,SLPR,70.1,82.18,70.1,0.82,85.3,0.74,ito:ITO_00101,Vision process,Recall
43,1,Scene Text Detection,SCUT-CTW1500,2018-06,PSENet-1s,79.89,93.66,9.8,0.11,85.3,0.84,ito:ITO_00101,Vision process,Recall
44,1,Scene Text Detection,SCUT-CTW1500,2018-07,TextSnake,85.3,100.0,5.4,0.06,85.3,0.9,ito:ITO_00101,Vision process,Recall
45,1,Object Localization,Pupil,2018-06,Hausdorff Loss,89.2,100.0,89.2,1.0,89.2,0.94,ito:ITO_00101,Vision process,Recall
46,1,Zero-Shot Object Detection,MS-COCO,2018-11,ZSD-Polarity Loss,43.56,100.0,43.56,1.0,43.56,0.46,ito:ITO_00101,Vision process,Recall
47,1,Lung Nodule Segmentation,NIH,2019-04,U-Net+R+A4,0.956,100.0,0.956,1.0,0.956,0.01,ito:ITO_00101,Vision process,Recall
0,1,Scene Text Detection,ICDAR 2013,2014-12,Jaderberg et al.,76.8,83.39,76.8,0.83,92.1,0.82,ito:ITO_00101,Vision process,F\\-Measure
1,1,Scene Text Detection,ICDAR 2013,2015-04,Neumann et al. *,77.1,83.71,0.3,0.0,92.1,0.83,ito:ITO_00101,Vision process,F\\-Measure
2,1,Scene Text Detection,ICDAR 2013,2015-07,CRNN,86.7,94.14,9.6,0.1,92.1,0.93,ito:ITO_00101,Vision process,F\\-Measure
3,1,Scene Text Detection,ICDAR 2013,2017-07,STN-OCR,90.3,98.05,3.6,0.04,92.1,0.97,ito:ITO_00101,Vision process,F\\-Measure
4,1,Scene Text Detection,ICDAR 2013,2017-08,WordSup (VGG16-synth-icdar),90.34,98.09,0.0,0.0,92.1,0.97,ito:ITO_00101,Vision process,F\\-Measure
5,1,Scene Text Detection,ICDAR 2013,2018-07,Mask TextSpotter,91.7,99.57,1.4,0.02,92.1,0.98,ito:ITO_00101,Vision process,F\\-Measure
6,1,Scene Text Detection,ICDAR 2013,2018-11,SPCNET,92.1,100.0,0.4,0.0,92.1,0.99,ito:ITO_00101,Vision process,F\\-Measure
7,1,Curved Text Detection,SCUT-CTW1500,2015-05,"CTD+TLOC [[Noh et al.(2015)Noh, Hong, and Han]]",73.4,85.05,73.4,0.85,86.3,0.79,ito:ITO_00101,Vision process,F\\-Measure
8,1,Curved Text Detection,SCUT-CTW1500,2018-07,"TextSnake [[Long et al.(2018)Long, Ruan, Zhang, He, Wu, and Yao]]",75.6,87.6,2.2,0.03,86.3,0.81,ito:ITO_00101,Vision process,F\\-Measure
9,1,Curved Text Detection,SCUT-CTW1500,2019-04,TextCohesion,86.3,100.0,10.7,0.12,86.3,0.92,ito:ITO_00101,Vision process,F\\-Measure
10,1,Scene Text Detection,ICDAR 2015,2016-04,MCLAB_FCN,53.6,58.55,53.6,0.59,91.55,0.57,ito:ITO_00101,Vision process,F\\-Measure
11,1,Scene Text Detection,ICDAR 2015,2017-03,SegLink,75.0,81.92,21.4,0.23,91.55,0.8,ito:ITO_00101,Vision process,F\\-Measure
12,1,Scene Text Detection,ICDAR 2015,2017-04,EAST + PVANET2x RBOX (multi-scale),80.7,88.15,5.7,0.06,91.55,0.86,ito:ITO_00101,Vision process,F\\-Measure
13,1,Scene Text Detection,ICDAR 2015,2017-09,FTSN + MNMS,84.1,91.86,3.4,0.04,91.55,0.9,ito:ITO_00101,Vision process,F\\-Measure
14,1,Scene Text Detection,ICDAR 2015,2018-01,FOTS,87.99,96.11,3.9,0.04,91.55,0.94,ito:ITO_00101,Vision process,F\\-Measure
15,1,Scene Text Detection,ICDAR 2015,2018-01,FOTS MS,89.84,98.13,1.9,0.02,91.55,0.96,ito:ITO_00101,Vision process,F\\-Measure
16,1,Scene Text Detection,ICDAR 2015,2019-10,CharNet H-57 (multi-scale),90.06,98.37,0.2,0.0,91.55,0.96,ito:ITO_00101,Vision process,F\\-Measure
17,1,Scene Text Detection,ICDAR 2015,2019-10,CharNet H-88 (multi-scale),91.55,100.0,1.5,0.02,91.55,0.98,ito:ITO_00101,Vision process,F\\-Measure
18,1,Scene Text Detection,COCO-Text,2016-06,Yao et al.,33.31,56.36,33.31,0.56,59.1,0.36,ito:ITO_00101,Vision process,F\\-Measure
19,1,Scene Text Detection,COCO-Text,2017-04,EAST + VGG16,39.45,66.75,6.1,0.1,59.1,0.42,ito:ITO_00101,Vision process,F\\-Measure
20,1,Scene Text Detection,COCO-Text,2018-01,TextBoxes++_MS,58.72,99.36,19.3,0.33,59.1,0.63,ito:ITO_00101,Vision process,F\\-Measure
21,1,Scene Text Detection,COCO-Text,2018-04,Corner-based Region Proposals,59.1,100.0,0.4,0.01,59.1,0.63,ito:ITO_00101,Vision process,F\\-Measure
22,1,Scene Text Detection,MSRA-TD500,2017-03,SegLink,77.0,90.69,77.0,0.91,84.9,0.82,ito:ITO_00101,Vision process,F\\-Measure
23,1,Scene Text Detection,MSRA-TD500,2018-01,PixelLink + VGG16 2s,77.8,91.64,0.8,0.01,84.9,0.83,ito:ITO_00101,Vision process,F\\-Measure
24,1,Scene Text Detection,MSRA-TD500,2018-02,Corner Localization,81.5,96.0,3.7,0.04,84.9,0.87,ito:ITO_00101,Vision process,F\\-Measure
25,1,Scene Text Detection,MSRA-TD500,2019-08,PAN,84.1,99.06,2.6,0.03,84.9,0.9,ito:ITO_00101,Vision process,F\\-Measure
26,1,Scene Text Detection,MSRA-TD500,2019-11,DB-ResNet-50 (736),84.9,100.0,0.8,0.01,84.9,0.91,ito:ITO_00101,Vision process,F\\-Measure
27,1,Scene Text Detection,Total-Text,2017-04,EAST,42.0,48.55,42.0,0.49,86.5,0.45,ito:ITO_00101,Vision process,F\\-Measure
28,1,Scene Text Detection,Total-Text,2017-09,FTSN,81.3,93.99,39.3,0.45,86.5,0.87,ito:ITO_00101,Vision process,F\\-Measure
29,1,Scene Text Detection,Total-Text,2018-11,SPCNET,82.9,95.84,1.6,0.02,86.5,0.89,ito:ITO_00101,Vision process,F\\-Measure
30,1,Scene Text Detection,Total-Text,2019-04,TextCohesion,84.6,97.8,1.7,0.02,86.5,0.91,ito:ITO_00101,Vision process,F\\-Measure
31,1,Scene Text Detection,Total-Text,2019-08,PAN-640,85.0,98.27,0.4,0.0,86.5,0.91,ito:ITO_00101,Vision process,F\\-Measure
32,1,Scene Text Detection,Total-Text,2019-10,CharNet H-88 (multi-scale),86.5,100.0,1.5,0.02,86.5,0.93,ito:ITO_00101,Vision process,F\\-Measure
33,1,Scene Text Detection,ICDAR 2017 MLT,2018-01,FOTS,67.25,83.93,67.25,0.84,80.13,0.72,ito:ITO_00101,Vision process,F\\-Measure
34,1,Scene Text Detection,ICDAR 2017 MLT,2018-01,FOTS MS,70.75,88.29,3.5,0.04,80.13,0.76,ito:ITO_00101,Vision process,F\\-Measure
35,1,Scene Text Detection,ICDAR 2017 MLT,2018-02,Corner Localization (multi-scale),72.4,90.35,1.7,0.02,80.13,0.78,ito:ITO_00101,Vision process,F\\-Measure
36,1,Scene Text Detection,ICDAR 2017 MLT,2018-06,PSENet-1s,72.45,90.42,0.0,0.0,80.13,0.78,ito:ITO_00101,Vision process,F\\-Measure
37,1,Scene Text Detection,ICDAR 2017 MLT,2018-11,SPCNET,74.1,92.47,1.6,0.02,80.13,0.79,ito:ITO_00101,Vision process,F\\-Measure
38,1,Scene Text Detection,ICDAR 2017 MLT,2018-11,PAN,74.3,92.72,0.2,0.0,80.13,0.8,ito:ITO_00101,Vision process,F\\-Measure
39,1,Scene Text Detection,ICDAR 2017 MLT,2019-03,PMTD*,80.13,100.0,5.8,0.07,80.13,0.86,ito:ITO_00101,Vision process,F\\-Measure
40,1,Object Skeleton Detection,SK-LARGE,2018-01,Hi-Fi,0.724,98.91,0.724,0.99,0.732,0.01,ito:ITO_00101,Vision process,F\\-Measure
41,1,Object Skeleton Detection,SK-LARGE,2018-11,DeepFlux,0.732,100.0,0.0,0.0,0.732,0.01,ito:ITO_00101,Vision process,F\\-Measure
42,1,Scene Text Detection,SCUT-CTW1500,2018-06,PSENet-1s,81.17,95.49,81.17,0.95,85.0,0.87,ito:ITO_00101,Vision process,F\\-Measure
43,1,Scene Text Detection,SCUT-CTW1500,2018-11,PAN,85.0,100.0,3.8,0.04,85.0,0.91,ito:ITO_00101,Vision process,F\\-Measure
44,1,Scene Text Detection,IC19-ReCTs,2019-06,BDN,93.36,100.0,93.36,1.0,93.36,1.0,ito:ITO_00101,Vision process,F\\-Measure
0,1,Image Retrieval,Flickr30K 1K test,2014-12,"DVSA (R-CNN, AlexNet)",15.2,29.51,15.2,0.3,51.5,0.16,ito:ITO_00101,Vision process,R\\-at\\-1
1,1,Image Retrieval,Flickr30K 1K test,2015-04,mCNN,26.2,50.87,11.0,0.21,51.5,0.28,ito:ITO_00101,Vision process,R\\-at\\-1
2,1,Image Retrieval,Flickr30K 1K test,2015-11,SPE,29.7,57.67,3.5,0.07,51.5,0.31,ito:ITO_00101,Vision process,R\\-at\\-1
3,1,Image Retrieval,Flickr30K 1K test,2016-08,2WayNet (VGG),36.0,69.9,6.3,0.12,51.5,0.38,ito:ITO_00101,Vision process,R\\-at\\-1
4,1,Image Retrieval,Flickr30K 1K test,2016-11,DAN,39.4,76.5,3.4,0.07,51.5,0.42,ito:ITO_00101,Vision process,R\\-at\\-1
5,1,Image Retrieval,Flickr30K 1K test,2017-12,SCO,41.1,79.81,1.7,0.03,51.5,0.43,ito:ITO_00101,Vision process,R\\-at\\-1
6,1,Image Retrieval,Flickr30K 1K test,2018-03,SCAN i-t,44.0,85.44,2.9,0.06,51.5,0.46,ito:ITO_00101,Vision process,R\\-at\\-1
7,1,Image Retrieval,Flickr30K 1K test,2019-09,CAMP,51.5,100.0,7.5,0.15,51.5,0.54,ito:ITO_00101,Vision process,R\\-at\\-1
8,1,Visual Dialog,VisDial v0.9 val,2016-05,HieCoAtt-QI,43.51,78.88,43.51,0.79,55.16,0.46,ito:ITO_00101,Vision process,R\\-at\\-1
9,1,Visual Dialog,VisDial v0.9 val,2017-09,AMEM Seo et al. (2017),48.53,87.98,5.0,0.09,55.16,0.51,ito:ITO_00101,Vision process,R\\-at\\-1
10,1,Visual Dialog,VisDial v0.9 val,2017-11,CoAtt Wu et al. (2018),50.29,91.17,1.8,0.03,55.16,0.53,ito:ITO_00101,Vision process,R\\-at\\-1
11,1,Visual Dialog,VisDial v0.9 val,2018-09,CorefNMN (ResNet-152),50.92,92.31,0.6,0.01,55.16,0.54,ito:ITO_00101,Vision process,R\\-at\\-1
12,1,Visual Dialog,VisDial v0.9 val,2019-02,DAN,53.33,96.68,2.4,0.04,55.16,0.56,ito:ITO_00101,Vision process,R\\-at\\-1
13,1,Visual Dialog,VisDial v0.9 val,2019-02,HACAN,54.76,99.27,1.4,0.03,55.16,0.58,ito:ITO_00101,Vision process,R\\-at\\-1
14,1,Visual Dialog,VisDial v0.9 val,2019-04,9xFGA (VGG),55.16,100.0,0.4,0.01,55.16,0.58,ito:ITO_00101,Vision process,R\\-at\\-1
15,1,Sketch-Based Image Retrieval,Chairs,2016-06,Chairs net +,72.2,84.35,72.2,0.84,85.6,0.76,ito:ITO_00101,Vision process,R\\-at\\-1
16,1,Sketch-Based Image Retrieval,Chairs,2017-09,EdgeMAC + whitening,85.6,100.0,13.4,0.16,85.6,0.9,ito:ITO_00101,Vision process,R\\-at\\-1
17,1,Sketch-Based Image Retrieval,Handbags,2016-06,Chairs net +,26.2,51.17,26.2,0.51,51.2,0.28,ito:ITO_00101,Vision process,R\\-at\\-1
18,1,Sketch-Based Image Retrieval,Handbags,2017-09,EdgeMAC + whitening,51.2,100.0,25.0,0.49,51.2,0.54,ito:ITO_00101,Vision process,R\\-at\\-1
19,1,3D Shape Classification,Pix3D,2016-10,3D-VAE-GAN,0.02,3.77,0.02,0.04,0.53,0.0,ito:ITO_00101,Vision process,R\\-at\\-1
20,1,3D Shape Classification,Pix3D,2017-11,MarrNet,0.42,79.25,0.4,0.75,0.53,0.0,ito:ITO_00101,Vision process,R\\-at\\-1
21,1,3D Shape Classification,Pix3D,2018-04,MarrNet extension (w/o Pose),0.53,100.0,0.1,0.19,0.53,0.01,ito:ITO_00101,Vision process,R\\-at\\-1
22,1,3D Shape Retrieval,Pix3D,2016-10,3D-VAE-GAN,0.02,3.77,0.02,0.04,0.53,0.0,ito:ITO_00101,Vision process,R\\-at\\-1
23,1,3D Shape Retrieval,Pix3D,2017-11,MarrNet,0.42,79.25,0.4,0.75,0.53,0.0,ito:ITO_00101,Vision process,R\\-at\\-1
24,1,3D Shape Retrieval,Pix3D,2018-04,MarrNet extension (w/o Pose),0.53,100.0,0.1,0.19,0.53,0.01,ito:ITO_00101,Vision process,R\\-at\\-1
25,1,Metric Learning,CUB-200-2011,2016-10,PDDM Quadruplet,58.3,80.75,58.3,0.81,72.2,0.61,ito:ITO_00101,Vision process,R\\-at\\-1
26,1,Metric Learning,CUB-200-2011,2016-11,HDC,60.7,84.07,2.4,0.03,72.2,0.64,ito:ITO_00101,Vision process,R\\-at\\-1
27,1,Metric Learning,CUB-200-2011,2017-06,ResNet-50 + Margin,63.6,88.09,2.9,0.04,72.2,0.67,ito:ITO_00101,Vision process,R\\-at\\-1
28,1,Metric Learning,CUB-200-2011,2019-08,ABE + HORDE,66.8,92.52,3.2,0.04,72.2,0.7,ito:ITO_00101,Vision process,R\\-at\\-1
29,1,Metric Learning,CUB-200-2011,2020-03,ResNet-50 + Cross-Entropy,69.2,95.84,2.4,0.03,72.2,0.73,ito:ITO_00101,Vision process,R\\-at\\-1
30,1,Metric Learning,CUB-200-2011,2020-04,ProxyNCA++,72.2,100.0,3.0,0.04,72.2,0.76,ito:ITO_00101,Vision process,R\\-at\\-1
31,1,Image Retrieval,SOP,2016-11,HDC,69.5,82.54,69.5,0.83,84.2,0.73,ito:ITO_00101,Vision process,R\\-at\\-1
32,1,Image Retrieval,SOP,2018-01,A-BIER,74.2,88.12,4.7,0.06,84.2,0.78,ito:ITO_00101,Vision process,R\\-at\\-1
33,1,Image Retrieval,SOP,2018-04,ABE-8,76.3,90.62,2.1,0.02,84.2,0.8,ito:ITO_00101,Vision process,R\\-at\\-1
34,1,Image Retrieval,SOP,2018-11,NormSoftmax2048 (ResNet-50),79.5,94.42,3.2,0.04,84.2,0.84,ito:ITO_00101,Vision process,R\\-at\\-1
35,1,Image Retrieval,SOP,2019-03,CGD (SG/GS),84.2,100.0,4.7,0.06,84.2,0.89,ito:ITO_00101,Vision process,R\\-at\\-1
36,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,44.15,79.34,44.15,0.79,55.65,0.47,ito:ITO_00101,Vision process,R\\-at\\-1
37,1,Visual Dialog,Visual Dialog v1.0 test-std,2018-09,CorefNMN (ResNet-152),47.55,85.44,3.4,0.06,55.65,0.5,ito:ITO_00101,Vision process,R\\-at\\-1
38,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,DAN,49.63,89.18,2.1,0.04,55.65,0.52,ito:ITO_00101,Vision process,R\\-at\\-1
39,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,HACAN,50.88,91.43,1.2,0.02,55.65,0.54,ito:ITO_00101,Vision process,R\\-at\\-1
40,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-04,5xFGA (F-RCNNx101),55.65,100.0,4.8,0.09,55.65,0.59,ito:ITO_00101,Vision process,R\\-at\\-1
41,1,Metric Learning,CARS196,2017-06,ResNet-50 + Margin,79.6,88.35,79.6,0.88,90.1,0.84,ito:ITO_00101,Vision process,R\\-at\\-1
42,1,Metric Learning,CARS196,2018-04,ABE-8-512,85.2,94.56,5.6,0.06,90.1,0.9,ito:ITO_00101,Vision process,R\\-at\\-1
43,1,Metric Learning,CARS196,2019-08,ABE + HORDE,88.0,97.67,2.8,0.03,90.1,0.93,ito:ITO_00101,Vision process,R\\-at\\-1
44,1,Metric Learning,CARS196,2020-03,ResNet-50 + Cross-Entropy,89.3,99.11,1.3,0.01,90.1,0.94,ito:ITO_00101,Vision process,R\\-at\\-1
45,1,Metric Learning,CARS196,2020-04,ProxyNCA++,90.1,100.0,0.8,0.01,90.1,0.95,ito:ITO_00101,Vision process,R\\-at\\-1
46,1,Image Retrieval,CARS196,2017-06,Margin,86.9,91.67,86.9,0.92,94.8,0.92,ito:ITO_00101,Vision process,R\\-at\\-1
47,1,Image Retrieval,CARS196,2018-11,NormSoftmax2048 (ResNet-50),89.3,94.2,2.4,0.03,94.8,0.94,ito:ITO_00101,Vision process,R\\-at\\-1
48,1,Image Retrieval,CARS196,2019-03,CGD (MG/SG),94.8,100.0,5.5,0.06,94.8,1.0,ito:ITO_00101,Vision process,R\\-at\\-1
49,1,Sketch-Based Image Retrieval,Shoes,2017-09,EdgeMAC + whitening,54.8,100.0,54.8,1.0,54.8,0.58,ito:ITO_00101,Vision process,R\\-at\\-1
50,1,Image Retrieval,In-Shop,2018-04,ABE-8,87.3,94.99,87.3,0.95,91.9,0.92,ito:ITO_00101,Vision process,R\\-at\\-1
51,1,Image Retrieval,In-Shop,2018-11,NormSoftmax2048 (ResNet-50),89.4,97.28,2.1,0.02,91.9,0.94,ito:ITO_00101,Vision process,R\\-at\\-1
52,1,Image Retrieval,In-Shop,2019-03,CGD (SG/GS),91.9,100.0,2.5,0.03,91.9,0.97,ito:ITO_00101,Vision process,R\\-at\\-1
53,1,Phrase Grounding,Flickr30k Entities Test,2018-05,BAN (Bottom-Up detector),69.69,97.7,69.69,0.98,71.33,0.74,ito:ITO_00101,Vision process,R\\-at\\-1
54,1,Phrase Grounding,Flickr30k Entities Test,2019-08,VisualBERT,71.33,100.0,1.6,0.02,71.33,0.75,ito:ITO_00101,Vision process,R\\-at\\-1
55,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),47.55,85.44,47.55,0.85,55.65,0.5,ito:ITO_00101,Vision process,R\\-at\\-1
56,1,Visual Dialog,VisDial v1.0 test-std,2019-02,DAN,49.63,89.18,2.1,0.04,55.65,0.52,ito:ITO_00101,Vision process,R\\-at\\-1
57,1,Visual Dialog,VisDial v1.0 test-std,2019-04,5xFGA (F-RCNNx101),55.65,100.0,6.0,0.11,55.65,0.59,ito:ITO_00101,Vision process,R\\-at\\-1
58,1,Image Retrieval,CUB-200-2011,2018-11,NormSoftmax2048 (ResNet-50),65.3,82.45,65.3,0.82,79.2,0.69,ito:ITO_00101,Vision process,R\\-at\\-1
59,1,Image Retrieval,CUB-200-2011,2019-03,CGD (MG/SG),79.2,100.0,13.9,0.18,79.2,0.84,ito:ITO_00101,Vision process,R\\-at\\-1
60,1,Phrase Grounding,Flickr30k Entities Dev,2019-08,VisualBERT,70.4,100.0,70.4,1.0,70.4,0.74,ito:ITO_00101,Vision process,R\\-at\\-1
61,1,Metric Learning,Stanford Online Products,2020-03,ResNet-50 + Cross-Entropy,81.1,99.63,81.1,1.0,81.4,0.86,ito:ITO_00101,Vision process,R\\-at\\-1
62,1,Metric Learning,Stanford Online Products,2020-04,ProxyNCA++,81.4,100.0,0.3,0.0,81.4,0.86,ito:ITO_00101,Vision process,R\\-at\\-1
63,1,Metric Learning,In-Shop,2020-03,ResNet-50 + Cross-Entropy,90.6,99.67,90.6,1.0,90.9,0.96,ito:ITO_00101,Vision process,R\\-at\\-1
64,1,Metric Learning,In-Shop,2020-04,ProxyNCA++,90.9,100.0,0.3,0.0,90.9,0.96,ito:ITO_00101,Vision process,R\\-at\\-1
0,1,Image Retrieval,Flickr30K 1K test,2014-12,"DVSA (R-CNN, AlexNet)",50.5,59.2,50.5,0.59,85.3,0.51,ito:ITO_00101,Vision process,R\\-at\\-10
1,1,Image Retrieval,Flickr30K 1K test,2015-04,mCNN,69.6,81.59,19.1,0.22,85.3,0.7,ito:ITO_00101,Vision process,R\\-at\\-10
2,1,Image Retrieval,Flickr30K 1K test,2015-11,SPE,72.1,84.53,2.5,0.03,85.3,0.73,ito:ITO_00101,Vision process,R\\-at\\-10
3,1,Image Retrieval,Flickr30K 1K test,2016-11,DAN,79.1,92.73,7.0,0.08,85.3,0.8,ito:ITO_00101,Vision process,R\\-at\\-10
4,1,Image Retrieval,Flickr30K 1K test,2017-12,SCO,80.1,93.9,1.0,0.01,85.3,0.81,ito:ITO_00101,Vision process,R\\-at\\-10
5,1,Image Retrieval,Flickr30K 1K test,2018-03,SCAN i-t,82.6,96.83,2.5,0.03,85.3,0.83,ito:ITO_00101,Vision process,R\\-at\\-10
6,1,Image Retrieval,Flickr30K 1K test,2019-09,CAMP,85.3,100.0,2.7,0.03,85.3,0.86,ito:ITO_00101,Vision process,R\\-at\\-10
7,1,Visual Dialog,VisDial v0.9 val,2016-05,HieCoAtt-QI,83.96,90.33,83.96,0.9,92.95,0.85,ito:ITO_00101,Vision process,R\\-at\\-10
8,1,Visual Dialog,VisDial v0.9 val,2017-09,AMEM Seo et al. (2017),87.43,94.06,3.5,0.04,92.95,0.88,ito:ITO_00101,Vision process,R\\-at\\-10
9,1,Visual Dialog,VisDial v0.9 val,2017-11,CoAtt Wu et al. (2018),88.81,95.55,1.4,0.02,92.95,0.9,ito:ITO_00101,Vision process,R\\-at\\-10
10,1,Visual Dialog,VisDial v0.9 val,2019-02,DAN,90.38,97.24,1.6,0.02,92.95,0.91,ito:ITO_00101,Vision process,R\\-at\\-10
11,1,Visual Dialog,VisDial v0.9 val,2019-02,HACAN,90.68,97.56,0.3,0.0,92.95,0.92,ito:ITO_00101,Vision process,R\\-at\\-10
12,1,Visual Dialog,VisDial v0.9 val,2019-04,9xFGA (VGG),92.95,100.0,2.3,0.02,92.95,0.94,ito:ITO_00101,Vision process,R\\-at\\-10
13,1,Sketch-Based Image Retrieval,Handbags,2016-06,Chairs net +,58.3,68.03,58.3,0.68,85.7,0.59,ito:ITO_00101,Vision process,R\\-at\\-10
14,1,Sketch-Based Image Retrieval,Handbags,2016-06,Shoes net +,59.5,69.43,1.2,0.01,85.7,0.6,ito:ITO_00101,Vision process,R\\-at\\-10
15,1,Sketch-Based Image Retrieval,Handbags,2017-09,EdgeMAC + whitening,85.7,100.0,26.2,0.31,85.7,0.87,ito:ITO_00101,Vision process,R\\-at\\-10
16,1,Sketch-Based Image Retrieval,Chairs,2016-06,Chairs net +,99.0,100.0,99.0,1.0,99.0,1.0,ito:ITO_00101,Vision process,R\\-at\\-10
17,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,86.88,92.38,86.88,0.92,94.05,0.88,ito:ITO_00101,Vision process,R\\-at\\-10
18,1,Visual Dialog,Visual Dialog v1.0 test-std,2018-09,CorefNMN (ResNet-152),88.8,94.42,1.9,0.02,94.05,0.9,ito:ITO_00101,Vision process,R\\-at\\-10
19,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,DAN,89.35,95.0,0.5,0.01,94.05,0.9,ito:ITO_00101,Vision process,R\\-at\\-10
20,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,HACAN,89.45,95.11,0.1,0.0,94.05,0.9,ito:ITO_00101,Vision process,R\\-at\\-10
21,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-04,5xFGA (F-RCNNx101),94.05,100.0,4.6,0.05,94.05,0.95,ito:ITO_00101,Vision process,R\\-at\\-10
22,1,Sketch-Based Image Retrieval,Shoes,2017-09,EdgeMAC + whitening,92.2,100.0,92.2,1.0,92.2,0.93,ito:ITO_00101,Vision process,R\\-at\\-10
23,1,Phrase Grounding,Flickr30k Entities Test,2018-05,BAN (Bottom-Up detector),86.35,99.82,86.35,1.0,86.51,0.87,ito:ITO_00101,Vision process,R\\-at\\-10
24,1,Phrase Grounding,Flickr30k Entities Test,2019-08,VisualBERT,86.51,100.0,0.2,0.0,86.51,0.87,ito:ITO_00101,Vision process,R\\-at\\-10
25,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),88.8,94.42,88.8,0.94,94.05,0.9,ito:ITO_00101,Vision process,R\\-at\\-10
26,1,Visual Dialog,VisDial v1.0 test-std,2019-02,DAN,89.35,95.0,0.5,0.01,94.05,0.9,ito:ITO_00101,Vision process,R\\-at\\-10
27,1,Visual Dialog,VisDial v1.0 test-std,2019-04,5xFGA (F-RCNNx101),94.05,100.0,4.7,0.05,94.05,0.95,ito:ITO_00101,Vision process,R\\-at\\-10
28,1,Phrase Grounding,Flickr30k Entities Dev,2019-08,VisualBERT,86.31,100.0,86.31,1.0,86.31,0.87,ito:ITO_00101,Vision process,R\\-at\\-10
0,1,Text-Image Retrieval,COCO,2014-12,DVSA,80.5,80.66,80.5,0.81,99.8,0.81,ito:ITO_00101,Vision process,Recall\\-at\\-10
1,1,Text-Image Retrieval,COCO,2020-04,Oscar,99.8,100.0,19.3,0.19,99.8,1.0,ito:ITO_00101,Vision process,Recall\\-at\\-10
2,1,Image-Based Localization,cvusa,2020-02,Instance Loss,74.58,100.0,74.58,1.0,74.58,0.75,ito:ITO_00101,Vision process,Recall\\-at\\-10
0,1,Real-Time Semantic Segmentation,Cityscapes test,2014-12,DeepLab,4000.0,100.0,4000.0,1.0,4000.0,1.0,ito:ITO_00101,Vision process,Time\\ \\(ms\\)
1,1,Real-Time Semantic Segmentation,CamVid,2014-12,DeepLab,203.0,89.43,203.0,0.89,227.0,0.05,ito:ITO_00101,Vision process,Time\\ \\(ms\\)
2,1,Real-Time Semantic Segmentation,CamVid,2015-11,SegNet,217.0,95.59,14.0,0.06,227.0,0.05,ito:ITO_00101,Vision process,Time\\ \\(ms\\)
3,1,Real-Time Semantic Segmentation,CamVid,2015-11,Dilation10,227.0,100.0,10.0,0.04,227.0,0.06,ito:ITO_00101,Vision process,Time\\ \\(ms\\)
0,1,Semantic Segmentation,Cityscapes test,2014-12,DeepLab,63.1,74.67,63.1,0.75,84.5,0.75,ito:ITO_00101,Vision process,Mean\\ IoU\\ \\(class\\)
1,1,Semantic Segmentation,Cityscapes test,2015-04,Context,71.6,84.73,8.5,0.1,84.5,0.85,ito:ITO_00101,Vision process,Mean\\ IoU\\ \\(class\\)
2,1,Semantic Segmentation,Cityscapes test,2016-05,LRR-4x,71.8,84.97,0.2,0.0,84.5,0.85,ito:ITO_00101,Vision process,Mean\\ IoU\\ \\(class\\)
3,1,Semantic Segmentation,Cityscapes test,2016-11,RefineNet (ResNet-101),73.6,87.1,1.8,0.02,84.5,0.87,ito:ITO_00101,Vision process,Mean\\ IoU\\ \\(class\\)
4,1,Semantic Segmentation,Cityscapes test,2016-11,ResNet-38,78.4,92.78,4.8,0.06,84.5,0.93,ito:ITO_00101,Vision process,Mean\\ IoU\\ \\(class\\)
5,1,Semantic Segmentation,Cityscapes test,2016-12,"PSPNet (ResNet-101, coarse)",81.2,96.09,2.8,0.03,84.5,0.96,ito:ITO_00101,Vision process,Mean\\ IoU\\ \\(class\\)
6,1,Semantic Segmentation,Cityscapes test,2017-06,"DeepLabv3 (ResNet-101, coarse)",81.3,96.21,0.1,0.0,84.5,0.96,ito:ITO_00101,Vision process,Mean\\ IoU\\ \\(class\\)
7,1,Semantic Segmentation,Cityscapes test,2017-12,Mapillary,82.0,97.04,0.7,0.01,84.5,0.97,ito:ITO_00101,Vision process,Mean\\ IoU\\ \\(class\\)
8,1,Semantic Segmentation,Cityscapes test,2018-02,DeepLabv3+ (Xception-JFT),82.1,97.16,0.1,0.0,84.5,0.97,ito:ITO_00101,Vision process,Mean\\ IoU\\ \\(class\\)
9,1,Semantic Segmentation,Cityscapes test,2018-08,SSMA,82.3,97.4,0.2,0.0,84.5,0.97,ito:ITO_00101,Vision process,Mean\\ IoU\\ \\(class\\)
10,1,Semantic Segmentation,Cityscapes test,2018-09,Dense Prediction Cell,82.7,97.87,0.4,0.0,84.5,0.98,ito:ITO_00101,Vision process,Mean\\ IoU\\ \\(class\\)
11,1,Semantic Segmentation,Cityscapes test,2018-12,DeepLabV3Plus + SDCNetAug,83.5,98.82,0.8,0.01,84.5,0.99,ito:ITO_00101,Vision process,Mean\\ IoU\\ \\(class\\)
12,1,Semantic Segmentation,Cityscapes test,2019-09,HRNetV2 + OCR +,84.5,100.0,1.0,0.01,84.5,1.0,ito:ITO_00101,Vision process,Mean\\ IoU\\ \\(class\\)
13,1,Semantic Segmentation,KITTI Semantic Segmentation,2018-12,DeepLabV3Plus + SDCNetAug,72.8,100.0,72.8,1.0,72.8,0.86,ito:ITO_00101,Vision process,Mean\\ IoU\\ \\(class\\)
0,1,Real-Time Semantic Segmentation,CamVid,2014-12,DeepLab,4.9,3.94,4.9,0.04,124.5,0.03,ito:ITO_00101,Vision process,Frame\\ \\(fps\\)
1,1,Real-Time Semantic Segmentation,CamVid,2016-12,PSPNet,5.4,4.34,0.5,0.0,124.5,0.03,ito:ITO_00101,Vision process,Frame\\ \\(fps\\)
2,1,Real-Time Semantic Segmentation,CamVid,2017-04,ICNet,27.8,22.33,22.4,0.18,124.5,0.17,ito:ITO_00101,Vision process,Frame\\ \\(fps\\)
3,1,Real-Time Semantic Segmentation,CamVid,2020-04,BiSeNet V2-Large(Cityscapes-Pretrained),32.7,26.27,4.9,0.04,124.5,0.2,ito:ITO_00101,Vision process,Frame\\ \\(fps\\)
4,1,Real-Time Semantic Segmentation,CamVid,2020-04,BiSeNet V2,124.5,100.0,91.8,0.74,124.5,0.76,ito:ITO_00101,Vision process,Frame\\ \\(fps\\)
5,1,Real-Time Semantic Segmentation,Cityscapes test,2014-12,DeepLab,0.25,0.15,0.25,0.0,163.9,0.0,ito:ITO_00101,Vision process,Frame\\ \\(fps\\)
6,1,Real-Time Semantic Segmentation,Cityscapes test,2015-02,CRF-RNN,1.4,0.85,1.2,0.01,163.9,0.01,ito:ITO_00101,Vision process,Frame\\ \\(fps\\)
7,1,Real-Time Semantic Segmentation,Cityscapes test,2015-11,SegNet,16.7,10.19,15.3,0.09,163.9,0.1,ito:ITO_00101,Vision process,Frame\\ \\(fps\\)
8,1,Real-Time Semantic Segmentation,Cityscapes test,2016-06,ENet,76.9,46.92,60.2,0.37,163.9,0.47,ito:ITO_00101,Vision process,Frame\\ \\(fps\\)
9,1,Real-Time Semantic Segmentation,Cityscapes test,2018-08,BiSeNet(Xception39),105.8,64.55,28.9,0.18,163.9,0.65,ito:ITO_00101,Vision process,Frame\\ \\(fps\\)
10,1,Real-Time Semantic Segmentation,Cityscapes test,2020-01,FasterSeg,163.9,100.0,58.1,0.35,163.9,1.0,ito:ITO_00101,Vision process,Frame\\ \\(fps\\)
11,1,Real-time Instance Segmentation,MSCOCO,2019-04,YOLACT,45.5,91.0,45.5,0.91,50.0,0.28,ito:ITO_00101,Vision process,Frame\\ \\(fps\\)
12,1,Real-time Instance Segmentation,MSCOCO,2019-11,CenterMask + MobileNetV2,50.0,100.0,4.5,0.09,50.0,0.31,ito:ITO_00101,Vision process,Frame\\ \\(fps\\)
0,1,Image Super-Resolution,Set5,2014-12,SRCNN,30.49,89.99,30.49,0.9,33.88,0.76,ito:ITO_00101,Vision process,PSNR
1,1,Image Super-Resolution,Set5,2015-08,TNRD,30.85,91.06,0.4,0.01,33.88,0.76,ito:ITO_00101,Vision process,PSNR
2,1,Image Super-Resolution,Set5,2015-11,IA,31.1,91.79,0.2,0.01,33.88,0.77,ito:ITO_00101,Vision process,PSNR
3,1,Image Super-Resolution,Set5,2015-11,DRCN,31.52,93.03,0.4,0.01,33.88,0.78,ito:ITO_00101,Vision process,PSNR
4,1,Image Super-Resolution,Set5,2016-09,SRResNet,32.05,94.6,0.5,0.01,33.88,0.79,ito:ITO_00101,Vision process,PSNR
5,1,Image Super-Resolution,Set5,2016-11,Manifold Simplification,32.23,95.13,0.2,0.01,33.88,0.8,ito:ITO_00101,Vision process,PSNR
6,1,Image Super-Resolution,Set5,2017-07,EDSR,32.46,95.81,0.2,0.01,33.88,0.8,ito:ITO_00101,Vision process,PSNR
7,1,Image Super-Resolution,Set5,2018-02,RDN,32.47,95.84,0.0,0.0,33.88,0.8,ito:ITO_00101,Vision process,PSNR
8,1,Image Super-Resolution,Set5,2018-07,RCAN,32.63,96.31,0.2,0.01,33.88,0.81,ito:ITO_00101,Vision process,PSNR
9,1,Image Super-Resolution,Set5,2018-09,SRGAN + Residual-in-Residual Dense Block,32.73,96.61,0.1,0.0,33.88,0.81,ito:ITO_00101,Vision process,PSNR
10,1,Image Super-Resolution,Set5,2018-11,PFF,32.74,96.64,0.0,0.0,33.88,0.81,ito:ITO_00101,Vision process,PSNR
11,1,Image Super-Resolution,Set5,2019-07,CAR,33.88,100.0,1.1,0.03,33.88,0.84,ito:ITO_00101,Vision process,PSNR
12,1,Video Super-Resolution,Vid4,2014-12,SRCNN,24.68,90.24,24.68,0.9,27.35,0.61,ito:ITO_00101,Vision process,PSNR
13,1,Video Super-Resolution,Vid4,2016-09,ESPCN,25.06,91.63,0.4,0.01,27.35,0.62,ito:ITO_00101,Vision process,PSNR
14,1,Video Super-Resolution,Vid4,2016-11,VESPCN,25.35,92.69,0.3,0.01,27.35,0.63,ito:ITO_00101,Vision process,PSNR
15,1,Video Super-Resolution,Vid4,2017-04,DRDVSR,25.88,94.63,0.5,0.02,27.35,0.64,ito:ITO_00101,Vision process,PSNR
16,1,Video Super-Resolution,Vid4,2018-01,FRVSR,26.69,97.59,0.8,0.03,27.35,0.66,ito:ITO_00101,Vision process,PSNR
17,1,Video Super-Resolution,Vid4,2018-06,VSR-DUF,27.31,99.85,0.6,0.02,27.35,0.68,ito:ITO_00101,Vision process,PSNR
18,1,Video Super-Resolution,Vid4,2019-05,EDVR,27.35,100.0,0.0,0.0,27.35,0.68,ito:ITO_00101,Vision process,PSNR
19,1,Image Super-Resolution,BSD100,2014-12,SRCNN,26.9,92.28,26.9,0.92,29.15,0.67,ito:ITO_00101,Vision process,PSNR
20,1,Image Super-Resolution,BSD100,2015-11,IA,27.16,93.17,0.3,0.01,29.15,0.67,ito:ITO_00101,Vision process,PSNR
21,1,Image Super-Resolution,BSD100,2015-11,DRCN,27.21,93.34,0.1,0.0,29.15,0.67,ito:ITO_00101,Vision process,PSNR
22,1,Image Super-Resolution,BSD100,2016-03,RED30,27.4,94.0,0.2,0.01,29.15,0.68,ito:ITO_00101,Vision process,PSNR
23,1,Image Super-Resolution,BSD100,2016-09,SRResNet,27.58,94.61,0.2,0.01,29.15,0.68,ito:ITO_00101,Vision process,PSNR
24,1,Image Super-Resolution,BSD100,2016-11,Manifold Simplification,27.66,94.89,0.1,0.0,29.15,0.69,ito:ITO_00101,Vision process,PSNR
25,1,Image Super-Resolution,BSD100,2017-07,EDSR,27.71,95.06,0.1,0.0,29.15,0.69,ito:ITO_00101,Vision process,PSNR
26,1,Image Super-Resolution,BSD100,2018-02,RDN,27.72,95.09,0.0,0.0,29.15,0.69,ito:ITO_00101,Vision process,PSNR
27,1,Image Super-Resolution,BSD100,2018-04,ProSR,27.79,95.33,0.1,0.0,29.15,0.69,ito:ITO_00101,Vision process,PSNR
28,1,Image Super-Resolution,BSD100,2018-09,SRGAN + Residual-in-Residual Dense Block,27.85,95.54,0.1,0.0,29.15,0.69,ito:ITO_00101,Vision process,PSNR
29,1,Image Super-Resolution,BSD100,2019-06,SAN,27.86,95.57,0.0,0.0,29.15,0.69,ito:ITO_00101,Vision process,PSNR
30,1,Image Super-Resolution,BSD100,2019-06,DRLN+,27.87,95.61,0.0,0.0,29.15,0.69,ito:ITO_00101,Vision process,PSNR
31,1,Image Super-Resolution,BSD100,2019-07,CAR,29.15,100.0,1.3,0.04,29.15,0.72,ito:ITO_00101,Vision process,PSNR
32,1,Image Super-Resolution,FFHQ 1024 x 1024,2014-12,SRCNN,27.4,80.35,27.4,0.8,34.1,0.68,ito:ITO_00101,Vision process,PSNR
33,1,Image Super-Resolution,FFHQ 1024 x 1024,2016-12,EnhanceNet,29.42,86.28,2.0,0.06,34.1,0.73,ito:ITO_00101,Vision process,PSNR
34,1,Image Super-Resolution,FFHQ 1024 x 1024,2019-10,CAGFace,34.1,100.0,4.7,0.14,34.1,0.84,ito:ITO_00101,Vision process,PSNR
35,1,Image Super-Resolution,FFHQ 256 x 256,2014-12,SRCNN,23.12,84.32,23.12,0.84,27.42,0.57,ito:ITO_00101,Vision process,PSNR
36,1,Image Super-Resolution,FFHQ 256 x 256,2016-12,EnhanceNet,23.64,86.21,0.5,0.02,27.42,0.59,ito:ITO_00101,Vision process,PSNR
37,1,Image Super-Resolution,FFHQ 256 x 256,2019-10,CAGFace,27.42,100.0,3.8,0.14,27.42,0.68,ito:ITO_00101,Vision process,PSNR
38,1,Image Super-Resolution,Set14,2014-12,SRCNN,27.5,90.73,27.5,0.91,30.31,0.68,ito:ITO_00101,Vision process,PSNR
39,1,Image Super-Resolution,Set14,2015-08,TNRD,27.68,91.32,0.2,0.01,30.31,0.69,ito:ITO_00101,Vision process,PSNR
40,1,Image Super-Resolution,Set14,2015-11,IA,27.88,91.98,0.2,0.01,30.31,0.69,ito:ITO_00101,Vision process,PSNR
41,1,Image Super-Resolution,Set14,2015-11,DRCN,28.02,92.44,0.1,0.0,30.31,0.69,ito:ITO_00101,Vision process,PSNR
42,1,Image Super-Resolution,Set14,2016-08,DnCNN-3,28.04,92.51,0.0,0.0,30.31,0.69,ito:ITO_00101,Vision process,PSNR
43,1,Image Super-Resolution,Set14,2016-09,SRResNet,28.49,94.0,0.4,0.01,30.31,0.71,ito:ITO_00101,Vision process,PSNR
44,1,Image Super-Resolution,Set14,2016-11,Manifold Simplification,28.8,95.02,0.3,0.01,30.31,0.71,ito:ITO_00101,Vision process,PSNR
45,1,Image Super-Resolution,Set14,2018-02,RDN,28.81,95.05,0.0,0.0,30.31,0.71,ito:ITO_00101,Vision process,PSNR
46,1,Image Super-Resolution,Set14,2018-03,D-DBPN,28.82,95.08,0.0,0.0,30.31,0.71,ito:ITO_00101,Vision process,PSNR
47,1,Image Super-Resolution,Set14,2018-04,ProSR,28.94,95.48,0.1,0.0,30.31,0.72,ito:ITO_00101,Vision process,PSNR
48,1,Image Super-Resolution,Set14,2018-09,SRGAN + Residual-in-Residual Dense Block,28.99,95.65,0.0,0.0,30.31,0.72,ito:ITO_00101,Vision process,PSNR
49,1,Image Super-Resolution,Set14,2019-04,DBPN-RES-MR64-3,29.03,95.78,0.0,0.0,30.31,0.72,ito:ITO_00101,Vision process,PSNR
50,1,Image Super-Resolution,Set14,2019-06,SAN,29.05,95.84,0.0,0.0,30.31,0.72,ito:ITO_00101,Vision process,PSNR
51,1,Image Super-Resolution,Set14,2019-07,CAR,30.31,100.0,1.3,0.04,30.31,0.75,ito:ITO_00101,Vision process,PSNR
52,1,Image Super-Resolution,Urban100,2014-12,SRCNN,24.52,83.74,24.52,0.84,29.28,0.61,ito:ITO_00101,Vision process,PSNR
53,1,Image Super-Resolution,Urban100,2016-08,DnCNN-3,25.2,86.07,0.7,0.02,29.28,0.62,ito:ITO_00101,Vision process,PSNR
54,1,Image Super-Resolution,Urban100,2016-11,Manifold Simplification,26.42,90.23,1.2,0.04,29.28,0.65,ito:ITO_00101,Vision process,PSNR
55,1,Image Super-Resolution,Urban100,2017-07,EDSR,26.64,90.98,0.2,0.01,29.28,0.66,ito:ITO_00101,Vision process,PSNR
56,1,Image Super-Resolution,Urban100,2018-04,ProSR,26.89,91.84,0.2,0.01,29.28,0.67,ito:ITO_00101,Vision process,PSNR
57,1,Image Super-Resolution,Urban100,2018-09,SRGAN + Residual-in-Residual Dense Block,27.03,92.32,0.1,0.0,29.28,0.67,ito:ITO_00101,Vision process,PSNR
58,1,Image Super-Resolution,Urban100,2019-04,DBPN-RES-MR64-3,27.08,92.49,0.0,0.0,29.28,0.67,ito:ITO_00101,Vision process,PSNR
59,1,Image Super-Resolution,Urban100,2019-06,SAN,27.23,93.0,0.2,0.01,29.28,0.67,ito:ITO_00101,Vision process,PSNR
60,1,Image Super-Resolution,Urban100,2019-06,HBPN,27.3,93.24,0.1,0.0,29.28,0.68,ito:ITO_00101,Vision process,PSNR
61,1,Image Super-Resolution,Urban100,2019-07,CAR,29.28,100.0,2.0,0.07,29.28,0.73,ito:ITO_00101,Vision process,PSNR
62,1,Image Super-Resolution,Manga109,2014-12,SRCNN,27.58,86.76,27.58,0.87,31.79,0.68,ito:ITO_00101,Vision process,PSNR
63,1,Image Super-Resolution,Manga109,2017-07,EDSR,31.02,97.58,3.4,0.11,31.79,0.77,ito:ITO_00101,Vision process,PSNR
64,1,Image Super-Resolution,Manga109,2018-07,RCAN,31.22,98.21,0.2,0.01,31.79,0.77,ito:ITO_00101,Vision process,PSNR
65,1,Image Super-Resolution,Manga109,2018-09,SRGAN + Residual-in-Residual Dense Block,31.66,99.59,0.4,0.01,31.79,0.78,ito:ITO_00101,Vision process,PSNR
66,1,Image Super-Resolution,Manga109,2019-04,DBPN-RES-MR64-3,31.74,99.84,0.1,0.0,31.79,0.79,ito:ITO_00101,Vision process,PSNR
67,1,Image Super-Resolution,Manga109,2019-06,DRLN+,31.78,99.97,0.0,0.0,31.79,0.79,ito:ITO_00101,Vision process,PSNR
68,1,Image Super-Resolution,Manga109,2019-10,ABPN,31.79,100.0,0.0,0.0,31.79,0.79,ito:ITO_00101,Vision process,PSNR
69,1,Denoising,Darmstadt Noise Dataset,2015-08,TNRD,33.65,87.63,33.65,0.88,38.4,0.83,ito:ITO_00101,Vision process,PSNR
70,1,Denoising,Darmstadt Noise Dataset,2017-05,MCWNNM,37.38,97.34,3.7,0.1,38.4,0.93,ito:ITO_00101,Vision process,PSNR
71,1,Denoising,Darmstadt Noise Dataset,2018-07,TWSC,37.93,98.78,0.5,0.01,38.4,0.94,ito:ITO_00101,Vision process,PSNR
72,1,Denoising,Darmstadt Noise Dataset,2019-04,Pixel-shuffling Downsampling,38.4,100.0,0.5,0.01,38.4,0.95,ito:ITO_00101,Vision process,PSNR
73,1,Grayscale Image Denoising,BSD68 sigma25,2015-08,TNRD,28.92,98.33,28.92,0.98,29.41,0.72,ito:ITO_00101,Vision process,PSNR
74,1,Grayscale Image Denoising,BSD68 sigma25,2016-08,DnCNN,29.23,99.39,0.3,0.01,29.41,0.72,ito:ITO_00101,Vision process,PSNR
75,1,Grayscale Image Denoising,BSD68 sigma25,2018-05,MWCNN,29.41,100.0,0.2,0.01,29.41,0.73,ito:ITO_00101,Vision process,PSNR
76,1,Grayscale Image Denoising,BSD68 sigma15,2015-08,TNRD,31.42,98.56,31.42,0.99,31.88,0.78,ito:ITO_00101,Vision process,PSNR
77,1,Grayscale Image Denoising,BSD68 sigma15,2017-04,Deep CNN Denoiser,31.63,99.22,0.2,0.01,31.88,0.78,ito:ITO_00101,Vision process,PSNR
78,1,Grayscale Image Denoising,BSD68 sigma15,2018-05,MWCNN,31.86,99.94,0.2,0.01,31.88,0.79,ito:ITO_00101,Vision process,PSNR
79,1,Grayscale Image Denoising,BSD68 sigma15,2018-06,NLRN,31.88,100.0,0.0,0.0,31.88,0.79,ito:ITO_00101,Vision process,PSNR
80,1,Grayscale Image Denoising,Urban100 sigma15,2015-08,TNRD,31.98,95.61,31.98,0.96,33.45,0.79,ito:ITO_00101,Vision process,PSNR
81,1,Grayscale Image Denoising,Urban100 sigma15,2016-08,DnCNN,32.67,97.67,0.7,0.02,33.45,0.81,ito:ITO_00101,Vision process,PSNR
82,1,Grayscale Image Denoising,Urban100 sigma15,2018-05,MWCNN,33.17,99.16,0.5,0.01,33.45,0.82,ito:ITO_00101,Vision process,PSNR
83,1,Grayscale Image Denoising,Urban100 sigma15,2018-06,NLRN,33.45,100.0,0.3,0.01,33.45,0.83,ito:ITO_00101,Vision process,PSNR
84,1,Image Super-Resolution,Set5,2015-11,VDSR [[Kim et al.2016a]],37.53,96.38,37.53,0.96,38.94,0.93,ito:ITO_00101,Vision process,PSNR
85,1,Image Super-Resolution,Set5,2015-11,DRCN [[Kim et al.2016b]],37.63,96.64,0.1,0.0,38.94,0.93,ito:ITO_00101,Vision process,PSNR
86,1,Image Super-Resolution,Set5,2016-06,RED30,37.66,96.71,0.0,0.0,38.94,0.93,ito:ITO_00101,Vision process,PSNR
87,1,Image Super-Resolution,Set5,2018-03,CARN [[Ahn et al.2018]],37.76,96.97,0.1,0.0,38.94,0.94,ito:ITO_00101,Vision process,PSNR
88,1,Image Super-Resolution,Set5,2018-05,MWCNN,37.91,97.35,0.1,0.0,38.94,0.94,ito:ITO_00101,Vision process,PSNR
89,1,Image Super-Resolution,Set5,2019-03,SRFBN,38.11,97.87,0.2,0.01,38.94,0.94,ito:ITO_00101,Vision process,PSNR
90,1,Image Super-Resolution,Set5,2019-06,HBPN,38.13,97.92,0.0,0.0,38.94,0.94,ito:ITO_00101,Vision process,PSNR
91,1,Image Super-Resolution,Set5,2019-06,DRLN+,38.34,98.46,0.2,0.01,38.94,0.95,ito:ITO_00101,Vision process,PSNR
92,1,Image Super-Resolution,Set5,2019-07,CAR,38.94,100.0,0.6,0.02,38.94,0.96,ito:ITO_00101,Vision process,PSNR
93,1,Image Super-Resolution,VggFace2,2015-11,VDSR,22.5,87.99,22.5,0.88,25.57,0.56,ito:ITO_00101,Vision process,PSNR
94,1,Image Super-Resolution,VggFace2,2016-09,SRGAN,23.01,89.99,0.5,0.02,25.57,0.57,ito:ITO_00101,Vision process,PSNR
95,1,Image Super-Resolution,VggFace2,2018-04,GFRNet,24.1,94.25,1.1,0.04,25.57,0.6,ito:ITO_00101,Vision process,PSNR
96,1,Image Super-Resolution,VggFace2,2019-06,Full-GWAInet,25.57,100.0,1.5,0.06,25.57,0.63,ito:ITO_00101,Vision process,PSNR
97,1,Image Super-Resolution,BSD100,2015-11,DRCN [[Kim et al.2016b]],31.85,94.15,31.85,0.94,33.83,0.79,ito:ITO_00101,Vision process,PSNR
98,1,Image Super-Resolution,BSD100,2016-06,RED30,31.99,94.56,0.1,0.0,33.83,0.79,ito:ITO_00101,Vision process,PSNR
99,1,Image Super-Resolution,BSD100,2018-03,CARN [[Ahn et al.2018]],32.09,94.86,0.1,0.0,33.83,0.8,ito:ITO_00101,Vision process,PSNR
100,1,Image Super-Resolution,BSD100,2018-05,MWCNN,32.23,95.27,0.1,0.0,33.83,0.8,ito:ITO_00101,Vision process,PSNR
101,1,Image Super-Resolution,BSD100,2019-03,SRFBN,32.29,95.45,0.1,0.0,33.83,0.8,ito:ITO_00101,Vision process,PSNR
102,1,Image Super-Resolution,BSD100,2019-06,HBPN,32.33,95.57,0.0,0.0,33.83,0.8,ito:ITO_00101,Vision process,PSNR
103,1,Image Super-Resolution,BSD100,2019-06,DRLN+,32.47,95.98,0.1,0.0,33.83,0.8,ito:ITO_00101,Vision process,PSNR
104,1,Image Super-Resolution,BSD100,2019-07,CAR,33.83,100.0,1.4,0.04,33.83,0.84,ito:ITO_00101,Vision process,PSNR
105,1,Image Super-Resolution,Urban100,2015-11,VDSR [[Kim et al.2016a]],30.76,87.29,30.76,0.87,35.24,0.76,ito:ITO_00101,Vision process,PSNR
106,1,Image Super-Resolution,Urban100,2018-05,MWCNN,32.3,91.66,1.5,0.04,35.24,0.8,ito:ITO_00101,Vision process,PSNR
107,1,Image Super-Resolution,Urban100,2019-03,SRFBN,32.62,92.57,0.3,0.01,35.24,0.81,ito:ITO_00101,Vision process,PSNR
108,1,Image Super-Resolution,Urban100,2019-04,DBPN-RES-MR64-3,32.92,93.42,0.3,0.01,35.24,0.82,ito:ITO_00101,Vision process,PSNR
109,1,Image Super-Resolution,Urban100,2019-06,HBPN,33.12,93.98,0.2,0.01,35.24,0.82,ito:ITO_00101,Vision process,PSNR
110,1,Image Super-Resolution,Urban100,2019-06,DRLN+,33.54,95.18,0.4,0.01,35.24,0.83,ito:ITO_00101,Vision process,PSNR
111,1,Image Super-Resolution,Urban100,2019-07,CAR,35.24,100.0,1.7,0.05,35.24,0.87,ito:ITO_00101,Vision process,PSNR
112,1,Image Super-Resolution,Set14,2015-11,DRCN [[Kim et al.2016b]],33.04,92.78,33.04,0.93,35.61,0.82,ito:ITO_00101,Vision process,PSNR
113,1,Image Super-Resolution,Set14,2018-03,CARN-M [[Ahn et al.2018]],33.26,93.4,0.2,0.01,35.61,0.82,ito:ITO_00101,Vision process,PSNR
114,1,Image Super-Resolution,Set14,2018-03,CARN [[Ahn et al.2018]],33.52,94.13,0.3,0.01,35.61,0.83,ito:ITO_00101,Vision process,PSNR
115,1,Image Super-Resolution,Set14,2018-05,MWCNN,33.7,94.64,0.2,0.01,35.61,0.83,ito:ITO_00101,Vision process,PSNR
116,1,Image Super-Resolution,Set14,2019-03,SRFBN,33.82,94.97,0.1,0.0,35.61,0.84,ito:ITO_00101,Vision process,PSNR
117,1,Image Super-Resolution,Set14,2019-04,DBPN-RES-MR64-3,34.09,95.73,0.3,0.01,35.61,0.84,ito:ITO_00101,Vision process,PSNR
118,1,Image Super-Resolution,Set14,2019-06,DRLN+,34.43,96.69,0.3,0.01,35.61,0.85,ito:ITO_00101,Vision process,PSNR
119,1,Image Super-Resolution,Set14,2019-07,CAR,35.61,100.0,1.2,0.03,35.61,0.88,ito:ITO_00101,Vision process,PSNR
120,1,Image Super-Resolution,WebFace,2015-11,VDSR,23.65,86.92,23.65,0.87,27.21,0.59,ito:ITO_00101,Vision process,PSNR
121,1,Image Super-Resolution,WebFace,2016-09,SRGAN,24.49,90.0,0.8,0.03,27.21,0.61,ito:ITO_00101,Vision process,PSNR
122,1,Image Super-Resolution,WebFace,2018-04,GFRNet,27.21,100.0,2.7,0.1,27.21,0.67,ito:ITO_00101,Vision process,PSNR
123,1,Image Super-Resolution,Set5,2016-06,RED30,33.82,97.02,33.82,0.97,34.86,0.84,ito:ITO_00101,Vision process,PSNR
124,1,Image Super-Resolution,Set5,2018-05,MWCNN,34.17,98.02,0.4,0.01,34.86,0.85,ito:ITO_00101,Vision process,PSNR
125,1,Image Super-Resolution,Set5,2019-03,SRFBN,34.7,99.54,0.5,0.01,34.86,0.86,ito:ITO_00101,Vision process,PSNR
126,1,Image Super-Resolution,Set5,2019-06,DRLN+,34.86,100.0,0.2,0.01,34.86,0.86,ito:ITO_00101,Vision process,PSNR
127,1,Image Super-Resolution,Set14,2016-06,RED30,29.61,96.14,29.61,0.96,30.8,0.73,ito:ITO_00101,Vision process,PSNR
128,1,Image Super-Resolution,Set14,2016-08,DnCNN-3,29.81,96.79,0.2,0.01,30.8,0.74,ito:ITO_00101,Vision process,PSNR
129,1,Image Super-Resolution,Set14,2018-05,MWCNN,30.16,97.92,0.4,0.01,30.8,0.75,ito:ITO_00101,Vision process,PSNR
130,1,Image Super-Resolution,Set14,2019-06,DRLN+,30.8,100.0,0.6,0.02,30.8,0.76,ito:ITO_00101,Vision process,PSNR
131,1,Image Super-Resolution,BSD100,2016-06,RED30,28.93,98.4,28.93,0.98,29.4,0.72,ito:ITO_00101,Vision process,PSNR
132,1,Image Super-Resolution,BSD100,2018-05,MWCNN,29.12,99.05,0.2,0.01,29.4,0.72,ito:ITO_00101,Vision process,PSNR
133,1,Image Super-Resolution,BSD100,2019-03,SRFBN,29.24,99.46,0.1,0.0,29.4,0.72,ito:ITO_00101,Vision process,PSNR
134,1,Image Super-Resolution,BSD100,2019-06,DRLN+,29.4,100.0,0.2,0.01,29.4,0.73,ito:ITO_00101,Vision process,PSNR
135,1,Grayscale Image Denoising,BSD200 sigma70,2016-06,RED30,24.37,78.18,24.37,0.78,31.17,0.6,ito:ITO_00101,Vision process,PSNR
136,1,Grayscale Image Denoising,BSD200 sigma70,2018-06,NLRN-MV,24.62,78.99,0.2,0.01,31.17,0.61,ito:ITO_00101,Vision process,PSNR
137,1,Grayscale Image Denoising,BSD200 sigma70,2019-10,RC-Net,31.17,100.0,6.6,0.21,31.17,0.77,ito:ITO_00101,Vision process,PSNR
138,1,Grayscale Image Denoising,BSD200 sigma50,2016-06,RED30,25.75,79.28,25.75,0.79,32.48,0.64,ito:ITO_00101,Vision process,PSNR
139,1,Grayscale Image Denoising,BSD200 sigma50,2018-06,NLRN-MV,25.97,79.96,0.2,0.01,32.48,0.64,ito:ITO_00101,Vision process,PSNR
140,1,Grayscale Image Denoising,BSD200 sigma50,2019-10,RC-Net,32.48,100.0,6.5,0.2,32.48,0.8,ito:ITO_00101,Vision process,PSNR
141,1,Grayscale Image Denoising,BSD200 sigma30,2016-06,RED30,27.95,83.26,27.95,0.83,33.57,0.69,ito:ITO_00101,Vision process,PSNR
142,1,Grayscale Image Denoising,BSD200 sigma30,2018-06,NLRN-MV,28.2,84.0,0.2,0.01,33.57,0.7,ito:ITO_00101,Vision process,PSNR
143,1,Grayscale Image Denoising,BSD200 sigma30,2019-10,RC-Net,33.57,100.0,5.4,0.16,33.57,0.83,ito:ITO_00101,Vision process,PSNR
144,1,Grayscale Image Denoising,BSD200 sigma10,2016-06,RED30,33.63,92.49,33.63,0.92,36.36,0.83,ito:ITO_00101,Vision process,PSNR
145,1,Grayscale Image Denoising,BSD200 sigma10,2019-10,RC-Net,36.36,100.0,2.7,0.07,36.36,0.9,ito:ITO_00101,Vision process,PSNR
146,1,Image Super-Resolution,Urban100,2016-08,DnCNN-3,27.15,92.44,27.15,0.92,29.37,0.67,ito:ITO_00101,Vision process,PSNR
147,1,Image Super-Resolution,Urban100,2018-05,MWCNN,28.13,95.78,1.0,0.03,29.37,0.7,ito:ITO_00101,Vision process,PSNR
148,1,Image Super-Resolution,Urban100,2019-03,SRFBN,28.73,97.82,0.6,0.02,29.37,0.71,ito:ITO_00101,Vision process,PSNR
149,1,Image Super-Resolution,Urban100,2019-06,DRLN+,29.37,100.0,0.6,0.02,29.37,0.73,ito:ITO_00101,Vision process,PSNR
150,1,Grayscale Image Denoising,Urban100 sigma25,2016-08,DnCNN,29.97,96.86,29.97,0.97,30.94,0.74,ito:ITO_00101,Vision process,PSNR
151,1,Grayscale Image Denoising,Urban100 sigma25,2018-05,MWCNN,30.66,99.1,0.7,0.02,30.94,0.76,ito:ITO_00101,Vision process,PSNR
152,1,Grayscale Image Denoising,Urban100 sigma25,2018-06,NLRN,30.94,100.0,0.3,0.01,30.94,0.77,ito:ITO_00101,Vision process,PSNR
153,1,Color Image Denoising,BSD68 sigma15,2016-08,DnCNN-3,31.46,92.91,31.46,0.93,33.86,0.78,ito:ITO_00101,Vision process,PSNR
154,1,Color Image Denoising,BSD68 sigma15,2017-04,Deep CNN Denoiser,33.86,100.0,2.4,0.07,33.86,0.84,ito:ITO_00101,Vision process,PSNR
155,1,Color Image Denoising,BSD68 sigma25,2016-08,DnCNN-3,29.02,93.13,29.02,0.93,31.16,0.72,ito:ITO_00101,Vision process,PSNR
156,1,Color Image Denoising,BSD68 sigma25,2017-04,Deep CNN Denoiser,31.16,100.0,2.1,0.07,31.16,0.77,ito:ITO_00101,Vision process,PSNR
157,1,Color Image Denoising,CBSD68 sigma35,2016-08,DnCNN-B*,28.74,97.16,28.74,0.97,29.58,0.71,ito:ITO_00101,Vision process,PSNR
158,1,Color Image Denoising,CBSD68 sigma35,2017-10,FFDNet,29.58,100.0,0.8,0.03,29.58,0.73,ito:ITO_00101,Vision process,PSNR
159,1,Image Super-Resolution,FFHQ 512 x 512,2016-09,SRGAN,27.494,91.08,27.494,0.91,30.188,0.68,ito:ITO_00101,Vision process,PSNR
160,1,Image Super-Resolution,FFHQ 512 x 512,2017-07,EDSR,30.188,100.0,2.7,0.09,30.188,0.75,ito:ITO_00101,Vision process,PSNR
161,1,Color Image Denoising,CBSD68 sigma50,2016-11,DnCNN,28.01,98.84,28.01,0.99,28.34,0.69,ito:ITO_00101,Vision process,PSNR
162,1,Color Image Denoising,CBSD68 sigma50,2018-02,Residual Dense Network +,28.34,100.0,0.3,0.01,28.34,0.7,ito:ITO_00101,Vision process,PSNR
163,1,Unsupervised Image-To-Image Translation,Freiburg Forest Dataset,2017-03,UNIT,9.42,43.51,9.42,0.44,21.65,0.23,ito:ITO_00101,Vision process,PSNR
164,1,Unsupervised Image-To-Image Translation,Freiburg Forest Dataset,2017-03,cycGAN,18.57,85.77,9.2,0.42,21.65,0.46,ito:ITO_00101,Vision process,PSNR
165,1,Unsupervised Image-To-Image Translation,Freiburg Forest Dataset,2017-11,In2I,21.65,100.0,3.1,0.14,21.65,0.54,ito:ITO_00101,Vision process,PSNR
166,1,Multimodal Unsupervised Image-To-Image Translation,EPFL NIR-VIS,2017-03,UNIT,15.33,66.33,15.33,0.66,23.11,0.38,ito:ITO_00101,Vision process,PSNR
167,1,Multimodal Unsupervised Image-To-Image Translation,EPFL NIR-VIS,2017-03,cycGAN,17.38,75.21,2.0,0.09,23.11,0.43,ito:ITO_00101,Vision process,PSNR
168,1,Multimodal Unsupervised Image-To-Image Translation,EPFL NIR-VIS,2017-11,In2I,23.11,100.0,5.7,0.25,23.11,0.57,ito:ITO_00101,Vision process,PSNR
169,1,Color Image Denoising,BSD68 sigma35,2017-04,Deep CNN Denoiser,29.5,100.0,29.5,1.0,29.5,0.73,ito:ITO_00101,Vision process,PSNR
170,1,Color Image Denoising,BSD68 sigma5,2017-04,Deep CNN Denoiser,40.36,100.0,40.36,1.0,40.36,1.0,ito:ITO_00101,Vision process,PSNR
171,1,Grayscale Image Denoising,BSD68 sigma50,2017-04,Deep CNN Denoiser,26.19,98.72,26.19,0.99,26.53,0.65,ito:ITO_00101,Vision process,PSNR
172,1,Grayscale Image Denoising,BSD68 sigma50,2017-10,FFDNet,26.29,99.1,0.1,0.0,26.53,0.65,ito:ITO_00101,Vision process,PSNR
173,1,Grayscale Image Denoising,BSD68 sigma50,2018-05,MWCNN,26.53,100.0,0.2,0.01,26.53,0.66,ito:ITO_00101,Vision process,PSNR
174,1,Gesture-to-Gesture Translation,NTU Hand Digit,2017-05,PG2,28.2403,86.47,28.2403,0.86,32.6574,0.7,ito:ITO_00101,Vision process,PSNR
175,1,Gesture-to-Gesture Translation,NTU Hand Digit,2017-12,DPIG,30.6487,93.85,2.4,0.07,32.6574,0.76,ito:ITO_00101,Vision process,PSNR
176,1,Gesture-to-Gesture Translation,NTU Hand Digit,2018-08,GestureGAN,32.6091,99.85,2.0,0.06,32.6574,0.81,ito:ITO_00101,Vision process,PSNR
177,1,Gesture-to-Gesture Translation,NTU Hand Digit,2019-12,UniGAN,32.6574,100.0,0.0,0.0,32.6574,0.81,ito:ITO_00101,Vision process,PSNR
178,1,Gesture-to-Gesture Translation,Senz3D,2017-05,PG2,26.5138,84.06,26.5138,0.84,31.542,0.66,ito:ITO_00101,Vision process,PSNR
179,1,Gesture-to-Gesture Translation,Senz3D,2017-07,SAMG,26.9545,85.46,0.4,0.01,31.542,0.67,ito:ITO_00101,Vision process,PSNR
180,1,Gesture-to-Gesture Translation,Senz3D,2017-12,PoseGAN,27.3014,86.56,0.3,0.01,31.542,0.68,ito:ITO_00101,Vision process,PSNR
181,1,Gesture-to-Gesture Translation,Senz3D,2018-08,GestureGAN,27.9749,88.69,0.7,0.02,31.542,0.69,ito:ITO_00101,Vision process,PSNR
182,1,Gesture-to-Gesture Translation,Senz3D,2019-12,UniGAN,31.542,100.0,3.6,0.11,31.542,0.78,ito:ITO_00101,Vision process,PSNR
183,1,Video Frame Interpolation,Vimeo90k,2017-08,SepConv-L1,33.8,93.63,33.8,0.94,36.1,0.84,ito:ITO_00101,Vision process,PSNR
184,1,Video Frame Interpolation,Vimeo90k,2018-10,MEMC-Net*,34.4,95.29,0.6,0.02,36.1,0.85,ito:ITO_00101,Vision process,PSNR
185,1,Video Frame Interpolation,Vimeo90k,2019-04,DAIN,34.71,96.15,0.3,0.01,36.1,0.86,ito:ITO_00101,Vision process,PSNR
186,1,Video Frame Interpolation,Vimeo90k,2020-03,SoftSplat,36.1,100.0,1.4,0.04,36.1,0.89,ito:ITO_00101,Vision process,PSNR
187,1,Grayscale Image Denoising,Clip300 sigma25,2017-10,FFDNet-Clip,29.25,100.0,29.25,1.0,29.25,0.72,ito:ITO_00101,Vision process,PSNR
188,1,Grayscale Image Denoising,BSD68 sigma35,2017-10,FFDNet,27.73,100.0,27.73,1.0,27.73,0.69,ito:ITO_00101,Vision process,PSNR
189,1,Grayscale Image Denoising,Clip300 sigma50,2017-10,FFDNet-Clip,26.25,100.0,26.25,1.0,26.25,0.65,ito:ITO_00101,Vision process,PSNR
190,1,Grayscale Image Denoising,Clip300 sigma15,2017-10,FFDNet-Clip,31.68,100.0,31.68,1.0,31.68,0.78,ito:ITO_00101,Vision process,PSNR
191,1,Grayscale Image Denoising,Set12 sigma15,2017-10,FFDNet,25.49,76.87,25.49,0.77,33.16,0.63,ito:ITO_00101,Vision process,PSNR
192,1,Grayscale Image Denoising,Set12 sigma15,2018-05,MWCNN,33.15,99.97,7.7,0.23,33.16,0.82,ito:ITO_00101,Vision process,PSNR
193,1,Grayscale Image Denoising,Set12 sigma15,2018-06,NLRN,33.16,100.0,0.0,0.0,33.16,0.82,ito:ITO_00101,Vision process,PSNR
194,1,Grayscale Image Denoising,Clip300 sigma35,2017-10,FFDNet-Clip,27.75,100.0,27.75,1.0,27.75,0.69,ito:ITO_00101,Vision process,PSNR
195,1,Color Image Denoising,McMaster sigma15,2017-10,FFDNet,34.66,100.0,34.66,1.0,34.66,0.86,ito:ITO_00101,Vision process,PSNR
196,1,Color Image Denoising,CBSD68 sigma25,2017-10,FFDNet,31.21,100.0,31.21,1.0,31.21,0.77,ito:ITO_00101,Vision process,PSNR
197,1,Color Image Denoising,Kodak25 sigma25,2017-10,FFDNet,32.13,100.0,32.13,1.0,32.13,0.8,ito:ITO_00101,Vision process,PSNR
198,1,Color Image Denoising,Kodak25 sigma35,2017-10,FFDNet,30.57,100.0,30.57,1.0,30.57,0.76,ito:ITO_00101,Vision process,PSNR
199,1,Color Image Denoising,Kodak25 sigma15,2017-10,FFDNet,34.63,100.0,34.63,1.0,34.63,0.86,ito:ITO_00101,Vision process,PSNR
200,1,Color Image Denoising,Kodak25 sigma50,2017-10,FFDNet,28.98,100.0,28.98,1.0,28.98,0.72,ito:ITO_00101,Vision process,PSNR
201,1,Color Image Denoising,McMaster sigma75,2017-10,FFDNet,27.33,100.0,27.33,1.0,27.33,0.68,ito:ITO_00101,Vision process,PSNR
202,1,Grayscale Image Denoising,BSD68 sigma75,2017-10,FFDNet,24.79,100.0,24.79,1.0,24.79,0.61,ito:ITO_00101,Vision process,PSNR
203,1,Color Image Denoising,McMaster sigma35,2017-10,FFDNet,30.81,100.0,30.81,1.0,30.81,0.76,ito:ITO_00101,Vision process,PSNR
204,1,Color Image Denoising,McMaster sigma25,2017-10,FFDNet,32.35,100.0,32.35,1.0,32.35,0.8,ito:ITO_00101,Vision process,PSNR
205,1,Grayscale Image Denoising,Clip300 sigma60,2017-10,FFDNet-Clip,25.51,100.0,25.51,1.0,25.51,0.63,ito:ITO_00101,Vision process,PSNR
206,1,Color Image Denoising,Kodak25 sigma75,2017-10,FFDNet,27.27,100.0,27.27,1.0,27.27,0.68,ito:ITO_00101,Vision process,PSNR
207,1,Color Image Denoising,McMaster sigma50,2017-10,FFDNet,29.18,100.0,29.18,1.0,29.18,0.72,ito:ITO_00101,Vision process,PSNR
208,1,Color Image Denoising,CBSD68 sigma75,2017-10,FFDNet,26.24,99.58,26.24,1.0,26.35,0.65,ito:ITO_00101,Vision process,PSNR
209,1,Color Image Denoising,CBSD68 sigma75,2019-04,AdaFM-Net,26.35,100.0,0.1,0.0,26.35,0.65,ito:ITO_00101,Vision process,PSNR
210,1,Color Image Denoising,CBSD68 sigma15,2017-10,FFDNet,33.87,99.33,33.87,0.99,34.1,0.84,ito:ITO_00101,Vision process,PSNR
211,1,Color Image Denoising,CBSD68 sigma15,2019-04,AdaFM-Net,34.1,100.0,0.2,0.01,34.1,0.84,ito:ITO_00101,Vision process,PSNR
212,1,Grayscale Image Denoising,Set12 sigma50,2018-05,MWCNN,27.74,100.0,27.74,1.0,27.74,0.69,ito:ITO_00101,Vision process,PSNR
213,1,Grayscale Image Denoising,Set12 sigma25,2018-05,MWCNN,30.79,100.0,30.79,1.0,30.79,0.76,ito:ITO_00101,Vision process,PSNR
214,1,Grayscale Image Denoising,Urban100 sigma50,2018-05,MWCNN,27.42,99.75,27.42,1.0,27.49,0.68,ito:ITO_00101,Vision process,PSNR
215,1,Grayscale Image Denoising,Urban100 sigma50,2018-06,NLRN,27.49,100.0,0.1,0.0,27.49,0.68,ito:ITO_00101,Vision process,PSNR
216,1,Super-Resolution,Set5,2018-07,RCAN,32.63,100.0,32.63,1.0,32.63,0.81,ito:ITO_00101,Vision process,PSNR
217,1,Grayscale Image Denoising,BSD68 sigma70,2018-10,N3Net,25.14,100.0,25.14,1.0,25.14,0.62,ito:ITO_00101,Vision process,PSNR
218,1,Grayscale Image Denoising,Urban100 sigma70,2018-10,N3Net,25.15,100.0,25.15,1.0,25.15,0.62,ito:ITO_00101,Vision process,PSNR
219,1,Grayscale Image Denoising,Set12 sigma70,2018-10,N3Net,25.9,100.0,25.9,1.0,25.9,0.64,ito:ITO_00101,Vision process,PSNR
220,1,Facial Inpainting,VggFace2,2018-12,SymmFCNet (Full),27.81,100.0,27.81,1.0,27.81,0.69,ito:ITO_00101,Vision process,PSNR
221,1,Facial Inpainting,WebFace,2018-12,SymmFCNet (Full),27.22,100.0,27.22,1.0,27.22,0.67,ito:ITO_00101,Vision process,PSNR
222,1,Image Super-Resolution,Manga109,2019-02,LFFN-S,37.93,95.42,37.93,0.95,39.75,0.94,ito:ITO_00101,Vision process,PSNR
223,1,Image Super-Resolution,Manga109,2019-03,SRFBN,39.08,98.31,1.1,0.03,39.75,0.97,ito:ITO_00101,Vision process,PSNR
224,1,Image Super-Resolution,Manga109,2019-04,DBPN-RES-MR64-3,39.28,98.82,0.2,0.01,39.75,0.97,ito:ITO_00101,Vision process,PSNR
225,1,Image Super-Resolution,Manga109,2019-06,HBPN,39.3,98.87,0.0,0.0,39.75,0.97,ito:ITO_00101,Vision process,PSNR
226,1,Image Super-Resolution,Manga109,2019-06,DRLN+,39.75,100.0,0.5,0.01,39.75,0.98,ito:ITO_00101,Vision process,PSNR
227,1,Image Super-Resolution,Manga109,2019-02,LFFN-S,32.8,93.88,32.8,0.94,34.94,0.81,ito:ITO_00101,Vision process,PSNR
228,1,Image Super-Resolution,Manga109,2019-03,SRFBN,34.18,97.82,1.4,0.04,34.94,0.85,ito:ITO_00101,Vision process,PSNR
229,1,Image Super-Resolution,Manga109,2019-06,DRLN+,34.94,100.0,0.8,0.02,34.94,0.87,ito:ITO_00101,Vision process,PSNR
230,1,Image Super-Resolution,Sun80,2019-03,SRNTT-l2,28.54,100.0,28.54,1.0,28.54,0.71,ito:ITO_00101,Vision process,PSNR
231,1,Image Super-Resolution,CUFED5,2019-03,SRNTT-l2,26.24,100.0,26.24,1.0,26.24,0.65,ito:ITO_00101,Vision process,PSNR
232,1,Image Super-Resolution,Middlebury,2019-03,PASSRnet,34.05,100.0,34.05,1.0,34.05,0.84,ito:ITO_00101,Vision process,PSNR
233,1,Image Super-Resolution,KITTI 2012,2019-03,PASSRnet,26.26,100.0,26.26,1.0,26.26,0.65,ito:ITO_00101,Vision process,PSNR
234,1,Image Super-Resolution,KITTI 2012,2019-03,PASSRnet,30.65,100.0,30.65,1.0,30.65,0.76,ito:ITO_00101,Vision process,PSNR
235,1,Image Super-Resolution,KITTI 2015,2019-03,PASSRnet,25.43,100.0,25.43,1.0,25.43,0.63,ito:ITO_00101,Vision process,PSNR
236,1,Image Super-Resolution,KITTI 2015,2019-03,PASSRnet,29.78,100.0,29.78,1.0,29.78,0.74,ito:ITO_00101,Vision process,PSNR
237,1,Image Super-Resolution,Middlebury,2019-03,PASSRnet,28.63,100.0,28.63,1.0,28.63,0.71,ito:ITO_00101,Vision process,PSNR
238,1,Image Super-Resolution,Set5,2019-03,DeepRED,26.04,94.66,26.04,0.95,27.51,0.65,ito:ITO_00101,Vision process,PSNR
239,1,Image Super-Resolution,Set5,2019-04,DBPN-RES-MR64-3,27.51,100.0,1.5,0.05,27.51,0.68,ito:ITO_00101,Vision process,PSNR
240,1,Image Super-Resolution,Set14,2019-03,DeepRED,24.28,95.55,24.28,0.96,25.41,0.6,ito:ITO_00101,Vision process,PSNR
241,1,Image Super-Resolution,Set14,2019-04,DBPN-RES-MR64-3,25.41,100.0,1.1,0.04,25.41,0.63,ito:ITO_00101,Vision process,PSNR
242,1,Video Frame Interpolation,X4K1000FPS,2019-04,DAIN_f,27.52,100.0,27.52,1.0,27.52,0.68,ito:ITO_00101,Vision process,PSNR
243,1,Video Frame Interpolation,UCF101,2019-04,DAIN,34.99,98.87,34.99,0.99,35.39,0.87,ito:ITO_00101,Vision process,PSNR
244,1,Video Frame Interpolation,UCF101,2020-03,SoftSplat,35.39,100.0,0.4,0.01,35.39,0.88,ito:ITO_00101,Vision process,PSNR
245,1,Image Super-Resolution,BSDS100,2019-04,DBPN-RES-MR64-3,32.31,100.0,32.31,1.0,32.31,0.8,ito:ITO_00101,Vision process,PSNR
246,1,Image Super-Resolution,Manga109,2019-04,DBPN-RES-MR64-3,25.71,100.0,25.71,1.0,25.71,0.64,ito:ITO_00101,Vision process,PSNR
247,1,Image Super-Resolution,BSDS100,2019-04,DBPN-RES-MR64-3,27.82,100.0,27.82,1.0,27.82,0.69,ito:ITO_00101,Vision process,PSNR
248,1,Image Super-Resolution,Urban100,2019-04,DBPN-RES-MR64-3,23.2,99.83,23.2,1.0,23.24,0.57,ito:ITO_00101,Vision process,PSNR
249,1,Image Super-Resolution,Urban100,2019-06,DRLN+,23.24,100.0,0.0,0.0,23.24,0.58,ito:ITO_00101,Vision process,PSNR
250,1,Image Super-Resolution,BSDS100,2019-04,DBPN-RES-MR64-3,25.05,100.0,25.05,1.0,25.05,0.62,ito:ITO_00101,Vision process,PSNR
251,1,Video Denoising,DAVIS sigma20,2019-06,DVDnet,35.7,99.55,35.7,1.0,35.86,0.88,ito:ITO_00101,Vision process,PSNR
252,1,Video Denoising,DAVIS sigma20,2019-07,FastDVDnet,35.86,100.0,0.2,0.01,35.86,0.89,ito:ITO_00101,Vision process,PSNR
253,1,Video Denoising,Set8 sigma20,2019-06,DVDnet,33.49,100.0,33.49,1.0,33.49,0.83,ito:ITO_00101,Vision process,PSNR
254,1,Video Denoising,DAVIS sigma10,2019-06,DVDnet,38.13,97.84,38.13,0.98,38.97,0.94,ito:ITO_00101,Vision process,PSNR
255,1,Video Denoising,DAVIS sigma10,2019-07,FastDVDnet,38.97,100.0,0.8,0.02,38.97,0.97,ito:ITO_00101,Vision process,PSNR
256,1,Video Denoising,Set8 sigma30,2019-06,DVDnet,31.79,100.0,31.79,1.0,31.79,0.79,ito:ITO_00101,Vision process,PSNR
257,1,Video Denoising,Set8 sigma40,2019-06,DVDnet,30.55,100.0,30.55,1.0,30.55,0.76,ito:ITO_00101,Vision process,PSNR
258,1,Video Denoising,Set8 sigma50,2019-06,DVDnet,29.56,100.0,29.56,1.0,29.56,0.73,ito:ITO_00101,Vision process,PSNR
259,1,Video Denoising,DAVIS sigma30,2019-06,DVDnet,34.08,100.0,34.08,1.0,34.08,0.84,ito:ITO_00101,Vision process,PSNR
260,1,Video Denoising,Set8 sigma10,2019-06,DVDnet,36.08,99.04,36.08,0.99,36.43,0.89,ito:ITO_00101,Vision process,PSNR
261,1,Video Denoising,Set8 sigma10,2019-07,FastDVDnet,36.43,100.0,0.4,0.01,36.43,0.9,ito:ITO_00101,Vision process,PSNR
262,1,Video Denoising,DAVIS sigma50,2019-06,DVDnet,31.85,100.0,31.85,1.0,31.85,0.79,ito:ITO_00101,Vision process,PSNR
263,1,Video Denoising,DAVIS sigma40,2019-06,DVDnet,32.86,100.0,32.86,1.0,32.86,0.81,ito:ITO_00101,Vision process,PSNR
264,1,Image Super-Resolution,BSD100,2019-06,HBPN,24.93,99.48,24.93,0.99,25.06,0.62,ito:ITO_00101,Vision process,PSNR
265,1,Image Super-Resolution,BSD100,2019-06,DRLN+,25.06,100.0,0.1,0.0,25.06,0.62,ito:ITO_00101,Vision process,PSNR
266,1,Image Super-Resolution,DIV2K val,2019-07,CAR,38.26,100.0,38.26,1.0,38.26,0.95,ito:ITO_00101,Vision process,PSNR
267,1,Image Super-Resolution,DIV2K val,2019-07,CAR,32.82,100.0,32.82,1.0,32.82,0.81,ito:ITO_00101,Vision process,PSNR
268,1,Grayscale Image Denoising,Set12 sigma30,2019-08,Index Network,30.43,100.0,30.43,1.0,30.43,0.75,ito:ITO_00101,Vision process,PSNR
269,1,Face Alignment,CelebA Aligned,2019-08,Progressive Face SR,22.66,100.0,22.66,1.0,22.66,0.56,ito:ITO_00101,Vision process,PSNR
270,1,Image Super-Resolution,Celeb-HQ 4x upscaling,2019-09,Edge-informed SR,28.23,100.0,28.23,1.0,28.23,0.7,ito:ITO_00101,Vision process,PSNR
271,1,Image Super-Resolution,USR-248,2019-09,SRDRM-GAN,24.62,100.0,24.62,1.0,24.62,0.61,ito:ITO_00101,Vision process,PSNR
272,1,Image Super-Resolution,Manga109,2019-10,ABPN,21.25,100.0,21.25,1.0,21.25,0.53,ito:ITO_00101,Vision process,PSNR
273,1,Image Super-Resolution,DIV2K val,2019-10,ABPN,24.38,100.0,24.38,1.0,24.38,0.6,ito:ITO_00101,Vision process,PSNR
274,1,Image Super-Resolution,DIV8K val,2019-10,ABPN,26.71,100.0,26.71,1.0,26.71,0.66,ito:ITO_00101,Vision process,PSNR
275,1,Image Super-Resolution,BSD100,2019-10,ABPN,22.72,100.0,22.72,1.0,22.72,0.56,ito:ITO_00101,Vision process,PSNR
276,1,Image Super-Resolution,Urban100,2019-10,ABPN,20.39,100.0,20.39,1.0,20.39,0.51,ito:ITO_00101,Vision process,PSNR
277,1,Image Dehazing,SOTS Outdoor,2019-11,FFA-Net,33.38,100.0,33.38,1.0,33.38,0.83,ito:ITO_00101,Vision process,PSNR
278,1,Image Dehazing,SOTS Indoor,2019-11,FFA-Net,35.77,100.0,35.77,1.0,35.77,0.89,ito:ITO_00101,Vision process,PSNR
279,1,Image Enhancement,MIT-Adobe 5k,2019-11,"DIFAR (MSCA, level 1)",24.2,100.0,24.2,1.0,24.2,0.6,ito:ITO_00101,Vision process,PSNR
280,1,Cross-View Image-to-Image Translation,cvusa,2019-12,UniGAN,22.8223,100.0,22.8223,1.0,22.8223,0.57,ito:ITO_00101,Vision process,PSNR
281,1,Facial Inpainting,FFHQ,2020-02,DMFN,26.49,100.0,26.49,1.0,26.49,0.66,ito:ITO_00101,Vision process,PSNR
282,1,Video Frame Interpolation,Middlebury,2020-03,SoftSplat,38.42,100.0,38.42,1.0,38.42,0.95,ito:ITO_00101,Vision process,PSNR
0,1,Video Super-Resolution,Xiph HD,2014-12,SRCNN,31.47,99.37,31.47,0.99,31.67,0.83,ito:ITO_00101,Vision process,Average\\ PSNR
1,1,Video Super-Resolution,Xiph HD,2016-09,ESPCN,31.67,100.0,0.2,0.01,31.67,0.84,ito:ITO_00101,Vision process,Average\\ PSNR
2,1,Video Super-Resolution,Ultra Video Group HD,2014-12,SRCNN,37.52,98.97,37.52,0.99,37.91,0.99,ito:ITO_00101,Vision process,Average\\ PSNR
3,1,Video Super-Resolution,Ultra Video Group HD,2016-09,ESPCN,37.91,100.0,0.4,0.01,37.91,1.0,ito:ITO_00101,Vision process,Average\\ PSNR
4,1,Deblurring,REDS,2017-11,DeblurGAN,24.09,69.22,24.09,0.69,34.8,0.64,ito:ITO_00101,Vision process,Average\\ PSNR
5,1,Deblurring,REDS,2019-05,EDVR_Deblur,34.8,100.0,10.7,0.31,34.8,0.92,ito:ITO_00101,Vision process,Average\\ PSNR
6,1,Low-Light Image Enhancement,LOL,2019-05,KinD,20.8665,100.0,20.8665,1.0,20.8665,0.55,ito:ITO_00101,Vision process,Average\\ PSNR
0,1,Image Super-Resolution,FFHQ 1024 x 1024,2014-12,SRCNN,0.801,88.41,0.801,0.88,0.906,0.01,ito:ITO_00101,Vision process,SSIM
1,1,Image Super-Resolution,FFHQ 1024 x 1024,2016-08,FSRCNN,0.804,88.74,0.0,0.0,0.906,0.01,ito:ITO_00101,Vision process,SSIM
2,1,Image Super-Resolution,FFHQ 1024 x 1024,2016-12,EnhanceNet,0.832,91.83,0.0,0.0,0.906,0.01,ito:ITO_00101,Vision process,SSIM
3,1,Image Super-Resolution,FFHQ 1024 x 1024,2019-10,CAGFace,0.906,100.0,0.1,0.11,0.906,0.01,ito:ITO_00101,Vision process,SSIM
4,1,Image Super-Resolution,Manga109,2014-12,SRCNN,0.8555,92.77,0.8555,0.93,0.9222,0.01,ito:ITO_00101,Vision process,SSIM
5,1,Image Super-Resolution,Manga109,2017-07,EDSR,0.9148,99.2,0.1,0.11,0.9222,0.01,ito:ITO_00101,Vision process,SSIM
6,1,Image Super-Resolution,Manga109,2018-02,RDN,0.9151,99.23,0.0,0.0,0.9222,0.01,ito:ITO_00101,Vision process,SSIM
7,1,Image Super-Resolution,Manga109,2018-07,RCAN,0.9173,99.47,0.0,0.0,0.9222,0.01,ito:ITO_00101,Vision process,SSIM
8,1,Image Super-Resolution,Manga109,2018-09,SRGAN + Residual-in-Residual Dense Block,0.9196,99.72,0.0,0.0,0.9222,0.01,ito:ITO_00101,Vision process,SSIM
9,1,Image Super-Resolution,Manga109,2019-04,DBPN-RES-MR64-3,0.921,99.87,0.0,0.0,0.9222,0.01,ito:ITO_00101,Vision process,SSIM
10,1,Image Super-Resolution,Manga109,2019-06,SAN,0.9222,100.0,0.0,0.0,0.9222,0.01,ito:ITO_00101,Vision process,SSIM
11,1,Image Super-Resolution,BSD100,2014-12,SRCNN,0.7101,83.44,0.7101,0.83,0.851,0.01,ito:ITO_00101,Vision process,SSIM
12,1,Image Super-Resolution,BSD100,2015-11,DRCN,0.7493,88.05,0.0,0.0,0.851,0.01,ito:ITO_00101,Vision process,SSIM
13,1,Image Super-Resolution,BSD100,2016-09,SRResNet,0.762,89.54,0.0,0.0,0.851,0.01,ito:ITO_00101,Vision process,SSIM
14,1,Image Super-Resolution,BSD100,2019-04,IKC,0.8014,94.17,0.0,0.0,0.851,0.01,ito:ITO_00101,Vision process,SSIM
15,1,Image Super-Resolution,BSD100,2019-09,Edge-informed SR,0.851,100.0,0.0,0.0,0.851,0.01,ito:ITO_00101,Vision process,SSIM
16,1,Image Super-Resolution,Urban100,2014-12,SRCNN,0.7221,82.9,0.7221,0.83,0.8711,0.01,ito:ITO_00101,Vision process,SSIM
17,1,Image Super-Resolution,Urban100,2016-08,DnCNN-3,0.7521,86.34,0.0,0.0,0.8711,0.01,ito:ITO_00101,Vision process,SSIM
18,1,Image Super-Resolution,Urban100,2016-11,Manifold Simplification,0.794,91.15,0.0,0.0,0.8711,0.01,ito:ITO_00101,Vision process,SSIM
19,1,Image Super-Resolution,Urban100,2017-07,EDSR,0.8033,92.22,0.0,0.0,0.8711,0.01,ito:ITO_00101,Vision process,SSIM
20,1,Image Super-Resolution,Urban100,2018-07,RCAN,0.8087,92.84,0.0,0.0,0.8711,0.01,ito:ITO_00101,Vision process,SSIM
21,1,Image Super-Resolution,Urban100,2018-09,SRGAN + Residual-in-Residual Dense Block,0.8153,93.59,0.0,0.0,0.8711,0.01,ito:ITO_00101,Vision process,SSIM
22,1,Image Super-Resolution,Urban100,2019-06,SAN,0.8169,93.78,0.0,0.0,0.8711,0.01,ito:ITO_00101,Vision process,SSIM
23,1,Image Super-Resolution,Urban100,2019-06,HBPN,0.818,93.9,0.0,0.0,0.8711,0.01,ito:ITO_00101,Vision process,SSIM
24,1,Image Super-Resolution,Urban100,2019-07,CAR,0.8711,100.0,0.1,0.11,0.8711,0.01,ito:ITO_00101,Vision process,SSIM
25,1,Image Super-Resolution,FFHQ 256 x 256,2014-12,SRCNN,0.688,84.31,0.688,0.84,0.816,0.01,ito:ITO_00101,Vision process,SSIM
26,1,Image Super-Resolution,FFHQ 256 x 256,2016-08,FSRCNN,0.709,86.89,0.0,0.0,0.816,0.01,ito:ITO_00101,Vision process,SSIM
27,1,Image Super-Resolution,FFHQ 256 x 256,2019-10,CAGFace,0.816,100.0,0.1,0.12,0.816,0.01,ito:ITO_00101,Vision process,SSIM
28,1,Image Super-Resolution,Set5,2014-12,SRCNN,0.8628,89.41,0.8628,0.89,0.965,0.01,ito:ITO_00101,Vision process,SSIM
29,1,Image Super-Resolution,Set5,2015-11,DRCN,0.8938,92.62,0.0,0.0,0.965,0.01,ito:ITO_00101,Vision process,SSIM
30,1,Image Super-Resolution,Set5,2016-09,SRResNet,0.9019,93.46,0.0,0.0,0.965,0.01,ito:ITO_00101,Vision process,SSIM
31,1,Image Super-Resolution,Set5,2018-11,PFF,0.9021,93.48,0.0,0.0,0.965,0.01,ito:ITO_00101,Vision process,SSIM
32,1,Image Super-Resolution,Set5,2019-04,IKC,0.9278,96.15,0.0,0.0,0.965,0.01,ito:ITO_00101,Vision process,SSIM
33,1,Image Super-Resolution,Set5,2019-09,Edge-informed SR,0.965,100.0,0.0,0.0,0.965,0.02,ito:ITO_00101,Vision process,SSIM
34,1,Video Super-Resolution,Vid4,2014-12,SRCNN,0.7158,86.03,0.7158,0.86,0.832,0.01,ito:ITO_00101,Vision process,SSIM
35,1,Video Super-Resolution,Vid4,2016-09,ESPCN,0.7394,88.87,0.0,0.0,0.832,0.01,ito:ITO_00101,Vision process,SSIM
36,1,Video Super-Resolution,Vid4,2016-11,VESPCN,0.7557,90.83,0.0,0.0,0.832,0.01,ito:ITO_00101,Vision process,SSIM
37,1,Video Super-Resolution,Vid4,2017-04,DRDVSR,0.774,93.03,0.0,0.0,0.832,0.01,ito:ITO_00101,Vision process,SSIM
38,1,Video Super-Resolution,Vid4,2018-01,FRVSR,0.822,98.8,0.0,0.0,0.832,0.01,ito:ITO_00101,Vision process,SSIM
39,1,Video Super-Resolution,Vid4,2018-06,VSR-DUF,0.832,100.0,0.0,0.0,0.832,0.01,ito:ITO_00101,Vision process,SSIM
40,1,Image Super-Resolution,Set14,2014-12,SRCNN,0.7513,84.04,0.7513,0.84,0.894,0.01,ito:ITO_00101,Vision process,SSIM
41,1,Image Super-Resolution,Set14,2015-11,DRCN,0.8074,90.31,0.1,0.11,0.894,0.01,ito:ITO_00101,Vision process,SSIM
42,1,Image Super-Resolution,Set14,2016-09,SRResNet,0.8184,91.54,0.0,0.0,0.894,0.01,ito:ITO_00101,Vision process,SSIM
43,1,Image Super-Resolution,Set14,2019-07,CAR,0.8382,93.76,0.0,0.0,0.894,0.01,ito:ITO_00101,Vision process,SSIM
44,1,Image Super-Resolution,Set14,2019-09,Edge-informed SR,0.894,100.0,0.1,0.11,0.894,0.01,ito:ITO_00101,Vision process,SSIM
45,1,Image Super-Resolution,BSD100,2016-06,RED30,0.8974,96.89,0.8974,0.97,0.9262,0.01,ito:ITO_00101,Vision process,SSIM
46,1,Image Super-Resolution,BSD100,2019-04,IKC,0.9097,98.22,0.0,0.0,0.9262,0.01,ito:ITO_00101,Vision process,SSIM
47,1,Image Super-Resolution,BSD100,2019-07,CAR,0.9262,100.0,0.0,0.0,0.9262,0.01,ito:ITO_00101,Vision process,SSIM
48,1,Image Super-Resolution,BSD100,2016-06,RED30,0.7994,94.12,0.7994,0.94,0.8493,0.01,ito:ITO_00101,Vision process,SSIM
49,1,Image Super-Resolution,BSD100,2019-04,IKC,0.8493,100.0,0.0,0.0,0.8493,0.01,ito:ITO_00101,Vision process,SSIM
50,1,Image Super-Resolution,Set5,2016-06,RED30,0.9599,99.39,0.9599,0.99,0.9658,0.02,ito:ITO_00101,Vision process,SSIM
51,1,Image Super-Resolution,Set5,2019-04,DBPN-RES-MR64-3,0.96,99.4,0.0,0.0,0.9658,0.02,ito:ITO_00101,Vision process,SSIM
52,1,Image Super-Resolution,Set5,2019-04,IKC,0.9658,100.0,0.0,0.0,0.9658,0.02,ito:ITO_00101,Vision process,SSIM
53,1,Image Super-Resolution,Set14,2016-06,RED30,0.8341,98.15,0.8341,0.98,0.8498,0.01,ito:ITO_00101,Vision process,SSIM
54,1,Image Super-Resolution,Set14,2019-06,DRLN+,0.8498,100.0,0.0,0.0,0.8498,0.01,ito:ITO_00101,Vision process,SSIM
55,1,Grayscale Image Denoising,BSD200 sigma10,2016-06,RED30,0.9319,100.0,0.9319,1.0,0.9319,0.01,ito:ITO_00101,Vision process,SSIM
56,1,Grayscale Image Denoising,BSD200 sigma70,2016-06,RED30,0.6551,100.0,0.6551,1.0,0.6551,0.01,ito:ITO_00101,Vision process,SSIM
57,1,Grayscale Image Denoising,BSD200 sigma50,2016-06,RED30,0.7167,100.0,0.7167,1.0,0.7167,0.01,ito:ITO_00101,Vision process,SSIM
58,1,Grayscale Image Denoising,BSD200 sigma30,2016-06,RED30,0.8019,100.0,0.8019,1.0,0.8019,0.01,ito:ITO_00101,Vision process,SSIM
59,1,Image Super-Resolution,Set5,2016-06,RED30,0.923,97.98,0.923,0.98,0.942,0.01,ito:ITO_00101,Vision process,SSIM
60,1,Image Super-Resolution,Set5,2019-02,LFFN-S,0.9233,98.01,0.0,0.0,0.942,0.01,ito:ITO_00101,Vision process,SSIM
61,1,Image Super-Resolution,Set5,2019-04,IKC,0.942,100.0,0.0,0.0,0.942,0.01,ito:ITO_00101,Vision process,SSIM
62,1,Image Super-Resolution,Set14,2016-06,RED30,0.9144,97.24,0.9144,0.97,0.9404,0.01,ito:ITO_00101,Vision process,SSIM
63,1,Image Super-Resolution,Set14,2019-04,DBPN-RES-MR64-3,0.921,97.94,0.0,0.0,0.9404,0.01,ito:ITO_00101,Vision process,SSIM
64,1,Image Super-Resolution,Set14,2019-06,DRLN+,0.9247,98.33,0.0,0.0,0.9404,0.01,ito:ITO_00101,Vision process,SSIM
65,1,Image Super-Resolution,Set14,2019-07,CAR,0.9404,100.0,0.0,0.0,0.9404,0.01,ito:ITO_00101,Vision process,SSIM
66,1,Image Super-Resolution,FFHQ 512 x 512,2016-09,SRGAN,0.735,88.88,0.735,0.89,0.827,0.01,ito:ITO_00101,Vision process,SSIM
67,1,Image Super-Resolution,FFHQ 512 x 512,2017-07,EDSR,0.824,99.64,0.1,0.12,0.827,0.01,ito:ITO_00101,Vision process,SSIM
68,1,Image Super-Resolution,FFHQ 512 x 512,2019-03,SRFBN,0.827,100.0,0.0,0.0,0.827,0.01,ito:ITO_00101,Vision process,SSIM
69,1,Cross-View Image-to-Image Translation,Ego2Top,2016-11,Pix2pix,0.2213,36.74,0.2213,0.37,0.6024,0.0,ito:ITO_00101,Vision process,SSIM
70,1,Cross-View Image-to-Image Translation,Ego2Top,2018-03,X-Fork,0.274,45.48,0.1,0.17,0.6024,0.0,ito:ITO_00101,Vision process,SSIM
71,1,Cross-View Image-to-Image Translation,Ego2Top,2019-04,SelectionGAN,0.6024,100.0,0.3,0.5,0.6024,0.01,ito:ITO_00101,Vision process,SSIM
72,1,Cross-View Image-to-Image Translation,cvusa,2016-11,Pix2pix,0.3923,73.11,0.3923,0.73,0.5366,0.01,ito:ITO_00101,Vision process,SSIM
73,1,Cross-View Image-to-Image Translation,cvusa,2016-12,CrossNet,0.4147,77.28,0.0,0.0,0.5366,0.01,ito:ITO_00101,Vision process,SSIM
74,1,Cross-View Image-to-Image Translation,cvusa,2018-03,X-Fork,0.4356,81.18,0.0,0.0,0.5366,0.01,ito:ITO_00101,Vision process,SSIM
75,1,Cross-View Image-to-Image Translation,cvusa,2019-04,SelectionGAN,0.5323,99.2,0.1,0.19,0.5366,0.01,ito:ITO_00101,Vision process,SSIM
76,1,Cross-View Image-to-Image Translation,cvusa,2019-12,UniGAN,0.5366,100.0,0.0,0.0,0.5366,0.01,ito:ITO_00101,Vision process,SSIM
77,1,Pose Transfer,Deep-Fashion,2017-05,PG Squared,0.762,98.58,0.762,0.99,0.773,0.01,ito:ITO_00101,Vision process,SSIM
78,1,Pose Transfer,Deep-Fashion,2019-04,Progressive Pose Attention,0.773,100.0,0.0,0.0,0.773,0.01,ito:ITO_00101,Vision process,SSIM
79,1,Face Sketch Synthesis,CUHK,2017-10,PS2-MAN,61.56,97.28,61.56,0.97,63.28,0.97,ito:ITO_00101,Vision process,SSIM
80,1,Face Sketch Synthesis,CUHK,2018-12,Residual net + Pseudo Sketch Feature Loss + LSGAN,63.28,100.0,1.7,0.03,63.28,1.0,ito:ITO_00101,Vision process,SSIM
81,1,Video Prediction,Human3.6M,2017-12,PredRNN,0.781,98.86,0.781,0.99,0.79,0.01,ito:ITO_00101,Vision process,SSIM
82,1,Video Prediction,Human3.6M,2018-11,MIM,0.79,100.0,0.0,0.0,0.79,0.01,ito:ITO_00101,Vision process,SSIM
83,1,Novel View Synthesis,ShapeNet Chair,2018-10,Multi-view to Novel View,0.895,100.0,0.895,1.0,0.895,0.01,ito:ITO_00101,Vision process,SSIM
84,1,Probabilistic Time Series Forecasting,Probabilistic Time Series Forecasting,2018-10,Multi-view to Novel View,0.895,100.0,0.895,1.0,0.895,0.01,ito:ITO_00101,Vision process,SSIM
85,1,Novel View Synthesis,Synthia Novel View Synthesis,2018-10,Multi-view to Novel View,0.697,100.0,0.697,1.0,0.697,0.01,ito:ITO_00101,Vision process,SSIM
86,1,COVID-19 Tracking,COVID-19 Tracking,2018-10,Multi-view to Novel View,0.697,100.0,0.697,1.0,0.697,0.01,ito:ITO_00101,Vision process,SSIM
87,1,Novel View Synthesis,ShapeNet Car,2018-10,Multi-view to Novel View,0.923,100.0,0.923,1.0,0.923,0.01,ito:ITO_00101,Vision process,SSIM
88,1,Novel View Synthesis,KITTI Novel View Synthesis,2018-10,Multi-view to Novel View,0.626,100.0,0.626,1.0,0.626,0.01,ito:ITO_00101,Vision process,SSIM
89,1,Mutual Gaze,Mutual Gaze,2018-10,Multi-view to Novel View,0.923,100.0,0.923,1.0,0.923,0.01,ito:ITO_00101,Vision process,SSIM
90,1,Face Parsing,Face Parsing,2018-10,Multi-view to Novel View,0.626,100.0,0.626,1.0,0.626,0.01,ito:ITO_00101,Vision process,SSIM
91,1,Grayscale Image Denoising,Urban100 sigma25,2018-10,N3Net,0.892,100.0,0.892,1.0,0.892,0.01,ito:ITO_00101,Vision process,SSIM
92,1,Face Sketch Synthesis,CUFS,2018-12,Residual net + Pseudo Sketch Feature Loss + LSGAN,54.63,100.0,54.63,1.0,54.63,0.86,ito:ITO_00101,Vision process,SSIM
93,1,Face Sketch Synthesis,CUFSF,2018-12,Residual net + Pseudo Sketch Feature Loss + LSGAN,40.85,100.0,40.85,1.0,40.85,0.65,ito:ITO_00101,Vision process,SSIM
94,1,Image Super-Resolution,Manga109,2019-02,LFFN-S,0.9381,98.56,0.9381,0.99,0.9518,0.01,ito:ITO_00101,Vision process,SSIM
95,1,Image Super-Resolution,Manga109,2019-06,DRLN+,0.9518,100.0,0.0,0.0,0.9518,0.02,ito:ITO_00101,Vision process,SSIM
96,1,Image Super-Resolution,Manga109,2019-02,LFFN-S,0.9746,99.53,0.9746,1.0,0.9792,0.02,ito:ITO_00101,Vision process,SSIM
97,1,Image Super-Resolution,Manga109,2019-04,DBPN-RES-MR64-3,0.977,99.78,0.0,0.0,0.9792,0.02,ito:ITO_00101,Vision process,SSIM
98,1,Image Super-Resolution,Manga109,2019-06,HBPN,0.979,99.98,0.0,0.0,0.9792,0.02,ito:ITO_00101,Vision process,SSIM
99,1,Image Super-Resolution,Manga109,2019-06,DRLN+,0.9792,100.0,0.0,0.0,0.9792,0.02,ito:ITO_00101,Vision process,SSIM
100,1,Video Frame Interpolation,UCF101,2019-04,DAIN,0.9683,100.0,0.9683,1.0,0.9683,0.02,ito:ITO_00101,Vision process,SSIM
101,1,Video Frame Interpolation,Vimeo90k,2019-04,DAIN,0.9756,100.0,0.9756,1.0,0.9756,0.02,ito:ITO_00101,Vision process,SSIM
102,1,Video Frame Interpolation,X4K1000FPS,2019-04,DAIN_f,0.821,100.0,0.821,1.0,0.821,0.01,ito:ITO_00101,Vision process,SSIM
103,1,Image Super-Resolution,Set14,2019-04,DBPN-RES-MR64-3,0.657,100.0,0.657,1.0,0.657,0.01,ito:ITO_00101,Vision process,SSIM
104,1,Image Super-Resolution,Set5,2019-04,DBPN-RES-MR64-3,0.793,100.0,0.793,1.0,0.793,0.01,ito:ITO_00101,Vision process,SSIM
105,1,Image Super-Resolution,Manga109,2019-04,DBPN-RES-MR64-3,0.813,100.0,0.813,1.0,0.813,0.01,ito:ITO_00101,Vision process,SSIM
106,1,Image Super-Resolution,BSDS100,2019-04,DBPN-RES-MR64-3,0.901,100.0,0.901,1.0,0.901,0.01,ito:ITO_00101,Vision process,SSIM
107,1,Image Super-Resolution,Urban100,2019-04,DBPN-RES-MR64-3,0.935,97.68,0.935,0.98,0.9572,0.01,ito:ITO_00101,Vision process,SSIM
108,1,Image Super-Resolution,Urban100,2019-06,HBPN,0.938,97.99,0.0,0.0,0.9572,0.01,ito:ITO_00101,Vision process,SSIM
109,1,Image Super-Resolution,Urban100,2019-06,DRLN+,0.9402,98.22,0.0,0.0,0.9572,0.01,ito:ITO_00101,Vision process,SSIM
110,1,Image Super-Resolution,Urban100,2019-07,CAR,0.9572,100.0,0.0,0.0,0.9572,0.02,ito:ITO_00101,Vision process,SSIM
111,1,Image Super-Resolution,BSDS100,2019-04,DBPN-RES-MR64-3,0.607,100.0,0.607,1.0,0.607,0.01,ito:ITO_00101,Vision process,SSIM
112,1,Image Super-Resolution,Urban100,2019-04,DBPN-RES-MR64-3,0.652,99.95,0.652,1.0,0.6523,0.01,ito:ITO_00101,Vision process,SSIM
113,1,Image Super-Resolution,Urban100,2019-06,DRLN+,0.6523,100.0,0.0,0.0,0.6523,0.01,ito:ITO_00101,Vision process,SSIM
114,1,Image Super-Resolution,BSDS100,2019-04,DBPN-RES-MR64-3,0.744,100.0,0.744,1.0,0.744,0.01,ito:ITO_00101,Vision process,SSIM
115,1,Image Super-Resolution,Urban100,2019-04,IKC,0.8165,93.36,0.8165,0.93,0.8746,0.01,ito:ITO_00101,Vision process,SSIM
116,1,Image Super-Resolution,Urban100,2019-06,DRLN+,0.8746,100.0,0.1,0.11,0.8746,0.01,ito:ITO_00101,Vision process,SSIM
117,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,0.311,100.0,0.311,1.0,0.311,0.0,ito:ITO_00101,Vision process,SSIM
118,1,Image Super-Resolution,BSD100,2019-06,HBPN,0.602,99.18,0.602,0.99,0.607,0.01,ito:ITO_00101,Vision process,SSIM
119,1,Image Super-Resolution,BSD100,2019-06,DRLN+,0.607,100.0,0.0,0.0,0.607,0.01,ito:ITO_00101,Vision process,SSIM
120,1,Image Super-Resolution,DIV2K val,2019-07,CAR,0.9599,100.0,0.9599,1.0,0.9599,0.02,ito:ITO_00101,Vision process,SSIM
121,1,Image Super-Resolution,DIV2K val,2019-07,CAR,0.8837,100.0,0.8837,1.0,0.8837,0.01,ito:ITO_00101,Vision process,SSIM
122,1,Face Alignment,CelebA Aligned,2019-08,Progressive Face SR,0.685,100.0,0.685,1.0,0.685,0.01,ito:ITO_00101,Vision process,SSIM
123,1,Image Super-Resolution,Celeb-HQ 4x upscaling,2019-09,Edge-informed SR,0.912,100.0,0.912,1.0,0.912,0.01,ito:ITO_00101,Vision process,SSIM
124,1,Image Super-Resolution,USR-248,2019-09,SRDRM-GAN,0.69,100.0,0.69,1.0,0.69,0.01,ito:ITO_00101,Vision process,SSIM
125,1,Image Super-Resolution,Manga109,2019-10,ABPN,0.673,100.0,0.673,1.0,0.673,0.01,ito:ITO_00101,Vision process,SSIM
126,1,Image Super-Resolution,Urban100,2019-10,ABPN,0.515,100.0,0.515,1.0,0.515,0.01,ito:ITO_00101,Vision process,SSIM
127,1,Image Super-Resolution,DIV2K val,2019-10,ABPN,0.641,100.0,0.641,1.0,0.641,0.01,ito:ITO_00101,Vision process,SSIM
128,1,Image Super-Resolution,DIV8K val,2019-10,ABPN,0.65,100.0,0.65,1.0,0.65,0.01,ito:ITO_00101,Vision process,SSIM
129,1,Image Super-Resolution,BSD100,2019-10,ABPN,0.512,100.0,0.512,1.0,0.512,0.01,ito:ITO_00101,Vision process,SSIM
130,1,Talking Face Generation,LRW,2019-10,LipGAN,0.96,100.0,0.96,1.0,0.96,0.02,ito:ITO_00101,Vision process,SSIM
131,1,Image Dehazing,SOTS Outdoor,2019-11,FFA-Net,0.9804,100.0,0.9804,1.0,0.9804,0.02,ito:ITO_00101,Vision process,SSIM
132,1,Image Dehazing,SOTS Indoor,2019-11,FFA-Net,0.9846,100.0,0.9846,1.0,0.9846,0.02,ito:ITO_00101,Vision process,SSIM
133,1,Image Enhancement,MIT-Adobe 5k,2019-11,"DIFAR (MSCA, level 1)",0.88,100.0,0.88,1.0,0.88,0.01,ito:ITO_00101,Vision process,SSIM
134,1,Facial Inpainting,FFHQ,2020-02,DMFN,0.8985,100.0,0.8985,1.0,0.8985,0.01,ito:ITO_00101,Vision process,SSIM
135,1,Video Frame Interpolation,Middlebury,2020-03,SoftSplat,0.971,100.0,0.971,1.0,0.971,0.02,ito:ITO_00101,Vision process,SSIM
0,1,Image Super-Resolution,FFHQ 256 x 256,2014-12,SRCNN,147.21,88.49,147.21,0.88,166.36,0.36,ito:ITO_00101,Vision process,FID
1,1,Image Super-Resolution,FFHQ 256 x 256,2016-09,SRGAN,156.07,93.81,8.9,0.05,166.36,0.39,ito:ITO_00101,Vision process,FID
2,1,Image Super-Resolution,FFHQ 256 x 256,2018-09,ESRGAN,166.36,100.0,10.3,0.06,166.36,0.41,ito:ITO_00101,Vision process,FID
3,1,Image Super-Resolution,FFHQ 1024 x 1024,2014-12,SRCNN,31.84,43.78,31.84,0.44,72.73,0.08,ito:ITO_00101,Vision process,FID
4,1,Image Super-Resolution,FFHQ 1024 x 1024,2016-09,SRGAN,60.67,83.42,28.8,0.4,72.73,0.15,ito:ITO_00101,Vision process,FID
5,1,Image Super-Resolution,FFHQ 1024 x 1024,2018-09,ESRGAN,72.73,100.0,12.1,0.17,72.73,0.18,ito:ITO_00101,Vision process,FID
6,1,Image Generation,CUB 128 x 128,2016-06,InfoGAN,13.2,37.81,13.2,0.38,34.91,0.03,ito:ITO_00101,Vision process,FID
7,1,Image Generation,CUB 128 x 128,2017-03,LR-GAN,34.91,100.0,21.7,0.62,34.91,0.09,ito:ITO_00101,Vision process,FID
8,1,Image Generation,Stanford Cars,2016-06,InfoGAN,17.63,19.85,17.63,0.2,88.8,0.04,ito:ITO_00101,Vision process,FID
9,1,Image Generation,Stanford Cars,2017-03,LR-GAN,88.8,100.0,71.2,0.8,88.8,0.22,ito:ITO_00101,Vision process,FID
10,1,Image Generation,Stanford Dogs,2016-06,InfoGAN,29.34,53.43,29.34,0.53,54.91,0.07,ito:ITO_00101,Vision process,FID
11,1,Image Generation,Stanford Dogs,2017-03,LR-GAN,54.91,100.0,25.6,0.47,54.91,0.14,ito:ITO_00101,Vision process,FID
12,1,Image Super-Resolution,FFHQ 512 x 512,2016-09,SRGAN,4.396,21.33,4.396,0.21,20.605,0.01,ito:ITO_00101,Vision process,FID
13,1,Image Super-Resolution,FFHQ 512 x 512,2017-07,EDSR,20.605,100.0,16.2,0.79,20.605,0.05,ito:ITO_00101,Vision process,FID
14,1,Text-to-Image Generation,CUB,2016-10,GAWWN,67.22,100.0,67.22,1.0,67.22,0.17,ito:ITO_00101,Vision process,FID
15,1,Image Reconstruction,Edge-to-Handbags,2016-11,pix2pix,96.31,100.0,96.31,1.0,96.31,0.24,ito:ITO_00101,Vision process,FID
16,1,Image Reconstruction,Edge-to-Shoes,2016-11,pix2pix,197.492,100.0,197.492,1.0,197.492,0.49,ito:ITO_00101,Vision process,FID
17,1,Fundus to Angiography Generation,Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients,2016-11,pix2pix,48.6,100.0,48.6,1.0,48.6,0.12,ito:ITO_00101,Vision process,FID
18,1,Image Generation,CIFAR-10,2017-03,WGAN-GP,29.3,56.13,29.3,0.56,52.202,0.07,ito:ITO_00101,Vision process,FID
19,1,Image Generation,CIFAR-10,2019-05,GLF+perceptual loss (ours),44.6,85.44,15.3,0.29,52.202,0.11,ito:ITO_00101,Vision process,FID
20,1,Image Generation,CIFAR-10,2019-06,Residual Flow,46.37,88.83,1.8,0.03,52.202,0.11,ito:ITO_00101,Vision process,FID
21,1,Image Generation,CIFAR-10,2019-10,PresGAN,52.202,100.0,5.8,0.11,52.202,0.13,ito:ITO_00101,Vision process,FID
22,1,Image Generation,CAT 256x256,2017-03,WGAN-GP,155.46,100.0,155.46,1.0,155.46,0.38,ito:ITO_00101,Vision process,FID
23,1,Image Generation,LSUN Bedroom 64 x 64,2017-06,WGAN-GP + TT Update Rule,9.5,83.33,9.5,0.83,11.4,0.02,ito:ITO_00101,Vision process,FID
24,1,Image Generation,LSUN Bedroom 64 x 64,2018-02,FOGAN,11.4,100.0,1.9,0.17,11.4,0.03,ito:ITO_00101,Vision process,FID
25,1,Image Generation,LSUN Bedroom 256 x 256,2017-06,WGAN-GP + TT Update Rule,9.5,26.68,9.5,0.27,35.61,0.02,ito:ITO_00101,Vision process,FID
26,1,Image Generation,LSUN Bedroom 256 x 256,2017-10,StackGAN-v2,35.61,100.0,26.1,0.73,35.61,0.09,ito:ITO_00101,Vision process,FID
27,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2017-07,CRN,104.7,100.0,104.7,1.0,104.7,0.26,ito:ITO_00101,Vision process,FID
28,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2017-07,CRN,70.4,63.14,70.4,0.63,111.5,0.17,ito:ITO_00101,Vision process,FID
29,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2017-11,pix2pixHD,111.5,100.0,41.1,0.37,111.5,0.28,ito:ITO_00101,Vision process,FID
30,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2017-07,CRN,99.0,100.0,99.0,1.0,99.0,0.24,ito:ITO_00101,Vision process,FID
31,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2017-07,CRN,73.3,89.61,73.3,0.9,81.8,0.18,ito:ITO_00101,Vision process,FID
32,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2017-11,pix2pixHD,81.8,100.0,8.5,0.1,81.8,0.2,ito:ITO_00101,Vision process,FID
33,1,Face Hallucination,FFHQ 512 x 512,2017-10,WaveletCNN,60.916,100.0,60.916,1.0,60.916,0.15,ito:ITO_00101,Vision process,FID
34,1,Text-to-Image Generation,Oxford 102 Flowers,2017-10,StackGAN-v2,48.68,88.06,48.68,0.88,55.28,0.12,ito:ITO_00101,Vision process,FID
35,1,Text-to-Image Generation,Oxford 102 Flowers,2017-10,StackGAN-v1 ,55.28,100.0,6.6,0.12,55.28,0.14,ito:ITO_00101,Vision process,FID
36,1,Text-to-Image Generation,COCO,2017-10,StackGAN-v1 ,74.05,90.76,74.05,0.91,81.59,0.18,ito:ITO_00101,Vision process,FID
37,1,Text-to-Image Generation,COCO,2017-10,StackGAN-v2,81.59,100.0,7.5,0.09,81.59,0.2,ito:ITO_00101,Vision process,FID
38,1,Image Generation,FFHQ,2017-10,PGGAN,8.04,100.0,8.04,1.0,8.04,0.02,ito:ITO_00101,Vision process,FID
39,1,Image Generation,LSUN Cat 256 x 256,2017-10,PGGAN,37.52,100.0,37.52,1.0,37.52,0.09,ito:ITO_00101,Vision process,FID
40,1,Image Generation,CelebA-HQ 1024x1024,2017-10,PGGAN,7.3,76.92,7.3,0.77,9.49,0.02,ito:ITO_00101,Vision process,FID
41,1,Image Generation,CelebA-HQ 1024x1024,2019-03,COCO-GAN,9.49,100.0,2.2,0.23,9.49,0.02,ito:ITO_00101,Vision process,FID
42,1,Image Generation,LSUN Churches 256 x 256,2017-10,PGGAN,6.42,100.0,6.42,1.0,6.42,0.02,ito:ITO_00101,Vision process,FID
43,1,Image Generation,CelebA-HQ 256x256,2017-10,PGGAN,8.03,11.65,8.03,0.12,68.93,0.02,ito:ITO_00101,Vision process,FID
44,1,Image Generation,CelebA-HQ 256x256,2018-07,GLOW,68.93,100.0,60.9,0.88,68.93,0.17,ito:ITO_00101,Vision process,FID
45,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2017-11,AttnGAN,125.98,96.13,125.98,0.96,131.05,0.31,ito:ITO_00101,Vision process,FID
46,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2019-04,DM-GAN,131.05,100.0,5.1,0.04,131.05,0.32,ito:ITO_00101,Vision process,FID
47,1,Conditional Image Generation,ImageNet 128x128,2018-02,Projection Discriminator,27.62,100.0,27.62,1.0,27.62,0.07,ito:ITO_00101,Vision process,FID
48,1,Conditional Image Generation,CIFAR-10,2018-02,Projection Discriminator,17.5,100.0,17.5,1.0,17.5,0.04,ito:ITO_00101,Vision process,FID
49,1,Image Generation,STL-10,2018-02,SN-GAN,40.1,85.79,40.1,0.86,46.74,0.1,ito:ITO_00101,Vision process,FID
50,1,Image Generation,STL-10,2019-05,ProbGAN,46.74,100.0,6.6,0.14,46.74,0.12,ito:ITO_00101,Vision process,FID
51,1,Layout-to-Image Generation,COCO-Stuff 64x64,2018-04,SG2Im,67.96,100.0,67.96,1.0,67.96,0.17,ito:ITO_00101,Vision process,FID
52,1,Layout-to-Image Generation,Visual Genome 64x64,2018-04,SG2Im,74.61,100.0,74.61,1.0,74.61,0.18,ito:ITO_00101,Vision process,FID
53,1,Multimodal Unsupervised Image-To-Image Translation,CelebA-HQ,2018-04,MUNIT,31.4,60.27,31.4,0.6,52.1,0.08,ito:ITO_00101,Vision process,FID
54,1,Multimodal Unsupervised Image-To-Image Translation,CelebA-HQ,2018-08,DRIT,52.1,100.0,20.7,0.4,52.1,0.13,ito:ITO_00101,Vision process,FID
55,1,Multimodal Unsupervised Image-To-Image Translation,AFHQ,2018-04,MUNIT,41.5,43.41,41.5,0.43,95.6,0.1,ito:ITO_00101,Vision process,FID
56,1,Multimodal Unsupervised Image-To-Image Translation,AFHQ,2018-08,DRIT,95.6,100.0,54.1,0.57,95.6,0.24,ito:ITO_00101,Vision process,FID
57,1,Image Generation,ImageNet 256x256,2018-09,BigGAN-deep,8.1,100.0,8.1,1.0,8.1,0.02,ito:ITO_00101,Vision process,FID
58,1,Image Generation,ImageNet 128x128,2018-09,BigGAN,14.88,33.92,14.88,0.34,43.87,0.04,ito:ITO_00101,Vision process,FID
59,1,Image Generation,ImageNet 128x128,2018-11,SS-GAN (sBN),43.87,100.0,29.0,0.66,43.87,0.11,ito:ITO_00101,Vision process,FID
60,1,Image Generation,CelebA-HQ 128x128,2018-11,SS-GAN (sBN),24.36,100.0,24.36,1.0,24.36,0.06,ito:ITO_00101,Vision process,FID
61,1,Image Generation,Oxford 102 Flowers 256 x 256,2019-03,MSG-StyleGAN,19.6,100.0,19.6,1.0,19.6,0.05,ito:ITO_00101,Vision process,FID
62,1,Image Generation,Indian Celebs 256 x 256,2019-03,MSG-StyleGAN,28.44,100.0,28.44,1.0,28.44,0.07,ito:ITO_00101,Vision process,FID
63,1,Image Generation,CelebA-HQ 64x64,2019-03,COCO-GAN,4.0,100.0,4,1.0,4,0.01,ito:ITO_00101,Vision process,FID
64,1,Video Generation,TrailerFaces,2019-04,PG-SWGAN-3D,404.1,100.0,404.1,1.0,404.1,1.0,ito:ITO_00101,Vision process,FID
65,1,Talking Head Generation,VoxCeleb2,2019-05,Few-shot Adversarial Model,30.6,100.0,30.6,1.0,30.6,0.08,ito:ITO_00101,Vision process,FID
66,1,Talking Head Generation,VoxCeleb1,2019-05,Few-shot Adversarial Model,38.0,100.0,38,1.0,38,0.09,ito:ITO_00101,Vision process,FID
67,1,Talking Head Generation,VoxCeleb1,2019-05,Few-shot Adversarial Model,43.0,100.0,43,1.0,43,0.11,ito:ITO_00101,Vision process,FID
68,1,Talking Head Generation,VoxCeleb1,2019-05,Few-shot Adversarial Model,29.5,100.0,29.5,1.0,29.5,0.07,ito:ITO_00101,Vision process,FID
69,1,Talking Head Generation,VoxCeleb2,2019-05,Few-shot Adversarial Model,42.2,100.0,42.2,1.0,42.2,0.1,ito:ITO_00101,Vision process,FID
70,1,Talking Head Generation,VoxCeleb2,2019-05,Few-shot Adversarial Model,48.5,100.0,48.5,1.0,48.5,0.12,ito:ITO_00101,Vision process,FID
71,1,Image Generation,MNIST,2019-05,GLF+perceptual loss (ours),5.8,13.8,5.8,0.14,42.019,0.01,ito:ITO_00101,Vision process,FID
72,1,Image Generation,MNIST,2019-10,PresGAN,42.019,100.0,36.2,0.86,42.019,0.1,ito:ITO_00101,Vision process,FID
73,1,Image Generation,Fashion-MNIST,2019-05,GLF+perceptual loss (ours),10.3,100.0,10.3,1.0,10.3,0.03,ito:ITO_00101,Vision process,FID
74,1,Image Generation,CelebA 256x256,2019-05,GLF+perceptual loss (ours),41.8,100.0,41.8,1.0,41.8,0.1,ito:ITO_00101,Vision process,FID
75,1,Image Generation,ImageNet 64x64,2019-07,BigBiGAN,15.82,100.0,15.82,1.0,15.82,0.04,ito:ITO_00101,Vision process,FID
76,1,Video Generation,"Kinetics-600 12 frames, 64x64",2019-07,DVD-GAN,0.91,100.0,0.91,1.0,0.91,0.0,ito:ITO_00101,Vision process,FID
77,1,Video Generation,"Kinetics-600 48 frames, 64x64",2019-07,DVD-GAN,12.92,100.0,12.92,1.0,12.92,0.03,ito:ITO_00101,Vision process,FID
78,1,Video Generation,"Kinetics-600 12 frames, 128x128",2019-07,DVD-GAN,2.16,100.0,2.16,1.0,2.16,0.01,ito:ITO_00101,Vision process,FID
79,1,Layout-to-Image Generation,COCO-Stuff 128x128,2019-08,LostGAN,29.65,49.83,29.65,0.5,59.5,0.07,ito:ITO_00101,Vision process,FID
80,1,Layout-to-Image Generation,COCO-Stuff 128x128,2019-09,SOARISG,59.5,100.0,29.8,0.5,59.5,0.15,ito:ITO_00101,Vision process,FID
81,1,Layout-to-Image Generation,Visual Genome 128x128,2019-08,LostGAN,29.36,100.0,29.36,1.0,29.36,0.07,ito:ITO_00101,Vision process,FID
82,1,Image Generation,Stacked MNIST,2019-10,PresGAN,23.965,100.0,23.965,1.0,23.965,0.06,ito:ITO_00101,Vision process,FID
83,1,Image Generation,CelebA 128 x 128,2019-10,PresGAN,29.115,100.0,29.115,1.0,29.115,0.07,ito:ITO_00101,Vision process,FID
84,1,Image Reconstruction,Edge-to-Clothes,2019-10,bFT,58.4,100.0,58.4,1.0,58.4,0.14,ito:ITO_00101,Vision process,FID
85,1,Pose Transfer,Deep-Fashion,2019-10,bFT,12.266,100.0,12.266,1.0,12.266,0.03,ito:ITO_00101,Vision process,FID
86,1,Video-to-Video Synthesis,Street Scene,2019-10,Few-shot Video-to-Video,144.24,100.0,144.24,1.0,144.24,0.36,ito:ITO_00101,Vision process,FID
87,1,Video-to-Video Synthesis,YouTube Dancing,2019-10,Few-shot Video-to-Video,80.44,100.0,80.44,1.0,80.44,0.2,ito:ITO_00101,Vision process,FID
88,1,Image Generation,ImageNet 32x32,2019-11,MSGAN,12.3,100.0,12.3,1.0,12.3,0.03,ito:ITO_00101,Vision process,FID
89,1,Image Generation,CIFAR-100,2019-11,MSGAN,19.74,100.0,19.74,1.0,19.74,0.05,ito:ITO_00101,Vision process,FID
90,1,Image Generation,Cityscapes-5K 256x512,2019-11,SB-GAN,65.49,100.0,65.49,1.0,65.49,0.16,ito:ITO_00101,Vision process,FID
91,1,Image Generation,Cityscapes-25K 256x512,2019-11,SB-GAN,62.97,100.0,62.97,1.0,62.97,0.16,ito:ITO_00101,Vision process,FID
92,1,Image Generation,ADE-Indoor,2019-11,SB-GAN,85.27,100.0,85.27,1.0,85.27,0.21,ito:ITO_00101,Vision process,FID
93,1,Image-to-Image Translation,ADE-Indoor Labels-to-Photo,2019-11,SB-GAN,48.15,100.0,48.15,1.0,48.15,0.12,ito:ITO_00101,Vision process,FID
94,1,Image Generation,LSUN Car 256 x 256,2019-12,StyleGAN2,2.32,100.0,2.32,1.0,2.32,0.01,ito:ITO_00101,Vision process,FID
95,1,Image Generation,LSUN Car 512 x 384,2019-12,StyleGAN2,2.32,100.0,2.32,1.0,2.32,0.01,ito:ITO_00101,Vision process,FID
96,1,Image Generation,LSUN Horse 256 x 256,2019-12,StyleGAN2,3.43,100.0,3.43,1.0,3.43,0.01,ito:ITO_00101,Vision process,FID
97,1,Image-to-Image Translation,CelebA-HQ,2019-12,StarGAN v2,18.0,100.0,18.0,1.0,18.0,0.04,ito:ITO_00101,Vision process,FID
98,1,Image-to-Image Translation,AFHQ,2019-12,StarGAN v2,24.4,100.0,24.4,1.0,24.4,0.06,ito:ITO_00101,Vision process,FID
99,1,Gesture-to-Gesture Translation,Senz3D,2019-12,UniGAN,12.4465,100.0,12.4465,1.0,12.4465,0.03,ito:ITO_00101,Vision process,FID
100,1,Gesture-to-Gesture Translation,NTU Hand Digit,2019-12,UniGAN,6.7493,100.0,6.7493,1.0,6.7493,0.02,ito:ITO_00101,Vision process,FID
101,1,Image-to-Image Translation,Deep-Fashion,2020-04,CoCosNet,14.4,100.0,14.4,1.0,14.4,0.04,ito:ITO_00101,Vision process,FID
0,1,Video Super-Resolution,Vid4,2014-12,SRCNN,6.9,74.11,6.9,0.74,9.31,0.74,ito:ITO_00101,Vision process,MOVIE
1,1,Video Super-Resolution,Vid4,2016-11,bicubic,9.31,100.0,2.4,0.26,9.31,1.0,ito:ITO_00101,Vision process,MOVIE
0,1,Image Super-Resolution,FFHQ 1024 x 1024,2014-12,SRCNN,0.924,95.16,0.924,0.95,0.971,0.95,ito:ITO_00101,Vision process,MS\\-SSIM
1,1,Image Super-Resolution,FFHQ 1024 x 1024,2016-08,FSRCNN,0.951,97.94,0.0,0.0,0.971,0.98,ito:ITO_00101,Vision process,MS\\-SSIM
2,1,Image Super-Resolution,FFHQ 1024 x 1024,2019-10,CAGFace,0.971,100.0,0.0,0.0,0.971,1.0,ito:ITO_00101,Vision process,MS\\-SSIM
3,1,Image Super-Resolution,FFHQ 256 x 256,2014-12,SRCNN,0.9,93.95,0.9,0.94,0.958,0.93,ito:ITO_00101,Vision process,MS\\-SSIM
4,1,Image Super-Resolution,FFHQ 256 x 256,2016-08,FSRCNN,0.93,97.08,0.0,0.0,0.958,0.96,ito:ITO_00101,Vision process,MS\\-SSIM
5,1,Image Super-Resolution,FFHQ 256 x 256,2019-10,CAGFace,0.958,100.0,0.0,0.0,0.958,0.99,ito:ITO_00101,Vision process,MS\\-SSIM
6,1,Image Super-Resolution,FFHQ 512 x 512,2016-09,SRGAN,0.935,97.29,0.935,0.97,0.961,0.96,ito:ITO_00101,Vision process,MS\\-SSIM
7,1,Image Super-Resolution,FFHQ 512 x 512,2017-07,EDSR,0.961,100.0,0.0,0.0,0.961,0.99,ito:ITO_00101,Vision process,MS\\-SSIM
8,1,Face Alignment,CelebA Aligned,2019-08,Progressive Face SR,0.902,100.0,0.902,1.0,0.902,0.93,ito:ITO_00101,Vision process,MS\\-SSIM
0,1,Face Verification,IJB-C,2015-03,FaceNet,66.5,68.44,66.5,0.68,97.17,0.68,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.01
1,1,Face Verification,IJB-C,2017-10,VGGFace2_ft,96.7,99.52,30.2,0.31,97.17,0.98,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.01
2,1,Face Verification,IJB-C,2019-04,PFEfuse + match,97.17,100.0,0.5,0.01,97.17,0.99,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.01
3,1,Face Verification,IJB-A,2015-07,Deep CNN + COTS matcher,73.3,75.1,73.3,0.75,97.6,0.74,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.01
4,1,Face Verification,IJB-A,2015-08,DCNN,83.8,85.86,10.5,0.11,97.6,0.85,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.01
5,1,Face Verification,IJB-A,2016-03,Template adaptation,93.9,96.21,10.1,0.1,97.6,0.95,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.01
6,1,Face Verification,IJB-A,2016-03,NAN,94.1,96.41,0.2,0.0,97.6,0.96,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.01
7,1,Face Verification,IJB-A,2017-03,L2-constrained softmax loss,97.0,99.39,2.9,0.03,97.6,0.98,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.01
8,1,Face Verification,IJB-A,2017-12,Dual-Agent GANs,97.6,100.0,0.6,0.01,97.6,0.99,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.01
9,1,Face Verification,Oulu-CASIA NIR-VIS,2017-08,W-CNN He et al. (2018),81.5,82.74,81.5,0.83,98.5,0.83,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.01
10,1,Face Verification,Oulu-CASIA NIR-VIS,2018-09,DVR Wu et al. (2019),97.2,98.68,15.7,0.16,98.5,0.99,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.01
11,1,Face Verification,Oulu-CASIA NIR-VIS,2019-03,LightCNN-29 + DVG,98.5,100.0,1.3,0.01,98.5,1.0,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.01
12,1,Face Verification,BUAA-VisNir,2017-08,W-CNN He et al. (2018),96.0,97.46,96.0,0.97,98.5,0.97,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.01
13,1,Face Verification,BUAA-VisNir,2018-09,DVR Wu et al. (2019),98.5,100.0,2.5,0.03,98.5,1.0,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.01
14,1,Face Verification,IJB-B,2017-08,FPN,96.5,100.0,96.5,1.0,96.5,0.98,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.01
15,1,Face Verification,IIIT-D Viewed Sketch,2019-03,LightCNN-29 + DVG,97.86,100.0,97.86,1.0,97.86,0.99,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.01
0,1,Sequential Image Classification,Sequential MNIST,2015-04,iRNN,97.0,97.51,97.0,0.98,99.48,0.98,ito:ITO_00101,Vision process,Unpermuted\\ Accuracy
1,1,Sequential Image Classification,Sequential MNIST,2015-11,LSTM,98.2,98.71,1.2,0.01,99.48,0.99,ito:ITO_00101,Vision process,Unpermuted\\ Accuracy
2,1,Sequential Image Classification,Sequential MNIST,2016-03,BN LSTM,99.0,99.52,0.8,0.01,99.48,1.0,ito:ITO_00101,Vision process,Unpermuted\\ Accuracy
3,1,Sequential Image Classification,Sequential MNIST,2017-10,Dilated GRU,99.2,99.72,0.2,0.0,99.48,1.0,ito:ITO_00101,Vision process,Unpermuted\\ Accuracy
4,1,Sequential Image Classification,Sequential MNIST,2019-10,Dense IndRNN,99.48,100.0,0.3,0.0,99.48,1.0,ito:ITO_00101,Vision process,Unpermuted\\ Accuracy
5,1,Sequential Image Classification,Sequential CIFAR-10,2018-03,"Transformer (self-attention) (Trinh et al., 2018)",62.2,84.72,62.2,0.85,73.42,0.63,ito:ITO_00101,Vision process,Unpermuted\\ Accuracy
6,1,Sequential Image Classification,Sequential CIFAR-10,2018-10,Trellis Network,73.42,100.0,11.2,0.15,73.42,0.74,ito:ITO_00101,Vision process,Unpermuted\\ Accuracy
0,1,Sequential Image Classification,Sequential MNIST,2015-04,iRNN,82.0,84.36,82.0,0.84,97.2,0.84,ito:ITO_00101,Vision process,Permuted\\ Accuracy
1,1,Sequential Image Classification,Sequential MNIST,2015-11,LSTM,88.0,90.53,6.0,0.06,97.2,0.91,ito:ITO_00101,Vision process,Permuted\\ Accuracy
2,1,Sequential Image Classification,Sequential MNIST,2016-03,BN LSTM,95.4,98.15,7.4,0.08,97.2,0.98,ito:ITO_00101,Vision process,Permuted\\ Accuracy
3,1,Sequential Image Classification,Sequential MNIST,2018-03,Temporal Convolutional Network,97.2,100.0,1.8,0.02,97.2,1.0,ito:ITO_00101,Vision process,Permuted\\ Accuracy
0,1,Lane Detection,Caltech Lanes Washington,2015-04,Overfeat CNN detector + DBSCAN,0.861,99.08,0.861,0.99,0.869,0.01,ito:ITO_00101,Vision process,F1
1,1,Lane Detection,Caltech Lanes Washington,2017-10,VPGNet,0.869,100.0,0.0,0.0,0.869,0.01,ito:ITO_00101,Vision process,F1
2,1,Lane Detection,Caltech Lanes Cordova,2015-04,Overfeat CNN detector + DBSCAN,0.866,97.96,0.866,0.98,0.884,0.01,ito:ITO_00101,Vision process,F1
3,1,Lane Detection,Caltech Lanes Cordova,2017-10,VPGNet,0.884,100.0,0.0,0.0,0.884,0.01,ito:ITO_00101,Vision process,F1
4,1,3D Point Cloud Classification,Sydney Urban Objects,2016-04,ORION,77.8,99.23,77.8,0.99,78.4,0.78,ito:ITO_00101,Vision process,F1
5,1,3D Point Cloud Classification,Sydney Urban Objects,2017-04,ECC,78.4,100.0,0.6,0.01,78.4,0.79,ito:ITO_00101,Vision process,F1
6,1,Facial Action Unit Detection,BP4D,2017-02,Baseline,45.2,78.34,45.2,0.78,57.7,0.45,ito:ITO_00101,Vision process,F1
7,1,Facial Action Unit Detection,BP4D,2017-04,Multi-View,57.7,100.0,12.5,0.22,57.7,0.58,ito:ITO_00101,Vision process,F1
8,1,Node Classification,PPI,2017-06,GraphSAGE,61.2,61.51,61.2,0.62,99.5,0.62,ito:ITO_00101,Vision process,F1
9,1,Node Classification,PPI,2017-10,GAT,97.3,97.79,36.1,0.36,99.5,0.98,ito:ITO_00101,Vision process,F1
10,1,Node Classification,PPI,2018-03,GaAN,98.7,99.2,1.4,0.01,99.5,0.99,ito:ITO_00101,Vision process,F1
11,1,Node Classification,PPI,2019-05,Cluster-GCN,99.36,99.86,0.7,0.01,99.5,1.0,ito:ITO_00101,Vision process,F1
12,1,Node Classification,PPI,2019-06,GraphStar,99.4,99.9,0.0,0.0,99.5,1.0,ito:ITO_00101,Vision process,F1
13,1,Node Classification,PPI,2019-07,GraphSAINT,99.5,100.0,0.1,0.0,99.5,1.0,ito:ITO_00101,Vision process,F1
14,1,3D Facial Landmark Localization,3D Facial Landmark Localization,2017-06,GraphSAGE,61.2,61.51,61.2,0.62,99.5,0.62,ito:ITO_00101,Vision process,F1
15,1,3D Facial Landmark Localization,3D Facial Landmark Localization,2017-10,GAT,97.3,97.79,36.1,0.36,99.5,0.98,ito:ITO_00101,Vision process,F1
16,1,3D Facial Landmark Localization,3D Facial Landmark Localization,2018-03,GaAN,98.7,99.2,1.4,0.01,99.5,0.99,ito:ITO_00101,Vision process,F1
17,1,3D Facial Landmark Localization,3D Facial Landmark Localization,2019-05,Cluster-GCN,99.36,99.86,0.7,0.01,99.5,1.0,ito:ITO_00101,Vision process,F1
18,1,3D Facial Landmark Localization,3D Facial Landmark Localization,2019-06,GraphStar,99.4,99.9,0.0,0.0,99.5,1.0,ito:ITO_00101,Vision process,F1
19,1,3D Facial Landmark Localization,3D Facial Landmark Localization,2019-07,GraphSAINT,99.5,100.0,0.1,0.0,99.5,1.0,ito:ITO_00101,Vision process,F1
20,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,bc-LSTM+Att,56.19,87.55,56.19,0.88,64.18,0.56,ito:ITO_00101,Vision process,F1
21,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,ICON,58.54,91.21,2.4,0.04,64.18,0.59,ito:ITO_00101,Vision process,F1
22,1,Emotion Recognition in Conversation,IEMOCAP,2019-05,DialogueRNN,62.75,97.77,4.2,0.07,64.18,0.63,ito:ITO_00101,Vision process,F1
23,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,DialogueGCN,64.18,100.0,1.4,0.02,64.18,0.65,ito:ITO_00101,Vision process,F1
24,1,Multimodal Emotion Recognition,IEMOCAP,2018-06,CHFusion (A+T+V),0.768,100.0,0.768,1.0,0.768,0.01,ito:ITO_00101,Vision process,F1
25,1,Iris Segmentation,UBIRIS,2019-01,IrisParseNet (ASPP),91.82,100.0,91.82,1.0,91.82,0.92,ito:ITO_00101,Vision process,F1
26,1,Iris Segmentation,CASIA,2019-01,IrisParseNet (ASPP) CASIA,94.3,100.0,94.3,1.0,94.3,0.95,ito:ITO_00101,Vision process,F1
27,1,Iris Segmentation,MICHE,2019-01,IrisParseNet (PSP),91.5,100.0,91.5,1.0,91.5,0.92,ito:ITO_00101,Vision process,F1
28,1,Click-Through Rate Prediction,MovieLens 20M,2019-03,KGCN-sum,0.932,100.0,0.932,1.0,0.932,0.01,ito:ITO_00101,Vision process,F1
29,1,Multi-Animal Tracking with identification,Multi-Animal Tracking with identification,2019-03,KGCN-sum,0.932,100.0,0.932,1.0,0.932,0.01,ito:ITO_00101,Vision process,F1
30,1,Speech Emotion Recognition,IEMOCAP,2019-04,Ensemble (Random Forests + Gradient Boosted Trees + Multi Layer Perceptron + Multinomial Naive Bayes + Logistic Regression) / (A+T),0.718,100.0,0.718,1.0,0.718,0.01,ito:ITO_00101,Vision process,F1
31,1,Edge Detection,BSDS500,2019-04,RCN,0.824,100.0,0.824,1.0,0.824,0.01,ito:ITO_00101,Vision process,F1
32,1,Head Detection,Rebar Head,2019-04,"WSMA-Seg (stack=2 ,base=40, depth=5)",98.83,100.0,98.83,1.0,98.83,0.99,ito:ITO_00101,Vision process,F1
0,1,Multi-Object Tracking,MOT16,2015-04,NOMT,46.4,67.54,46.4,0.68,68.7,0.55,ito:ITO_00101,Vision process,MOTA
1,1,Multi-Object Tracking,MOT16,2018-04,GCRA,48.2,70.16,1.8,0.03,68.7,0.57,ito:ITO_00101,Vision process,MOTA
2,1,Multi-Object Tracking,MOT16,2018-11,TNT,49.2,71.62,1.0,0.01,68.7,0.58,ito:ITO_00101,Vision process,MOTA
3,1,Multi-Object Tracking,MOT16,2019-06,DeepMOT-Tracktor,54.8,79.77,5.6,0.08,68.7,0.65,ito:ITO_00101,Vision process,MOTA
4,1,Multi-Object Tracking,MOT16,2019-09,JDE,64.4,93.74,9.6,0.14,68.7,0.76,ito:ITO_00101,Vision process,MOTA
5,1,Multi-Object Tracking,MOT16,2020-04,FairMOT,68.7,100.0,4.3,0.06,68.7,0.81,ito:ITO_00101,Vision process,MOTA
6,1,Multiple Object Tracking,KITTI Tracking test,2015-04,NOMT,78.15,92.19,78.15,0.92,84.77,0.92,ito:ITO_00101,Vision process,MOTA
7,1,Multiple Object Tracking,KITTI Tracking test,2018-02,RRC-IIITH,84.24,99.37,6.1,0.07,84.77,0.99,ito:ITO_00101,Vision process,MOTA
8,1,Multiple Object Tracking,KITTI Tracking test,2018-11,3DT,84.52,99.71,0.3,0.0,84.77,1.0,ito:ITO_00101,Vision process,MOTA
9,1,Multiple Object Tracking,KITTI Tracking test,2019-09,mmMOT-normal,84.77,100.0,0.2,0.0,84.77,1.0,ito:ITO_00101,Vision process,MOTA
10,1,Pose Tracking,Multi-Person PoseTrack,2016-11,PoseTrack,28.2,100.0,28.2,1.0,28.2,0.33,ito:ITO_00101,Vision process,MOTA
11,1,Pose Tracking,PoseTrack2017,2017-10,PoseTrack,48.4,82.88,48.4,0.83,58.4,0.57,ito:ITO_00101,Vision process,MOTA
12,1,Pose Tracking,PoseTrack2017,2017-12,ProTracker,51.82,88.73,3.4,0.06,58.4,0.61,ito:ITO_00101,Vision process,MOTA
13,1,Pose Tracking,PoseTrack2017,2018-04,MSRA,57.8,98.97,6.0,0.1,58.4,0.68,ito:ITO_00101,Vision process,MOTA
14,1,Pose Tracking,PoseTrack2017,2018-04,MSRA (FlowTrack),57.81,98.99,0.0,0.0,58.4,0.68,ito:ITO_00101,Vision process,MOTA
15,1,Pose Tracking,PoseTrack2017,2018-11,STAF,58.4,100.0,0.6,0.01,58.4,0.69,ito:ITO_00101,Vision process,MOTA
16,1,3D Multi-Object Tracking,KITTI,2018-02,BeyondPixels,84.24,100.0,84.24,1.0,84.24,0.99,ito:ITO_00101,Vision process,MOTA
17,1,Pose Tracking,PoseTrack2018,2018-04,MSRA,61.37,100.0,61.37,1.0,61.37,0.72,ito:ITO_00101,Vision process,MOTA
18,1,Multi-Object Tracking,MOT17,2018-09,MOTDT17,50.9,75.41,50.9,0.75,67.5,0.6,ito:ITO_00101,Vision process,MOTA
19,1,Multi-Object Tracking,MOT17,2018-11,TNT,51.9,76.89,1.0,0.01,67.5,0.61,ito:ITO_00101,Vision process,MOTA
20,1,Multi-Object Tracking,MOT17,2019-06,DeepMOT-Tracktor,53.7,79.56,1.8,0.03,67.5,0.63,ito:ITO_00101,Vision process,MOTA
21,1,Multi-Object Tracking,MOT17,2020-04,FairMOT,67.5,100.0,13.8,0.2,67.5,0.8,ito:ITO_00101,Vision process,MOTA
22,1,Online Multi-Object Tracking,MOT16,2018-09,MOTDT,47.6,87.5,47.6,0.88,54.4,0.56,ito:ITO_00101,Vision process,MOTA
23,1,Online Multi-Object Tracking,MOT16,2019-03,Tracktor++,54.4,100.0,6.8,0.12,54.4,0.64,ito:ITO_00101,Vision process,MOTA
24,1,Online Multi-Object Tracking,MOT17,2019-03,Tracktor++,53.5,100.0,53.5,1.0,53.5,0.63,ito:ITO_00101,Vision process,MOTA
25,1,Online Multi-Object Tracking,2D MOT 2015,2019-03,Tracktor++,44.1,100.0,44.1,1.0,44.1,0.52,ito:ITO_00101,Vision process,MOTA
26,1,Multi-Object Tracking,2D MOT 2015,2019-06,DeepMOT-Tracktor,44.1,100.0,44.1,1.0,44.1,0.52,ito:ITO_00101,Vision process,MOTA
27,1,Online Multi-Object Tracking,MOT15,2019-07,GMPHD Filter (Occlusion Group Management),30.7,100.0,30.7,1.0,30.7,0.36,ito:ITO_00101,Vision process,MOTA
28,1,Multi-Object Tracking,2DMOT15,2020-04,FairMOT,59.0,100.0,59,1.0,59,0.7,ito:ITO_00101,Vision process,MOTA
29,1,Multi-Object Tracking,MOT20,2020-04,FairMOT,58.7,100.0,58.7,1.0,58.7,0.69,ito:ITO_00101,Vision process,MOTA
0,1,Image Retrieval,Flickr30K 1K test,2015-04,mCNN,56.3,73.02,56.3,0.73,77.1,0.65,ito:ITO_00101,Vision process,R\\-at\\-5
1,1,Image Retrieval,Flickr30K 1K test,2015-11,SPE,60.1,77.95,3.8,0.05,77.1,0.69,ito:ITO_00101,Vision process,R\\-at\\-5
2,1,Image Retrieval,Flickr30K 1K test,2016-11,DAN,69.2,89.75,9.1,0.12,77.1,0.8,ito:ITO_00101,Vision process,R\\-at\\-5
3,1,Image Retrieval,Flickr30K 1K test,2017-12,SCO,70.5,91.44,1.3,0.02,77.1,0.81,ito:ITO_00101,Vision process,R\\-at\\-5
4,1,Image Retrieval,Flickr30K 1K test,2018-03,SCAN i-t,74.2,96.24,3.7,0.05,77.1,0.86,ito:ITO_00101,Vision process,R\\-at\\-5
5,1,Image Retrieval,Flickr30K 1K test,2019-09,CAMP,77.1,100.0,2.9,0.04,77.1,0.89,ito:ITO_00101,Vision process,R\\-at\\-5
6,1,Visual Dialog,VisDial v0.9 val,2016-05,HieCoAtt-QI,74.49,86.36,74.49,0.86,86.26,0.86,ito:ITO_00101,Vision process,R\\-at\\-5
7,1,Visual Dialog,VisDial v0.9 val,2017-09,AMEM Seo et al. (2017),78.66,91.19,4.2,0.05,86.26,0.91,ito:ITO_00101,Vision process,R\\-at\\-5
8,1,Visual Dialog,VisDial v0.9 val,2017-11,CoAtt Wu et al. (2018),80.71,93.57,2.0,0.02,86.26,0.93,ito:ITO_00101,Vision process,R\\-at\\-5
9,1,Visual Dialog,VisDial v0.9 val,2019-02,DAN,82.42,95.55,1.7,0.02,86.26,0.95,ito:ITO_00101,Vision process,R\\-at\\-5
10,1,Visual Dialog,VisDial v0.9 val,2019-02,HACAN,83.03,96.26,0.6,0.01,86.26,0.96,ito:ITO_00101,Vision process,R\\-at\\-5
11,1,Visual Dialog,VisDial v0.9 val,2019-04,9xFGA (VGG),86.26,100.0,3.2,0.04,86.26,0.99,ito:ITO_00101,Vision process,R\\-at\\-5
12,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,76.88,88.64,76.88,0.89,86.73,0.89,ito:ITO_00101,Vision process,R\\-at\\-5
13,1,Visual Dialog,Visual Dialog v1.0 test-std,2018-09,CorefNMN (ResNet-152),78.1,90.05,1.2,0.01,86.73,0.9,ito:ITO_00101,Vision process,R\\-at\\-5
14,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,DAN,79.75,91.95,1.7,0.02,86.73,0.92,ito:ITO_00101,Vision process,R\\-at\\-5
15,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,HACAN,80.63,92.97,0.9,0.01,86.73,0.93,ito:ITO_00101,Vision process,R\\-at\\-5
16,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-04,5xFGA (F-RCNNx101),86.73,100.0,6.1,0.07,86.73,1.0,ito:ITO_00101,Vision process,R\\-at\\-5
17,1,Phrase Grounding,Flickr30k Entities Test,2018-05,BAN (Bottom-Up detector),84.22,99.11,84.22,0.99,84.98,0.97,ito:ITO_00101,Vision process,R\\-at\\-5
18,1,Phrase Grounding,Flickr30k Entities Test,2019-08,VisualBERT,84.98,100.0,0.8,0.01,84.98,0.98,ito:ITO_00101,Vision process,R\\-at\\-5
19,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),78.1,90.05,78.1,0.9,86.73,0.9,ito:ITO_00101,Vision process,R\\-at\\-5
20,1,Visual Dialog,VisDial v1.0 test-std,2019-02,DAN,79.75,91.95,1.7,0.02,86.73,0.92,ito:ITO_00101,Vision process,R\\-at\\-5
21,1,Visual Dialog,VisDial v1.0 test-std,2019-04,5xFGA (F-RCNNx101),86.73,100.0,7.0,0.08,86.73,1.0,ito:ITO_00101,Vision process,R\\-at\\-5
22,1,Phrase Grounding,Flickr30k Entities Dev,2019-08,VisualBERT,84.49,100.0,84.49,1.0,84.49,0.97,ito:ITO_00101,Vision process,R\\-at\\-5
0,1,Brain Tumor Segmentation,BRATS-2013,2015-05,InputCascadeCNN,0.88,95.05,0.88,0.95,0.9258,0.01,ito:ITO_00101,Vision process,Dice\\ Score
1,1,Brain Tumor Segmentation,BRATS-2013,2019-08,ModelGenesis,0.9258,100.0,0.0,0.0,0.9258,0.01,ito:ITO_00101,Vision process,Dice\\ Score
2,1,Brain Tumor Segmentation,BRATS-2013 leaderboard,2015-05,InputCascadeCNN,0.84,100.0,0.84,1.0,0.84,0.01,ito:ITO_00101,Vision process,Dice\\ Score
3,1,Pancreas Segmentation,CT-150,2015-05,U-Net,0.814,96.9,0.814,0.97,0.84,0.01,ito:ITO_00101,Vision process,Dice\\ Score
4,1,Pancreas Segmentation,CT-150,2018-04,Att U-Net,0.84,100.0,0.0,0.0,0.84,0.01,ito:ITO_00101,Vision process,Dice\\ Score
5,1,Pancreas Segmentation,TCIA Pancreas-CT Dataset,2015-05,U-Net,0.82,93.61,0.82,0.94,0.876,0.01,ito:ITO_00101,Vision process,Dice\\ Score
6,1,Pancreas Segmentation,TCIA Pancreas-CT Dataset,2017-09,Recurrent Saliency Transformation Network,0.876,100.0,0.1,0.11,0.876,0.01,ito:ITO_00101,Vision process,Dice\\ Score
7,1,Brain Tumor Segmentation,BRATS-2015,2016-03,3D CNN + CRF,85.0,97.7,85,0.98,87,0.93,ito:ITO_00101,Vision process,Dice\\ Score
8,1,Brain Tumor Segmentation,BRATS-2015,2019-06,OM-Net + CGAp,87.0,100.0,2,0.02,87,0.95,ito:ITO_00101,Vision process,Dice\\ Score
9,1,Lesion Segmentation,ISLES-2015,2016-03,3D CNN + CRF,59.0,100.0,59,1.0,59,0.64,ito:ITO_00101,Vision process,Dice\\ Score
10,1,Volumetric Medical Image Segmentation,PROMISE 2012,2016-06,V-Net + Dice-based loss,0.869,100.0,0.869,1.0,0.869,0.01,ito:ITO_00101,Vision process,Dice\\ Score
11,1,3D Medical Imaging Segmentation,TCIA Pancreas-CT,2017-01,Holistic-nested CNN,81.3,100.0,81.3,1.0,81.3,0.89,ito:ITO_00101,Vision process,Dice\\ Score
12,1,Brain Tumor Segmentation,BRATS-2017 val,2017-09,Wang et al.,0.905,99.77,0.905,1.0,0.9071,0.01,ito:ITO_00101,Vision process,Dice\\ Score
13,1,Brain Tumor Segmentation,BRATS-2017 val,2019-06,OM-Net + CGAp,0.9071,100.0,0.0,0.0,0.9071,0.01,ito:ITO_00101,Vision process,Dice\\ Score
14,1,Brain Tumor Segmentation,BRATS-2014,2017-09,Cascaded Anisotropic CNNs,0.8739,100.0,0.8739,1.0,0.8739,0.01,ito:ITO_00101,Vision process,Dice\\ Score
15,1,Infant Brain MRI Segmentation,iSEG 2017 Challenge,2017-12,LiviaNet (SemiDenseNet),0.9243,100.0,0.9243,1.0,0.9243,0.01,ito:ITO_00101,Vision process,Dice\\ Score
16,1,Medical Image Segmentation,iSEG 2017 Challenge,2018-04,HyperDenseNet,0.9257,100.0,0.9257,1.0,0.9257,0.01,ito:ITO_00101,Vision process,Dice\\ Score
17,1,Lesion Segmentation,BUS 2017 Dataset B,2018-10,Attn U-Net + Multi-Input + FTL,0.804,100.0,0.804,1.0,0.804,0.01,ito:ITO_00101,Vision process,Dice\\ Score
18,1,Lesion Segmentation,ISIC 2018,2018-10,Attn U-Net + Multi-Input + FTL,0.856,95.64,0.856,0.96,0.895,0.01,ito:ITO_00101,Vision process,Dice\\ Score
19,1,Lesion Segmentation,ISIC 2018,2020-03,MCGU-Net,0.895,100.0,0.0,0.0,0.895,0.01,ito:ITO_00101,Vision process,Dice\\ Score
20,1,Brain Tumor Segmentation,BRATS 2018,2018-10,NVDLMED,0.87049,100.0,0.87049,1.0,0.87049,0.01,ito:ITO_00101,Vision process,Dice\\ Score
21,1,Brain Image Segmentation,T1-weighted MRI,2019-02,Learned Transformations (random augmentation),81.5,100.0,81.5,1.0,81.5,0.89,ito:ITO_00101,Vision process,Dice\\ Score
22,1,Lung Nodule Segmentation,NIH,2019-04,U-Net+R+A4,0.962,100.0,0.962,1.0,0.962,0.01,ito:ITO_00101,Vision process,Dice\\ Score
23,1,Brain Tumor Segmentation,BRATS 2018 val,2019-06,OM-Net + CGAp,91.59,100.0,91.59,1.0,91.59,1.0,ito:ITO_00101,Vision process,Dice\\ Score
24,1,Medical Image Segmentation,CHAOS MRI Dataset,2019-06,MS-Dual-Guided,86.75,100.0,86.75,1.0,86.75,0.95,ito:ITO_00101,Vision process,Dice\\ Score
25,1,Medical Image Segmentation,HSVM,2019-06,MS-Dual-Guided,83.2,100.0,83.2,1.0,83.2,0.91,ito:ITO_00101,Vision process,Dice\\ Score
26,1,Brain Segmentation,Brain MRI segmentation,2019-06,U-Net,0.82,100.0,0.82,1.0,0.82,0.01,ito:ITO_00101,Vision process,Dice\\ Score
27,1,Brain Image Segmentation,Brain MRI segmentation,2019-06,U-Net,0.82,100.0,0.82,1.0,0.82,0.01,ito:ITO_00101,Vision process,Dice\\ Score
28,1,Lung Nodule Segmentation,Lung Nodule ,2019-08,BCDU-net,0.994,100.0,0.994,1.0,0.994,0.01,ito:ITO_00101,Vision process,Dice\\ Score
0,1,Medical Image Segmentation,ISBI 2012 EM Segmentation,2015-05,U-Net,0.000353,100.0,0.000353,1.0,0.000353,1.0,ito:ITO_00101,Vision process,Warping\\ Error
0,1,Semantic Segmentation,Kvasir-Instrument,2015-05,UNet,0.9158,100.0,0.9158,1.0,0.9158,1.0,ito:ITO_00101,Vision process,DSC
0,1,Medical Image Segmentation,Kvasir-SEG,2015-05,U-Net,0.818,99.63,0.818,1.0,0.821,0.99,ito:ITO_00101,Vision process,mean\\ Dice
1,1,Medical Image Segmentation,Kvasir-SEG,2018-07,U-Net++,0.821,100.0,0.0,0.0,0.821,1.0,ito:ITO_00101,Vision process,mean\\ Dice
2,1,Medical Image Segmentation,CVC-ClinicDB,2015-05,U-Net,0.823,100.0,0.823,1.0,0.823,1.0,ito:ITO_00101,Vision process,mean\\ Dice
0,1,Medical Image Segmentation,RITE,2015-05,U-Net,31.11,79.48,31.11,0.79,39.14,0.79,ito:ITO_00101,Vision process,Jaccard\\ Index
1,1,Medical Image Segmentation,RITE,2015-11,SegNet,39.14,100.0,8.0,0.2,39.14,1.0,ito:ITO_00101,Vision process,Jaccard\\ Index
0,1,Medical Image Segmentation,Kvasir-SEG,2015-05,U-Net,0.055,100.0,0.055,1.0,0.055,0.41,ito:ITO_00101,Vision process,Average\\ MAE
1,1,RGB Salient Object Detection,SOC,2017-07,NLDF,0.106,79.7,0.106,0.8,0.133,0.8,ito:ITO_00101,Vision process,Average\\ MAE
2,1,RGB Salient Object Detection,SOC,2017-08,PiCANet,0.133,100.0,0.0,0.0,0.133,1.0,ito:ITO_00101,Vision process,Average\\ MAE
0,1,Medical Image Segmentation,Kvasir-SEG,2015-05,U-Net,0.858,99.54,0.858,1.0,0.862,0.01,ito:ITO_00101,Vision process,S\\-Measure
1,1,Medical Image Segmentation,Kvasir-SEG,2018-07,U-Net++,0.862,100.0,0.0,0.0,0.862,0.01,ito:ITO_00101,Vision process,S\\-Measure
2,1,RGB Salient Object Detection,SOC,2017-07,NLDF,0.816,97.03,0.816,0.97,0.841,0.01,ito:ITO_00101,Vision process,S\\-Measure
3,1,RGB Salient Object Detection,SOC,2019-06,BASNet,0.841,100.0,0.0,0.0,0.841,0.01,ito:ITO_00101,Vision process,S\\-Measure
4,1,RGB Salient Object Detection,DUTS-TE,2017-08,PiCANet,0.842,96.12,0.842,0.96,0.876,0.01,ito:ITO_00101,Vision process,S\\-Measure
5,1,RGB Salient Object Detection,DUTS-TE,2018-06,DGRL,0.846,96.58,0.0,0.0,0.876,0.01,ito:ITO_00101,Vision process,S\\-Measure
6,1,RGB Salient Object Detection,DUTS-TE,2019-06,BASNet,0.876,100.0,0.0,0.0,0.876,0.01,ito:ITO_00101,Vision process,S\\-Measure
7,1,Camouflaged Object Segmentation,COD,2019-04,CPD,74.7,100.0,74.7,1.0,74.7,1.0,ito:ITO_00101,Vision process,S\\-Measure
8,1,Camouflaged Object Segmentation,CAMO,2019-06,BASNet,61.8,100.0,61.8,1.0,61.8,0.83,ito:ITO_00101,Vision process,S\\-Measure
0,1,Medical Image Segmentation,Kvasir-SEG,2015-05,U-Net,0.893,98.13,0.893,0.98,0.91,0.98,ito:ITO_00101,Vision process,max\\ E\\-Measure
1,1,Medical Image Segmentation,Kvasir-SEG,2018-07,U-Net++,0.91,100.0,0.0,0.0,0.91,1.0,ito:ITO_00101,Vision process,max\\ E\\-Measure
0,1,Retinal Vessel Segmentation,STARE,2015-05,U-Net,0.9898,99.84,0.9898,1.0,0.9914,0.01,ito:ITO_00101,Vision process,AUC
1,1,Retinal Vessel Segmentation,STARE,2018-02,R2U-Net,0.9914,100.0,0.0,0.0,0.9914,0.01,ito:ITO_00101,Vision process,AUC
2,1,Retinal Vessel Segmentation,DRIVE,2015-05,U-Net,0.9755,99.38,0.9755,0.99,0.9816,0.01,ito:ITO_00101,Vision process,AUC
3,1,Retinal Vessel Segmentation,DRIVE,2017-11,Residual U-Net,0.9779,99.62,0.0,0.0,0.9816,0.01,ito:ITO_00101,Vision process,AUC
4,1,Retinal Vessel Segmentation,DRIVE,2018-06,VGN,0.9802,99.86,0.0,0.0,0.9816,0.01,ito:ITO_00101,Vision process,AUC
5,1,Retinal Vessel Segmentation,DRIVE,2019-12,IterNet,0.9816,100.0,0.0,0.0,0.9816,0.01,ito:ITO_00101,Vision process,AUC
6,1,Retinal Vessel Segmentation,CHASE_DB1,2015-05,U-Net,0.9772,99.2,0.9772,0.99,0.9851,0.01,ito:ITO_00101,Vision process,AUC
7,1,Retinal Vessel Segmentation,CHASE_DB1,2017-11,Residual U-Net,0.9779,99.27,0.0,0.0,0.9851,0.01,ito:ITO_00101,Vision process,AUC
8,1,Retinal Vessel Segmentation,CHASE_DB1,2018-02,R2U-Net,0.9815,99.63,0.0,0.0,0.9851,0.01,ito:ITO_00101,Vision process,AUC
9,1,Retinal Vessel Segmentation,CHASE_DB1,2018-06,VGN,0.983,99.79,0.0,0.0,0.9851,0.01,ito:ITO_00101,Vision process,AUC
10,1,Retinal Vessel Segmentation,CHASE_DB1,2018-10,LadderNet,0.9839,99.88,0.0,0.0,0.9851,0.01,ito:ITO_00101,Vision process,AUC
11,1,Retinal Vessel Segmentation,CHASE_DB1,2019-12,IterNet,0.9851,100.0,0.0,0.0,0.9851,0.01,ito:ITO_00101,Vision process,AUC
12,1,Electron Microscopy Image Segmentation,SNEMI3D,2015-05,U-Net,0.8676,96.91,0.8676,0.97,0.8953,0.01,ito:ITO_00101,Vision process,AUC
13,1,Electron Microscopy Image Segmentation,SNEMI3D,2019-08,DTN,0.8953,100.0,0.0,0.0,0.8953,0.01,ito:ITO_00101,Vision process,AUC
14,1,Lung Nodule Segmentation,LUNA,2015-05,U-Net,0.9784,98.37,0.9784,0.98,0.9946,0.01,ito:ITO_00101,Vision process,AUC
15,1,Lung Nodule Segmentation,LUNA,2017-11,Residual U-Net,0.9849,99.02,0.0,0.0,0.9946,0.01,ito:ITO_00101,Vision process,AUC
16,1,Lung Nodule Segmentation,LUNA,2019-08,BCDU-Net (d=3),0.9946,100.0,0.0,0.0,0.9946,0.01,ito:ITO_00101,Vision process,AUC
17,1,Skin Cancer Segmentation,Kaggle Skin Lesion Segmentation,2015-05,U-Net,0.9371,99.49,0.9371,0.99,0.9419,0.01,ito:ITO_00101,Vision process,AUC
18,1,Skin Cancer Segmentation,Kaggle Skin Lesion Segmentation,2017-11,Residual U-Net,0.9396,99.76,0.0,0.0,0.9419,0.01,ito:ITO_00101,Vision process,AUC
19,1,Skin Cancer Segmentation,Kaggle Skin Lesion Segmentation,2018-02,R2U-Net,0.9419,100.0,0.0,0.0,0.9419,0.01,ito:ITO_00101,Vision process,AUC
20,1,Click-Through Rate Prediction,iPinYou,2016-01,FNN,0.7619,93.21,0.7619,0.93,0.8174,0.01,ito:ITO_00101,Vision process,AUC
21,1,Click-Through Rate Prediction,iPinYou,2016-11,OPNN,0.8174,100.0,0.1,0.12,0.8174,0.01,ito:ITO_00101,Vision process,AUC
22,1,Few-Shot Video Object Detection,Few-Shot Video Object Detection,2016-01,FNN,0.7619,93.21,0.7619,0.93,0.8174,0.01,ito:ITO_00101,Vision process,AUC
23,1,Few-Shot Video Object Detection,Few-Shot Video Object Detection,2016-11,OPNN,0.8174,100.0,0.1,0.12,0.8174,0.01,ito:ITO_00101,Vision process,AUC
24,1,Click-Through Rate Prediction,Criteo,2016-01,FNN,0.7963,98.03,0.7963,0.98,0.8123,0.01,ito:ITO_00101,Vision process,AUC
25,1,Click-Through Rate Prediction,Criteo,2016-06,Wide & Deep (LR & DNN),0.7981,98.25,0.0,0.0,0.8123,0.01,ito:ITO_00101,Vision process,AUC
26,1,Click-Through Rate Prediction,Criteo,2016-11,PNN*,0.7987,98.33,0.0,0.0,0.8123,0.01,ito:ITO_00101,Vision process,AUC
27,1,Click-Through Rate Prediction,Criteo,2017-03,DeepFM,0.8007,98.57,0.0,0.0,0.8123,0.01,ito:ITO_00101,Vision process,AUC
28,1,Click-Through Rate Prediction,Criteo,2018-03,xDeepFM,0.8052,99.13,0.0,0.0,0.8123,0.01,ito:ITO_00101,Vision process,AUC
29,1,Click-Through Rate Prediction,Criteo,2018-10,AutoInt,0.8061,99.24,0.0,0.0,0.8123,0.01,ito:ITO_00101,Vision process,AUC
30,1,Click-Through Rate Prediction,Criteo,2019-10,Fi-GNN,0.8082,99.5,0.0,0.0,0.8123,0.01,ito:ITO_00101,Vision process,AUC
31,1,Click-Through Rate Prediction,Criteo,2020-02,Sparse DeepFwFM,0.8123,100.0,0.0,0.0,0.8123,0.01,ito:ITO_00101,Vision process,AUC
32,1,Sequential skip prediction,Sequential skip prediction,2016-01,FNN,0.7963,98.03,0.7963,0.98,0.8123,0.01,ito:ITO_00101,Vision process,AUC
33,1,Sequential skip prediction,Sequential skip prediction,2016-06,Wide & Deep (LR & DNN),0.7981,98.25,0.0,0.0,0.8123,0.01,ito:ITO_00101,Vision process,AUC
34,1,Sequential skip prediction,Sequential skip prediction,2016-11,PNN*,0.7987,98.33,0.0,0.0,0.8123,0.01,ito:ITO_00101,Vision process,AUC
35,1,Sequential skip prediction,Sequential skip prediction,2017-03,DeepFM,0.8007,98.57,0.0,0.0,0.8123,0.01,ito:ITO_00101,Vision process,AUC
36,1,Sequential skip prediction,Sequential skip prediction,2018-03,xDeepFM,0.8052,99.13,0.0,0.0,0.8123,0.01,ito:ITO_00101,Vision process,AUC
37,1,Sequential skip prediction,Sequential skip prediction,2018-10,AutoInt,0.8061,99.24,0.0,0.0,0.8123,0.01,ito:ITO_00101,Vision process,AUC
38,1,Sequential skip prediction,Sequential skip prediction,2019-10,Fi-GNN,0.8082,99.5,0.0,0.0,0.8123,0.01,ito:ITO_00101,Vision process,AUC
39,1,Sequential skip prediction,Sequential skip prediction,2020-02,Sparse DeepFwFM,0.8123,100.0,0.0,0.0,0.8123,0.01,ito:ITO_00101,Vision process,AUC
40,1,Click-Through Rate Prediction,MovieLens 20M,2016-06,Wide & Deep,0.7304,74.68,0.7304,0.75,0.978,0.01,ito:ITO_00101,Vision process,AUC
41,1,Click-Through Rate Prediction,MovieLens 20M,2016-11,PNN,0.7321,74.86,0.0,0.0,0.978,0.01,ito:ITO_00101,Vision process,AUC
42,1,Click-Through Rate Prediction,MovieLens 20M,2017-03,DeepFM,0.7324,74.89,0.0,0.0,0.978,0.01,ito:ITO_00101,Vision process,AUC
43,1,Click-Through Rate Prediction,MovieLens 20M,2017-06,DIN + Dice Activation,0.7348,75.13,0.0,0.0,0.978,0.01,ito:ITO_00101,Vision process,AUC
44,1,Click-Through Rate Prediction,MovieLens 20M,2019-03,KGCN-sum,0.978,100.0,0.2,0.2,0.978,0.01,ito:ITO_00101,Vision process,AUC
45,1,Multi-Animal Tracking with identification,Multi-Animal Tracking with identification,2016-06,Wide & Deep,0.7304,74.68,0.7304,0.75,0.978,0.01,ito:ITO_00101,Vision process,AUC
46,1,Multi-Animal Tracking with identification,Multi-Animal Tracking with identification,2016-11,PNN,0.7321,74.86,0.0,0.0,0.978,0.01,ito:ITO_00101,Vision process,AUC
47,1,Multi-Animal Tracking with identification,Multi-Animal Tracking with identification,2017-03,DeepFM,0.7324,74.89,0.0,0.0,0.978,0.01,ito:ITO_00101,Vision process,AUC
48,1,Multi-Animal Tracking with identification,Multi-Animal Tracking with identification,2017-06,DIN + Dice Activation,0.7348,75.13,0.0,0.0,0.978,0.01,ito:ITO_00101,Vision process,AUC
49,1,Multi-Animal Tracking with identification,Multi-Animal Tracking with identification,2019-03,KGCN-sum,0.978,100.0,0.2,0.2,0.978,0.01,ito:ITO_00101,Vision process,AUC
50,1,Click-Through Rate Prediction,Amazon,2016-06,Wide & Deep,0.8637,97.36,0.8637,0.97,0.8871,0.01,ito:ITO_00101,Vision process,AUC
51,1,Click-Through Rate Prediction,Amazon,2016-11,PNN,0.8679,97.84,0.0,0.0,0.8871,0.01,ito:ITO_00101,Vision process,AUC
52,1,Click-Through Rate Prediction,Amazon,2017-03,DeepFM,0.8683,97.88,0.0,0.0,0.8871,0.01,ito:ITO_00101,Vision process,AUC
53,1,Click-Through Rate Prediction,Amazon,2017-06,DIN + Dice Activation,0.8871,100.0,0.0,0.0,0.8871,0.01,ito:ITO_00101,Vision process,AUC
54,1,Generalized Zero-Shot Learning,Generalized Zero-Shot Learning,2016-06,Wide & Deep,0.8637,97.36,0.8637,0.97,0.8871,0.01,ito:ITO_00101,Vision process,AUC
55,1,Generalized Zero-Shot Learning,Generalized Zero-Shot Learning,2016-11,PNN,0.8679,97.84,0.0,0.0,0.8871,0.01,ito:ITO_00101,Vision process,AUC
56,1,Generalized Zero-Shot Learning,Generalized Zero-Shot Learning,2017-03,DeepFM,0.8683,97.88,0.0,0.0,0.8871,0.01,ito:ITO_00101,Vision process,AUC
57,1,Generalized Zero-Shot Learning,Generalized Zero-Shot Learning,2017-06,DIN + Dice Activation,0.8871,100.0,0.0,0.0,0.8871,0.01,ito:ITO_00101,Vision process,AUC
58,1,Click-Through Rate Prediction,Bing News,2016-06,Wide & Deep,0.8377,99.73,0.8377,1.0,0.84,0.01,ito:ITO_00101,Vision process,AUC
59,1,Click-Through Rate Prediction,Bing News,2018-03,xDeepFM,0.84,100.0,0.0,0.0,0.84,0.01,ito:ITO_00101,Vision process,AUC
60,1,Replay Grounding,Replay Grounding,2016-06,Wide & Deep,0.8377,99.73,0.8377,1.0,0.84,0.01,ito:ITO_00101,Vision process,AUC
61,1,Replay Grounding,Replay Grounding,2018-03,xDeepFM,0.84,100.0,0.0,0.0,0.84,0.01,ito:ITO_00101,Vision process,AUC
62,1,Click-Through Rate Prediction,Dianping,2016-06,Wide & Deep,0.8361,96.78,0.8361,0.97,0.8639,0.01,ito:ITO_00101,Vision process,AUC
63,1,Click-Through Rate Prediction,Dianping,2016-11,PNN,0.8445,97.75,0.0,0.0,0.8639,0.01,ito:ITO_00101,Vision process,AUC
64,1,Click-Through Rate Prediction,Dianping,2017-03,DeepFM,0.8481,98.17,0.0,0.0,0.8639,0.01,ito:ITO_00101,Vision process,AUC
65,1,Click-Through Rate Prediction,Dianping,2018-03,xDeepFM,0.8639,100.0,0.0,0.0,0.8639,0.01,ito:ITO_00101,Vision process,AUC
66,1,3D Action Recognition,3D Action Recognition,2016-06,Wide & Deep,0.8361,96.78,0.8361,0.97,0.8639,0.01,ito:ITO_00101,Vision process,AUC
67,1,3D Action Recognition,3D Action Recognition,2016-11,PNN,0.8445,97.75,0.0,0.0,0.8639,0.01,ito:ITO_00101,Vision process,AUC
68,1,3D Action Recognition,3D Action Recognition,2017-03,DeepFM,0.8481,98.17,0.0,0.0,0.8639,0.01,ito:ITO_00101,Vision process,AUC
69,1,3D Action Recognition,3D Action Recognition,2018-03,xDeepFM,0.8639,100.0,0.0,0.0,0.8639,0.01,ito:ITO_00101,Vision process,AUC
70,1,Visual Object Tracking,OTB-2013,2016-06,SiamFC-3s,0.607,89.66,0.607,0.9,0.677,0.01,ito:ITO_00101,Vision process,AUC
71,1,Visual Object Tracking,OTB-2013,2017-04,CFNet,0.611,90.25,0.0,0.0,0.677,0.01,ito:ITO_00101,Vision process,AUC
72,1,Visual Object Tracking,OTB-2013,2017-10,DSiam,0.656,96.9,0.0,0.0,0.677,0.01,ito:ITO_00101,Vision process,AUC
73,1,Visual Object Tracking,OTB-2013,2018-02,SA-Siam,0.677,100.0,0.0,0.0,0.677,0.01,ito:ITO_00101,Vision process,AUC
74,1,Visual Object Tracking,OTB-50,2016-06,SiamFC-3s,0.516,84.59,0.516,0.85,0.61,0.01,ito:ITO_00101,Vision process,AUC
75,1,Visual Object Tracking,OTB-50,2017-04,CFNet,0.53,86.89,0.0,0.0,0.61,0.01,ito:ITO_00101,Vision process,AUC
76,1,Visual Object Tracking,OTB-50,2018-02,SA-Siam,0.61,100.0,0.1,0.16,0.61,0.01,ito:ITO_00101,Vision process,AUC
77,1,Visual Object Tracking,OTB-100,2017-04,CFNet,0.568,86.45,0.568,0.86,0.657,0.01,ito:ITO_00101,Vision process,AUC
78,1,Visual Object Tracking,OTB-100,2018-02,SA-Siam,0.657,100.0,0.1,0.15,0.657,0.01,ito:ITO_00101,Vision process,AUC
79,1,Visual Object Tracking,OTB-2015,2017-04,CFNet,0.568,82.08,0.568,0.82,0.692,0.01,ito:ITO_00101,Vision process,AUC
80,1,Visual Object Tracking,OTB-2015,2018-02,SA-Siam,0.657,94.94,0.1,0.14,0.692,0.01,ito:ITO_00101,Vision process,AUC
81,1,Visual Object Tracking,OTB-2015,2019-06,ASRCF,0.692,100.0,0.0,0.0,0.692,0.01,ito:ITO_00101,Vision process,AUC
82,1,3D Human Pose Estimation,MPI-INF-3DHP,2017-05,VNect (Augm.),42.0,67.31,42.0,0.67,62.4,0.43,ito:ITO_00101,Vision process,AUC
83,1,3D Human Pose Estimation,MPI-INF-3DHP,2018-06,"MargiPose (Procrustes alignment, PA)",61.4,98.4,19.4,0.31,62.4,0.63,ito:ITO_00101,Vision process,AUC
84,1,3D Human Pose Estimation,MPI-INF-3DHP,2018-06,"MargiPose (Procrustes alignment, PA, multi-crop)",62.2,99.68,0.8,0.01,62.4,0.64,ito:ITO_00101,Vision process,AUC
85,1,3D Human Pose Estimation,MPI-INF-3DHP,2020-02,Explicit Compositional Depth Maps,62.4,100.0,0.2,0.0,62.4,0.64,ito:ITO_00101,Vision process,AUC
86,1,Abnormal Event Detection In Video,UCSD,2017-08,Adversarial Generator,97.4,100.0,97.4,1.0,97.4,1.0,ito:ITO_00101,Vision process,AUC
87,1,Semi-supervised Anomaly Detection,UBI-Fights,2017-08,Adversarial Generator,0.533,100.0,0.533,1.0,0.533,0.01,ito:ITO_00101,Vision process,AUC
88,1,Abnormal Event Detection In Video,UBI-Fights,2017-08,Adversarial Generator,0.523,100.0,0.523,1.0,0.523,0.01,ito:ITO_00101,Vision process,AUC
89,1,Click-Through Rate Prediction,MovieLens 1M,2018-03,RippleNet,0.921,97.47,0.921,0.97,0.9449,0.01,ito:ITO_00101,Vision process,AUC
90,1,Click-Through Rate Prediction,MovieLens 1M,2019-08,KNI,0.9449,100.0,0.0,0.0,0.9449,0.01,ito:ITO_00101,Vision process,AUC
91,1,Weakly-Supervised Action Recognition,Weakly-Supervised Action Recognition,2018-03,RippleNet,0.921,97.47,0.921,0.97,0.9449,0.01,ito:ITO_00101,Vision process,AUC
92,1,Weakly-Supervised Action Recognition,Weakly-Supervised Action Recognition,2019-08,KNI,0.9449,100.0,0.0,0.0,0.9449,0.01,ito:ITO_00101,Vision process,AUC
93,1,Retinal Vessel Segmentation,HRF,2018-06,VGN,0.9838,100.0,0.9838,1.0,0.9838,0.01,ito:ITO_00101,Vision process,AUC
94,1,Node Classification,Wiki,2018-10,DANMF,41.12,100.0,41.12,1.0,41.12,0.42,ito:ITO_00101,Vision process,AUC
95,1,Micro-Expression Recognition,Micro-Expression Recognition,2018-10,DANMF,41.12,100.0,41.12,1.0,41.12,0.42,ito:ITO_00101,Vision process,AUC
96,1,Click-Through Rate Prediction,KDD12,2018-10,AutoInt,0.7881,100.0,0.7881,1.0,0.7881,0.01,ito:ITO_00101,Vision process,AUC
97,1,Video-Text Retrieval,Video-Text Retrieval,2018-10,AutoInt,0.7881,100.0,0.7881,1.0,0.7881,0.01,ito:ITO_00101,Vision process,AUC
98,1,Visual Object Tracking,LaSOT,2018-11,ATOM,51.4,100.0,51.4,1.0,51.4,0.53,ito:ITO_00101,Vision process,AUC
99,1,Click-Through Rate Prediction,Children's Book Test Common noun,2019-01,MKR,0.734,100.0,0.734,1.0,0.734,0.01,ito:ITO_00101,Vision process,AUC
100,1,Generalized Zero Shot skeletal action recognition,Generalized Zero Shot skeletal action recognition,2019-01,MKR,0.734,100.0,0.734,1.0,0.734,0.01,ito:ITO_00101,Vision process,AUC
101,1,Unsupervised Anomaly Detection,ECG5000,2019-04,VRAE+SVM,0.9836,100.0,0.9836,1.0,0.9836,0.01,ito:ITO_00101,Vision process,AUC
102,1,Click-Through Rate Prediction,Huawei App Store,2019-04,FGCNN+IPNN,0.9407,100.0,0.9407,1.0,0.9407,0.01,ito:ITO_00101,Vision process,AUC
103,1,Multi-label zero-shot learning,Multi-label zero-shot learning,2019-04,FGCNN+IPNN,0.9407,100.0,0.9407,1.0,0.9407,0.01,ito:ITO_00101,Vision process,AUC
104,1,Band Gap,OQMD v1.2,2019-05,CGNN Ensemble,0.9713,100.0,0.9713,1.0,0.9713,0.01,ito:ITO_00101,Vision process,AUC
105,1,Total Magnetization,OQMD v1.2,2019-05,CGNN Ensemble,0.9569,100.0,0.9569,1.0,0.9569,0.01,ito:ITO_00101,Vision process,AUC
106,1,Visual Tracking,OTB-100,2019-06,ASRCF,0.692,100.0,0.692,1.0,0.692,0.01,ito:ITO_00101,Vision process,AUC
107,1,Horizon Line Estimation,KITTI Horizon,2019-07,"ConvLSTM (Huber Loss, naive residual path)",74.55,100.0,74.55,1.0,74.55,0.77,ito:ITO_00101,Vision process,AUC
108,1,Anomaly Detection,Census,2019-11,DevNet,0.828,100.0,0.828,1.0,0.828,0.01,ito:ITO_00101,Vision process,AUC
109,1,Anomaly Detection,Thyroid,2019-11,DevNet,0.783,100.0,0.783,1.0,0.783,0.01,ito:ITO_00101,Vision process,AUC
0,1,3D Shape Reconstruction,Pix3D,2018-04,MarrNet extension (w/ Pose),0.282,100.0,0.282,1.0,0.282,0.0,ito:ITO_00101,Vision process,IoU
1,1,Lung Nodule Segmentation,LIDC-IDRI,2019-08,ModelGenesis,77.62,100.0,77.62,1.0,77.62,0.83,ito:ITO_00101,Vision process,IoU
2,1,Liver Segmentation,LiTS2017,2019-08,ModelGenesis,79.52,100.0,79.52,1.0,79.52,0.85,ito:ITO_00101,Vision process,IoU
3,1,Skin Cancer Segmentation,PH2,2019-11,SegNet,93.61,100.0,93.61,1.0,93.61,1.0,ito:ITO_00101,Vision process,IoU
4,1,Brain Image Segmentation,Brain Tumor,2019-12,UNet++,91.21,100.0,91.21,1.0,91.21,0.97,ito:ITO_00101,Vision process,IoU
5,1,Medical Image Segmentation,EM,2019-12,UNet++,89.33,100.0,89.33,1.0,89.33,0.95,ito:ITO_00101,Vision process,IoU
6,1,Medical Image Segmentation,Cell,2019-12,UNet++,91.21,100.0,91.21,1.0,91.21,0.97,ito:ITO_00101,Vision process,IoU
0,1,Retinal Vessel Segmentation,CHASE_DB1,2015-05,U-Net,0.7783,96.41,0.7783,0.96,0.8073,0.01,ito:ITO_00101,Vision process,F1\\ score
1,1,Retinal Vessel Segmentation,CHASE_DB1,2017-11,Residual U-Net,0.78,96.62,0.0,0.0,0.8073,0.01,ito:ITO_00101,Vision process,F1\\ score
2,1,Retinal Vessel Segmentation,CHASE_DB1,2018-02,R2U-Net,0.7928,98.2,0.0,0.0,0.8073,0.01,ito:ITO_00101,Vision process,F1\\ score
3,1,Retinal Vessel Segmentation,CHASE_DB1,2018-06,VGN,0.8034,99.52,0.0,0.0,0.8073,0.01,ito:ITO_00101,Vision process,F1\\ score
4,1,Retinal Vessel Segmentation,CHASE_DB1,2019-12,IterNet,0.8073,100.0,0.0,0.0,0.8073,0.01,ito:ITO_00101,Vision process,F1\\ score
5,1,Lung Nodule Segmentation,LUNA,2015-05,U-Net,0.9658,97.52,0.9658,0.98,0.9904,0.01,ito:ITO_00101,Vision process,F1\\ score
6,1,Lung Nodule Segmentation,LUNA,2017-11,Residual U-Net,0.969,97.84,0.0,0.0,0.9904,0.01,ito:ITO_00101,Vision process,F1\\ score
7,1,Lung Nodule Segmentation,LUNA,2019-08,BCDU-Net (d=3),0.9904,100.0,0.0,0.0,0.9904,0.01,ito:ITO_00101,Vision process,F1\\ score
8,1,Retinal Vessel Segmentation,STARE,2015-05,U-Net,0.8373,98.8,0.8373,0.99,0.8475,0.01,ito:ITO_00101,Vision process,F1\\ score
9,1,Retinal Vessel Segmentation,STARE,2017-11,Residual U-Net,0.8388,98.97,0.0,0.0,0.8475,0.01,ito:ITO_00101,Vision process,F1\\ score
10,1,Retinal Vessel Segmentation,STARE,2018-02,R2U-Net,0.8475,100.0,0.0,0.0,0.8475,0.01,ito:ITO_00101,Vision process,F1\\ score
11,1,Retinal Vessel Segmentation,DRIVE,2015-05,U-Net,0.8142,98.54,0.8142,0.99,0.8263,0.01,ito:ITO_00101,Vision process,F1\\ score
12,1,Retinal Vessel Segmentation,DRIVE,2017-11,Residual U-Net,0.8149,98.62,0.0,0.0,0.8263,0.01,ito:ITO_00101,Vision process,F1\\ score
13,1,Retinal Vessel Segmentation,DRIVE,2018-06,VGN,0.8263,100.0,0.0,0.0,0.8263,0.01,ito:ITO_00101,Vision process,F1\\ score
14,1,Skin Cancer Segmentation,Kaggle Skin Lesion Segmentation,2015-05,U-Net,0.8682,97.33,0.8682,0.97,0.892,0.01,ito:ITO_00101,Vision process,F1\\ score
15,1,Skin Cancer Segmentation,Kaggle Skin Lesion Segmentation,2017-11,Residual U-Net,0.8799,98.64,0.0,0.0,0.892,0.01,ito:ITO_00101,Vision process,F1\\ score
16,1,Skin Cancer Segmentation,Kaggle Skin Lesion Segmentation,2018-02,R2U-Net,0.892,100.0,0.0,0.0,0.892,0.01,ito:ITO_00101,Vision process,F1\\ score
17,1,Lane Detection,CULane,2017-12,SCNN,71.6,100.0,71.6,1.0,71.6,0.74,ito:ITO_00101,Vision process,F1\\ score
18,1,Lane Detection,TuSimple,2017-12,Spatial CNN,95.97,99.7,95.97,1.0,96.26,1.0,ito:ITO_00101,Vision process,F1\\ score
19,1,Lane Detection,TuSimple,2018-06,EL-GAN,96.26,100.0,0.3,0.0,96.26,1.0,ito:ITO_00101,Vision process,F1\\ score
20,1,Line Segment Detection,wireframe dataset,2018-06,Wireframe parser,0.728,89.22,0.728,0.89,0.816,0.01,ito:ITO_00101,Vision process,F1\\ score
21,1,Line Segment Detection,wireframe dataset,2019-02,atrous Residual U-Net,0.773,94.73,0.0,0.0,0.816,0.01,ito:ITO_00101,Vision process,F1\\ score
22,1,Line Segment Detection,wireframe dataset,2019-05,L-CNN,0.816,100.0,0.0,0.0,0.816,0.01,ito:ITO_00101,Vision process,F1\\ score
23,1,Line Segment Detection,York Urban Dataset,2018-06,Wireframe parser,0.627,97.06,0.627,0.97,0.646,0.01,ito:ITO_00101,Vision process,F1\\ score
24,1,Line Segment Detection,York Urban Dataset,2019-02,atrous Residual U-Net,0.646,100.0,0.0,0.0,0.646,0.01,ito:ITO_00101,Vision process,F1\\ score
25,1,Retinal Vessel Segmentation,HRF,2018-06,VGN,0.8151,100.0,0.8151,1.0,0.8151,0.01,ito:ITO_00101,Vision process,F1\\ score
26,1,Medical Image Segmentation,DRIVE,2019-08,BCDU-net,0.8222,100.0,0.8222,1.0,0.8222,0.01,ito:ITO_00101,Vision process,F1\\ score
0,1,Video Retrieval,YouCook2,2015-06,HGLMM FV CCA,75.0,100.0,75,1.0,75,1.0,ito:ITO_00101,Vision process,text\\-to\\-video\\ Median\\ Rank
1,1,Video Retrieval,MSR-VTT,2016-09,C+LSTM+SA+FC7,55.0,100.0,55.0,1.0,55.0,0.73,ito:ITO_00101,Vision process,text\\-to\\-video\\ Median\\ Rank
2,1,Video Retrieval,LSMDC,2016-10,CT-SAN,46.0,88.46,46,0.88,52,0.61,ito:ITO_00101,Vision process,text\\-to\\-video\\ Median\\ Rank
3,1,Video Retrieval,LSMDC,2017-07,Large-Scale Discriminative Clustering,52.0,100.0,6,0.12,52,0.69,ito:ITO_00101,Vision process,text\\-to\\-video\\ Median\\ Rank
4,1,Video Retrieval,MSR-VTT-1kA,2018-08,JSFusion,13.0,100.0,13,1.0,13,0.17,ito:ITO_00101,Vision process,text\\-to\\-video\\ Median\\ Rank
5,1,Video Retrieval,MSVD,2019-07,Collaborative Experts,6.0,100.0,6,1.0,6,0.08,ito:ITO_00101,Vision process,text\\-to\\-video\\ Median\\ Rank
6,1,Video Retrieval,ActivityNet,2019-07,Collaborative Experts,6.0,100.0,6,1.0,6,0.08,ito:ITO_00101,Vision process,text\\-to\\-video\\ Median\\ Rank
7,1,Video Retrieval,DiDeMo,2019-07,Collaborative Experts,8.3,100.0,8.3,1.0,8.3,0.11,ito:ITO_00101,Vision process,text\\-to\\-video\\ Median\\ Rank
0,1,Video Retrieval,YouCook2,2015-06,HGLMM FV CCA,4.6,56.1,4.6,0.56,8.2,0.22,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
1,1,Video Retrieval,YouCook2,2019-06,Text-Video Embedding,8.2,100.0,3.6,0.44,8.2,0.39,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
2,1,Video Retrieval,MSR-VTT,2016-09,C+LSTM+SA+FC7,4.2,28.19,4.2,0.28,14.9,0.2,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
3,1,Video Retrieval,MSR-VTT,2016-12,Kaufman,4.7,31.54,0.5,0.03,14.9,0.22,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
4,1,Video Retrieval,MSR-VTT,2018-06,JEMC,7.0,46.98,2.3,0.15,14.9,0.33,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
5,1,Video Retrieval,MSR-VTT,2018-08,JSFusion,10.2,68.46,3.2,0.21,14.9,0.49,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
6,1,Video Retrieval,MSR-VTT,2019-06,Text-Video Embedding,14.9,100.0,4.7,0.32,14.9,0.71,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
7,1,Video Retrieval,LSMDC,2016-10,CT-SAN,5.1,45.54,5.1,0.46,11.2,0.24,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
8,1,Video Retrieval,LSMDC,2017-07,Large-Scale Discriminative Clustering,7.3,65.18,2.2,0.2,11.2,0.35,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
9,1,Video Retrieval,LSMDC,2018-04,MoEE,10.1,90.18,2.8,0.25,11.2,0.48,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
10,1,Video Retrieval,LSMDC,2019-07,Collaborative Experts,11.2,100.0,1.1,0.1,11.2,0.54,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
11,1,Video Retrieval,MSR-VTT-1kA,2018-08,JSFusion,10.2,48.8,10.2,0.49,20.9,0.49,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
12,1,Video Retrieval,MSR-VTT-1kA,2019-06,HT-Pretrained,14.9,71.29,4.7,0.22,20.9,0.71,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
13,1,Video Retrieval,MSR-VTT-1kA,2019-07,Collaborative Experts,20.9,100.0,6.0,0.29,20.9,1.0,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
14,1,Video Retrieval,DiDeMo,2019-07,Collaborative Experts,16.1,100.0,16.1,1.0,16.1,0.77,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
15,1,Video Retrieval,MSVD,2019-07,Collaborative Experts,19.8,97.54,19.8,0.98,20.3,0.95,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
16,1,Video Retrieval,MSVD,2020-03,SSML,20.3,100.0,0.5,0.02,20.3,0.97,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
17,1,Video Retrieval,ActivityNet,2019-07,Collaborative Experts,20.5,100.0,20.5,1.0,20.5,0.98,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-1
0,1,Video Retrieval,YouCook2,2015-06,HGLMM FV CCA,14.3,58.37,14.3,0.58,24.5,0.29,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-5
1,1,Video Retrieval,YouCook2,2019-06,Text-Video Embedding,24.5,100.0,10.2,0.42,24.5,0.5,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-5
2,1,Video Retrieval,LSMDC,2016-10,CT-SAN,16.3,60.59,16.3,0.61,26.9,0.33,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-5
3,1,Video Retrieval,LSMDC,2017-07,Large-Scale Discriminative Clustering,19.2,71.38,2.9,0.11,26.9,0.39,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-5
4,1,Video Retrieval,LSMDC,2018-04,MoEE,25.6,95.17,6.4,0.24,26.9,0.52,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-5
5,1,Video Retrieval,LSMDC,2019-07,Collaborative Experts,26.9,100.0,1.3,0.05,26.9,0.55,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-5
6,1,Video Retrieval,MSR-VTT,2018-06,JEMC,20.9,72.07,20.9,0.72,29.0,0.43,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-5
7,1,Video Retrieval,MSR-VTT,2019-07,Collaborative Experts,29.0,100.0,8.1,0.28,29.0,0.59,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-5
8,1,Video Retrieval,MSR-VTT-1kA,2018-08,JSFusion,31.2,63.93,31.2,0.64,48.8,0.64,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-5
9,1,Video Retrieval,MSR-VTT-1kA,2019-06,HT-Pretrained,40.2,82.38,9.0,0.18,48.8,0.82,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-5
10,1,Video Retrieval,MSR-VTT-1kA,2019-07,Collaborative Experts,48.8,100.0,8.6,0.18,48.8,1.0,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-5
11,1,Video Retrieval,DiDeMo,2019-07,Collaborative Experts,41.1,100.0,41.1,1.0,41.1,0.84,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-5
12,1,Video Retrieval,MSVD,2019-07,Collaborative Experts,49.0,100.0,49,1.0,49,1.0,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-5
13,1,Video Retrieval,ActivityNet,2019-07,Collaborative Experts,47.7,100.0,47.7,1.0,47.7,0.97,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-5
0,1,Video Retrieval,YouCook2,2015-06,HGLMM FV CCA,21.6,61.19,21.6,0.61,35.3,0.34,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
1,1,Video Retrieval,YouCook2,2019-06,Text-Video Embedding,35.3,100.0,13.7,0.39,35.3,0.55,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
2,1,Video Retrieval,MSR-VTT,2016-09,C+LSTM+SA+FC7,19.9,37.69,19.9,0.38,52.8,0.31,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
3,1,Video Retrieval,MSR-VTT,2016-12,Kaufman,24.1,45.64,4.2,0.08,52.8,0.38,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
4,1,Video Retrieval,MSR-VTT,2018-06,JEMC,29.7,56.25,5.6,0.11,52.8,0.46,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
5,1,Video Retrieval,MSR-VTT,2018-08,JSFusion,43.2,81.82,13.5,0.26,52.8,0.68,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
6,1,Video Retrieval,MSR-VTT,2019-06,Text-Video Embedding,52.8,100.0,9.6,0.18,52.8,0.83,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
7,1,Video Retrieval,LSMDC,2016-10,CT-SAN,25.2,72.41,25.2,0.72,34.8,0.39,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
8,1,Video Retrieval,LSMDC,2017-07,Large-Scale Discriminative Clustering,27.1,77.87,1.9,0.05,34.8,0.42,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
9,1,Video Retrieval,LSMDC,2018-04,MoEE,34.6,99.43,7.5,0.22,34.8,0.54,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
10,1,Video Retrieval,LSMDC,2019-07,Collaborative Experts,34.8,100.0,0.2,0.01,34.8,0.54,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
11,1,Video Retrieval,MSR-VTT-1kA,2018-08,JSFusion,43.2,69.23,43.2,0.69,62.4,0.68,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
12,1,Video Retrieval,MSR-VTT-1kA,2019-06,HT-Pretrained,52.8,84.62,9.6,0.15,62.4,0.83,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
13,1,Video Retrieval,MSR-VTT-1kA,2019-07,Collaborative Experts,62.4,100.0,9.6,0.15,62.4,0.98,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
14,1,Video Retrieval,MSVD,2019-07,Collaborative Experts,63.8,100.0,63.8,1.0,63.8,1.0,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
15,1,Video Retrieval,DiDeMo,2019-07,Collaborative Experts,54.4,100.0,54.4,1.0,54.4,0.85,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
16,1,Video Retrieval,ActivityNet,2019-07,Collaborative Experts,63.9,100.0,63.9,1.0,63.9,1.0,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-10
0,1,Object Counting,CARPK,2015-06,Faster R-CNN (2015),39.88,25.56,39.88,0.26,156.0,0.02,ito:ITO_00101,Vision process,MAE
1,1,Object Counting,CARPK,2015-06,YOLO (2016),156.0,100.0,116.1,0.74,156.0,0.08,ito:ITO_00101,Vision process,MAE
2,1,Crowd Counting,UCF-QNRF,2015-11,Encoder-Decoder,270.0,100.0,270,1.0,270,0.14,ito:ITO_00101,Vision process,MAE
3,1,Head Pose Estimation,AFLW2000,2015-11,3DDFA,7.393,81.1,7.393,0.81,9.116,0.0,ito:ITO_00101,Vision process,MAE
4,1,Head Pose Estimation,AFLW2000,2017-03,FAN (12 points),9.116,100.0,1.7,0.19,9.116,0.0,ito:ITO_00101,Vision process,MAE
5,1,Head Pose Estimation,BIWI,2015-11,3DDFA,19.068,100.0,19.068,1.0,19.068,0.01,ito:ITO_00101,Vision process,MAE
6,1,RGB Salient Object Detection,DUTS-TE,2016-03,DCL,0.081,69.83,0.081,0.7,0.116,0.0,ito:ITO_00101,Vision process,MAE
7,1,RGB Salient Object Detection,DUTS-TE,2017-08,UCF,0.116,100.0,0.0,0.0,0.116,0.0,ito:ITO_00101,Vision process,MAE
8,1,Salient Object Detection,DUTS-TE,2016-03,DCL,0.081,69.83,0.081,0.7,0.116,0.0,ito:ITO_00101,Vision process,MAE
9,1,Salient Object Detection,DUTS-TE,2017-08,UCF,0.116,100.0,0.0,0.0,0.116,0.0,ito:ITO_00101,Vision process,MAE
10,1,Head Pose Estimation,BJUT-3D,2016-11,Ours DLDL (KL),0.09,100.0,0.09,1.0,0.09,0.0,ito:ITO_00101,Vision process,MAE
11,1,Head Pose Estimation,AFLW,2016-11,DLDL (KL),9.78,100.0,9.78,1.0,9.78,0.01,ito:ITO_00101,Vision process,MAE
12,1,Head Pose Estimation,Pointing'04,2016-11,Ours DLDL (KL),4.64,100.0,4.64,1.0,4.64,0.0,ito:ITO_00101,Vision process,MAE
13,1,Age Estimation,ChaLearn 2015,2016-11,DLDL+VGG-Face,3.51,100.0,3.51,1.0,3.51,0.0,ito:ITO_00101,Vision process,MAE
14,1,Age Estimation,MORPH Album2,2016-11,"DLDL+VGG-Face (KL, Max)3",2.42,93.44,2.42,0.93,2.59,0.0,ito:ITO_00101,Vision process,MAE
15,1,Age Estimation,MORPH Album2,2019-01,CORAL,2.59,100.0,0.2,0.08,2.59,0.0,ito:ITO_00101,Vision process,MAE
16,1,Formation Energy,QM9,2017-02,HDAD+KRR,0.58,100.0,0.58,1.0,0.58,0.0,ito:ITO_00101,Vision process,MAE
17,1,Crowd Counting,ShanghaiTech B,2017-07,Cascaded-MTL,20.0,100.0,20.0,1.0,20.0,0.01,ito:ITO_00101,Vision process,MAE
18,1,Crowd Counting,UCF CC 50,2017-07,Cascaded-MTL,322.8,100.0,322.8,1.0,322.8,0.17,ito:ITO_00101,Vision process,MAE
19,1,Crowd Counting,ShanghaiTech A,2017-07,Proposed method,101.3,100.0,101.3,1.0,101.3,0.05,ito:ITO_00101,Vision process,MAE
20,1,Saliency Detection,DUT-OMRON,2017-08,UCF,0.1203,100.0,0.1203,1.0,0.1203,0.0,ito:ITO_00101,Vision process,MAE
21,1,Depth Completion,KITTI Depth Completion,2017-08,SparseConvs,481.0,100.0,481.0,1.0,481.0,0.25,ito:ITO_00101,Vision process,MAE
22,1,Formation Energy,Materials Project,2017-10,CGCNN,39.0,95.12,39.0,0.95,41.0,0.02,ito:ITO_00101,Vision process,MAE
23,1,Formation Energy,Materials Project,2018-11,MT-CGCNN,41.0,100.0,2.0,0.05,41.0,0.02,ito:ITO_00101,Vision process,MAE
24,1,Band Gap,Materials Project,2017-10,CGCNN,0.388,100.0,0.388,1.0,0.388,0.0,ito:ITO_00101,Vision process,MAE
25,1,Video Prediction,Human3.6M,2017-12,PredRNN,1895.2,99.69,1895.2,1.0,1901.1,1.0,ito:ITO_00101,Vision process,MAE
26,1,Video Prediction,Human3.6M,2017-12,FRNN,1901.1,100.0,5.9,0.0,1901.1,1.0,ito:ITO_00101,Vision process,MAE
27,1,Facial Beauty Prediction,SCUT-FBP,2018-01,Combined Features + Gaussian Reg,0.3931,100.0,0.3931,1.0,0.3931,0.0,ito:ITO_00101,Vision process,MAE
28,1,Age Estimation,FGNET,2018-04,CMAAE-OR,3.62,6.96,3.62,0.07,52.0,0.0,ito:ITO_00101,Vision process,MAE
29,1,Age Estimation,FGNET,2018-04,Zhu et al. (Actual),4.58,8.81,1.0,0.02,52.0,0.0,ito:ITO_00101,Vision process,MAE
30,1,Age Estimation,FGNET,2019-04,AEBFI,52.0,100.0,47.4,0.91,52.0,0.03,ito:ITO_00101,Vision process,MAE
31,1,Age Estimation,MORPH,2018-04,CMAAE-OR,1.48,100.0,1.48,1.0,1.48,0.0,ito:ITO_00101,Vision process,MAE
32,1,Salient Object Detection,PASCAL-S,2018-06,BMPM,0.074,74.75,0.074,0.75,0.099,0.0,ito:ITO_00101,Vision process,MAE
33,1,Salient Object Detection,PASCAL-S,2019-04,DSS (Res2Net-50),0.099,100.0,0.0,0.0,0.099,0.0,ito:ITO_00101,Vision process,MAE
34,1,RGB Salient Object Detection,SOD,2018-06,BMPM,0.108,94.74,0.108,0.95,0.114,0.0,ito:ITO_00101,Vision process,MAE
35,1,RGB Salient Object Detection,SOD,2019-06,BASNet,0.114,100.0,0.0,0.0,0.114,0.0,ito:ITO_00101,Vision process,MAE
36,1,RGB Salient Object Detection,PASCAL-S,2018-06,BMPM,0.074,97.37,0.074,0.97,0.076,0.0,ito:ITO_00101,Vision process,MAE
37,1,RGB Salient Object Detection,PASCAL-S,2019-06,BASNet,0.076,100.0,0.0,0.0,0.076,0.0,ito:ITO_00101,Vision process,MAE
38,1,Salient Object Detection,SOD,2018-06,BMPM,0.108,94.74,0.108,0.95,0.114,0.0,ito:ITO_00101,Vision process,MAE
39,1,Salient Object Detection,SOD,2019-06,BASNet,0.114,100.0,0.0,0.0,0.114,0.0,ito:ITO_00101,Vision process,MAE
40,1,Steering Control,Comma.ai,2018-11,FM-Net,0.7048,100.0,0.7048,1.0,0.7048,0.0,ito:ITO_00101,Vision process,MAE
41,1,Steering Control,Udacity,2018-11,FM-Net,1.6236,100.0,1.6236,1.0,1.6236,0.0,ito:ITO_00101,Vision process,MAE
42,1,Age Estimation,UTKFace,2019-01,CORAL,5.39,100.0,5.39,1.0,5.39,0.0,ito:ITO_00101,Vision process,MAE
43,1,Age Estimation,AFAD,2019-01,CORAL,3.48,100.0,3.48,1.0,3.48,0.0,ito:ITO_00101,Vision process,MAE
44,1,Age Estimation,CACD,2019-01,CORAL,5.35,100.0,5.35,1.0,5.35,0.0,ito:ITO_00101,Vision process,MAE
45,1,Saliency Detection,HKU-IS,2019-03,Pyramid Feature Attention,0.0324,100.0,0.0324,1.0,0.0324,0.0,ito:ITO_00101,Vision process,MAE
46,1,Saliency Detection,DUTS-test,2019-03,Pyramid Feature Attention,0.0405,100.0,0.0405,1.0,0.0405,0.0,ito:ITO_00101,Vision process,MAE
47,1,Saliency Detection,ECSSD,2019-03,Pyramid Feature Attention,0.0328,100.0,0.0328,1.0,0.0328,0.0,ito:ITO_00101,Vision process,MAE
48,1,Saliency Detection,PASCAL-S,2019-03,Pyramid Feature Attention,0.0677,100.0,0.0677,1.0,0.0677,0.0,ito:ITO_00101,Vision process,MAE
49,1,Salient Object Detection,HKU-IS,2019-04,DSS (Res2Net-50),0.05,100.0,0.05,1.0,0.05,0.0,ito:ITO_00101,Vision process,MAE
50,1,Salient Object Detection,ECSSD,2019-04,DSS (Res2Net-50),0.056,100.0,0.056,1.0,0.056,0.0,ito:ITO_00101,Vision process,MAE
51,1,Salient Object Detection,DUT-OMRON,2019-04,DSS (Res2Net-50),0.071,100.0,0.071,1.0,0.071,0.0,ito:ITO_00101,Vision process,MAE
52,1,RGB Salient Object Detection,ECSSD,2019-04,CPD-R (ResNet50),0.037,97.37,0.037,0.97,0.038,0.0,ito:ITO_00101,Vision process,MAE
53,1,RGB Salient Object Detection,ECSSD,2019-04,PoolNet (VGG-16),0.038,100.0,0.0,0.0,0.038,0.0,ito:ITO_00101,Vision process,MAE
54,1,RGB Salient Object Detection,HKU-IS,2019-04,CPD-R (ResNet50),0.034,100.0,0.034,1.0,0.034,0.0,ito:ITO_00101,Vision process,MAE
55,1,Salient Object Detection,DUTS-test,2019-04,CPD-R (ResNet50),0.043,100.0,0.043,1.0,0.043,0.0,ito:ITO_00101,Vision process,MAE
56,1,RGB Salient Object Detection,DUT-OMRON,2019-04,CPD-R (ResNet50),0.056,100.0,0.056,1.0,0.056,0.0,ito:ITO_00101,Vision process,MAE
57,1,Camouflaged Object Segmentation,COD,2019-04,CPD,0.059,56.19,0.059,0.56,0.105,0.0,ito:ITO_00101,Vision process,MAE
58,1,Camouflaged Object Segmentation,COD,2019-06,BASNet,0.105,100.0,0.0,0.0,0.105,0.0,ito:ITO_00101,Vision process,MAE
59,1,RGB Salient Object Detection,DUTS-test,2019-04,CPD-R (ResNet50),0.043,100.0,0.043,1.0,0.043,0.0,ito:ITO_00101,Vision process,MAE
60,1,Depth Completion,VOID,2019-05,VOICED,85.05,100.0,85.05,1.0,85.05,0.04,ito:ITO_00101,Vision process,MAE
61,1,Formation Energy,OQMD v1.2,2019-05,CGNN Ensemble,30.5,85.43,30.5,0.85,35.7,0.02,ito:ITO_00101,Vision process,MAE
62,1,Formation Energy,OQMD v1.2,2019-05,CGNN-192,34.6,96.92,4.1,0.11,35.7,0.02,ito:ITO_00101,Vision process,MAE
63,1,Formation Energy,OQMD v1.2,2019-05,CGNN-160,35.1,98.32,0.5,0.01,35.7,0.02,ito:ITO_00101,Vision process,MAE
64,1,Formation Energy,OQMD v1.2,2019-05,CGNN-128,35.7,100.0,0.6,0.02,35.7,0.02,ito:ITO_00101,Vision process,MAE
65,1,Band Gap,OQMD v1.2,2019-05,CGNN Ensemble,0.0461,100.0,0.0461,1.0,0.0461,0.0,ito:ITO_00101,Vision process,MAE
66,1,Total Magnetization,OQMD v1.2,2019-05,CGNN Ensemble,0.0691,100.0,0.0691,1.0,0.0691,0.0,ito:ITO_00101,Vision process,MAE
67,1,Camouflaged Object Segmentation,CAMO,2019-06,BASNet,0.159,100.0,0.159,1.0,0.159,0.0,ito:ITO_00101,Vision process,MAE
68,1,Crowd Counting,ShanghaiTech,2020-01,CC-Mod,73.8,100.0,73.8,1.0,73.8,0.04,ito:ITO_00101,Vision process,MAE
0,1,Real-Time Object Detection,PASCAL VOC 2007,2015-06,Faster R-CNN,7.0,15.22,7.0,0.15,46.0,0.06,ito:ITO_00101,Vision process,FPS
1,1,Real-Time Object Detection,PASCAL VOC 2007,2015-06,YOLO,46.0,100.0,39.0,0.85,46.0,0.37,ito:ITO_00101,Vision process,FPS
2,1,Keypoint Detection,COCO,2016-12,AlphaPose,23.0,100.0,23,1.0,23,0.19,ito:ITO_00101,Vision process,FPS
3,1,Real-Time Object Detection,COCO,2017-03,Mask R-CNN X-152-32x8d,3.0,2.42,3.0,0.02,124.0,0.02,ito:ITO_00101,Vision process,FPS
4,1,Real-Time Object Detection,COCO,2018-04,YOLOv3-418,34.0,27.42,31.0,0.25,124.0,0.27,ito:ITO_00101,Vision process,FPS
5,1,Real-Time Object Detection,COCO,2018-04,YOLOv3-320,45.0,36.29,11.0,0.09,124.0,0.36,ito:ITO_00101,Vision process,FPS
6,1,Real-Time Object Detection,COCO,2019-09,TTFNet,54.4,43.87,9.4,0.08,124.0,0.44,ito:ITO_00101,Vision process,FPS
7,1,Real-Time Object Detection,COCO,2019-11,CSPResNeXt50-PANet-SPP,58.0,46.77,3.6,0.03,124.0,0.47,ito:ITO_00101,Vision process,FPS
8,1,Real-Time Object Detection,COCO,2020-04,YOLOv4-608,62.0,50.0,4.0,0.03,124.0,0.5,ito:ITO_00101,Vision process,FPS
9,1,Real-Time Object Detection,COCO,2020-04,YOLOv4-416,96.0,77.42,34.0,0.27,124.0,0.77,ito:ITO_00101,Vision process,FPS
10,1,Real-Time Object Detection,COCO,2020-04,YOLOv4-320,124.0,100.0,28.0,0.23,124.0,1.0,ito:ITO_00101,Vision process,FPS
11,1,Multi-Person Pose Estimation,CrowdPose,2018-12,Joint-candidate SPPE +,10.1,100.0,10.1,1.0,10.1,0.08,ito:ITO_00101,Vision process,FPS
12,1,Hand Pose Estimation,ICVL Hands,2019-08,A2J,105.06,100.0,105.06,1.0,105.06,0.85,ito:ITO_00101,Vision process,FPS
13,1,Hand Pose Estimation,NYU Hands,2019-08,A2J,105.06,100.0,105.06,1.0,105.06,0.85,ito:ITO_00101,Vision process,FPS
14,1,3D Pose Estimation,K2HPD,2019-08,A2J,93.78,100.0,93.78,1.0,93.78,0.76,ito:ITO_00101,Vision process,FPS
0,1,Dense Object Detection,SKU-110K,2015-06,Faster-RCNN,0.01,1.8,0.01,0.02,0.556,0.0,ito:ITO_00101,Vision process,AP75
1,1,Dense Object Detection,SKU-110K,2016-12,YOLO9000opt,0.073,13.13,0.1,0.18,0.556,0.0,ito:ITO_00101,Vision process,AP75
2,1,Dense Object Detection,SKU-110K,2017-08,RetinaNet,0.389,69.96,0.3,0.54,0.556,0.0,ito:ITO_00101,Vision process,AP75
3,1,Dense Object Detection,SKU-110K,2019-04,Soft-IoU + EM-Merger unit,0.556,100.0,0.2,0.36,0.556,0.01,ito:ITO_00101,Vision process,AP75
4,1,Object Detection,COCO test-dev,2015-12,SSD512,30.3,51.79,30.3,0.52,58.5,0.36,ito:ITO_00101,Vision process,AP75
5,1,Object Detection,COCO test-dev,2017-03,Mask R-CNN (ResNet-101-FPN),41.7,71.28,11.4,0.19,58.5,0.49,ito:ITO_00101,Vision process,AP75
6,1,Object Detection,COCO test-dev,2017-03,Mask R-CNN (ResNeXt-101-FPN),43.4,74.19,1.7,0.03,58.5,0.51,ito:ITO_00101,Vision process,AP75
7,1,Object Detection,COCO test-dev,2017-08,RetinaNet (ResNeXt-101-FPN),44.1,75.38,0.7,0.01,58.5,0.52,ito:ITO_00101,Vision process,AP75
8,1,Object Detection,COCO test-dev,2017-11,RefineDet512+ (ResNet-101),45.7,78.12,1.6,0.03,58.5,0.54,ito:ITO_00101,Vision process,AP75
9,1,Object Detection,COCO test-dev,2017-11,"D-RFCN + SNIP (DPN-98 with flip, multi-scale)",51.1,87.35,5.4,0.09,58.5,0.6,ito:ITO_00101,Vision process,AP75
10,1,Object Detection,COCO test-dev,2018-03,"PANet (ResNeXt-101, multi-scale)",51.8,88.55,0.7,0.01,58.5,0.61,ito:ITO_00101,Vision process,AP75
11,1,Object Detection,COCO test-dev,2019-01,"TridentNet (ResNet-101-Deformable, Image Pyramid)",53.5,91.45,1.7,0.03,58.5,0.63,ito:ITO_00101,Vision process,AP75
12,1,Object Detection,COCO test-dev,2019-09,"Cascade Mask R-CNN (Triple-ResNeXt152, multi-scale)",58.5,100.0,5.0,0.09,58.5,0.69,ito:ITO_00101,Vision process,AP75
13,1,Instance Segmentation,COCO test-dev,2015-12,MNC,24.8,52.32,24.8,0.52,47.4,0.29,ito:ITO_00101,Vision process,AP75
14,1,Instance Segmentation,COCO test-dev,2017-03,Mask R-CNN (ResNeXt-101-FPN),39.4,83.12,14.6,0.31,47.4,0.47,ito:ITO_00101,Vision process,AP75
15,1,Instance Segmentation,COCO test-dev,2019-08,"Cascade R-CNN (ResNet-101-FPN, map-guided)",42.9,90.51,3.5,0.07,47.4,0.51,ito:ITO_00101,Vision process,AP75
16,1,Instance Segmentation,COCO test-dev,2019-11,CenterMask + VoVNetV2-99 (multi-scale),47.4,100.0,4.5,0.09,47.4,0.56,ito:ITO_00101,Vision process,AP75
17,1,Keypoint Detection,COCO test-dev,2016-11,AE,72.3,85.56,72.3,0.86,84.5,0.85,ito:ITO_00101,Vision process,AP75
18,1,Keypoint Detection,COCO test-dev,2017-11,CPN,80.0,94.67,7.7,0.09,84.5,0.95,ito:ITO_00101,Vision process,AP75
19,1,Keypoint Detection,COCO test-dev,2017-11,CPN+,80.9,95.74,0.9,0.01,84.5,0.96,ito:ITO_00101,Vision process,AP75
20,1,Keypoint Detection,COCO test-dev,2018-04,Simple Base,81.1,95.98,0.2,0.0,84.5,0.96,ito:ITO_00101,Vision process,AP75
21,1,Keypoint Detection,COCO test-dev,2018-04,Simple Base+*,84.0,99.41,2.9,0.03,84.5,0.99,ito:ITO_00101,Vision process,AP75
22,1,Keypoint Detection,COCO test-dev,2019-02,HRNet*,84.5,100.0,0.5,0.01,84.5,1.0,ito:ITO_00101,Vision process,AP75
23,1,Multi-Person Pose Estimation,COCO test-dev,2016-11,CMU-Pose,67.5,87.44,67.5,0.87,77.2,0.8,ito:ITO_00101,Vision process,AP75
24,1,Multi-Person Pose Estimation,COCO test-dev,2016-12,RMPE,69.8,90.41,2.3,0.03,77.2,0.83,ito:ITO_00101,Vision process,AP75
25,1,Multi-Person Pose Estimation,COCO test-dev,2017-01,G-RMI,71.3,92.36,1.5,0.02,77.2,0.84,ito:ITO_00101,Vision process,AP75
26,1,Multi-Person Pose Estimation,COCO test-dev,2018-03,PersonLab,75.4,97.67,4.1,0.05,77.2,0.89,ito:ITO_00101,Vision process,AP75
27,1,Multi-Person Pose Estimation,COCO test-dev,2019-08,HigherHRNet (HR-Net-48),77.2,100.0,1.8,0.02,77.2,0.91,ito:ITO_00101,Vision process,AP75
28,1,Pose Estimation,COCO test-dev,2016-11,CMU-Pose,67.5,79.79,67.5,0.8,84.6,0.8,ito:ITO_00101,Vision process,AP75
29,1,Pose Estimation,COCO test-dev,2016-12,RMPE++,79.1,93.5,11.6,0.14,84.6,0.93,ito:ITO_00101,Vision process,AP75
30,1,Pose Estimation,COCO test-dev,2017-11,CPN,80.0,94.56,0.9,0.01,84.6,0.95,ito:ITO_00101,Vision process,AP75
31,1,Pose Estimation,COCO test-dev,2017-11,"CPN+ [6, 9]",80.9,95.63,0.9,0.01,84.6,0.96,ito:ITO_00101,Vision process,AP75
32,1,Pose Estimation,COCO test-dev,2018-04,Flow-based (ResNet-152),81.1,95.86,0.2,0.0,84.6,0.96,ito:ITO_00101,Vision process,AP75
33,1,Pose Estimation,COCO test-dev,2018-12,PoseFix,81.9,96.81,0.8,0.01,84.6,0.97,ito:ITO_00101,Vision process,AP75
34,1,Pose Estimation,COCO test-dev,2019-01,MSPN,83.8,99.05,1.9,0.02,84.6,0.99,ito:ITO_00101,Vision process,AP75
35,1,Pose Estimation,COCO test-dev,2019-02,HRNet-W48,84.5,99.88,0.7,0.01,84.6,1.0,ito:ITO_00101,Vision process,AP75
36,1,Pose Estimation,COCO test-dev,2019-10,DARK (extra data),84.6,100.0,0.1,0.0,84.6,1.0,ito:ITO_00101,Vision process,AP75
37,1,Object Detection,COCO minival,2016-12,FPN+,43.3,75.87,43.3,0.76,57.07,0.51,ito:ITO_00101,Vision process,AP75
38,1,Object Detection,COCO minival,2017-11,Mask R-CNN (ResNeXt-152 + 1 NL),48.9,85.68,5.6,0.1,57.07,0.58,ito:ITO_00101,Vision process,AP75
39,1,Object Detection,COCO minival,2018-11,Mask R-CNN (ResNeXt-152-FPN),51.1,89.54,2.2,0.04,57.07,0.6,ito:ITO_00101,Vision process,AP75
40,1,Object Detection,COCO minival,2018-11,"Mask R-CNN (ResNeXt-152-FPN, cascade)",52.9,92.69,1.8,0.03,57.07,0.63,ito:ITO_00101,Vision process,AP75
41,1,Object Detection,COCO minival,2019-12,"RetinaNet (SpineNet-190, single-scale)",56.5,99.0,3.6,0.06,57.07,0.67,ito:ITO_00101,Vision process,AP75
42,1,Object Detection,COCO minival,2020-04,ResNeSt-200 (multi-scale),57.07,100.0,0.6,0.01,57.07,0.67,ito:ITO_00101,Vision process,AP75
43,1,Keypoint Detection,COCO test-challenge,2017-01,G-RMI*,75.2,91.04,75.2,0.91,82.6,0.89,ito:ITO_00101,Vision process,AP75
44,1,Keypoint Detection,COCO test-challenge,2017-11,CPN+,78.9,95.52,3.7,0.04,82.6,0.93,ito:ITO_00101,Vision process,AP75
45,1,Keypoint Detection,COCO test-challenge,2018-04,Simple Base+*,80.8,97.82,1.9,0.02,82.6,0.96,ito:ITO_00101,Vision process,AP75
46,1,Keypoint Detection,COCO test-challenge,2019-01,MSPN+*,82.6,100.0,1.8,0.02,82.6,0.98,ito:ITO_00101,Vision process,AP75
47,1,Video Instance Segmentation,YouTube-VIS validation,2018-02,OSMN,29.1,100.0,29.1,1.0,29.1,0.34,ito:ITO_00101,Vision process,AP75
48,1,3D object detection from stereo images,KITTI Cars Moderate,2018-12,Pseudo-LiDAR,34.05,80.25,34.05,0.8,42.43,0.4,ito:ITO_00101,Vision process,AP75
49,1,3D object detection from stereo images,KITTI Cars Moderate,2020-01,Pseudo-LiDAR++,42.43,100.0,8.4,0.2,42.43,0.5,ito:ITO_00101,Vision process,AP75
50,1,Instance Segmentation,COCO minival,2019-03,"Mask R-CNN-FPN (ResNeXt-101, GN+WS)",40.82,94.27,40.82,0.94,43.3,0.48,ito:ITO_00101,Vision process,AP75
51,1,Instance Segmentation,COCO minival,2019-08,Mask R-CNN-FPN (AOGNet-40M),43.3,100.0,2.5,0.06,43.3,0.51,ito:ITO_00101,Vision process,AP75
52,1,Real-time Instance Segmentation,MSCOCO,2019-04,YOLACT-550 (ResNet-101-FPN),29.2,100.0,29.2,1.0,29.2,0.35,ito:ITO_00101,Vision process,AP75
53,1,3D Object Detection,nuScenes-FB,2019-05,RRPN + R101,37.0,100.0,37,1.0,37,0.44,ito:ITO_00101,Vision process,AP75
54,1,3D Object Detection,nuScenes-F,2019-05,RRPN + R101,48.5,100.0,48.5,1.0,48.5,0.57,ito:ITO_00101,Vision process,AP75
0,1,Gesture Recognition,Montalbano,2015-06,Temp Conv + LSTM,90.6,100.0,90.6,1.0,90.6,1.0,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
1,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2016-06,OFL,68.0,78.52,68.0,0.79,86.6,0.75,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
2,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2016-11,OSVOS,79.8,92.15,11.8,0.14,86.6,0.88,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
3,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2017-06,OnAVOS,86.1,99.42,6.3,0.07,86.6,0.95,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
4,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2019-08,RANet+ (online learning),86.6,100.0,0.5,0.01,86.6,0.96,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
5,1,Visual Object Tracking,DAVIS-2017,2016-11,OSVOS,56.6,79.05,56.6,0.79,71.6,0.62,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
6,1,Visual Object Tracking,DAVIS-2017,2017-06,OnAVOS,61.6,86.03,5.0,0.07,71.6,0.68,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
7,1,Visual Object Tracking,DAVIS-2017,2019-07,PTSNet,71.6,100.0,10.0,0.14,71.6,0.79,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
8,1,Visual Object Tracking,DAVIS 2016,2016-12,MSK,79.7,92.03,79.7,0.92,86.6,0.88,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
9,1,Visual Object Tracking,DAVIS 2016,2017-06,OnAVOS,86.1,99.42,6.4,0.07,86.6,0.95,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
10,1,Visual Object Tracking,DAVIS 2016,2019-08,RANet+ (online learning),86.6,100.0,0.5,0.01,86.6,0.96,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
11,1,Unsupervised Video Object Segmentation,DAVIS 2016,2017-09,SFL,67.4,83.73,67.4,0.84,80.5,0.74,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
12,1,Unsupervised Video Object Segmentation,DAVIS 2016,2020-01,COSNet,80.5,100.0,13.1,0.16,80.5,0.89,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
13,1,Semantic Segmentation,38-Cloud,2019-01,Cloud-Net,87.32,98.22,87.32,0.98,88.9,0.96,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
14,1,Semantic Segmentation,38-Cloud,2020-01,Cloud-Net+,88.9,100.0,1.6,0.02,88.9,0.98,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
15,1,Video Object Segmentation,FBMS,2020-01,COSNet,75.6,100.0,75.6,1.0,75.6,0.83,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
16,1,Video Object Segmentation,DAVIS 2016,2020-01,COSNet,80.5,100.0,80.5,1.0,80.5,0.89,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
17,1,Unsupervised Video Object Segmentation,FBMS,2020-01,COSNet,75.6,100.0,75.6,1.0,75.6,0.83,ito:ITO_00101,Vision process,Jaccard\\ \\(Mean\\)
0,1,Face Alignment,WFLW,2015-06,CFSS,0.366,61.9,0.366,0.62,0.5913,0.62,ito:ITO_00101,Vision process,AUC\\-at\\-0\\.1\\ \\(all\\)
1,1,Face Alignment,WFLW,2017-07,DVLN,0.456,77.12,0.1,0.17,0.5913,0.77,ito:ITO_00101,Vision process,AUC\\-at\\-0\\.1\\ \\(all\\)
2,1,Face Alignment,WFLW,2017-11,Wing,0.554,93.69,0.1,0.17,0.5913,0.94,ito:ITO_00101,Vision process,AUC\\-at\\-0\\.1\\ \\(all\\)
3,1,Face Alignment,WFLW,2019-02,3DDE (Inter-ocular Norm),0.5544,93.76,0.0,0.0,0.5913,0.94,ito:ITO_00101,Vision process,AUC\\-at\\-0\\.1\\ \\(all\\)
4,1,Face Alignment,WFLW,2019-04,DeCaFA,0.563,95.21,0.0,0.0,0.5913,0.95,ito:ITO_00101,Vision process,AUC\\-at\\-0\\.1\\ \\(all\\)
5,1,Face Alignment,WFLW,2019-06,GRegNet + LRefNet,0.584,98.77,0.0,0.0,0.5913,0.99,ito:ITO_00101,Vision process,AUC\\-at\\-0\\.1\\ \\(all\\)
6,1,Face Alignment,WFLW,2019-08,AVS,0.5913,100.0,0.0,0.0,0.5913,1.0,ito:ITO_00101,Vision process,AUC\\-at\\-0\\.1\\ \\(all\\)
0,1,Face Alignment,WFLW,2015-06,CFSS,20.56,100.0,20.56,1.0,20.56,1.0,ito:ITO_00101,Vision process,"FR\\-at\\-0\\.1\\(%,\\ all\\)"
0,1,Face Alignment,WFLW,2015-06,CFSS,9.07,83.67,9.07,0.84,10.84,0.84,ito:ITO_00101,Vision process,"ME\\ \\(%,\\ all\\)"
1,1,Face Alignment,WFLW,2017-07,DVLN,10.84,100.0,1.8,0.17,10.84,1.0,ito:ITO_00101,Vision process,"ME\\ \\(%,\\ all\\)"
0,1,Dense Pixel Correspondence Estimation,HPatches,2015-06,DeepMatching*,5.84,15.81,5.84,0.16,36.94,0.16,ito:ITO_00101,Vision process,Viewpoint\\ I\\ AEPE
1,1,Dense Pixel Correspondence Estimation,HPatches,2016-11,SPyNet,36.94,100.0,31.1,0.84,36.94,1.0,ito:ITO_00101,Vision process,Viewpoint\\ I\\ AEPE
0,1,Dense Pixel Correspondence Estimation,HPatches,2015-06,DeepMatching*,4.63,9.09,4.63,0.09,50.92,0.09,ito:ITO_00101,Vision process,Viewpoint\\ II\\ AEPE
1,1,Dense Pixel Correspondence Estimation,HPatches,2016-11,SPyNet,50.92,100.0,46.3,0.91,50.92,1.0,ito:ITO_00101,Vision process,Viewpoint\\ II\\ AEPE
0,1,Dense Pixel Correspondence Estimation,HPatches,2015-06,DeepMatching*,12.43,22.9,12.43,0.23,54.29,0.23,ito:ITO_00101,Vision process,Viewpoint\\ III\\ AEPE
1,1,Dense Pixel Correspondence Estimation,HPatches,2016-11,SPyNet,54.29,100.0,41.9,0.77,54.29,1.0,ito:ITO_00101,Vision process,Viewpoint\\ III\\ AEPE
0,1,Dense Pixel Correspondence Estimation,HPatches,2015-06,DeepMatching*,12.17,19.44,12.17,0.19,62.6,0.19,ito:ITO_00101,Vision process,Viewpoint\\ IV\\ AEPE
1,1,Dense Pixel Correspondence Estimation,HPatches,2016-11,SPyNet,62.6,100.0,50.4,0.81,62.6,1.0,ito:ITO_00101,Vision process,Viewpoint\\ IV\\ AEPE
0,1,Dense Pixel Correspondence Estimation,HPatches,2015-06,DeepMatching*,22.55,31.07,22.55,0.31,72.57,0.31,ito:ITO_00101,Vision process,Viewpoint\\ V\\ AEPE
1,1,Dense Pixel Correspondence Estimation,HPatches,2016-11,SPyNet,72.57,100.0,50.0,0.69,72.57,1.0,ito:ITO_00101,Vision process,Viewpoint\\ V\\ AEPE
0,1,Human Pose Forecasting,Human3.6M,2015-08,ERD,1.78,100.0,1.78,1.0,1.78,1.0,ito:ITO_00101,Vision process,"MAR,\\ walking,\\ 400ms"
0,1,Human Pose Forecasting,Human3.6M,2015-08,ERD,2.38,100.0,2.38,1.0,2.38,1.0,ito:ITO_00101,Vision process,"MAR,\\ walking,\\ 1,000ms"
0,1,Color Image Denoising,Darmstadt Noise Dataset,2015-08,TNRD,33.65,88.41,33.65,0.88,38.06,0.88,ito:ITO_00101,Vision process,PSNR\\ \\(sRGB\\)
1,1,Color Image Denoising,Darmstadt Noise Dataset,2018-07,TWSC,37.94,99.68,4.3,0.11,38.06,1.0,ito:ITO_00101,Vision process,PSNR\\ \\(sRGB\\)
2,1,Color Image Denoising,Darmstadt Noise Dataset,2018-07,CBDNet (Blind),38.06,100.0,0.1,0.0,38.06,1.0,ito:ITO_00101,Vision process,PSNR\\ \\(sRGB\\)
3,1,Image Denoising,DND,2018-07,CBDNet,38.06,100.0,38.06,1.0,38.06,1.0,ito:ITO_00101,Vision process,PSNR\\ \\(sRGB\\)
4,1,Image Denoising,SIDD,2018-07,CBDNet,30.78,100.0,30.78,1.0,30.78,0.81,ito:ITO_00101,Vision process,PSNR\\ \\(sRGB\\)
0,1,Color Image Denoising,Darmstadt Noise Dataset,2015-08,TNRD,0.8306,88.16,0.8306,0.88,0.9421,0.88,ito:ITO_00101,Vision process,SSIM\\ \\(sRGB\\)
1,1,Color Image Denoising,Darmstadt Noise Dataset,2018-07,TWSC,0.9403,99.81,0.1,0.11,0.9421,1.0,ito:ITO_00101,Vision process,SSIM\\ \\(sRGB\\)
2,1,Color Image Denoising,Darmstadt Noise Dataset,2018-07,CBDNet (Blind),0.9421,100.0,0.0,0.0,0.9421,1.0,ito:ITO_00101,Vision process,SSIM\\ \\(sRGB\\)
3,1,Image Denoising,DND,2018-07,CBDNet,0.942,100.0,0.942,1.0,0.942,1.0,ito:ITO_00101,Vision process,SSIM\\ \\(sRGB\\)
4,1,Image Denoising,SIDD,2018-07,CBDNet,0.801,100.0,0.801,1.0,0.801,0.85,ito:ITO_00101,Vision process,SSIM\\ \\(sRGB\\)
0,1,Anomaly Detection,Numenta Anomaly Benchmark,2015-10,Numenta HTM,64.7,92.3,64.7,0.92,70.1,0.92,ito:ITO_00101,Vision process,NAB\\ score
1,1,Anomaly Detection,Numenta Anomaly Benchmark,2017-06,HTM AL,70.1,100.0,5.4,0.08,70.1,1.0,ito:ITO_00101,Vision process,NAB\\ score
0,1,3D Object Detection,SUN-RGBD val,2015-11,DSS,42.1,71.24,42.1,0.71,59.1,0.66,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.25
1,1,3D Object Detection,SUN-RGBD val,2016-06,COG,47.6,80.54,5.5,0.09,59.1,0.74,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.25
2,1,3D Object Detection,SUN-RGBD val,2017-11,F-PointNet,54.0,91.37,6.4,0.11,59.1,0.84,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.25
3,1,3D Object Detection,SUN-RGBD val,2019-04,VoteNet (Geo only),59.1,100.0,5.1,0.09,59.1,0.92,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.25
4,1,3D Object Detection,SUN-RGBD,2017-11,Frustum PointNets,54.0,85.17,54.0,0.85,63.4,0.84,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.25
5,1,3D Object Detection,SUN-RGBD,2020-01,ImVoteNet,63.4,100.0,9.4,0.15,63.4,0.99,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.25
6,1,3D Object Detection,ScanNetV2,2017-11,SGPN,20.7,32.24,20.7,0.32,64.2,0.32,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.25
7,1,3D Object Detection,ScanNetV2,2018-12,GSPN,30.6,47.66,9.9,0.15,64.2,0.48,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.25
8,1,3D Object Detection,ScanNetV2,2018-12,3D-SIS,40.2,62.62,9.6,0.15,64.2,0.63,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.25
9,1,3D Object Detection,ScanNetV2,2019-04,VoteNet,58.6,91.28,18.4,0.29,64.2,0.91,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.25
10,1,3D Object Detection,ScanNetV2,2020-03,3D-MPA,64.2,100.0,5.6,0.09,64.2,1.0,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.25
11,1,3D Semantic Instance Segmentation,ScanNetV1,2017-11,SGPN,35.1,100.0,35.1,1.0,35.1,0.55,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.25
0,1,Weakly Supervised Object Detection,COCO test-dev,2015-11,WSDDN,11.5,46.37,11.5,0.46,24.8,0.12,ito:ITO_00101,Vision process,AP50
1,1,Weakly Supervised Object Detection,COCO test-dev,2016-11,WCCN,12.3,49.6,0.8,0.03,24.8,0.13,ito:ITO_00101,Vision process,AP50
2,1,Weakly Supervised Object Detection,COCO test-dev,2017-11,WSGARN+SSD,13.6,54.84,1.3,0.05,24.8,0.15,ito:ITO_00101,Vision process,AP50
3,1,Weakly Supervised Object Detection,COCO test-dev,2020-04,"wetectron(single-model, VGG16)",24.8,100.0,11.2,0.45,24.8,0.27,ito:ITO_00101,Vision process,AP50
4,1,Object Detection,COCO test-dev,2015-12,SSD512,48.5,67.36,48.5,0.67,72.0,0.52,ito:ITO_00101,Vision process,AP50
5,1,Object Detection,COCO test-dev,2017-03,DeformConv-R-FCN (Aligned-Inception-ResNet),58.0,80.56,9.5,0.13,72.0,0.62,ito:ITO_00101,Vision process,AP50
6,1,Object Detection,COCO test-dev,2017-03,Mask R-CNN (ResNeXt-101-FPN),62.3,86.53,4.3,0.06,72.0,0.67,ito:ITO_00101,Vision process,AP50
7,1,Object Detection,COCO test-dev,2017-11,RefineDet512+ (ResNet-101),62.9,87.36,0.6,0.01,72.0,0.67,ito:ITO_00101,Vision process,AP50
8,1,Object Detection,COCO test-dev,2017-11,"D-RFCN + SNIP (DPN-98 with flip, multi-scale)",67.3,93.47,4.4,0.06,72.0,0.72,ito:ITO_00101,Vision process,AP50
9,1,Object Detection,COCO test-dev,2018-11,"DCNv2 (ResNet-101, multi-scale)",67.9,94.31,0.6,0.01,72.0,0.73,ito:ITO_00101,Vision process,AP50
10,1,Object Detection,COCO test-dev,2019-01,"TridentNet (ResNet-101-Deformable, Image Pyramid)",69.7,96.81,1.8,0.02,72.0,0.75,ito:ITO_00101,Vision process,AP50
11,1,Object Detection,COCO test-dev,2019-09,"Cascade Mask R-CNN (Triple-ResNeXt152, multi-scale)",71.9,99.86,2.2,0.03,72.0,0.77,ito:ITO_00101,Vision process,AP50
12,1,Object Detection,COCO test-dev,2020-04,ResNeSt-200DCN,72.0,100.0,0.1,0.0,72.0,0.77,ito:ITO_00101,Vision process,AP50
13,1,Instance Segmentation,COCO test-dev,2015-12,MNC,44.3,66.92,44.3,0.67,66.2,0.47,ito:ITO_00101,Vision process,AP50
14,1,Instance Segmentation,COCO test-dev,2016-11,FCIS+++  +OHEM,54.5,82.33,10.2,0.15,66.2,0.58,ito:ITO_00101,Vision process,AP50
15,1,Instance Segmentation,COCO test-dev,2017-03,Mask R-CNN (ResNeXt-101-FPN),60.0,90.63,5.5,0.08,66.2,0.64,ito:ITO_00101,Vision process,AP50
16,1,Instance Segmentation,COCO test-dev,2019-08,"Cascade R-CNN (ResNet-101-FPN, map-guided)",61.4,92.75,1.4,0.02,66.2,0.66,ito:ITO_00101,Vision process,AP50
17,1,Instance Segmentation,COCO test-dev,2019-11,CenterMask + VoVNetV2-99 (multi-scale),66.2,100.0,4.8,0.07,66.2,0.71,ito:ITO_00101,Vision process,AP50
18,1,Few-Shot Image Classification,CUB-200-2011,2016-05,Word CNN-RNN (DS-SJE Embedding),48.7,100.0,48.7,1.0,48.7,0.52,ito:ITO_00101,Vision process,AP50
19,1,Few-Shot Image Classification,Flowers-102,2016-05,Word CNN-RNN (DS-SJE Embedding),59.6,100.0,59.6,1.0,59.6,0.64,ito:ITO_00101,Vision process,AP50
20,1,Keypoint Detection,COCO test-dev,2016-11,AE,86.8,92.93,86.8,0.93,93.4,0.93,ito:ITO_00101,Vision process,AP50
21,1,Keypoint Detection,COCO test-dev,2017-03,Mask R-CNN,87.3,93.47,0.5,0.01,93.4,0.93,ito:ITO_00101,Vision process,AP50
22,1,Keypoint Detection,COCO test-dev,2017-11,CPN,91.4,97.86,4.1,0.04,93.4,0.98,ito:ITO_00101,Vision process,AP50
23,1,Keypoint Detection,COCO test-dev,2017-11,CPN+,91.7,98.18,0.3,0.0,93.4,0.98,ito:ITO_00101,Vision process,AP50
24,1,Keypoint Detection,COCO test-dev,2018-04,Simple Base,91.9,98.39,0.2,0.0,93.4,0.98,ito:ITO_00101,Vision process,AP50
25,1,Keypoint Detection,COCO test-dev,2018-04,Simple Base+*,92.4,98.93,0.5,0.01,93.4,0.99,ito:ITO_00101,Vision process,AP50
26,1,Keypoint Detection,COCO test-dev,2019-01,MSPN,93.4,100.0,1.0,0.01,93.4,1.0,ito:ITO_00101,Vision process,AP50
27,1,Pose Estimation,COCO test-dev,2016-11,CMU-Pose,84.9,90.9,84.9,0.91,93.4,0.91,ito:ITO_00101,Vision process,AP50
28,1,Pose Estimation,COCO test-dev,2016-12,RMPE++,89.2,95.5,4.3,0.05,93.4,0.96,ito:ITO_00101,Vision process,AP50
29,1,Pose Estimation,COCO test-dev,2017-11,CPN,91.4,97.86,2.2,0.02,93.4,0.98,ito:ITO_00101,Vision process,AP50
30,1,Pose Estimation,COCO test-dev,2017-11,"CPN+ [6, 9]",91.7,98.18,0.3,0.0,93.4,0.98,ito:ITO_00101,Vision process,AP50
31,1,Pose Estimation,COCO test-dev,2018-04,Flow-based (ResNet-152),91.9,98.39,0.2,0.0,93.4,0.98,ito:ITO_00101,Vision process,AP50
32,1,Pose Estimation,COCO test-dev,2019-01,MSPN,93.4,100.0,1.5,0.02,93.4,1.0,ito:ITO_00101,Vision process,AP50
33,1,Multi-Person Pose Estimation,COCO test-dev,2016-11,CMU-Pose,84.9,95.07,84.9,0.95,89.3,0.91,ito:ITO_00101,Vision process,AP50
34,1,Multi-Person Pose Estimation,COCO test-dev,2017-01,G-RMI,85.5,95.74,0.6,0.01,89.3,0.92,ito:ITO_00101,Vision process,AP50
35,1,Multi-Person Pose Estimation,COCO test-dev,2018-03,PersonLab,89.0,99.66,3.5,0.04,89.3,0.95,ito:ITO_00101,Vision process,AP50
36,1,Multi-Person Pose Estimation,COCO test-dev,2019-08,HigherHRNet (HR-Net-48),89.3,100.0,0.3,0.0,89.3,0.96,ito:ITO_00101,Vision process,AP50
37,1,Object Detection,COCO minival,2016-12,FPN+,61.3,85.73,61.3,0.86,71.5,0.66,ito:ITO_00101,Vision process,AP50
38,1,Object Detection,COCO minival,2017-11,Mask R-CNN (ResNet-101 + 1 NL),63.1,88.25,1.8,0.03,71.5,0.68,ito:ITO_00101,Vision process,AP50
39,1,Object Detection,COCO minival,2017-11,Mask R-CNN (ResNeXt-152 + 1 NL),67.8,94.83,4.7,0.07,71.5,0.73,ito:ITO_00101,Vision process,AP50
40,1,Object Detection,COCO minival,2019-12,"RetinaNet (SpineNet-190, single-scale)",71.5,100.0,3.7,0.05,71.5,0.77,ito:ITO_00101,Vision process,AP50
41,1,Keypoint Detection,COCO test-challenge,2017-01,G-RMI*,85.9,92.47,85.9,0.92,92.9,0.92,ito:ITO_00101,Vision process,AP50
42,1,Keypoint Detection,COCO test-challenge,2017-03,Mask R-CNN*,89.2,96.02,3.3,0.04,92.9,0.96,ito:ITO_00101,Vision process,AP50
43,1,Keypoint Detection,COCO test-challenge,2017-11,CPN+,90.5,97.42,1.3,0.01,92.9,0.97,ito:ITO_00101,Vision process,AP50
44,1,Keypoint Detection,COCO test-challenge,2018-04,Simple Base+*,90.9,97.85,0.4,0.0,92.9,0.97,ito:ITO_00101,Vision process,AP50
45,1,Keypoint Detection,COCO test-challenge,2019-01,MSPN+*,92.9,100.0,2.0,0.02,92.9,0.99,ito:ITO_00101,Vision process,AP50
46,1,Instance Segmentation,COCO minival,2019-03,"Mask R-CNN-FPN (ResNeXt-101, GN+WS)",61.07,96.63,61.07,0.97,63.2,0.65,ito:ITO_00101,Vision process,AP50
47,1,Instance Segmentation,COCO minival,2019-08,Mask R-CNN-FPN (AOGNet-40M),63.2,100.0,2.1,0.03,63.2,0.68,ito:ITO_00101,Vision process,AP50
48,1,Real-time Instance Segmentation,MSCOCO,2019-04,YOLACT-550 (ResNet-101-FPN),46.6,100.0,46.6,1.0,46.6,0.5,ito:ITO_00101,Vision process,AP50
49,1,3D Object Detection,nuScenes-F,2019-05,RRPN + R101,64.9,100.0,64.9,1.0,64.9,0.69,ito:ITO_00101,Vision process,AP50
50,1,3D Object Detection,nuScenes-FB,2019-05,RRPN + R101,59.0,100.0,59,1.0,59,0.63,ito:ITO_00101,Vision process,AP50
51,1,Object Detection,MSCOCO,2020-04,yolov4.cfg/weights,65.7,100.0,65.7,1.0,65.7,0.7,ito:ITO_00101,Vision process,AP50
0,1,Image Super-Resolution,Set5,2015-11,DRCN,3.26,91.06,3.26,0.91,3.58,0.87,ito:ITO_00101,Vision process,MOS
1,1,Image Super-Resolution,Set5,2016-09,SRResNet,3.37,94.13,0.1,0.03,3.58,0.9,ito:ITO_00101,Vision process,MOS
2,1,Image Super-Resolution,Set5,2016-09,SRGAN,3.58,100.0,0.2,0.06,3.58,0.96,ito:ITO_00101,Vision process,MOS
3,1,Image Super-Resolution,Set14,2015-11,DRCN,2.84,76.34,2.84,0.76,3.72,0.76,ito:ITO_00101,Vision process,MOS
4,1,Image Super-Resolution,Set14,2016-09,SRResNet,2.98,80.11,0.1,0.03,3.72,0.8,ito:ITO_00101,Vision process,MOS
5,1,Image Super-Resolution,Set14,2016-09,SRGAN,3.72,100.0,0.7,0.19,3.72,1.0,ito:ITO_00101,Vision process,MOS
6,1,Image Super-Resolution,BSD100,2015-11,DRCN,2.12,59.55,2.12,0.6,3.56,0.57,ito:ITO_00101,Vision process,MOS
7,1,Image Super-Resolution,BSD100,2016-09,SRGAN,3.56,100.0,1.4,0.39,3.56,0.95,ito:ITO_00101,Vision process,MOS
8,1,Face Alignment,CelebA Aligned,2019-08,Progressive Face SR,3.73,100.0,3.73,1.0,3.73,1.0,ito:ITO_00101,Vision process,MOS
0,1,Conditional Image Generation,CIFAR-10,2015-11,DCGAN,6.58,68.68,6.58,0.69,9.58,0.04,ito:ITO_00101,Vision process,Inception\\ score
1,1,Conditional Image Generation,CIFAR-10,2016-06,Improved GAN,8.09,84.45,1.5,0.16,9.58,0.05,ito:ITO_00101,Vision process,Inception\\ score
2,1,Conditional Image Generation,CIFAR-10,2016-10,AC-GAN,8.25,86.12,0.2,0.02,9.58,0.05,ito:ITO_00101,Vision process,Inception\\ score
3,1,Conditional Image Generation,CIFAR-10,2016-12,SGAN,8.59,89.67,0.3,0.03,9.58,0.05,ito:ITO_00101,Vision process,Inception\\ score
4,1,Conditional Image Generation,CIFAR-10,2017-03,WGAN-GP,8.67,90.5,0.1,0.01,9.58,0.05,ito:ITO_00101,Vision process,Inception\\ score
5,1,Conditional Image Generation,CIFAR-10,2017-09,Splitting GAN,8.87,92.59,0.2,0.02,9.58,0.05,ito:ITO_00101,Vision process,Inception\\ score
6,1,Conditional Image Generation,CIFAR-10,2018-09,BigGAN,9.22,96.24,0.4,0.04,9.58,0.06,ito:ITO_00101,Vision process,Inception\\ score
7,1,Conditional Image Generation,CIFAR-10,2019-12,MHingeGAN,9.58,100.0,0.4,0.04,9.58,0.06,ito:ITO_00101,Vision process,Inception\\ score
8,1,Image Generation,CIFAR-10,2016-06,ALI,5.34,57.92,5.34,0.58,9.22,0.03,ito:ITO_00101,Vision process,Inception\\ score
9,1,Image Generation,CIFAR-10,2016-06,Improved GAN,6.86,74.4,1.5,0.16,9.22,0.04,ito:ITO_00101,Vision process,Inception\\ score
10,1,Image Generation,CIFAR-10,2017-02,CEGAN-Ent-VI,7.07,76.68,0.2,0.02,9.22,0.04,ito:ITO_00101,Vision process,Inception\\ score
11,1,Image Generation,CIFAR-10,2017-03,LR-GAN,7.17,77.77,0.1,0.01,9.22,0.04,ito:ITO_00101,Vision process,Inception\\ score
12,1,Image Generation,CIFAR-10,2017-03,WGAN-GP,7.86,85.25,0.7,0.08,9.22,0.05,ito:ITO_00101,Vision process,Inception\\ score
13,1,Image Generation,CIFAR-10,2017-09,Splitting GAN,7.9,85.68,0.0,0.0,9.22,0.05,ito:ITO_00101,Vision process,Inception\\ score
14,1,Image Generation,CIFAR-10,2017-10,PGGAN,8.8,95.44,0.9,0.1,9.22,0.05,ito:ITO_00101,Vision process,Inception\\ score
15,1,Image Generation,CIFAR-10,2018-09,BigGAN,9.22,100.0,0.4,0.04,9.22,0.06,ito:ITO_00101,Vision process,Inception\\ score
16,1,Image Generation,CUB 128 x 128,2016-06,InfoGAN,47.32,90.08,47.32,0.9,52.53,0.28,ito:ITO_00101,Vision process,Inception\\ score
17,1,Image Generation,CUB 128 x 128,2018-11,FineGAN,52.53,100.0,5.2,0.1,52.53,0.32,ito:ITO_00101,Vision process,Inception\\ score
18,1,Image Generation,Stanford Dogs,2016-06,InfoGAN,43.16,91.99,43.16,0.92,46.92,0.26,ito:ITO_00101,Vision process,Inception\\ score
19,1,Image Generation,Stanford Dogs,2018-11,FineGAN,46.92,100.0,3.8,0.08,46.92,0.28,ito:ITO_00101,Vision process,Inception\\ score
20,1,Image Generation,Stanford Cars,2016-06,InfoGAN,28.62,87.74,28.62,0.88,32.62,0.17,ito:ITO_00101,Vision process,Inception\\ score
21,1,Image Generation,Stanford Cars,2018-11,FineGAN,32.62,100.0,4.0,0.12,32.62,0.2,ito:ITO_00101,Vision process,Inception\\ score
22,1,Text-to-Image Generation,CUB,2016-10,GAWWN,3.62,76.21,3.62,0.76,4.75,0.02,ito:ITO_00101,Vision process,Inception\\ score
23,1,Text-to-Image Generation,CUB,2016-12,StackGAN,3.7,77.89,0.1,0.02,4.75,0.02,ito:ITO_00101,Vision process,Inception\\ score
24,1,Text-to-Image Generation,CUB,2017-10,StackGAN-v2,3.82,80.42,0.1,0.02,4.75,0.02,ito:ITO_00101,Vision process,Inception\\ score
25,1,Text-to-Image Generation,CUB,2017-11,AttnGAN,4.36,91.79,0.5,0.11,4.75,0.03,ito:ITO_00101,Vision process,Inception\\ score
26,1,Text-to-Image Generation,CUB,2019-03,MirrorGAN,4.56,96.0,0.2,0.04,4.75,0.03,ito:ITO_00101,Vision process,Inception\\ score
27,1,Text-to-Image Generation,CUB,2019-04,DM-GAN,4.75,100.0,0.2,0.04,4.75,0.03,ito:ITO_00101,Vision process,Inception\\ score
28,1,Conditional Image Generation,ImageNet 128x128,2016-10,AC-GAN,28.5,17.12,28.5,0.17,166.5,0.17,ito:ITO_00101,Vision process,Inception\\ score
29,1,Conditional Image Generation,ImageNet 128x128,2018-02,Projection Discriminator,36.8,22.1,8.3,0.05,166.5,0.22,ito:ITO_00101,Vision process,Inception\\ score
30,1,Conditional Image Generation,ImageNet 128x128,2018-05,SAGAN,52.52,31.54,15.7,0.09,166.5,0.32,ito:ITO_00101,Vision process,Inception\\ score
31,1,Conditional Image Generation,ImageNet 128x128,2018-09,BigGAN-deep,124.5,74.77,72.0,0.43,166.5,0.75,ito:ITO_00101,Vision process,Inception\\ score
32,1,Conditional Image Generation,ImageNet 128x128,2018-09,BigGAN-deep,166.5,100.0,42.0,0.25,166.5,1.0,ito:ITO_00101,Vision process,Inception\\ score
33,1,Text-to-Image Generation,COCO,2016-12,StackGAN,8.45,16.03,8.45,0.16,52.73,0.05,ito:ITO_00101,Vision process,Inception\\ score
34,1,Text-to-Image Generation,COCO,2017-11,AttnGAN,25.89,49.1,17.4,0.33,52.73,0.16,ito:ITO_00101,Vision process,Inception\\ score
35,1,Text-to-Image Generation,COCO,2019-03,MirrorGAN,26.47,50.2,0.6,0.01,52.73,0.16,ito:ITO_00101,Vision process,Inception\\ score
36,1,Text-to-Image Generation,COCO,2019-04,DM-GAN,30.49,57.82,4.0,0.08,52.73,0.18,ito:ITO_00101,Vision process,Inception\\ score
37,1,Text-to-Image Generation,COCO,2019-12,CPGAN,52.73,100.0,22.2,0.42,52.73,0.32,ito:ITO_00101,Vision process,Inception\\ score
38,1,Text-to-Image Generation,Oxford 102 Flowers,2016-12,StackGAN,3.2,98.16,3.2,0.98,3.26,0.02,ito:ITO_00101,Vision process,Inception\\ score
39,1,Text-to-Image Generation,Oxford 102 Flowers,2017-10,StackGAN-v2,3.26,100.0,0.1,0.03,3.26,0.02,ito:ITO_00101,Vision process,Inception\\ score
40,1,Image Generation,STL-10,2017-09,D2GAN,7.98,85.44,7.98,0.85,9.34,0.05,ito:ITO_00101,Vision process,Inception\\ score
41,1,Image Generation,STL-10,2018-02,SN-GAN,9.1,97.43,1.1,0.12,9.34,0.05,ito:ITO_00101,Vision process,Inception\\ score
42,1,Image Generation,STL-10,2018-12,Improving MMD GAN,9.34,100.0,0.2,0.02,9.34,0.06,ito:ITO_00101,Vision process,Inception\\ score
0,1,Unsupervised Image Classification,SVHN,2015-11,DEC,10.0,100.0,10,1.0,10,1.0,ito:ITO_00101,Vision process,\\#\\ of\\ clusters\\ \\(k\\)
0,1,Unsupervised Image Classification,SVHN,2015-11,DEC,11.9,15.49,11.9,0.15,76.8,0.12,ito:ITO_00101,Vision process,Acc
1,1,Unsupervised Image Classification,SVHN,2017-02,IMSAT,57.3,74.61,45.4,0.59,76.8,0.58,ito:ITO_00101,Vision process,Acc
2,1,Unsupervised Image Classification,SVHN,2018-02,ACOL-GAR,76.8,100.0,19.5,0.25,76.8,0.77,ito:ITO_00101,Vision process,Acc
3,1,Retinal OCT Disease Classification,OCT2017,2015-12,InceptionV3 (limited),93.4,93.96,93.4,0.94,99.4,0.94,ito:ITO_00101,Vision process,Acc
4,1,Retinal OCT Disease Classification,OCT2017,2015-12,InceptionV3,96.6,97.18,3.2,0.03,99.4,0.97,ito:ITO_00101,Vision process,Acc
5,1,Retinal OCT Disease Classification,OCT2017,2015-12,ResNet50-v1,99.3,99.9,2.7,0.03,99.4,1.0,ito:ITO_00101,Vision process,Acc
6,1,Retinal OCT Disease Classification,OCT2017,2018-01,MobileNet-v2,99.4,100.0,0.1,0.0,99.4,1.0,ito:ITO_00101,Vision process,Acc
7,1,Retinal OCT Disease Classification,Srinivasan2014,2015-12,ResNet50-v1,94.92,97.39,94.92,0.97,97.46,0.95,ito:ITO_00101,Vision process,Acc
8,1,Retinal OCT Disease Classification,Srinivasan2014,2018-01,MobileNet-v2,97.46,100.0,2.5,0.03,97.46,0.98,ito:ITO_00101,Vision process,Acc
9,1,Action Segmentation,GTEA,2016-02,ST-CNN,60.6,75.94,60.6,0.76,79.8,0.61,ito:ITO_00101,Vision process,Acc
10,1,Action Segmentation,GTEA,2016-11,ED-TCN,64.0,80.2,3.4,0.04,79.8,0.64,ito:ITO_00101,Vision process,Acc
11,1,Action Segmentation,GTEA,2018-06,TDRN,70.1,87.84,6.1,0.08,79.8,0.71,ito:ITO_00101,Vision process,Acc
12,1,Action Segmentation,GTEA,2019-03,MS-TCN,79.2,99.25,9.1,0.11,79.8,0.8,ito:ITO_00101,Vision process,Acc
13,1,Action Segmentation,GTEA,2020-03,SSTDA,79.8,100.0,0.6,0.01,79.8,0.8,ito:ITO_00101,Vision process,Acc
14,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2017-11,AttnGAN,13.0,79.27,13.0,0.79,16.4,0.13,ito:ITO_00101,Vision process,Acc
15,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2019-04,DM-GAN,16.4,100.0,3.4,0.21,16.4,0.16,ito:ITO_00101,Vision process,Acc
16,1,Action Segmentation,50 Salads,2019-03,MS-TCN,80.7,97.0,80.7,0.97,83.2,0.81,ito:ITO_00101,Vision process,Acc
17,1,Action Segmentation,50 Salads,2020-03,SSTDA,83.2,100.0,2.5,0.03,83.2,0.84,ito:ITO_00101,Vision process,Acc
18,1,Action Segmentation,Breakfast,2019-03,MS-TCN (IDT),65.1,92.74,65.1,0.93,70.2,0.65,ito:ITO_00101,Vision process,Acc
19,1,Action Segmentation,Breakfast,2019-03,MS-TCN (I3D),66.3,94.44,1.2,0.02,70.2,0.67,ito:ITO_00101,Vision process,Acc
20,1,Action Segmentation,Breakfast,2020-03,SSTDA,70.2,100.0,3.9,0.06,70.2,0.71,ito:ITO_00101,Vision process,Acc
21,1,Few-Shot Learning,Mini-ImageNet,2020-03,DPGN,67.6,100.0,67.6,1.0,67.6,0.68,ito:ITO_00101,Vision process,Acc
0,1,Face Anti-Spoofing,Replay-Attack,2015-11,YCbCr+HSV-LBP,2.9,100.0,2.9,1.0,2.9,1.0,ito:ITO_00101,Vision process,HTER
1,1,Face Anti-Spoofing,CASIA-MFSD,2019-01,3D Synthesis (balancing sampling),1.67,100.0,1.67,1.0,1.67,0.58,ito:ITO_00101,Vision process,HTER
0,1,Face Anti-Spoofing,MSU-MFSD,2015-11,Color LBP,10.8,100.0,10.8,1.0,10.8,1.0,ito:ITO_00101,Vision process,Equal\\ Error\\ Rate
0,1,Multi-Person Pose Estimation,WAF,2015-11,DeepCut,86.5,98.18,86.5,0.98,88.1,0.98,ito:ITO_00101,Vision process,AOP
1,1,Multi-Person Pose Estimation,WAF,2016-05,DeeperCut,88.1,100.0,1.6,0.02,88.1,1.0,ito:ITO_00101,Vision process,AOP
0,1,Semantic Segmentation,CamVid,2015-11,ReSeg,88.7,96.94,88.7,0.97,91.5,0.97,ito:ITO_00101,Vision process,Global\\ Accuracy
1,1,Semantic Segmentation,CamVid,2016-11,FC-DenseNet103,91.5,100.0,2.8,0.03,91.5,1.0,ito:ITO_00101,Vision process,Global\\ Accuracy
0,1,Action Recognition In Videos,THUMOS’14,2015-11,Yeung et. al.,17.1,45.72,17.1,0.46,37.4,0.21,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
1,1,Action Recognition In Videos,THUMOS’14,2016-01,Shou et. al.,19.0,50.8,1.9,0.05,37.4,0.23,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
2,1,Action Recognition In Videos,THUMOS’14,2017-03,TURN,24.5,65.51,5.5,0.15,37.4,0.3,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
3,1,Action Recognition In Videos,THUMOS’14,2017-03,Single-stream R-C3D  (two-way buffer),28.9,77.27,4.4,0.12,37.4,0.35,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
4,1,Action Recognition In Videos,THUMOS’14,2017-04,SSN,29.8,79.68,0.9,0.02,37.4,0.36,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
5,1,Action Recognition In Videos,THUMOS’14,2018-06,BSN,36.9,98.66,7.1,0.19,37.4,0.45,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
6,1,Action Recognition In Videos,THUMOS’14,2018-11,MGG UNet,37.4,100.0,0.5,0.01,37.4,0.46,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
7,1,Action Recognition,THUMOS’14,2015-11,Yeung et. al.,17.1,44.07,17.1,0.44,38.8,0.21,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
8,1,Action Recognition,THUMOS’14,2016-01,Shou et. al.,19.0,48.97,1.9,0.05,38.8,0.23,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
9,1,Action Recognition,THUMOS’14,2017-03,TURN,24.5,63.14,5.5,0.14,38.8,0.3,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
10,1,Action Recognition,THUMOS’14,2017-03,Single-stream R-C3D  (one-way buffer),27.0,69.59,2.5,0.06,38.8,0.33,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
11,1,Action Recognition,THUMOS’14,2017-03,Single-stream R-C3D  (two-way buffer),28.9,74.48,1.9,0.05,38.8,0.35,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
12,1,Action Recognition,THUMOS’14,2017-04,SSN,29.8,76.8,0.9,0.02,38.8,0.36,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
13,1,Action Recognition,THUMOS’14,2018-06,BSN,36.9,95.1,7.1,0.18,38.8,0.45,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
14,1,Action Recognition,THUMOS’14,2018-11,MGG UNet,37.4,96.39,0.5,0.01,38.8,0.46,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
15,1,Action Recognition,THUMOS’14,2019-07,BMN,38.8,100.0,1.4,0.04,38.8,0.47,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
16,1,Keypoint Detection,MPII Multi-Person,2016-05,DeeperCut,59.4,72.35,59.4,0.72,82.1,0.72,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
17,1,Keypoint Detection,MPII Multi-Person,2016-08,Local Joint-to-Person Association,62.2,75.76,2.8,0.03,82.1,0.76,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
18,1,Keypoint Detection,MPII Multi-Person,2016-11,Associative Embedding,77.5,94.4,15.3,0.19,82.1,0.94,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
19,1,Keypoint Detection,MPII Multi-Person,2016-12,AlphaPose,82.1,100.0,4.6,0.06,82.1,1.0,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
20,1,Weakly Supervised Action Localization,THUMOS 2014,2017-03,UntrimmedNets,13.7,50.74,13.7,0.51,27.0,0.17,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
21,1,Weakly Supervised Action Localization,THUMOS 2014,2017-12,STPN,16.9,62.59,3.2,0.12,27.0,0.21,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
22,1,Weakly Supervised Action Localization,THUMOS 2014,2018-07,W-TALC,22.8,84.44,5.9,0.22,27.0,0.28,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
23,1,Weakly Supervised Action Localization,THUMOS 2014,2019-06,CMCS,23.1,85.56,0.3,0.01,27.0,0.28,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
24,1,Weakly Supervised Action Localization,THUMOS 2014,2019-08,3C-Net,26.6,98.52,3.5,0.13,27.0,0.32,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
25,1,Weakly Supervised Action Localization,THUMOS 2014,2019-11,BaS-Net,27.0,100.0,0.4,0.01,27.0,0.33,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
26,1,Instance Segmentation,NYU Depth v2,2017-11,SGPN-CNN,30.5,100.0,30.5,1.0,30.5,0.37,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
27,1,Weakly Supervised Action Localization,ActivityNet-1.3,2017-12,STPN,29.3,84.93,29.3,0.85,34.5,0.36,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
28,1,Weakly Supervised Action Localization,ActivityNet-1.3,2019-05,MAAN,33.7,97.68,4.4,0.13,34.5,0.41,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
29,1,Weakly Supervised Action Localization,ActivityNet-1.3,2019-06,CMCS,34.0,98.55,0.3,0.01,34.5,0.41,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
30,1,Weakly Supervised Action Localization,ActivityNet-1.3,2019-11,BaS-Net,34.5,100.0,0.5,0.01,34.5,0.42,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
31,1,Unsupervised Domain Adaptation,Cityscapes to Foggy Cityscapes,2018-03,DA-Faster,26.1,75.0,26.1,0.75,34.8,0.32,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
32,1,Unsupervised Domain Adaptation,Cityscapes to Foggy Cityscapes,2018-12,SWDA,34.8,100.0,8.7,0.25,34.8,0.42,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
33,1,Weakly Supervised Action Localization,ActivityNet-1.2,2018-07,W-TALC,37.0,96.1,37.0,0.96,38.5,0.45,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
34,1,Weakly Supervised Action Localization,ActivityNet-1.2,2019-08,3C-Net,37.2,96.62,0.2,0.01,38.5,0.45,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
35,1,Weakly Supervised Action Localization,ActivityNet-1.2,2019-11,BaS-Net,38.5,100.0,1.3,0.03,38.5,0.47,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
36,1,3D Object Detection,ScanNetV2,2018-12,GSPN,17.7,35.98,17.7,0.36,49.2,0.22,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
37,1,3D Object Detection,ScanNetV2,2018-12,3D-SIS,22.5,45.73,4.8,0.1,49.2,0.27,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
38,1,3D Object Detection,ScanNetV2,2019-04,VoteNet,33.5,68.09,11.0,0.22,49.2,0.41,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
39,1,3D Object Detection,ScanNetV2,2020-03,3D-MPA,49.2,100.0,15.7,0.32,49.2,0.6,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
40,1,Unsupervised Domain Adaptation,SIM10K to BDD100K,2018-12,SWDA,42.9,94.7,42.9,0.95,45.3,0.52,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
41,1,Unsupervised Domain Adaptation,SIM10K to BDD100K,2020-03,CDN,45.3,100.0,2.4,0.05,45.3,0.55,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
42,1,3D Instance Segmentation,SceneNN,2019-04,MLS-CRF,12.1,25.69,12.1,0.26,47.1,0.15,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
43,1,3D Instance Segmentation,SceneNN,2020-03,OccuSeg,47.1,100.0,35.0,0.74,47.1,0.57,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
44,1,3D Object Detection,SUN-RGBD val,2019-04,VoteNet (Geo only),35.8,100.0,35.8,1.0,35.8,0.44,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
45,1,Object Detection,India Driving Dataset,2019-09,hybrid incremental net,31.57,100.0,31.57,1.0,31.57,0.38,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
46,1,Object Detection,BDD100k,2019-09,hybrid incremental net,45.7,100.0,45.7,1.0,45.7,0.56,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
47,1,Object Detection,BDD100K,2019-09,hybrid incremental net,45.7,100.0,45.7,1.0,45.7,0.56,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
48,1,Weakly Supervised Action Localization,THUMOS’14,2019-11,BasNet,27.0,100.0,27,1.0,27,0.33,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.5
0,1,Action Recognition,THUMOS’14,2015-11,Yeung et. al.,44.0,74.07,44.0,0.74,59.4,0.74,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.2
1,1,Action Recognition,THUMOS’14,2017-03,Single-stream R-C3D  (one-way buffer),49.2,82.83,5.2,0.09,59.4,0.83,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.2
2,1,Action Recognition,THUMOS’14,2017-03,Single-stream R-C3D  (two-way buffer),51.5,86.7,2.3,0.04,59.4,0.87,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.2
3,1,Action Recognition,THUMOS’14,2017-04,SSN,59.4,100.0,7.9,0.13,59.4,1.0,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.2
4,1,Action Recognition In Videos,THUMOS’14,2015-11,Yeung et. al.,44.0,74.07,44.0,0.74,59.4,0.74,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.2
5,1,Action Recognition In Videos,THUMOS’14,2017-03,Single-stream R-C3D  (two-way buffer),51.5,86.7,7.5,0.13,59.4,0.87,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.2
6,1,Action Recognition In Videos,THUMOS’14,2017-04,SSN,59.4,100.0,7.9,0.13,59.4,1.0,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.2
0,1,Action Recognition In Videos,THUMOS’14,2015-11,Yeung et. al.,36.0,66.79,36.0,0.67,53.9,0.64,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.3
1,1,Action Recognition In Videos,THUMOS’14,2016-01,Shou et. al.,36.3,67.35,0.3,0.01,53.9,0.65,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.3
2,1,Action Recognition In Videos,THUMOS’14,2017-03,TURN,46.3,85.9,10.0,0.19,53.9,0.83,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.3
3,1,Action Recognition In Videos,THUMOS’14,2017-04,SSN,51.9,96.29,5.6,0.1,53.9,0.93,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.3
4,1,Action Recognition In Videos,THUMOS’14,2018-06,BSN,53.5,99.26,1.6,0.03,53.9,0.96,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.3
5,1,Action Recognition In Videos,THUMOS’14,2018-11,MGG UNet,53.9,100.0,0.4,0.01,53.9,0.96,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.3
6,1,Action Recognition,THUMOS’14,2015-11,Yeung et. al.,36.0,64.29,36.0,0.64,56.0,0.64,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.3
7,1,Action Recognition,THUMOS’14,2016-01,Shou et. al.,36.3,64.82,0.3,0.01,56.0,0.65,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.3
8,1,Action Recognition,THUMOS’14,2017-03,TURN,46.3,82.68,10.0,0.18,56.0,0.83,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.3
9,1,Action Recognition,THUMOS’14,2017-04,SSN,51.9,92.68,5.6,0.1,56.0,0.93,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.3
10,1,Action Recognition,THUMOS’14,2018-06,BSN,53.5,95.54,1.6,0.03,56.0,0.96,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.3
11,1,Action Recognition,THUMOS’14,2018-11,MGG UNet,53.9,96.25,0.4,0.01,56.0,0.96,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.3
12,1,Action Recognition,THUMOS’14,2019-07,BMN,56.0,100.0,2.1,0.04,56.0,1.0,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.3
0,1,Action Recognition,THUMOS’14,2015-11,Yeung et. al.,48.9,74.09,48.9,0.74,66.0,0.74,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.1
1,1,Action Recognition,THUMOS’14,2017-03,Single-stream R-C3D  (one-way buffer),51.6,78.18,2.7,0.04,66.0,0.78,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.1
2,1,Action Recognition,THUMOS’14,2017-03,Single-stream R-C3D  (two-way buffer),54.5,82.58,2.9,0.04,66.0,0.83,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.1
3,1,Action Recognition,THUMOS’14,2017-04,SSN,66.0,100.0,11.5,0.17,66.0,1.0,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.1
4,1,Action Recognition In Videos,THUMOS’14,2015-11,Yeung et. al.,48.9,74.09,48.9,0.74,66.0,0.74,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.1
5,1,Action Recognition In Videos,THUMOS’14,2017-03,Single-stream R-C3D  (two-way buffer),54.5,82.58,5.6,0.08,66.0,0.83,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.1
6,1,Action Recognition In Videos,THUMOS’14,2017-04,SSN,66.0,100.0,11.5,0.17,66.0,1.0,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.1
0,1,Action Recognition In Videos,THUMOS’14,2015-11,Yeung et. al.,26.4,56.41,26.4,0.56,46.8,0.56,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.4
1,1,Action Recognition In Videos,THUMOS’14,2016-01,Shou et. al.,28.7,61.32,2.3,0.05,46.8,0.61,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.4
2,1,Action Recognition In Videos,THUMOS’14,2017-03,TURN,35.3,75.43,6.6,0.14,46.8,0.74,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.4
3,1,Action Recognition In Videos,THUMOS’14,2017-03,Single-stream R-C3D  (two-way buffer),35.6,76.07,0.3,0.01,46.8,0.75,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.4
4,1,Action Recognition In Videos,THUMOS’14,2017-04,SSN,41.0,87.61,5.4,0.12,46.8,0.86,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.4
5,1,Action Recognition In Videos,THUMOS’14,2018-06,BSN,45.0,96.15,4.0,0.09,46.8,0.95,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.4
6,1,Action Recognition In Videos,THUMOS’14,2018-11,MGG UNet,46.8,100.0,1.8,0.04,46.8,0.99,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.4
7,1,Action Recognition,THUMOS’14,2015-11,Yeung et. al.,26.4,55.7,26.4,0.56,47.4,0.56,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.4
8,1,Action Recognition,THUMOS’14,2016-01,Shou et. al.,28.7,60.55,2.3,0.05,47.4,0.61,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.4
9,1,Action Recognition,THUMOS’14,2017-03,TURN,35.3,74.47,6.6,0.14,47.4,0.74,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.4
10,1,Action Recognition,THUMOS’14,2017-03,Single-stream R-C3D  (two-way buffer),35.6,75.11,0.3,0.01,47.4,0.75,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.4
11,1,Action Recognition,THUMOS’14,2017-04,SSN,41.0,86.5,5.4,0.11,47.4,0.86,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.4
12,1,Action Recognition,THUMOS’14,2018-06,BSN,45.0,94.94,4.0,0.08,47.4,0.95,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.4
13,1,Action Recognition,THUMOS’14,2018-11,MGG UNet,46.8,98.73,1.8,0.04,47.4,0.99,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.4
14,1,Action Recognition,THUMOS’14,2019-07,BMN,47.4,100.0,0.6,0.01,47.4,1.0,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.4
0,1,Temporal Action Localization,THUMOS’14,2015-11,Yeung et al.,17.1,34.83,17.1,0.35,49.1,0.34,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.5
1,1,Temporal Action Localization,THUMOS’14,2016-01,S-CNN,19.0,38.7,1.9,0.04,49.1,0.38,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.5
2,1,Temporal Action Localization,THUMOS’14,2017-03,CDC,23.3,47.45,4.3,0.09,49.1,0.46,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.5
3,1,Temporal Action Localization,THUMOS’14,2017-03,TURN-FL-16 + S-CNN,25.6,52.14,2.3,0.05,49.1,0.51,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.5
4,1,Temporal Action Localization,THUMOS’14,2017-03,R-C3D,28.9,58.86,3.3,0.07,49.1,0.57,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.5
5,1,Temporal Action Localization,THUMOS’14,2017-05,CBR-TS,31.0,63.14,2.1,0.04,49.1,0.62,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.5
6,1,Temporal Action Localization,THUMOS’14,2018-04,TAL-Net,42.8,87.17,11.8,0.24,49.1,0.85,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.5
7,1,Temporal Action Localization,THUMOS’14,2019-04,Decouple-SSAD,44.2,90.02,1.4,0.03,49.1,0.88,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.5
8,1,Temporal Action Localization,THUMOS’14,2019-09,P-GCN,49.1,100.0,4.9,0.1,49.1,0.97,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.5
9,1,Temporal Action Localization,ActivityNet-1.3,2017-03,SSN,39.12,77.68,39.12,0.78,50.36,0.78,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.5
10,1,Temporal Action Localization,ActivityNet-1.3,2018-06,BSN,46.45,92.24,7.3,0.14,50.36,0.92,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.5
11,1,Temporal Action Localization,ActivityNet-1.3,2019-07,BMN,50.07,99.42,3.6,0.07,50.36,0.99,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.5
12,1,Temporal Action Localization,ActivityNet-1.3,2019-11,G-TAD,50.36,100.0,0.3,0.01,50.36,1.0,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.5
13,1,Temporal Action Localization,ActivityNet-1.2,2020-01,DeepMetricLearner,35.2,100.0,35.2,1.0,35.2,0.7,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.5
0,1,Temporal Action Localization,THUMOS’14,2015-11,Yeung et al.,48.9,70.36,48.9,0.7,69.5,0.7,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.1
1,1,Temporal Action Localization,THUMOS’14,2017-03,TURN-FL-16 + S-CNN,54.0,77.7,5.1,0.07,69.5,0.78,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.1
2,1,Temporal Action Localization,THUMOS’14,2017-03,R-C3D,54.5,78.42,0.5,0.01,69.5,0.78,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.1
3,1,Temporal Action Localization,THUMOS’14,2017-05,CBR-TS,60.1,86.47,5.6,0.08,69.5,0.86,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.1
4,1,Temporal Action Localization,THUMOS’14,2019-09,P-GCN,69.5,100.0,9.4,0.14,69.5,1.0,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.1
5,1,Temporal Action Localization,ActivityNet-1.2,2020-01,DeepMetricLearner,60.5,100.0,60.5,1.0,60.5,0.87,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.1
0,1,Temporal Action Localization,THUMOS’14,2015-11,Yeung et al.,44.0,64.9,44.0,0.65,67.8,0.65,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.2
1,1,Temporal Action Localization,THUMOS’14,2017-03,TURN-FL-16 + S-CNN,50.9,75.07,6.9,0.1,67.8,0.75,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.2
2,1,Temporal Action Localization,THUMOS’14,2017-03,R-C3D,51.5,75.96,0.6,0.01,67.8,0.76,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.2
3,1,Temporal Action Localization,THUMOS’14,2017-05,CBR-TS,56.7,83.63,5.2,0.08,67.8,0.84,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.2
4,1,Temporal Action Localization,THUMOS’14,2018-04,TAL-Net,57.1,84.22,0.4,0.01,67.8,0.84,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.2
5,1,Temporal Action Localization,THUMOS’14,2019-09,P-GCN,67.8,100.0,10.7,0.16,67.8,1.0,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.2
0,1,Temporal Action Localization,THUMOS’14,2015-11,Yeung et al.,36.0,56.6,36.0,0.57,63.6,0.57,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.3
1,1,Temporal Action Localization,THUMOS’14,2016-01,S-CNN,36.3,57.08,0.3,0.0,63.6,0.57,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.3
2,1,Temporal Action Localization,THUMOS’14,2017-03,CDC,40.1,63.05,3.8,0.06,63.6,0.63,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.3
3,1,Temporal Action Localization,THUMOS’14,2017-03,TURN-FL-16 + S-CNN,44.1,69.34,4.0,0.06,63.6,0.69,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.3
4,1,Temporal Action Localization,THUMOS’14,2017-03,R-C3D,44.8,70.44,0.7,0.01,63.6,0.7,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.3
5,1,Temporal Action Localization,THUMOS’14,2017-05,CBR-TS,50.1,78.77,5.3,0.08,63.6,0.79,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.3
6,1,Temporal Action Localization,THUMOS’14,2018-04,TAL-Net,53.2,83.65,3.1,0.05,63.6,0.84,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.3
7,1,Temporal Action Localization,THUMOS’14,2018-06,BSN UNet,53.5,84.12,0.3,0.0,63.6,0.84,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.3
8,1,Temporal Action Localization,THUMOS’14,2019-04,Decouple-SSAD,60.2,94.65,6.7,0.11,63.6,0.95,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.3
9,1,Temporal Action Localization,THUMOS’14,2019-09,P-GCN,63.6,100.0,3.4,0.05,63.6,1.0,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.3
10,1,Temporal Action Localization,ActivityNet-1.2,2020-01,DeepMetricLearner,48.4,100.0,48.4,1.0,48.4,0.76,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.3
0,1,Temporal Action Localization,THUMOS’14,2015-11,Yeung et al.,26.4,45.67,26.4,0.46,57.8,0.46,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.4
1,1,Temporal Action Localization,THUMOS’14,2016-01,S-CNN,28.7,49.65,2.3,0.04,57.8,0.5,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.4
2,1,Temporal Action Localization,THUMOS’14,2017-03,CDC,29.4,50.87,0.7,0.01,57.8,0.51,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.4
3,1,Temporal Action Localization,THUMOS’14,2017-03,TURN-FL-16 + S-CNN,34.9,60.38,5.5,0.1,57.8,0.6,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.4
4,1,Temporal Action Localization,THUMOS’14,2017-03,R-C3D,35.6,61.59,0.7,0.01,57.8,0.62,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.4
5,1,Temporal Action Localization,THUMOS’14,2017-05,CBR-TS,41.3,71.45,5.7,0.1,57.8,0.71,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.4
6,1,Temporal Action Localization,THUMOS’14,2018-04,TAL-Net,48.5,83.91,7.2,0.12,57.8,0.84,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.4
7,1,Temporal Action Localization,THUMOS’14,2019-04,Decouple-SSAD,54.1,93.6,5.6,0.1,57.8,0.94,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.4
8,1,Temporal Action Localization,THUMOS’14,2019-09,P-GCN,57.8,100.0,3.7,0.06,57.8,1.0,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.4
0,1,Head Pose Estimation,BIWI,2015-11,3DDFA,19.068,100.0,19.068,1.0,19.068,1.0,ito:ITO_00101,Vision process,MAE\\ \\(trained\\ with\\ other\\ data\\)
0,1,Face Alignment,AFLW2000-3D,2015-11,3DDFA + SDM,4.94,100.0,4.94,1.0,4.94,0.77,ito:ITO_00101,Vision process,Mean\\ NME
1,1,3D Face Reconstruction,Florence,2015-11,3DDFA,6.3833,100.0,6.3833,1.0,6.3833,1.0,ito:ITO_00101,Vision process,Mean\\ NME
2,1,3D Face Reconstruction,AFLW2000-3D,2015-11,3DDFA,5.3695,95.11,5.3695,0.95,5.6454,0.84,ito:ITO_00101,Vision process,Mean\\ NME
3,1,3D Face Reconstruction,AFLW2000-3D,2017-09,DeFA,5.6454,100.0,0.3,0.05,5.6454,0.88,ito:ITO_00101,Vision process,Mean\\ NME
4,1,Face Alignment,AFLW-Full,2017-03,Binary Face Alignment,2.85,100.0,2.85,1.0,2.85,0.45,ito:ITO_00101,Vision process,Mean\\ NME
5,1,Face Alignment,AFLW-LFPA,2017-09,DeFA,3.86,100.0,3.86,1.0,3.86,0.6,ito:ITO_00101,Vision process,Mean\\ NME
6,1,Facial Landmark Detection,AFLW-Full,2018-03,SAN,1.91,95.02,1.91,0.95,2.01,0.3,ito:ITO_00101,Vision process,Mean\\ NME
7,1,Facial Landmark Detection,AFLW-Full,2019-02,"3DDE (Box height Norm, 19 landmarks",2.01,100.0,0.1,0.05,2.01,0.31,ito:ITO_00101,Vision process,Mean\\ NME
8,1,Facial Landmark Detection,AFLW-Front,2018-03,SAN,1.85,100.0,1.85,1.0,1.85,0.29,ito:ITO_00101,Vision process,Mean\\ NME
9,1,Face Alignment,AFLW,2018-04,3DDFA,4.55,100.0,4.55,1.0,4.55,0.71,ito:ITO_00101,Vision process,Mean\\ NME
0,1,Monocular 3D Human Pose Estimation,Human3.6M,2015-11,Sparseness Meets Deepness,300.0,100.0,300,1.0,300,1.0,ito:ITO_00101,Vision process,Frames\\ Needed
0,1,Vehicle Pose Estimation,KITTI Cars Hard,2015-12,3DOP,76.52,97.25,76.52,0.97,78.68,0.97,ito:ITO_00101,Vision process,Average\\ Orientation\\ Similarity
1,1,Vehicle Pose Estimation,KITTI Cars Hard,2016-04,SubCNN,78.68,100.0,2.2,0.03,78.68,1.0,ito:ITO_00101,Vision process,Average\\ Orientation\\ Similarity
0,1,Facial Expression Recognition,Oulu-CASIA,2015-12,DTAGN,81.46,85.75,81.46,0.86,95.0,0.86,ito:ITO_00101,Vision process,Accuracy\\ \\(10\\-fold\\)
1,1,Facial Expression Recognition,Oulu-CASIA,2016-07,PPDN,84.59,89.04,3.1,0.03,95.0,0.89,ito:ITO_00101,Vision process,Accuracy\\ \\(10\\-fold\\)
2,1,Facial Expression Recognition,Oulu-CASIA,2017-11,MicroExpNet,95.0,100.0,10.4,0.11,95.0,1.0,ito:ITO_00101,Vision process,Accuracy\\ \\(10\\-fold\\)
0,1,Retinal OCT Disease Classification,OCT2017,2015-12,InceptionV3,97.8,98.39,97.8,0.98,99.4,0.98,ito:ITO_00101,Vision process,Sensitivity
1,1,Retinal OCT Disease Classification,OCT2017,2015-12,ResNet50-v1,99.3,99.9,1.5,0.02,99.4,1.0,ito:ITO_00101,Vision process,Sensitivity
2,1,Retinal OCT Disease Classification,OCT2017,2018-01,MobileNet-v2,99.4,100.0,0.1,0.0,99.4,1.0,ito:ITO_00101,Vision process,Sensitivity
0,1,Visual Object Tracking,TrackingNet,2015-12,STAPLE_CA,60.84,75.96,60.84,0.76,80.1,0.76,ito:ITO_00101,Vision process,Normalized\\ Precision
1,1,Visual Object Tracking,TrackingNet,2016-11,ECO,62.14,77.58,1.3,0.02,80.1,0.78,ito:ITO_00101,Vision process,Normalized\\ Precision
2,1,Visual Object Tracking,TrackingNet,2018-11,ATOM,77.11,96.27,15.0,0.19,80.1,0.96,ito:ITO_00101,Vision process,Normalized\\ Precision
3,1,Visual Object Tracking,TrackingNet,2018-12,SiamRPN++,79.98,99.85,2.9,0.04,80.1,1.0,ito:ITO_00101,Vision process,Normalized\\ Precision
4,1,Visual Object Tracking,TrackingNet,2019-04,DiMP-50,80.1,100.0,0.1,0.0,80.1,1.0,ito:ITO_00101,Vision process,Normalized\\ Precision
0,1,Object Detection,COCO test-dev,2015-12,SSD512,28.8,54.03,28.8,0.54,53.3,0.31,ito:ITO_00101,Vision process,box\\ AP
1,1,Object Detection,COCO test-dev,2015-12,"Faster R-CNN (box refinement, context, multi-scale testing)",34.9,65.48,6.1,0.11,53.3,0.37,ito:ITO_00101,Vision process,box\\ AP
2,1,Object Detection,COCO test-dev,2016-12,Faster R-CNN + FPN,36.2,67.92,1.3,0.02,53.3,0.39,ito:ITO_00101,Vision process,box\\ AP
3,1,Object Detection,COCO test-dev,2016-12,Faster R-CNN + TDM,36.8,69.04,0.6,0.01,53.3,0.39,ito:ITO_00101,Vision process,box\\ AP
4,1,Object Detection,COCO test-dev,2017-03,DeformConv-R-FCN (Aligned-Inception-ResNet),37.5,70.36,0.7,0.01,53.3,0.4,ito:ITO_00101,Vision process,box\\ AP
5,1,Object Detection,COCO test-dev,2017-03,Mask R-CNN (ResNeXt-101-FPN),39.8,74.67,2.3,0.04,53.3,0.42,ito:ITO_00101,Vision process,box\\ AP
6,1,Object Detection,COCO test-dev,2017-08,RetinaNet (ResNeXt-101-FPN),40.8,76.55,1.0,0.02,53.3,0.43,ito:ITO_00101,Vision process,box\\ AP
7,1,Object Detection,COCO test-dev,2017-11,RefineDet512+ (ResNet-101),41.8,78.42,1.0,0.02,53.3,0.44,ito:ITO_00101,Vision process,box\\ AP
8,1,Object Detection,COCO test-dev,2017-11,"D-RFCN + SNIP (DPN-98 with flip, multi-scale)",45.7,85.74,3.9,0.07,53.3,0.49,ito:ITO_00101,Vision process,box\\ AP
9,1,Object Detection,COCO test-dev,2018-03,"PANet (ResNeXt-101, multi-scale)",47.4,88.93,1.7,0.03,53.3,0.5,ito:ITO_00101,Vision process,box\\ AP
10,1,Object Detection,COCO test-dev,2019-01,"TridentNet (ResNet-101-Deformable, Image Pyramid)",48.4,90.81,1.0,0.02,53.3,0.51,ito:ITO_00101,Vision process,box\\ AP
11,1,Object Detection,COCO test-dev,2019-06,"NAS-FPN (AmoebaNet-D, learned aug)",50.7,95.12,2.3,0.04,53.3,0.54,ito:ITO_00101,Vision process,box\\ AP
12,1,Object Detection,COCO test-dev,2019-09,"Cascade Mask R-CNN (Triple-ResNeXt152, multi-scale)",53.3,100.0,2.6,0.05,53.3,0.57,ito:ITO_00101,Vision process,box\\ AP
13,1,Object Detection,COCO minival,2016-12,FPN+,39.8,75.85,39.8,0.76,52.47,0.42,ito:ITO_00101,Vision process,box\\ AP
14,1,Object Detection,COCO minival,2017-03,Mask R-CNN (ResNet-101-FPN),40.0,76.23,0.2,0.0,52.47,0.43,ito:ITO_00101,Vision process,box\\ AP
15,1,Object Detection,COCO minival,2017-11,Mask R-CNN (ResNet-101 + 1 NL),40.8,77.76,0.8,0.02,52.47,0.43,ito:ITO_00101,Vision process,box\\ AP
16,1,Object Detection,COCO minival,2017-11,Mask R-CNN (ResNeXt-152 + 1 NL),45.0,85.76,4.2,0.08,52.47,0.48,ito:ITO_00101,Vision process,box\\ AP
17,1,Object Detection,COCO minival,2018-11,"Mask R-CNN (ResNet-101-FPN, GN, Cascade)",47.4,90.34,2.4,0.05,52.47,0.5,ito:ITO_00101,Vision process,box\\ AP
18,1,Object Detection,COCO minival,2018-11,"Mask R-CNN (ResNeXt-152-FPN, cascade)",48.6,92.62,1.2,0.02,52.47,0.52,ito:ITO_00101,Vision process,box\\ AP
19,1,Object Detection,COCO minival,2019-11,EfficientDet-D7(single-scale),52.1,99.29,3.5,0.07,52.47,0.55,ito:ITO_00101,Vision process,box\\ AP
20,1,Object Detection,COCO minival,2020-04,ResNeSt-200 (multi-scale),52.47,100.0,0.4,0.01,52.47,0.56,ito:ITO_00101,Vision process,box\\ AP
21,1,3D Shape Modeling,Pix3D S1,2019-06,Mesh R-CNN,94.0,100.0,94,1.0,94,1.0,ito:ITO_00101,Vision process,box\\ AP
22,1,Road Segementation,Road Segementation,2019-06,Mesh R-CNN,94.0,100.0,94,1.0,94,1.0,ito:ITO_00101,Vision process,box\\ AP
23,1,3D Shape Modeling,Pix3D S2,2019-06,Mesh R-CNN,72.2,100.0,72.2,1.0,72.2,0.77,ito:ITO_00101,Vision process,box\\ AP
24,1,UNET Segmentation,UNET Segmentation,2019-06,Mesh R-CNN,72.2,100.0,72.2,1.0,72.2,0.77,ito:ITO_00101,Vision process,box\\ AP
25,1,Object Detection,MSCOCO,2020-04,yolov4.cfg/weights,43.5,100.0,43.5,1.0,43.5,0.46,ito:ITO_00101,Vision process,box\\ AP
0,1,Pedestrian Attribute Recognition,UAV-Human,2015-12,ResNet,63.5,99.37,63.5,0.99,63.9,0.99,ito:ITO_00101,Vision process,Backpack
1,1,Pedestrian Attribute Recognition,UAV-Human,2016-08,DenseNet,63.9,100.0,0.4,0.01,63.9,1.0,ito:ITO_00101,Vision process,Backpack
0,1,Pedestrian Attribute Recognition,UAV-Human,2015-12,ResNet,74.7,99.6,74.7,1.0,75.0,1.0,ito:ITO_00101,Vision process,Gender
1,1,Pedestrian Attribute Recognition,UAV-Human,2016-08,DenseNet,75.0,100.0,0.3,0.0,75.0,1.0,ito:ITO_00101,Vision process,Gender
0,1,Pedestrian Attribute Recognition,UAV-Human,2015-12,ResNet,65.2,97.02,65.2,0.97,67.2,0.97,ito:ITO_00101,Vision process,Hat
1,1,Pedestrian Attribute Recognition,UAV-Human,2016-08,DenseNet,67.2,100.0,2.0,0.03,67.2,1.0,ito:ITO_00101,Vision process,Hat
0,1,Pedestrian Attribute Recognition,UAV-Human,2015-12,ResNet,49.7,91.03,49.7,0.91,54.6,0.91,ito:ITO_00101,Vision process,LCC
1,1,Pedestrian Attribute Recognition,UAV-Human,2016-08,DenseNet,54.6,100.0,4.9,0.09,54.6,1.0,ito:ITO_00101,Vision process,LCC
0,1,Pedestrian Attribute Recognition,UAV-Human,2015-12,ResNet,69.3,100.0,69.3,1.0,69.3,1.0,ito:ITO_00101,Vision process,LCS
0,1,Pedestrian Attribute Recognition,UAV-Human,2015-12,ResNet,44.4,89.16,44.4,0.89,49.8,0.89,ito:ITO_00101,Vision process,UCC
1,1,Pedestrian Attribute Recognition,UAV-Human,2016-08,DenseNet,49.8,100.0,5.4,0.11,49.8,1.0,ito:ITO_00101,Vision process,UCC
0,1,Pedestrian Attribute Recognition,UAV-Human,2015-12,ResNet,68.9,94.38,68.9,0.94,73.0,0.94,ito:ITO_00101,Vision process,UCS
1,1,Pedestrian Attribute Recognition,UAV-Human,2016-08,DenseNet,73.0,100.0,4.1,0.06,73.0,1.0,ito:ITO_00101,Vision process,UCS
0,1,Domain Generalization,ImageNet-A,2015-12,ResNet-50 (300 Epochs),4.2,50.0,4.2,0.5,8.4,0.08,ito:ITO_00101,Vision process,Top\\-1\\ accuracy\\ %
1,1,Domain Generalization,ImageNet-A,2017-08,ResNet-50+Cutout,4.4,52.38,0.2,0.02,8.4,0.08,ito:ITO_00101,Vision process,Top\\-1\\ accuracy\\ %
2,1,Domain Generalization,ImageNet-A,2017-10,ResNet-50+Mixup,6.6,78.57,2.2,0.26,8.4,0.13,ito:ITO_00101,Vision process,Top\\-1\\ accuracy\\ %
3,1,Domain Generalization,ImageNet-A,2019-05,ResNet-50+CutMix,7.3,86.9,0.7,0.08,8.4,0.14,ito:ITO_00101,Vision process,Top\\-1\\ accuracy\\ %
4,1,Domain Generalization,ImageNet-A,2020-02,ResNet-50+CutMix+MoEx,8.4,100.0,1.1,0.13,8.4,0.16,ito:ITO_00101,Vision process,Top\\-1\\ accuracy\\ %
5,1,Compositional Zero-Shot Learning,UT-Zappos,2020-04,SymNet,52.1,100.0,52.1,1.0,52.1,1.0,ito:ITO_00101,Vision process,Top\\-1\\ accuracy\\ %
6,1,Compositional Zero-Shot Learning,MIT-States,2020-04,SymNet,19.9,100.0,19.9,1.0,19.9,0.38,ito:ITO_00101,Vision process,Top\\-1\\ accuracy\\ %
0,1,Domain Generalization,ImageNet-R,2015-12,ResNet-50,63.9,100.0,63.9,1.0,63.9,0.95,ito:ITO_00101,Vision process,Top\\-1\\ Error\\ Rate
1,1,Weakly-Supervised Object Localization,ILSVRC 2015,2015-12,AlexNet-GAP,67.19,100.0,67.19,1.0,67.19,1.0,ito:ITO_00101,Vision process,Top\\-1\\ Error\\ Rate
2,1,Fine-Grained Image Classification,Caltech-101,2018-05,UL-Hopfield (ULH),9.0,68.86,9.0,0.69,13.07,0.13,ito:ITO_00101,Vision process,Top\\-1\\ Error\\ Rate
3,1,Fine-Grained Image Classification,Caltech-101,2018-05,AutoAugment,13.07,100.0,4.1,0.31,13.07,0.19,ito:ITO_00101,Vision process,Top\\-1\\ Error\\ Rate
4,1,Fine-Grained Image Classification,Oxford 102 Flowers,2018-05,AutoAugment,4.64,100.0,4.64,1.0,4.64,0.07,ito:ITO_00101,Vision process,Top\\-1\\ Error\\ Rate
5,1,Fine-Grained Image Classification,Oxford-IIIT Pets,2018-05,AutoAugment,11.02,100.0,11.02,1.0,11.02,0.16,ito:ITO_00101,Vision process,Top\\-1\\ Error\\ Rate
6,1,Fine-Grained Image Classification,FGVC Aircraft,2018-05,AutoAugment,7.33,100.0,7.33,1.0,7.33,0.11,ito:ITO_00101,Vision process,Top\\-1\\ Error\\ Rate
7,1,Fine-Grained Image Classification,Stanford Cars,2018-05,AutoAugment,5.2,100.0,5.2,1.0,5.2,0.08,ito:ITO_00101,Vision process,Top\\-1\\ Error\\ Rate
8,1,Weakly-Supervised Object Localization,CUB-200-2011,2018-07,SPG,53.36,98.5,53.36,0.99,54.17,0.79,ito:ITO_00101,Vision process,Top\\-1\\ Error\\ Rate
9,1,Weakly-Supervised Object Localization,CUB-200-2011,2019-11,InfoCAM,54.17,100.0,0.8,0.01,54.17,0.81,ito:ITO_00101,Vision process,Top\\-1\\ Error\\ Rate
10,1,Image Recognition,ImageNet,2020-03,LIO/ResNet-50 (multi-stage),22.87,100.0,22.87,1.0,22.87,0.34,ito:ITO_00101,Vision process,Top\\-1\\ Error\\ Rate
0,1,Weakly-Supervised Object Localization,Tiny ImageNet,2015-12,CAM,40.55,93.56,40.55,0.94,43.34,0.73,ito:ITO_00101,Vision process,Top\\-1\\ Localization\\ Accuracy
1,1,Weakly-Supervised Object Localization,Tiny ImageNet,2019-11,InfoCAM,43.34,100.0,2.8,0.06,43.34,0.78,ito:ITO_00101,Vision process,Top\\-1\\ Localization\\ Accuracy
2,1,Weakly-Supervised Object Localization,CUB-200-2011,2019-11,InfoCAM,55.83,100.0,55.83,1.0,55.83,1.0,ito:ITO_00101,Vision process,Top\\-1\\ Localization\\ Accuracy
0,1,Weakly-Supervised Object Localization,ILSVRC 2016,2015-12,AlexNet-GAP,52.16,100.0,52.16,1.0,52.16,1.0,ito:ITO_00101,Vision process,Top\\-5\\ Error
1,1,Weakly-Supervised Object Localization,CUB-200-2011,2018-07,SPG,42.28,100.0,42.28,1.0,42.28,0.81,ito:ITO_00101,Vision process,Top\\-5\\ Error
0,1,Instance Segmentation,COCO test-dev,2015-12,MNC,43.6,70.78,43.6,0.71,61.6,0.49,ito:ITO_00101,Vision process,APL
1,1,Instance Segmentation,COCO test-dev,2016-11,FCIS  +OHEM,50.0,81.17,6.4,0.1,61.6,0.56,ito:ITO_00101,Vision process,APL
2,1,Instance Segmentation,COCO test-dev,2017-03,Mask R-CNN (ResNeXt-101-FPN),53.5,86.85,3.5,0.06,61.6,0.6,ito:ITO_00101,Vision process,APL
3,1,Instance Segmentation,COCO test-dev,2019-11,CenterMask + VoVNet99,54.3,88.15,0.8,0.01,61.6,0.61,ito:ITO_00101,Vision process,APL
4,1,Instance Segmentation,COCO test-dev,2019-12,YOLACT-550++ (ResNet-101-FPN),55.1,89.45,0.8,0.01,61.6,0.62,ito:ITO_00101,Vision process,APL
5,1,Instance Segmentation,COCO test-dev,2019-12,SOLO(Res-DCN-101-FPN),58.9,95.62,3.8,0.06,61.6,0.66,ito:ITO_00101,Vision process,APL
6,1,Instance Segmentation,COCO test-dev,2020-03,SOLOv2(Res-DCN-101-FPN),61.6,100.0,2.7,0.04,61.6,0.7,ito:ITO_00101,Vision process,APL
7,1,Keypoint Detection,COCO test-dev,2016-11,AE,72.6,87.36,72.6,0.87,83.1,0.82,ito:ITO_00101,Vision process,APL
8,1,Keypoint Detection,COCO test-dev,2016-12,AlphaPose,81.5,98.07,8.9,0.11,83.1,0.92,ito:ITO_00101,Vision process,APL
9,1,Keypoint Detection,COCO test-dev,2018-04,Simple Base+*,82.7,99.52,1.2,0.01,83.1,0.93,ito:ITO_00101,Vision process,APL
10,1,Keypoint Detection,COCO test-dev,2019-02,HRNet*,83.1,100.0,0.4,0.0,83.1,0.94,ito:ITO_00101,Vision process,APL
11,1,Pose Estimation,COCO test-dev,2016-11,CMU-Pose,68.2,81.48,68.2,0.81,83.7,0.77,ito:ITO_00101,Vision process,APL
12,1,Pose Estimation,COCO test-dev,2016-12,RMPE++,78.6,93.91,10.4,0.12,83.7,0.89,ito:ITO_00101,Vision process,APL
13,1,Pose Estimation,COCO test-dev,2018-04,Flow-based (ResNet-152),80.0,95.58,1.4,0.02,83.7,0.9,ito:ITO_00101,Vision process,APL
14,1,Pose Estimation,COCO test-dev,2018-12,PoseFix,81.2,97.01,1.2,0.01,83.7,0.92,ito:ITO_00101,Vision process,APL
15,1,Pose Estimation,COCO test-dev,2019-01,MSPN,81.5,97.37,0.3,0.0,83.7,0.92,ito:ITO_00101,Vision process,APL
16,1,Pose Estimation,COCO test-dev,2019-02,HRNet-W48 + extra data,83.1,99.28,1.6,0.02,83.7,0.94,ito:ITO_00101,Vision process,APL
17,1,Pose Estimation,COCO test-dev,2019-10,DARK (extra data),83.7,100.0,0.6,0.01,83.7,0.94,ito:ITO_00101,Vision process,APL
18,1,Multi-Person Pose Estimation,COCO test-dev,2016-11,CMU-Pose,68.2,89.97,68.2,0.9,75.8,0.77,ito:ITO_00101,Vision process,APL
19,1,Multi-Person Pose Estimation,COCO test-dev,2017-01,G-RMI,70.0,92.35,1.8,0.02,75.8,0.79,ito:ITO_00101,Vision process,APL
20,1,Multi-Person Pose Estimation,COCO test-dev,2018-03,PersonLab,75.5,99.6,5.5,0.07,75.8,0.85,ito:ITO_00101,Vision process,APL
21,1,Multi-Person Pose Estimation,COCO test-dev,2019-08,HigherHRNet (HR-Net-48),75.8,100.0,0.3,0.0,75.8,0.86,ito:ITO_00101,Vision process,APL
22,1,Object Detection,COCO minival,2016-12,FPN+,52.6,79.35,52.6,0.79,66.29,0.59,ito:ITO_00101,Vision process,APL
23,1,Object Detection,COCO minival,2017-12,"Cascade R-CNN (ResNet-101-FPN+, cascade)",57.4,86.59,4.8,0.07,66.29,0.65,ito:ITO_00101,Vision process,APL
24,1,Object Detection,COCO minival,2018-11,"Faster R-CNN (ResNet-101, DCNv2)",58.7,88.55,1.3,0.02,66.29,0.66,ito:ITO_00101,Vision process,APL
25,1,Object Detection,COCO minival,2019-01,"ExtremeNet (Hourglass-104, multi-scale)",59.4,89.61,0.7,0.01,66.29,0.67,ito:ITO_00101,Vision process,APL
26,1,Object Detection,COCO minival,2019-04,Res2Net101+HTC,62.1,93.68,2.7,0.04,66.29,0.7,ito:ITO_00101,Vision process,APL
27,1,Object Detection,COCO minival,2019-08,HTC (HRNetV2p-W48),62.2,93.83,0.1,0.0,66.29,0.7,ito:ITO_00101,Vision process,APL
28,1,Object Detection,COCO minival,2019-12,"RetinaNet (SpineNet-190, single-scale)",65.0,98.05,2.8,0.04,66.29,0.73,ito:ITO_00101,Vision process,APL
29,1,Object Detection,COCO minival,2020-04,ResNeSt-200 (multi-scale),66.29,100.0,1.3,0.02,66.29,0.75,ito:ITO_00101,Vision process,APL
30,1,Keypoint Detection,COCO test-challenge,2017-01,G-RMI*,82.4,93.0,82.4,0.93,88.6,0.93,ito:ITO_00101,Vision process,APL
31,1,Keypoint Detection,COCO test-challenge,2017-03,Mask R-CNN*,82.6,93.23,0.2,0.0,88.6,0.93,ito:ITO_00101,Vision process,APL
32,1,Keypoint Detection,COCO test-challenge,2017-11,CPN+,84.7,95.6,2.1,0.02,88.6,0.96,ito:ITO_00101,Vision process,APL
33,1,Keypoint Detection,COCO test-challenge,2018-04,Simple Base+*,87.5,98.76,2.8,0.03,88.6,0.99,ito:ITO_00101,Vision process,APL
34,1,Keypoint Detection,COCO test-challenge,2019-01,MSPN+*,88.6,100.0,1.1,0.01,88.6,1.0,ito:ITO_00101,Vision process,APL
35,1,Object Detection,COCO test-dev,2017-03,DeformConv-R-FCN (Aligned-Inception-ResNet),52.5,78.59,52.5,0.79,66.8,0.59,ito:ITO_00101,Vision process,APL
36,1,Object Detection,COCO test-dev,2017-11,RefineDet512+ (ResNet-101),54.1,80.99,1.6,0.02,66.8,0.61,ito:ITO_00101,Vision process,APL
37,1,Object Detection,COCO test-dev,2017-11,"D-RFCN + SNIP (ResNet-101, multi-scale)",54.9,82.19,0.8,0.01,66.8,0.62,ito:ITO_00101,Vision process,APL
38,1,Object Detection,COCO test-dev,2017-11,"D-RFCN + SNIP (DPN-98 with flip, multi-scale)",57.1,85.48,2.2,0.03,66.8,0.64,ito:ITO_00101,Vision process,APL
39,1,Object Detection,COCO test-dev,2018-03,"PANet (ResNeXt-101, multi-scale)",60.0,89.82,2.9,0.04,66.8,0.68,ito:ITO_00101,Vision process,APL
40,1,Object Detection,COCO test-dev,2019-01,"TridentNet (ResNet-101-Deformable, Image Pyramid)",60.3,90.27,0.3,0.0,66.8,0.68,ito:ITO_00101,Vision process,APL
41,1,Object Detection,COCO test-dev,2019-06,"NAS-FPN (AmoebaNet-D, learned aug)",64.5,96.56,4.2,0.06,66.8,0.73,ito:ITO_00101,Vision process,APL
42,1,Object Detection,COCO test-dev,2019-09,"Cascade Mask R-CNN (Triple-ResNeXt152, multi-scale)",66.7,99.85,2.2,0.03,66.8,0.75,ito:ITO_00101,Vision process,APL
43,1,Object Detection,COCO test-dev,2020-04,ResNeSt-200DCN,66.8,100.0,0.1,0.0,66.8,0.75,ito:ITO_00101,Vision process,APL
44,1,Instance Segmentation,COCO minival,2019-03,"Mask R-CNN-FPN (ResNeXt-101, GN+WS)",56.08,100.0,56.08,1.0,56.08,0.63,ito:ITO_00101,Vision process,APL
45,1,Real-time Instance Segmentation,MSCOCO,2019-04,YOLACT-550 (ResNet-101-FPN),44.8,91.99,44.8,0.92,48.7,0.51,ito:ITO_00101,Vision process,APL
46,1,Real-time Instance Segmentation,MSCOCO,2019-04,YOLACT,45.0,92.4,0.2,0.0,48.7,0.51,ito:ITO_00101,Vision process,APL
47,1,Real-time Instance Segmentation,MSCOCO,2019-11,CenterMask-Lite (ResNet-50-FPN),48.7,100.0,3.7,0.08,48.7,0.55,ito:ITO_00101,Vision process,APL
0,1,Instance Segmentation,COCO test-dev,2015-12,MNC,25.9,57.56,25.9,0.58,45.0,0.35,ito:ITO_00101,Vision process,APM
1,1,Instance Segmentation,COCO test-dev,2016-11,FCIS  +OHEM,31.3,69.56,5.4,0.12,45.0,0.43,ito:ITO_00101,Vision process,APM
2,1,Instance Segmentation,COCO test-dev,2017-03,Mask R-CNN (ResNeXt-101-FPN),39.9,88.67,8.6,0.19,45.0,0.54,ito:ITO_00101,Vision process,APM
3,1,Instance Segmentation,COCO test-dev,2019-08,"Cascade R-CNN (ResNet-101-FPN, map-guided)",42.5,94.44,2.6,0.06,45.0,0.58,ito:ITO_00101,Vision process,APM
4,1,Instance Segmentation,COCO test-dev,2019-11,CenterMask + VoVNetV2-99 (single-scale),42.8,95.11,0.3,0.01,45.0,0.58,ito:ITO_00101,Vision process,APM
5,1,Instance Segmentation,COCO test-dev,2019-11,CenterMask + VoVNet99,44.4,98.67,1.6,0.04,45.0,0.6,ito:ITO_00101,Vision process,APM
6,1,Instance Segmentation,COCO test-dev,2020-03,SOLOv2(Res-DCN-101-FPN),45.0,100.0,0.6,0.01,45.0,0.61,ito:ITO_00101,Vision process,APM
7,1,Keypoint Detection,COCO test-dev,2016-11,AE,60.6,82.56,60.6,0.83,73.4,0.82,ito:ITO_00101,Vision process,APM
8,1,Keypoint Detection,COCO test-dev,2017-01,G-RMI,62.3,84.88,1.7,0.02,73.4,0.85,ito:ITO_00101,Vision process,APM
9,1,Keypoint Detection,COCO test-dev,2017-11,CPN,68.7,93.6,6.4,0.09,73.4,0.93,ito:ITO_00101,Vision process,APM
10,1,Keypoint Detection,COCO test-dev,2017-11,CPN+,69.5,94.69,0.8,0.01,73.4,0.94,ito:ITO_00101,Vision process,APM
11,1,Keypoint Detection,COCO test-dev,2018-04,Simple Base,70.3,95.78,0.8,0.01,73.4,0.96,ito:ITO_00101,Vision process,APM
12,1,Keypoint Detection,COCO test-dev,2018-04,Simple Base+*,73.0,99.46,2.7,0.04,73.4,0.99,ito:ITO_00101,Vision process,APM
13,1,Keypoint Detection,COCO test-dev,2019-02,HRNet*,73.4,100.0,0.4,0.01,73.4,1.0,ito:ITO_00101,Vision process,APM
14,1,Multi-Person Pose Estimation,COCO test-dev,2016-11,CMU-Pose,57.1,85.48,57.1,0.85,66.8,0.78,ito:ITO_00101,Vision process,APM
15,1,Multi-Person Pose Estimation,COCO test-dev,2016-12,RMPE,58.6,87.72,1.5,0.02,66.8,0.8,ito:ITO_00101,Vision process,APM
16,1,Multi-Person Pose Estimation,COCO test-dev,2017-01,G-RMI,62.3,93.26,3.7,0.06,66.8,0.85,ito:ITO_00101,Vision process,APM
17,1,Multi-Person Pose Estimation,COCO test-dev,2018-03,PersonLab,64.1,95.96,1.8,0.03,66.8,0.87,ito:ITO_00101,Vision process,APM
18,1,Multi-Person Pose Estimation,COCO test-dev,2019-08,HigherHRNet (HR-Net-48),66.6,99.7,2.5,0.04,66.8,0.9,ito:ITO_00101,Vision process,APM
19,1,Multi-Person Pose Estimation,COCO test-dev,2019-11,Identity Mapping Hourglass,66.8,100.0,0.2,0.0,66.8,0.91,ito:ITO_00101,Vision process,APM
20,1,Pose Estimation,COCO test-dev,2016-12,RMPE++,68.0,92.39,68.0,0.92,73.6,0.92,ito:ITO_00101,Vision process,APM
21,1,Pose Estimation,COCO test-dev,2018-04,Flow-based (ResNet-152),70.3,95.52,2.3,0.03,73.6,0.96,ito:ITO_00101,Vision process,APM
22,1,Pose Estimation,COCO test-dev,2018-12,PoseFix,71.1,96.6,0.8,0.01,73.6,0.97,ito:ITO_00101,Vision process,APM
23,1,Pose Estimation,COCO test-dev,2019-01,MSPN,72.3,98.23,1.2,0.02,73.6,0.98,ito:ITO_00101,Vision process,APM
24,1,Pose Estimation,COCO test-dev,2019-02,HRNet-W48 + extra data,73.4,99.73,1.1,0.01,73.6,1.0,ito:ITO_00101,Vision process,APM
25,1,Pose Estimation,COCO test-dev,2019-10,DARK (extra data),73.6,100.0,0.2,0.0,73.6,1.0,ito:ITO_00101,Vision process,APM
26,1,Object Detection,COCO minival,2016-12,FPN+,43.3,72.53,43.3,0.73,59.7,0.59,ito:ITO_00101,Vision process,APM
27,1,Object Detection,COCO minival,2017-12,"Cascade R-CNN (ResNet-101-FPN+, cascade)",46.2,77.39,2.9,0.05,59.7,0.63,ito:ITO_00101,Vision process,APM
28,1,Object Detection,COCO minival,2018-03,"Mask R-CNN (ResNet-50-FPN, GroupNorm, long)",58.5,97.99,12.3,0.21,59.7,0.79,ito:ITO_00101,Vision process,APM
29,1,Object Detection,COCO minival,2018-03,"Mask R-CNN (ResNet-101-FPN, GroupNorm, long)",59.7,100.0,1.2,0.02,59.7,0.81,ito:ITO_00101,Vision process,APM
30,1,Object Detection,COCO test-dev,2017-03,DeformConv-R-FCN (Aligned-Inception-ResNet),40.1,69.98,40.1,0.7,57.3,0.54,ito:ITO_00101,Vision process,APM
31,1,Object Detection,COCO test-dev,2017-03,Mask R-CNN (ResNeXt-101-FPN),43.2,75.39,3.1,0.05,57.3,0.59,ito:ITO_00101,Vision process,APM
32,1,Object Detection,COCO test-dev,2017-08,RetinaNet (ResNeXt-101-FPN),44.2,77.14,1.0,0.02,57.3,0.6,ito:ITO_00101,Vision process,APM
33,1,Object Detection,COCO test-dev,2017-11,RefineDet512+ (ResNet-101),45.1,78.71,0.9,0.02,57.3,0.61,ito:ITO_00101,Vision process,APM
34,1,Object Detection,COCO test-dev,2017-11,"D-RFCN + SNIP (DPN-98 with flip, multi-scale)",48.8,85.17,3.7,0.06,57.3,0.66,ito:ITO_00101,Vision process,APM
35,1,Object Detection,COCO test-dev,2018-03,"PANet (ResNeXt-101, multi-scale)",51.7,90.23,2.9,0.05,57.3,0.7,ito:ITO_00101,Vision process,APM
36,1,Object Detection,COCO test-dev,2019-06,"NAS-FPN (AmoebaNet-D, learned aug)",55.5,96.86,3.8,0.07,57.3,0.75,ito:ITO_00101,Vision process,APM
37,1,Object Detection,COCO test-dev,2019-09,"Cascade Mask R-CNN (Triple-ResNeXt152, multi-scale)",55.8,97.38,0.3,0.01,57.3,0.76,ito:ITO_00101,Vision process,APM
38,1,Object Detection,COCO test-dev,2019-11,EfficientDet-D7(single-scale),55.9,97.56,0.1,0.0,57.3,0.76,ito:ITO_00101,Vision process,APM
39,1,Object Detection,COCO test-dev,2020-02,"Mask R-CNN (ResNet-101-FPN, CBN)",57.3,100.0,1.4,0.02,57.3,0.78,ito:ITO_00101,Vision process,APM
40,1,Instance Segmentation,COCO minival,2019-03,"Mask R-CNN-FPN (ResNeXt-101, GN+WS)",41.73,100.0,41.73,1.0,41.73,0.57,ito:ITO_00101,Vision process,APM
41,1,Real-time Instance Segmentation,MSCOCO,2019-04,YOLACT-550 (ResNet-101-FPN),29.3,84.44,29.3,0.84,34.7,0.4,ito:ITO_00101,Vision process,APM
42,1,Real-time Instance Segmentation,MSCOCO,2019-11,CenterMask-Lite (ResNet-50-FPN),34.7,100.0,5.4,0.16,34.7,0.47,ito:ITO_00101,Vision process,APM
0,1,Instance Segmentation,COCO test-dev,2015-12,MNC,4.7,17.28,4.7,0.17,27.2,0.13,ito:ITO_00101,Vision process,APS
1,1,Instance Segmentation,COCO test-dev,2016-11,FCIS  +OHEM,7.1,26.1,2.4,0.09,27.2,0.19,ito:ITO_00101,Vision process,APS
2,1,Instance Segmentation,COCO test-dev,2017-03,Mask R-CNN (ResNeXt-101-FPN),16.9,62.13,9.8,0.36,27.2,0.45,ito:ITO_00101,Vision process,APS
3,1,Instance Segmentation,COCO test-dev,2019-08,"Cascade R-CNN (ResNet-101-FPN, map-guided)",21.2,77.94,4.3,0.16,27.2,0.57,ito:ITO_00101,Vision process,APS
4,1,Instance Segmentation,COCO test-dev,2019-11,CenterMask + VoVNetV2-99 (multi-scale),27.2,100.0,6.0,0.22,27.2,0.73,ito:ITO_00101,Vision process,APS
5,1,Object Detection,COCO minival,2016-12,FPN+,22.9,61.23,22.9,0.61,37.4,0.61,ito:ITO_00101,Vision process,APS
6,1,Object Detection,COCO minival,2017-12,"Cascade R-CNN (ResNet-101-FPN+, cascade)",23.8,63.64,0.9,0.02,37.4,0.64,ito:ITO_00101,Vision process,APS
7,1,Object Detection,COCO minival,2018-03,"Mask R-CNN (ResNet-50-FPN, GroupNorm, long)",36.1,96.52,12.3,0.33,37.4,0.97,ito:ITO_00101,Vision process,APS
8,1,Object Detection,COCO minival,2018-03,"Mask R-CNN (ResNet-101-FPN, GroupNorm, long)",37.2,99.47,1.1,0.03,37.4,0.99,ito:ITO_00101,Vision process,APS
9,1,Object Detection,COCO minival,2019-12,"RetinaNet (SpineNet-190, single-scale)",37.4,100.0,0.2,0.01,37.4,1.0,ito:ITO_00101,Vision process,APS
10,1,Object Detection,COCO test-dev,2017-03,DeformConv-R-FCN (Aligned-Inception-ResNet),19.4,54.19,19.4,0.54,35.8,0.52,ito:ITO_00101,Vision process,APS
11,1,Object Detection,COCO test-dev,2017-03,Mask R-CNN (ResNet-101-FPN),20.1,56.15,0.7,0.02,35.8,0.54,ito:ITO_00101,Vision process,APS
12,1,Object Detection,COCO test-dev,2017-03,Mask R-CNN (ResNeXt-101-FPN),22.1,61.73,2.0,0.06,35.8,0.59,ito:ITO_00101,Vision process,APS
13,1,Object Detection,COCO test-dev,2017-08,RetinaNet (ResNeXt-101-FPN),24.1,67.32,2.0,0.06,35.8,0.64,ito:ITO_00101,Vision process,APS
14,1,Object Detection,COCO test-dev,2017-11,RefineDet512+ (ResNet-101),25.6,71.51,1.5,0.04,35.8,0.68,ito:ITO_00101,Vision process,APS
15,1,Object Detection,COCO test-dev,2017-11,"D-RFCN + SNIP (DPN-98 with flip, multi-scale)",29.3,81.84,3.7,0.1,35.8,0.78,ito:ITO_00101,Vision process,APS
16,1,Object Detection,COCO test-dev,2018-03,"PANet (ResNeXt-101, multi-scale)",30.1,84.08,0.8,0.02,35.8,0.8,ito:ITO_00101,Vision process,APS
17,1,Object Detection,COCO test-dev,2019-01,"TridentNet (ResNet-101-Deformable, Image Pyramid)",31.8,88.83,1.7,0.05,35.8,0.85,ito:ITO_00101,Vision process,APS
18,1,Object Detection,COCO test-dev,2019-06,"NAS-FPN (AmoebaNet-D, learned aug)",34.2,95.53,2.4,0.07,35.8,0.91,ito:ITO_00101,Vision process,APS
19,1,Object Detection,COCO test-dev,2019-09,"Cascade Mask R-CNN (Triple-ResNeXt152, multi-scale)",35.5,99.16,1.3,0.04,35.8,0.95,ito:ITO_00101,Vision process,APS
20,1,Object Detection,COCO test-dev,2020-02,"Mask R-CNN (ResNet-101-FPN, CBN)",35.8,100.0,0.3,0.01,35.8,0.96,ito:ITO_00101,Vision process,APS
21,1,Instance Segmentation,COCO minival,2019-03,"Mask R-CNN-FPN (ResNeXt-101, GN+WS)",18.32,100.0,18.32,1.0,18.32,0.49,ito:ITO_00101,Vision process,APS
22,1,Real-time Instance Segmentation,MSCOCO,2019-04,YOLACT-550 (ResNet-101-FPN),9.2,71.32,9.2,0.71,12.9,0.25,ito:ITO_00101,Vision process,APS
23,1,Real-time Instance Segmentation,MSCOCO,2019-11,CenterMask-Lite (ResNet-50-FPN),12.9,100.0,3.7,0.29,12.9,0.34,ito:ITO_00101,Vision process,APS
0,1,Multi-Human Parsing,PASCAL-Person-Part,2015-12,MNC,38.8,64.99,38.8,0.65,59.7,0.65,ito:ITO_00101,Vision process,AP\\ 0\\.5
1,1,Multi-Human Parsing,PASCAL-Person-Part,2017-09,Holistic instance-level,40.6,68.01,1.8,0.03,59.7,0.68,ito:ITO_00101,Vision process,AP\\ 0\\.5
2,1,Multi-Human Parsing,PASCAL-Person-Part,2018-04,NAN,59.7,100.0,19.1,0.32,59.7,1.0,ito:ITO_00101,Vision process,AP\\ 0\\.5
3,1,Multi-Human Parsing,PASCAL-Part,2015-12,MNC,38.8,64.99,38.8,0.65,59.7,0.65,ito:ITO_00101,Vision process,AP\\ 0\\.5
4,1,Multi-Human Parsing,PASCAL-Part,2017-09,Holistic instance-level,40.6,68.01,1.8,0.03,59.7,0.68,ito:ITO_00101,Vision process,AP\\ 0\\.5
5,1,Multi-Human Parsing,PASCAL-Part,2018-04,NAN,59.7,100.0,19.1,0.32,59.7,1.0,ito:ITO_00101,Vision process,AP\\ 0\\.5
6,1,Multi-Human Parsing,MHP v1.0,2017-03,Mask R-CNN,52.68,92.28,52.68,0.92,57.09,0.88,ito:ITO_00101,Vision process,AP\\ 0\\.5
7,1,Multi-Human Parsing,MHP v1.0,2018-04,NAN,57.09,100.0,4.4,0.08,57.09,0.96,ito:ITO_00101,Vision process,AP\\ 0\\.5
8,1,Multi-Human Parsing,MHP v2.0,2017-03,Mask R-CNN,14.9,59.27,14.9,0.59,25.14,0.25,ito:ITO_00101,Vision process,AP\\ 0\\.5
9,1,Multi-Human Parsing,MHP v2.0,2017-05,MH-Parser,17.99,71.56,3.1,0.12,25.14,0.3,ito:ITO_00101,Vision process,AP\\ 0\\.5
10,1,Multi-Human Parsing,MHP v2.0,2018-04,NAN,25.14,100.0,7.2,0.29,25.14,0.42,ito:ITO_00101,Vision process,AP\\ 0\\.5
11,1,One-Shot Object Detection,COCO,2018-11,Siamese Mask R-CNN,16.3,74.09,16.3,0.74,22.0,0.27,ito:ITO_00101,Vision process,AP\\ 0\\.5
12,1,One-Shot Object Detection,COCO,2019-11,One-Shot Object Detection,22.0,100.0,5.7,0.26,22.0,0.37,ito:ITO_00101,Vision process,AP\\ 0\\.5
13,1,One-Shot Instance Segmentation,COCO,2018-11,Siamese Mask R-CNN,14.5,100.0,14.5,1.0,14.5,0.24,ito:ITO_00101,Vision process,AP\\ 0\\.5
0,1,Entity Disambiguation,AIDA-CoNLL,2016-01,Wikipedia2Vec-GBRT,93.1,98.0,93.1,0.98,95.0,0.98,ito:ITO_00101,Vision process,Micro\\-F1
1,1,Entity Disambiguation,AIDA-CoNLL,2017-05,NTEE,94.7,99.68,1.6,0.02,95.0,1.0,ito:ITO_00101,Vision process,Micro\\-F1
2,1,Entity Disambiguation,AIDA-CoNLL,2019-09,confidence-order,95.0,100.0,0.3,0.0,95.0,1.0,ito:ITO_00101,Vision process,Micro\\-F1
3,1,Junction Detection,Junction Detection,2016-01,Wikipedia2Vec-GBRT,93.1,98.0,93.1,0.98,95.0,0.98,ito:ITO_00101,Vision process,Micro\\-F1
4,1,Junction Detection,Junction Detection,2017-05,NTEE,94.7,99.68,1.6,0.02,95.0,1.0,ito:ITO_00101,Vision process,Micro\\-F1
5,1,Junction Detection,Junction Detection,2019-09,confidence-order,95.0,100.0,0.3,0.0,95.0,1.0,ito:ITO_00101,Vision process,Micro\\-F1
6,1,Entity Disambiguation,WNED-WIKI,2017-04,Glonal,77.5,86.98,77.5,0.87,89.1,0.82,ito:ITO_00101,Vision process,Micro\\-F1
7,1,Entity Disambiguation,WNED-WIKI,2019-09,confidence-order,89.1,100.0,11.6,0.13,89.1,0.94,ito:ITO_00101,Vision process,Micro\\-F1
8,1,Adversarial Attack Detection,Adversarial Attack Detection,2017-04,Glonal,77.5,86.98,77.5,0.87,89.1,0.82,ito:ITO_00101,Vision process,Micro\\-F1
9,1,Adversarial Attack Detection,Adversarial Attack Detection,2019-09,confidence-order,89.1,100.0,11.6,0.13,89.1,0.94,ito:ITO_00101,Vision process,Micro\\-F1
10,1,Entity Disambiguation,ACE2004,2017-04,Global,88.5,96.3,88.5,0.96,91.9,0.93,ito:ITO_00101,Vision process,Micro\\-F1
11,1,Entity Disambiguation,ACE2004,2019-09,confidence-order,91.9,100.0,3.4,0.04,91.9,0.97,ito:ITO_00101,Vision process,Micro\\-F1
12,1,Few-Shot Transfer Learning for Saliency Prediction,Few-Shot Transfer Learning for Saliency Prediction,2017-04,Global,88.5,96.3,88.5,0.96,91.9,0.93,ito:ITO_00101,Vision process,Micro\\-F1
13,1,Few-Shot Transfer Learning for Saliency Prediction,Few-Shot Transfer Learning for Saliency Prediction,2019-09,confidence-order,91.9,100.0,3.4,0.04,91.9,0.97,ito:ITO_00101,Vision process,Micro\\-F1
14,1,Emotion Recognition in Conversation,EC,2019-03,HRLCE + BERT,0.7709,99.28,0.7709,0.99,0.7765,0.01,ito:ITO_00101,Vision process,Micro\\-F1
15,1,Emotion Recognition in Conversation,EC,2019-04,NELEC,0.7765,100.0,0.0,0.0,0.7765,0.01,ito:ITO_00101,Vision process,Micro\\-F1
16,1,Node Classification,Deezer Hungary,2019-08,Smooth GEMSEC 2,0.409,100.0,0.409,1.0,0.409,0.0,ito:ITO_00101,Vision process,Micro\\-F1
17,1,Face Quality Assessement,Face Quality Assessement,2019-08,Smooth GEMSEC 2,0.409,100.0,0.409,1.0,0.409,0.0,ito:ITO_00101,Vision process,Micro\\-F1
18,1,Emotion Recognition in Conversation,DailyDialog,2019-09,KET,53.37,100.0,53.37,1.0,53.37,0.56,ito:ITO_00101,Vision process,Micro\\-F1
0,1,Click-Through Rate Prediction,Criteo,2016-01,FNN,0.45738,84.89,0.45738,0.85,0.5388,0.85,ito:ITO_00101,Vision process,Log\\ Loss
1,1,Click-Through Rate Prediction,Criteo,2016-06,Wide & Deep (LR & DNN),0.46772,86.81,0.0,0.0,0.5388,0.87,ito:ITO_00101,Vision process,Log\\ Loss
2,1,Click-Through Rate Prediction,Criteo,2019-04,FGCNN+IPNN,0.5388,100.0,0.1,0.19,0.5388,1.0,ito:ITO_00101,Vision process,Log\\ Loss
3,1,Sequential skip prediction,Sequential skip prediction,2016-01,FNN,0.45738,84.89,0.45738,0.85,0.5388,0.85,ito:ITO_00101,Vision process,Log\\ Loss
4,1,Sequential skip prediction,Sequential skip prediction,2016-06,Wide & Deep (LR & DNN),0.46772,86.81,0.0,0.0,0.5388,0.87,ito:ITO_00101,Vision process,Log\\ Loss
5,1,Sequential skip prediction,Sequential skip prediction,2019-04,FGCNN+IPNN,0.5388,100.0,0.1,0.19,0.5388,1.0,ito:ITO_00101,Vision process,Log\\ Loss
6,1,Click-Through Rate Prediction,Dianping,2016-06,Wide & Deep,0.3364,98.25,0.3364,0.98,0.3424,0.62,ito:ITO_00101,Vision process,Log\\ Loss
7,1,Click-Through Rate Prediction,Dianping,2016-11,PNN,0.3424,100.0,0.0,0.0,0.3424,0.64,ito:ITO_00101,Vision process,Log\\ Loss
8,1,3D Action Recognition,3D Action Recognition,2016-06,Wide & Deep,0.3364,98.25,0.3364,0.98,0.3424,0.62,ito:ITO_00101,Vision process,Log\\ Loss
9,1,3D Action Recognition,3D Action Recognition,2016-11,PNN,0.3424,100.0,0.0,0.0,0.3424,0.64,ito:ITO_00101,Vision process,Log\\ Loss
10,1,Click-Through Rate Prediction,Bing News,2016-06,Wide & Deep,0.2668,96.14,0.2668,0.96,0.2775,0.5,ito:ITO_00101,Vision process,Log\\ Loss
11,1,Click-Through Rate Prediction,Bing News,2016-11,PNN,0.2775,100.0,0.0,0.0,0.2775,0.52,ito:ITO_00101,Vision process,Log\\ Loss
12,1,Replay Grounding,Replay Grounding,2016-06,Wide & Deep,0.2668,96.14,0.2668,0.96,0.2775,0.5,ito:ITO_00101,Vision process,Log\\ Loss
13,1,Replay Grounding,Replay Grounding,2016-11,PNN,0.2775,100.0,0.0,0.0,0.2775,0.52,ito:ITO_00101,Vision process,Log\\ Loss
14,1,Click-Through Rate Prediction,MovieLens 1M,2018-10,AutoInt,0.3784,100.0,0.3784,1.0,0.3784,0.7,ito:ITO_00101,Vision process,Log\\ Loss
15,1,Weakly-Supervised Action Recognition,Weakly-Supervised Action Recognition,2018-10,AutoInt,0.3784,100.0,0.3784,1.0,0.3784,0.7,ito:ITO_00101,Vision process,Log\\ Loss
16,1,Click-Through Rate Prediction,KDD12,2018-10,AutoInt,0.1545,100.0,0.1545,1.0,0.1545,0.29,ito:ITO_00101,Vision process,Log\\ Loss
17,1,Video-Text Retrieval,Video-Text Retrieval,2018-10,AutoInt,0.1545,100.0,0.1545,1.0,0.1545,0.29,ito:ITO_00101,Vision process,Log\\ Loss
18,1,Click-Through Rate Prediction,Huawei App Store,2019-04,FGCNN+IPNN,0.1134,100.0,0.1134,1.0,0.1134,0.21,ito:ITO_00101,Vision process,Log\\ Loss
19,1,Multi-label zero-shot learning,Multi-label zero-shot learning,2019-04,FGCNN+IPNN,0.1134,100.0,0.1134,1.0,0.1134,0.21,ito:ITO_00101,Vision process,Log\\ Loss
0,1,Person Identification,BioEye,2016-01,RBFN,98.69,100.0,98.69,1.0,98.69,1.0,ito:ITO_00101,Vision process,R1
0,1,Image Generation,Binarized MNIST,2016-01,PixelCNN,81.3,100.0,81.3,1.0,81.3,1.0,ito:ITO_00101,Vision process,nats
0,1,Image Generation,ImageNet 32x32,2016-01,PixelRNN,3.86,90.19,3.86,0.9,4.28,0.9,ito:ITO_00101,Vision process,bpd
1,1,Image Generation,ImageNet 32x32,2016-05,"Real NVP (Dinh et al., 2017)",4.28,100.0,0.4,0.09,4.28,1.0,ito:ITO_00101,Vision process,bpd
2,1,Image Generation,CelebA 256x256,2018-07,"Glow (Kingma and Dhariwal, 2018)",1.03,100.0,1.03,1.0,1.03,0.24,ito:ITO_00101,Vision process,bpd
3,1,Image Generation,MNIST,2018-11,i-ResNet,1.06,100.0,1.06,1.0,1.06,0.25,ito:ITO_00101,Vision process,bpd
4,1,Image Generation,ImageNet 64x64,2019-02,Flow++,3.69,98.4,3.69,0.98,3.75,0.86,ito:ITO_00101,Vision process,bpd
5,1,Image Generation,ImageNet 64x64,2019-02,MaCow (Unf),3.75,100.0,0.1,0.03,3.75,0.88,ito:ITO_00101,Vision process,bpd
0,1,Pose Estimation,FLIC Wrists,2016-01,Convolutional Pose Machines,95.03,97.97,95.03,0.98,97.0,0.96,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.2
1,1,Pose Estimation,FLIC Wrists,2016-03,Stacked Hourglass Networks,97.0,100.0,2.0,0.02,97.0,0.98,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.2
2,1,Pose Estimation,FLIC Elbows,2016-01,Convolutional Pose Machines,97.59,98.58,97.59,0.99,99.0,0.99,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.2
3,1,Pose Estimation,FLIC Elbows,2016-03,Stacked Hourglass Networks,99.0,100.0,1.4,0.01,99.0,1.0,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.2
4,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,62.9,80.54,62.9,0.81,78.1,0.64,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.2
5,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,69.6,89.12,6.7,0.09,78.1,0.7,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.2
6,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,78.1,100.0,8.5,0.11,78.1,0.79,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.2
0,1,Pose Estimation,J-HMDB,2016-01,CPM,91.9,98.18,91.9,0.98,93.6,0.93,ito:ITO_00101,Vision process,Mean\\ PCK\\-at\\-0\\.2
1,1,Pose Estimation,J-HMDB,2017-12,LSTM PM,93.6,100.0,1.7,0.02,93.6,0.94,ito:ITO_00101,Vision process,Mean\\ PCK\\-at\\-0\\.2
2,1,Pose Estimation,UPenn Action,2017-12,LSTM PM,97.7,98.39,97.7,0.98,99.3,0.98,ito:ITO_00101,Vision process,Mean\\ PCK\\-at\\-0\\.2
3,1,Pose Estimation,UPenn Action,2020-01,UniPose-LSTM,99.3,100.0,1.6,0.02,99.3,1.0,ito:ITO_00101,Vision process,Mean\\ PCK\\-at\\-0\\.2
0,1,Action Segmentation,GTEA,2016-02,ST-CNN,41.9,53.72,41.9,0.54,78.0,0.54,ito:ITO_00101,Vision process,F1@50%
1,1,Action Segmentation,GTEA,2016-11,ED-TCN,56.0,71.79,14.1,0.18,78.0,0.72,ito:ITO_00101,Vision process,F1@50%
2,1,Action Segmentation,GTEA,2018-06,TDRN,62.7,80.38,6.7,0.09,78.0,0.8,ito:ITO_00101,Vision process,F1@50%
3,1,Action Segmentation,GTEA,2019-03,MS-TCN,74.6,95.64,11.9,0.15,78.0,0.96,ito:ITO_00101,Vision process,F1@50%
4,1,Action Segmentation,GTEA,2020-03,SSTDA,78.0,100.0,3.4,0.04,78.0,1.0,ito:ITO_00101,Vision process,F1@50%
5,1,Action Segmentation,Breakfast,2019-03,MS-TCN (IDT),40.8,73.91,40.8,0.74,55.2,0.52,ito:ITO_00101,Vision process,F1@50%
6,1,Action Segmentation,Breakfast,2020-03,SSTDA,55.2,100.0,14.4,0.26,55.2,0.71,ito:ITO_00101,Vision process,F1@50%
7,1,Action Segmentation,50 Salads,2019-03,MS-TCN,64.5,87.4,64.5,0.87,73.8,0.83,ito:ITO_00101,Vision process,F1@50%
8,1,Action Segmentation,50 Salads,2020-03,SSTDA,73.8,100.0,9.3,0.13,73.8,0.95,ito:ITO_00101,Vision process,F1@50%
0,1,Action Segmentation,GTEA,2016-02,ST-CNN,54.4,61.05,54.4,0.61,89.1,0.61,ito:ITO_00101,Vision process,F1@25%
1,1,Action Segmentation,GTEA,2016-11,ED-TCN,69.3,77.78,14.9,0.17,89.1,0.78,ito:ITO_00101,Vision process,F1@25%
2,1,Action Segmentation,GTEA,2018-06,TDRN,74.4,83.5,5.1,0.06,89.1,0.84,ito:ITO_00101,Vision process,F1@25%
3,1,Action Segmentation,GTEA,2019-03,MS-TCN,85.4,95.85,11.0,0.12,89.1,0.96,ito:ITO_00101,Vision process,F1@25%
4,1,Action Segmentation,GTEA,2020-03,SSTDA,89.1,100.0,3.7,0.04,89.1,1.0,ito:ITO_00101,Vision process,F1@25%
5,1,Action Segmentation,50 Salads,2019-03,MS-TCN,74.0,90.8,74.0,0.91,81.5,0.83,ito:ITO_00101,Vision process,F1@25%
6,1,Action Segmentation,50 Salads,2020-03,SSTDA,81.5,100.0,7.5,0.09,81.5,0.91,ito:ITO_00101,Vision process,F1@25%
7,1,Action Segmentation,Breakfast,2019-03,MS-TCN (IDT),52.9,76.56,52.9,0.77,69.1,0.59,ito:ITO_00101,Vision process,F1@25%
8,1,Action Segmentation,Breakfast,2020-03,SSTDA,69.1,100.0,16.2,0.23,69.1,0.78,ito:ITO_00101,Vision process,F1@25%
0,1,Action Segmentation,GTEA,2016-02,ST-CNN,58.7,65.22,58.7,0.65,90.0,0.65,ito:ITO_00101,Vision process,F1@10%
1,1,Action Segmentation,GTEA,2016-11,ED-TCN,72.2,80.22,13.5,0.15,90.0,0.8,ito:ITO_00101,Vision process,F1@10%
2,1,Action Segmentation,GTEA,2018-06,TDRN,79.2,88.0,7.0,0.08,90.0,0.88,ito:ITO_00101,Vision process,F1@10%
3,1,Action Segmentation,GTEA,2019-03,MS-TCN,87.5,97.22,8.3,0.09,90.0,0.97,ito:ITO_00101,Vision process,F1@10%
4,1,Action Segmentation,GTEA,2020-03,SSTDA,90.0,100.0,2.5,0.03,90.0,1.0,ito:ITO_00101,Vision process,F1@10%
5,1,Action Segmentation,Breakfast,2019-03,MS-TCN (IDT),58.2,77.6,58.2,0.78,75.0,0.65,ito:ITO_00101,Vision process,F1@10%
6,1,Action Segmentation,Breakfast,2020-03,SSTDA,75.0,100.0,16.8,0.22,75.0,0.83,ito:ITO_00101,Vision process,F1@10%
7,1,Action Segmentation,50 Salads,2019-03,MS-TCN,76.3,91.93,76.3,0.92,83.0,0.85,ito:ITO_00101,Vision process,F1@10%
8,1,Action Segmentation,50 Salads,2020-03,SSTDA,83.0,100.0,6.7,0.08,83.0,0.92,ito:ITO_00101,Vision process,F1@10%
0,1,Action Segmentation,GTEA,2016-02,ST-CNN,58.7,65.22,58.7,0.65,90.0,0.65,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-10%
1,1,Action Segmentation,GTEA,2016-11,ED-TCN,72.2,80.22,13.5,0.15,90.0,0.8,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-10%
2,1,Action Segmentation,GTEA,2017-05,TricorNet,76.0,84.44,3.8,0.04,90.0,0.84,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-10%
3,1,Action Segmentation,GTEA,2018-06,TDRN,79.2,88.0,3.2,0.04,90.0,0.88,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-10%
4,1,Action Segmentation,GTEA,2019-03,MS-TCN (FT),87.5,97.22,8.3,0.09,90.0,0.97,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-10%
5,1,Action Segmentation,GTEA,2020-03,SSTDA,90.0,100.0,2.5,0.03,90.0,1.0,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-10%
6,1,Action Segmentation,Breakfast,2019-03,MS-TCN (IDT),58.2,77.6,58.2,0.78,75.0,0.65,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-10%
7,1,Action Segmentation,Breakfast,2020-03,SSTDA,75.0,100.0,16.8,0.22,75.0,0.83,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-10%
8,1,Action Segmentation,50 Salads,2020-03,SSTDA,83.0,100.0,83,1.0,83,0.92,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-10%
0,1,Action Segmentation,GTEA,2016-02,ST-CNN,41.9,53.72,41.9,0.54,78.0,0.54,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-50%
1,1,Action Segmentation,GTEA,2016-11,ED-TCN,56.0,71.79,14.1,0.18,78.0,0.72,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-50%
2,1,Action Segmentation,GTEA,2017-05,TricorNet,59.2,75.9,3.2,0.04,78.0,0.76,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-50%
3,1,Action Segmentation,GTEA,2018-06,TDRN,62.7,80.38,3.5,0.04,78.0,0.8,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-50%
4,1,Action Segmentation,GTEA,2019-03,MS-TCN (FT),74.6,95.64,11.9,0.15,78.0,0.96,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-50%
5,1,Action Segmentation,GTEA,2020-03,SSTDA,78.0,100.0,3.4,0.04,78.0,1.0,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-50%
6,1,Action Segmentation,Breakfast,2019-03,MS-TCN (IDT),40.8,73.91,40.8,0.74,55.2,0.52,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-50%
7,1,Action Segmentation,Breakfast,2020-03,SSTDA,55.2,100.0,14.4,0.26,55.2,0.71,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-50%
0,1,Salient Object Detection,DUTS-TE,2016-03,DCL,0.786,88.12,0.786,0.88,0.892,0.01,ito:ITO_00101,Vision process,F\\-measure
1,1,Salient Object Detection,DUTS-TE,2016-06,DHS,0.815,91.37,0.0,0.0,0.892,0.01,ito:ITO_00101,Vision process,F\\-measure
2,1,Salient Object Detection,DUTS-TE,2017-04,MSR,0.824,92.38,0.0,0.0,0.892,0.01,ito:ITO_00101,Vision process,F\\-measure
3,1,Salient Object Detection,DUTS-TE,2017-08,PiCANet,0.863,96.75,0.0,0.0,0.892,0.01,ito:ITO_00101,Vision process,F\\-measure
4,1,Salient Object Detection,DUTS-TE,2019-04,PoolNet (VGG-16),0.892,100.0,0.0,0.0,0.892,0.01,ito:ITO_00101,Vision process,F\\-measure
5,1,RGB Salient Object Detection,DUTS-TE,2016-03,DCL,0.786,88.12,0.786,0.88,0.892,0.01,ito:ITO_00101,Vision process,F\\-measure
6,1,RGB Salient Object Detection,DUTS-TE,2016-06,DHS,0.815,91.37,0.0,0.0,0.892,0.01,ito:ITO_00101,Vision process,F\\-measure
7,1,RGB Salient Object Detection,DUTS-TE,2017-04,MSR,0.824,92.38,0.0,0.0,0.892,0.01,ito:ITO_00101,Vision process,F\\-measure
8,1,RGB Salient Object Detection,DUTS-TE,2017-08,PiCANet,0.863,96.75,0.0,0.0,0.892,0.01,ito:ITO_00101,Vision process,F\\-measure
9,1,RGB Salient Object Detection,DUTS-TE,2019-04,PoolNet (VGG-16),0.892,100.0,0.0,0.0,0.892,0.01,ito:ITO_00101,Vision process,F\\-measure
10,1,Salient Object Detection,ECSSD,2019-04,DSS (Res2Net-50),0.926,97.99,0.926,0.98,0.945,0.01,ito:ITO_00101,Vision process,F\\-measure
11,1,Salient Object Detection,ECSSD,2019-04,PoolNet (VGG-16),0.945,100.0,0.0,0.0,0.945,0.01,ito:ITO_00101,Vision process,F\\-measure
12,1,Salient Object Detection,DUT-OMRON,2019-04,DSS (Res2Net-50),0.8,96.04,0.8,0.96,0.833,0.01,ito:ITO_00101,Vision process,F\\-measure
13,1,Salient Object Detection,DUT-OMRON,2019-04,PoolNet (VGG-16),0.833,100.0,0.0,0.0,0.833,0.01,ito:ITO_00101,Vision process,F\\-measure
14,1,Salient Object Detection,HKU-IS,2019-04,DSS (Res2Net-50),0.905,96.79,0.905,0.97,0.935,0.01,ito:ITO_00101,Vision process,F\\-measure
15,1,Salient Object Detection,HKU-IS,2019-04,PoolNet (VGG-16),0.935,100.0,0.0,0.0,0.935,0.01,ito:ITO_00101,Vision process,F\\-measure
16,1,Salient Object Detection,PASCAL-S,2019-04,DSS (Res2Net-50),0.841,95.57,0.841,0.96,0.88,0.01,ito:ITO_00101,Vision process,F\\-measure
17,1,Salient Object Detection,PASCAL-S,2019-04,PoolNet (VGG-16),0.88,100.0,0.0,0.0,0.88,0.01,ito:ITO_00101,Vision process,F\\-measure
18,1,Salient Object Detection,DUTS-test,2019-04,CPD-R (ResNet50),80.5,100.0,80.5,1.0,80.5,1.0,ito:ITO_00101,Vision process,F\\-measure
19,1,RGB Salient Object Detection,ECSSD,2019-04,CPD-R (ResNet50),0.917,97.04,0.917,0.97,0.945,0.01,ito:ITO_00101,Vision process,F\\-measure
20,1,RGB Salient Object Detection,ECSSD,2019-04,PoolNet (VGG-16),0.945,100.0,0.0,0.0,0.945,0.01,ito:ITO_00101,Vision process,F\\-measure
21,1,RGB Salient Object Detection,PASCAL-S,2019-04,CPD-R (ResNet50),0.824,93.64,0.824,0.94,0.88,0.01,ito:ITO_00101,Vision process,F\\-measure
22,1,RGB Salient Object Detection,PASCAL-S,2019-04,PoolNet (VGG-16),0.88,100.0,0.1,0.11,0.88,0.01,ito:ITO_00101,Vision process,F\\-measure
23,1,RGB Salient Object Detection,DUT-OMRON,2019-04,CPD-R (ResNet50),0.747,89.68,0.747,0.9,0.833,0.01,ito:ITO_00101,Vision process,F\\-measure
24,1,RGB Salient Object Detection,DUT-OMRON,2019-04,PoolNet (VGG-16),0.833,100.0,0.1,0.12,0.833,0.01,ito:ITO_00101,Vision process,F\\-measure
25,1,RGB Salient Object Detection,HKU-IS,2019-04,CPD-R (ResNet50),0.891,95.29,0.891,0.95,0.935,0.01,ito:ITO_00101,Vision process,F\\-measure
26,1,RGB Salient Object Detection,HKU-IS,2019-04,PoolNet (VGG-16),0.935,100.0,0.0,0.0,0.935,0.01,ito:ITO_00101,Vision process,F\\-measure
27,1,RGB Salient Object Detection,DUTS-test,2019-04,CPD-R (ResNet50),80.5,100.0,80.5,1.0,80.5,1.0,ito:ITO_00101,Vision process,F\\-measure
28,1,Salient Object Detection,SOD,2019-04,PoolNet (VGG-16),0.882,100.0,0.882,1.0,0.882,0.01,ito:ITO_00101,Vision process,F\\-measure
29,1,RGB Salient Object Detection,SOD,2019-04,PoolNet (VGG-16),0.882,100.0,0.882,1.0,0.882,0.01,ito:ITO_00101,Vision process,F\\-measure
0,1,Dimensionality Reduction,1B Words,2016-03,fst,1000000000.0,100.0,1000000000,1.0,1000000000,1.0,ito:ITO_00101,Vision process,14\\ gestures\\ accuracy
1,1,3D Facial Expression Recognition,2017_test set,2018-02,aan,2.0,100.0,2,1.0,2,0.0,ito:ITO_00101,Vision process,14\\ gestures\\ accuracy
2,1,Visual Question Answering,100 sleep nights of 8 caregivers,2018-10,TallyQA,10.0,100.0,10,1.0,10,0.0,ito:ITO_00101,Vision process,14\\ gestures\\ accuracy
3,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,MFA-Net,91.3,96.51,91.3,0.97,94.6,0.0,ito:ITO_00101,Vision process,14\\ gestures\\ accuracy
4,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,STA-Res-TCN,93.6,98.94,2.3,0.02,94.6,0.0,ito:ITO_00101,Vision process,14\\ gestures\\ accuracy
5,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,94.6,100.0,1.0,0.01,94.6,0.0,ito:ITO_00101,Vision process,14\\ gestures\\ accuracy
6,1,Adversarial Attack,1B Words,2019-02,xyz,0.9,100.0,0.9,1.0,0.9,0.0,ito:ITO_00101,Vision process,14\\ gestures\\ accuracy
7,1,Hand Gesture Recognition,SHREC 2017,2019-07,DG-STA,94.4,100.0,94.4,1.0,94.4,0.0,ito:ITO_00101,Vision process,14\\ gestures\\ accuracy
8,1,Hand Gesture Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,94.6,100.0,94.6,1.0,94.6,0.0,ito:ITO_00101,Vision process,14\\ gestures\\ accuracy
9,1,Factual Visual Question Answering,100 sleep nights of 8 caregivers,2019-11,TallyQA,10.0,100.0,10,1.0,10,0.0,ito:ITO_00101,Vision process,14\\ gestures\\ accuracy
0,1,Pose Estimation,ITOP top-view,2016-03,Multi-task learning + viewpoint invariance,75.5,90.48,75.5,0.9,83.44,0.02,ito:ITO_00101,Vision process,Mean\\ mAP
1,1,Pose Estimation,ITOP top-view,2017-11,V2V-PoseNet,83.44,100.0,7.9,0.09,83.44,0.03,ito:ITO_00101,Vision process,Mean\\ mAP
2,1,Pose Estimation,ITOP front-view,2016-03,Multi-task learning + viewpoint invariance,77.4,78.02,77.4,0.78,99.2,0.02,ito:ITO_00101,Vision process,Mean\\ mAP
3,1,Pose Estimation,ITOP front-view,2017-07,REN,84.9,85.58,7.5,0.08,99.2,0.03,ito:ITO_00101,Vision process,Mean\\ mAP
4,1,Pose Estimation,ITOP front-view,2017-11,V2V-PoseNet,88.74,89.46,3.8,0.04,99.2,0.03,ito:ITO_00101,Vision process,Mean\\ mAP
5,1,Pose Estimation,ITOP front-view,2019-08,A2J (Ours),99.2,100.0,10.5,0.11,99.2,0.03,ito:ITO_00101,Vision process,Mean\\ mAP
6,1,Multi-Person Pose Estimation,Multi-Person PoseTrack,2016-11,PoseTrack,38.2,100.0,38.2,1.0,38.2,0.01,ito:ITO_00101,Vision process,Mean\\ mAP
7,1,Multi-Person Pose Estimation,PoseTrack2017,2017-10,PoseTrack,59.4,76.21,59.4,0.76,77.94,0.02,ito:ITO_00101,Vision process,Mean\\ mAP
8,1,Multi-Person Pose Estimation,PoseTrack2017,2019-06,PoseWarper,77.9,99.95,18.5,0.24,77.94,0.02,ito:ITO_00101,Vision process,Mean\\ mAP
9,1,Multi-Person Pose Estimation,PoseTrack2017,2019-06,PoseWarper,77.94,100.0,0.0,0.0,77.94,0.02,ito:ITO_00101,Vision process,Mean\\ mAP
10,1,Image Retrieval,INRIA Holidays,2019-02,MultiGrain R50 @ 800,92.5,100.0,92.5,1.0,92.5,0.03,ito:ITO_00101,Vision process,Mean\\ mAP
11,1,Multi-Person Pose Estimation,PoseTrack2018,2019-06,PoseWarper,78.0,100.0,78,1.0,78,0.02,ito:ITO_00101,Vision process,Mean\\ mAP
12,1,Weakly Supervised Action Localization,ActivityNet-1.2,2019-08,3C-Net,21.7,100.0,21.7,1.0,21.7,0.01,ito:ITO_00101,Vision process,Mean\\ mAP
13,1,Object Detection,COCO 2017,2019-12,retinanet,3153.0,100.0,3153,1.0,3153,1.0,ito:ITO_00101,Vision process,Mean\\ mAP
0,1,Nuclear Segmentation,Cell17,2016-03,FnsNet,25.9102,100.0,25.9102,1.0,25.9102,1.0,ito:ITO_00101,Vision process,Hausdorff
0,1,Nuclear Segmentation,Cell17,2016-03,FnsNet,0.7413,85.75,0.7413,0.86,0.8645,0.01,ito:ITO_00101,Vision process,F1\\-score
1,1,Nuclear Segmentation,Cell17,2017-03,Mask R-CNN,0.8004,92.59,0.1,0.12,0.8645,0.01,ito:ITO_00101,Vision process,F1\\-score
2,1,Nuclear Segmentation,Cell17,2018-09,Cell R-CNN,0.8216,95.04,0.0,0.0,0.8645,0.01,ito:ITO_00101,Vision process,F1\\-score
3,1,Nuclear Segmentation,Cell17,2019-08,Deep Panoptic Model with Semantic Feature Fusion,0.8645,100.0,0.0,0.0,0.8645,0.01,ito:ITO_00101,Vision process,F1\\-score
4,1,Unsupervised Video Summarization,TvSum,2017-12,DR-DSN,57.6,97.96,57.6,0.98,58.8,0.98,ito:ITO_00101,Vision process,F1\\-score
5,1,Unsupervised Video Summarization,TvSum,2018-11,CSNet,58.8,100.0,1.2,0.02,58.8,1.0,ito:ITO_00101,Vision process,F1\\-score
6,1,Unsupervised Video Summarization,SumMe,2017-12,DR-DSN,41.4,80.7,41.4,0.81,51.3,0.7,ito:ITO_00101,Vision process,F1\\-score
7,1,Unsupervised Video Summarization,SumMe,2018-11,CSNet,51.3,100.0,9.9,0.19,51.3,0.87,ito:ITO_00101,Vision process,F1\\-score
0,1,3D Object Reconstruction,Data3D−R2N2,2016-04,3D-R2N2,0.56,84.72,0.56,0.85,0.661,0.01,ito:ITO_00101,Vision process,3DIoU
1,1,3D Object Reconstruction,Data3D−R2N2,2016-12,PSGN,0.64,96.82,0.1,0.15,0.661,0.01,ito:ITO_00101,Vision process,3DIoU
2,1,3D Object Reconstruction,Data3D−R2N2,2019-01,Pix2Vox-A,0.661,100.0,0.0,0.0,0.661,0.01,ito:ITO_00101,Vision process,3DIoU
3,1,3D Reconstruction,Data3D−R2N2,2016-04,3D-R2N2,0.56,84.72,0.56,0.85,0.661,0.01,ito:ITO_00101,Vision process,3DIoU
4,1,3D Reconstruction,Data3D−R2N2,2016-12,PSGN,0.64,96.82,0.1,0.15,0.661,0.01,ito:ITO_00101,Vision process,3DIoU
5,1,3D Reconstruction,Data3D−R2N2,2018-08,AttSets,0.642,97.13,0.0,0.0,0.661,0.01,ito:ITO_00101,Vision process,3DIoU
6,1,3D Reconstruction,Data3D−R2N2,2019-01,Pix2Vox-A,0.661,100.0,0.0,0.0,0.661,0.01,ito:ITO_00101,Vision process,3DIoU
7,1,Semantic Segmentation,ScanNet,2017-02,ScanNet,0.306,41.69,0.306,0.42,0.734,0.0,ito:ITO_00101,Vision process,3DIoU
8,1,Semantic Segmentation,ScanNet,2017-06,PointNet++,0.339,46.19,0.0,0.0,0.734,0.0,ito:ITO_00101,Vision process,3DIoU
9,1,Semantic Segmentation,ScanNet,2017-11,SparseConvNet,0.725,98.77,0.4,0.54,0.734,0.01,ito:ITO_00101,Vision process,3DIoU
10,1,Semantic Segmentation,ScanNet,2019-04,MinkowskiNet,0.734,100.0,0.0,0.0,0.734,0.01,ito:ITO_00101,Vision process,3DIoU
11,1,3D Room Layouts From A Single RGB Panorama,Stanford 2D-3D,2018-03,LayoutNet,76.33,95.66,76.33,0.96,79.79,0.93,ito:ITO_00101,Vision process,3DIoU
12,1,3D Room Layouts From A Single RGB Panorama,Stanford 2D-3D,2018-11,DuLa-Net,79.36,99.46,3.0,0.04,79.79,0.97,ito:ITO_00101,Vision process,3DIoU
13,1,3D Room Layouts From A Single RGB Panorama,Stanford 2D-3D,2019-01,HorizonNet,79.79,100.0,0.4,0.01,79.79,0.97,ito:ITO_00101,Vision process,3DIoU
14,1,3D Room Layouts From A Single RGB Panorama,Realtor360,2018-03,LayoutNet,62.77,81.31,62.77,0.81,77.2,0.76,ito:ITO_00101,Vision process,3DIoU
15,1,3D Room Layouts From A Single RGB Panorama,Realtor360,2018-11,DuLa-Net,77.2,100.0,14.4,0.19,77.2,0.94,ito:ITO_00101,Vision process,3DIoU
16,1,3D Room Layouts From A Single RGB Panorama,PanoContext,2018-03,LayoutNet,74.48,90.64,74.48,0.91,82.17,0.91,ito:ITO_00101,Vision process,3DIoU
17,1,3D Room Layouts From A Single RGB Panorama,PanoContext,2018-11,DuLa-Net,77.42,94.22,2.9,0.04,82.17,0.94,ito:ITO_00101,Vision process,3DIoU
18,1,3D Room Layouts From A Single RGB Panorama,PanoContext,2019-01,HorizonNet,82.17,100.0,4.8,0.06,82.17,1.0,ito:ITO_00101,Vision process,3DIoU
19,1,3D Room Layouts From A Single Rgb Panorama,Stanford 2D-3D,2018-03,LayoutNet,76.33,95.66,76.33,0.96,79.79,0.93,ito:ITO_00101,Vision process,3DIoU
20,1,3D Room Layouts From A Single Rgb Panorama,Stanford 2D-3D,2018-11,DuLa-Net,79.36,99.46,3.0,0.04,79.79,0.97,ito:ITO_00101,Vision process,3DIoU
21,1,3D Room Layouts From A Single Rgb Panorama,Stanford 2D-3D,2019-01,HorizonNet,79.79,100.0,0.4,0.01,79.79,0.97,ito:ITO_00101,Vision process,3DIoU
22,1,3D Room Layouts From A Single Rgb Panorama,Realtor360,2018-03,LayoutNet,62.77,81.31,62.77,0.81,77.2,0.76,ito:ITO_00101,Vision process,3DIoU
23,1,3D Room Layouts From A Single Rgb Panorama,Realtor360,2018-11,DuLa-Net,77.2,100.0,14.4,0.19,77.2,0.94,ito:ITO_00101,Vision process,3DIoU
24,1,3D Room Layouts From A Single Rgb Panorama,PanoContext,2018-03,LayoutNet,74.48,90.64,74.48,0.91,82.17,0.91,ito:ITO_00101,Vision process,3DIoU
25,1,3D Room Layouts From A Single Rgb Panorama,PanoContext,2018-11,DuLa-Net,77.42,94.22,2.9,0.04,82.17,0.94,ito:ITO_00101,Vision process,3DIoU
26,1,3D Room Layouts From A Single Rgb Panorama,PanoContext,2019-01,HorizonNet,82.17,100.0,4.8,0.06,82.17,1.0,ito:ITO_00101,Vision process,3DIoU
27,1,Single-View 3D Reconstruction,ShapeNet,2019-04,SoftRas,64.64,100.0,64.64,1.0,64.64,0.79,ito:ITO_00101,Vision process,3DIoU
28,1,3D Object Reconstruction,ShapeNet,2019-04,SoftRas,64.64,100.0,64.64,1.0,64.64,0.79,ito:ITO_00101,Vision process,3DIoU
29,1,Scene Segmentation,ScanNet,2019-04,KPConv,68.6,100.0,68.6,1.0,68.6,0.83,ito:ITO_00101,Vision process,3DIoU
0,1,3D Object Reconstruction,Data3D−R2N2,2016-04,3D-R2N2,39.01,57.9,39.01,0.58,67.37,0.58,ito:ITO_00101,Vision process,Avg\\ F1
1,1,3D Object Reconstruction,Data3D−R2N2,2016-12,PSG,48.58,72.11,9.6,0.14,67.37,0.72,ito:ITO_00101,Vision process,Avg\\ F1
2,1,3D Object Reconstruction,Data3D−R2N2,2018-02,MVD,66.39,98.55,17.8,0.26,67.37,0.99,ito:ITO_00101,Vision process,Avg\\ F1
3,1,3D Object Reconstruction,Data3D−R2N2,2019-01,GEOMetrics,67.37,100.0,1.0,0.01,67.37,1.0,ito:ITO_00101,Vision process,Avg\\ F1
4,1,Action Unit Detection,BP4D,2018-12,AU R-CNN,63.1,100.0,63.1,1.0,63.1,0.94,ito:ITO_00101,Vision process,Avg\\ F1
0,1,Horizon Line Estimation,Horizon Lines in the Wild,2016-04,"GoogleNet (Huber Loss, horizon line projection)",71.16,94.63,71.16,0.95,75.2,0.75,ito:ITO_00101,Vision process,AUC\\ \\(horizon\\ error\\)
1,1,Horizon Line Estimation,Horizon Lines in the Wild,2019-05,NG-DSAC,75.2,100.0,4.0,0.05,75.2,0.79,ito:ITO_00101,Vision process,AUC\\ \\(horizon\\ error\\)
2,1,Horizon Line Estimation,York Urban Dataset,2016-04,"GoogleNet (Huber Loss, horizon line projection)",86.41,91.17,86.41,0.91,94.78,0.91,ito:ITO_00101,Vision process,AUC\\ \\(horizon\\ error\\)
3,1,Horizon Line Estimation,York Urban Dataset,2016-08,CNN+FULL,94.78,100.0,8.4,0.09,94.78,1.0,ito:ITO_00101,Vision process,AUC\\ \\(horizon\\ error\\)
4,1,Horizon Line Estimation,Eurasian Cities Dataset,2016-04,"GoogleNet (Huber Loss, horizon line projection)",83.6,92.07,83.6,0.92,90.8,0.88,ito:ITO_00101,Vision process,AUC\\ \\(horizon\\ error\\)
5,1,Horizon Line Estimation,Eurasian Cities Dataset,2016-08,CNN+FULL,90.8,100.0,7.2,0.08,90.8,0.96,ito:ITO_00101,Vision process,AUC\\ \\(horizon\\ error\\)
0,1,Instance Segmentation,COCO test-dev,2016-04,MultiPath Network,25.0,56.56,25.0,0.57,44.2,0.28,ito:ITO_00101,Vision process,mask\\ AP
1,1,Instance Segmentation,COCO test-dev,2017-03,Mask R-CNN (ResNeXt-101-FPN),37.1,83.94,12.1,0.27,44.2,0.42,ito:ITO_00101,Vision process,mask\\ AP
2,1,Instance Segmentation,COCO test-dev,2017-12,"MaskLab+ (ResNet-101, JFT)",38.1,86.2,1.0,0.02,44.2,0.43,ito:ITO_00101,Vision process,mask\\ AP
3,1,Instance Segmentation,COCO test-dev,2018-03,PANet,42.0,95.02,3.9,0.09,44.2,0.48,ito:ITO_00101,Vision process,mask\\ AP
4,1,Instance Segmentation,COCO test-dev,2019-09,"Cascade Mask R-CNN (ResNeXt152, CBNet)",43.3,97.96,1.3,0.03,44.2,0.49,ito:ITO_00101,Vision process,mask\\ AP
5,1,Instance Segmentation,COCO test-dev,2020-04,ResNeSt-200DCN,44.2,100.0,0.9,0.02,44.2,0.5,ito:ITO_00101,Vision process,mask\\ AP
6,1,Instance Segmentation,COCO minival,2017-11,"Mask R-CNN (ResNext-152, +1 NL)",40.3,87.14,40.3,0.87,46.25,0.46,ito:ITO_00101,Vision process,mask\\ AP
7,1,Instance Segmentation,COCO minival,2019-02,HTC (HRNetV2p-W48),41.0,88.65,0.7,0.02,46.25,0.46,ito:ITO_00101,Vision process,mask\\ AP
8,1,Instance Segmentation,COCO minival,2019-04,Res2Net-101+HTC,41.3,89.3,0.3,0.01,46.25,0.47,ito:ITO_00101,Vision process,mask\\ AP
9,1,Instance Segmentation,COCO minival,2019-11,CenterMask-VoVNetV2-99 (multi-scale),42.5,91.89,1.2,0.03,46.25,0.48,ito:ITO_00101,Vision process,mask\\ AP
10,1,Instance Segmentation,COCO minival,2019-12,"Mask R-CNN (SpineNet-143, single-scale)",42.6,92.11,0.1,0.0,46.25,0.48,ito:ITO_00101,Vision process,mask\\ AP
11,1,Instance Segmentation,COCO minival,2020-04,ResNeSt-200 (multi-scale),46.25,100.0,3.6,0.08,46.25,0.52,ito:ITO_00101,Vision process,mask\\ AP
12,1,Real-time Instance Segmentation,MSCOCO,2019-04,YOLACT-550 (ResNet-101-FPN),28.2,80.11,28.2,0.8,35.2,0.32,ito:ITO_00101,Vision process,mask\\ AP
13,1,Real-time Instance Segmentation,MSCOCO,2019-11,CenterMask-Lite (ResNet-50-FPN),32.9,93.47,4.7,0.13,35.2,0.37,ito:ITO_00101,Vision process,mask\\ AP
14,1,Real-time Instance Segmentation,MSCOCO,2020-01,BlendMask-512 (DLA_34),35.2,100.0,2.3,0.07,35.2,0.4,ito:ITO_00101,Vision process,mask\\ AP
15,1,3D Shape Modeling,Pix3D S2,2019-06,Mesh R-CNN,63.9,100.0,63.9,1.0,63.9,0.72,ito:ITO_00101,Vision process,mask\\ AP
16,1,UNET Segmentation,UNET Segmentation,2019-06,Mesh R-CNN,63.9,100.0,63.9,1.0,63.9,0.72,ito:ITO_00101,Vision process,mask\\ AP
17,1,3D Shape Modeling,Pix3D S1,2019-06,Mesh R-CNN,88.4,100.0,88.4,1.0,88.4,1.0,ito:ITO_00101,Vision process,mask\\ AP
18,1,Road Segementation,Road Segementation,2019-06,Mesh R-CNN,88.4,100.0,88.4,1.0,88.4,1.0,ito:ITO_00101,Vision process,mask\\ AP
19,1,Instance Segmentation,LVIS v1.0,2019-12,"PointRend (MaskR-CNN, ResNet-50-FPN)",39.7,100.0,39.7,1.0,39.7,0.45,ito:ITO_00101,Vision process,mask\\ AP
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,13.0,44.83,13,0.45,29,0.45,ito:ITO_00101,Vision process,Accuracy\\ \\(CV\\ I\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,LSTM,16.0,55.17,3,0.1,29,0.55,ito:ITO_00101,Vision process,Accuracy\\ \\(CV\\ I\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-08,SK-CNN,26.0,89.66,10,0.34,29,0.9,ito:ITO_00101,Vision process,Accuracy\\ \\(CV\\ I\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,29.0,100.0,3,0.1,29,1.0,ito:ITO_00101,Vision process,Accuracy\\ \\(CV\\ I\\)
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,33.0,46.48,33,0.46,71,0.46,ito:ITO_00101,Vision process,Accuracy\\ \\(CV\\ II\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-11,TCN,43.0,60.56,10,0.14,71,0.61,ito:ITO_00101,Vision process,Accuracy\\ \\(CV\\ II\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-04,Res-TCN,48.0,67.61,5,0.07,71,0.68,ito:ITO_00101,Vision process,Accuracy\\ \\(CV\\ II\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-08,SK-CNN,68.0,95.77,20,0.28,71,0.96,ito:ITO_00101,Vision process,Accuracy\\ \\(CV\\ II\\)
4,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,71.0,100.0,3,0.04,71,1.0,ito:ITO_00101,Vision process,Accuracy\\ \\(CV\\ II\\)
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,LSTM,31.0,54.39,31,0.54,57,0.54,ito:ITO_00101,Vision process,Accuracy\\ \\(AV\\ I\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,33.0,57.89,2,0.04,57,0.58,ito:ITO_00101,Vision process,Accuracy\\ \\(AV\\ I\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-11,TCN,43.0,75.44,10,0.18,57,0.75,ito:ITO_00101,Vision process,Accuracy\\ \\(AV\\ I\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-04,Res-TCN,48.0,84.21,5,0.09,57,0.84,ito:ITO_00101,Vision process,Accuracy\\ \\(AV\\ I\\)
4,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2018-01,ST-GCN,53.0,92.98,5,0.09,57,0.93,ito:ITO_00101,Vision process,Accuracy\\ \\(AV\\ I\\)
5,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,57.0,100.0,4,0.07,57,1.0,ito:ITO_00101,Vision process,Accuracy\\ \\(AV\\ I\\)
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,50.0,64.94,50,0.65,77,0.65,ito:ITO_00101,Vision process,Accuracy\\ \\(AV\\ II\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,LSTM,68.0,88.31,18,0.23,77,0.88,ito:ITO_00101,Vision process,Accuracy\\ \\(AV\\ II\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-08,SK-CNN,77.0,100.0,9,0.12,77,1.0,ito:ITO_00101,Vision process,Accuracy\\ \\(AV\\ II\\)
0,1,Object Counting,Pascal VOC 2007 count-test,2016-04,Fast-RCNN,0.5,100.0,0.5,1.0,0.5,1.0,ito:ITO_00101,Vision process,mRMSE
1,1,Object Counting,COCO count-test,2016-04,Aso-sub-ft-3x3,0.38,77.55,0.38,0.78,0.49,0.76,ito:ITO_00101,Vision process,mRMSE
2,1,Object Counting,COCO count-test,2016-04,glance-ft-2L,0.42,85.71,0.0,0.0,0.49,0.84,ito:ITO_00101,Vision process,mRMSE
3,1,Object Counting,COCO count-test,2016-04,Fast-RCNN,0.49,100.0,0.1,0.2,0.49,0.98,ito:ITO_00101,Vision process,mRMSE
0,1,Object Counting,COCO count-test,2016-04,Aso-sub-ft-3x3,2.08,74.82,2.08,0.75,2.78,0.75,ito:ITO_00101,Vision process,mRMSE\\-nz
1,1,Object Counting,COCO count-test,2016-04,glance-ft-2L,2.25,80.94,0.2,0.07,2.78,0.81,ito:ITO_00101,Vision process,mRMSE\\-nz
2,1,Object Counting,COCO count-test,2016-04,Fast-RCNN,2.78,100.0,0.5,0.18,2.78,1.0,ito:ITO_00101,Vision process,mRMSE\\-nz
3,1,Object Counting,Pascal VOC 2007 count-test,2016-04,Fast-RCNN,1.92,100.0,1.92,1.0,1.92,0.69,ito:ITO_00101,Vision process,mRMSE\\-nz
0,1,3D Point Cloud Classification,ModelNet40,2016-04,Subvolume,89.2,96.02,89.2,0.96,92.9,0.89,ito:ITO_00101,Vision process,Overall\\ Accuracy
1,1,3D Point Cloud Classification,ModelNet40,2017-04,Kd-Net,91.8,98.82,2.6,0.03,92.9,0.92,ito:ITO_00101,Vision process,Overall\\ Accuracy
2,1,3D Point Cloud Classification,ModelNet40,2017-06,PointNet++,91.9,98.92,0.1,0.0,92.9,0.92,ito:ITO_00101,Vision process,Overall\\ Accuracy
3,1,3D Point Cloud Classification,ModelNet40,2018-03,SpiderCNN,92.4,99.46,0.5,0.01,92.9,0.92,ito:ITO_00101,Vision process,Overall\\ Accuracy
4,1,3D Point Cloud Classification,ModelNet40,2018-12,PointCNN,92.5,99.57,0.1,0.0,92.9,0.92,ito:ITO_00101,Vision process,Overall\\ Accuracy
5,1,3D Point Cloud Classification,ModelNet40,2019-04,KPConv,92.9,100.0,0.4,0.0,92.9,0.93,ito:ITO_00101,Vision process,Overall\\ Accuracy
6,1,Depiction Invariant Object Recognition,Photo-Art-50,2016-07,SwiDeN,93.02,100.0,93.02,1.0,93.02,0.93,ito:ITO_00101,Vision process,Overall\\ Accuracy
7,1,Hyperspectral Image Classification,Indian Pines,2016-12,BASSNet,96.77,96.95,96.77,0.97,99.81,0.97,ito:ITO_00101,Vision process,Overall\\ Accuracy
8,1,Hyperspectral Image Classification,Indian Pines,2019-02,HybridSN,99.81,100.0,3.0,0.03,99.81,1.0,ito:ITO_00101,Vision process,Overall\\ Accuracy
9,1,Hyperspectral Image Classification,Pavia University,2016-12,BASSNet,97.48,97.49,97.48,0.97,99.99,0.97,ito:ITO_00101,Vision process,Overall\\ Accuracy
10,1,Hyperspectral Image Classification,Pavia University,2018-07,WCRN,99.43,99.44,2.0,0.02,99.99,0.99,ito:ITO_00101,Vision process,Overall\\ Accuracy
11,1,Hyperspectral Image Classification,Pavia University,2019-02,HybridSN,99.99,100.0,0.6,0.01,99.99,1.0,ito:ITO_00101,Vision process,Overall\\ Accuracy
12,1,3D Point Cloud Classification,ScanObjectNN,2016-12,PointNet,68.2,86.88,68.2,0.87,78.5,0.68,ito:ITO_00101,Vision process,Overall\\ Accuracy
13,1,3D Point Cloud Classification,ScanObjectNN,2017-06,PointNet++,77.9,99.24,9.7,0.12,78.5,0.78,ito:ITO_00101,Vision process,Overall\\ Accuracy
14,1,3D Point Cloud Classification,ScanObjectNN,2018-01,PointCNN,78.5,100.0,0.6,0.01,78.5,0.78,ito:ITO_00101,Vision process,Overall\\ Accuracy
15,1,Hyperspectral Image Classification,Salinas Scene,2019-02,HybridSN,100.0,100.0,100,1.0,100,1.0,ito:ITO_00101,Vision process,Overall\\ Accuracy
16,1,Facial Expression Recognition,RAF-DB,2019-05,RAN (ResNet-18),86.9,100.0,86.9,1.0,86.9,0.87,ito:ITO_00101,Vision process,Overall\\ Accuracy
0,1,Object Counting,Pascal VOC 2007 count-test,2016-04,Fast-RCNN,0.85,100.0,0.85,1.0,0.85,0.75,ito:ITO_00101,Vision process,m\\-reIRMSE\\-nz
1,1,Object Counting,COCO count-test,2016-04,Aso-sub-ft-3x3,0.87,76.99,0.87,0.77,1.13,0.77,ito:ITO_00101,Vision process,m\\-reIRMSE\\-nz
2,1,Object Counting,COCO count-test,2016-04,glance-ft-2L,0.91,80.53,0.0,0.0,1.13,0.81,ito:ITO_00101,Vision process,m\\-reIRMSE\\-nz
3,1,Object Counting,COCO count-test,2016-04,Fast-RCNN,1.13,100.0,0.2,0.18,1.13,1.0,ito:ITO_00101,Vision process,m\\-reIRMSE\\-nz
0,1,Object Counting,Pascal VOC 2007 count-test,2016-04,Fast-RCNN,0.26,96.3,0.26,0.96,0.27,0.96,ito:ITO_00101,Vision process,m\\-relRMSE
1,1,Object Counting,Pascal VOC 2007 count-test,2016-04,glance-noft-2L,0.27,100.0,0.0,0.0,0.27,1.0,ito:ITO_00101,Vision process,m\\-relRMSE
0,1,Object Counting,COCO count-test,2016-04,Aso-sub-ft-3x3,0.24,100.0,0.24,1.0,0.24,1.0,ito:ITO_00101,Vision process,m\\-reIRMSE
0,1,Continuous Control,Inverted Pendulum,2016-04,TRPO,247.2,100.0,247.2,1.0,247.2,0.05,ito:ITO_00101,Vision process,Score
1,1,Continuous Control,Hopper,2016-04,TRPO,1183.3,100.0,1183.3,1.0,1183.3,0.24,ito:ITO_00101,Vision process,Score
2,1,Continuous Control,Cart-Pole Balancing,2016-04,TRPO,4869.8,100.0,4869.8,1.0,4869.8,1.0,ito:ITO_00101,Vision process,Score
3,1,Continuous Control,Double Inverted Pendulum,2016-04,TRPO,4412.4,100.0,4412.4,1.0,4412.4,0.91,ito:ITO_00101,Vision process,Score
4,1,Continuous Control,Ant,2016-04,TRPO,730.2,100.0,730.2,1.0,730.2,0.15,ito:ITO_00101,Vision process,Score
5,1,Continuous Control,Full Humanoid,2016-04,TRPO,287.0,100.0,287,1.0,287,0.06,ito:ITO_00101,Vision process,Score
6,1,Continuous Control,2D Walker,2016-04,TRPO,1353.8,100.0,1353.8,1.0,1353.8,0.28,ito:ITO_00101,Vision process,Score
7,1,Continuous Control,Swimmer,2016-04,TRPO,96.0,100.0,96,1.0,96,0.02,ito:ITO_00101,Vision process,Score
8,1,Continuous Control,Simple Humanoid,2016-04,TRPO,269.7,100.0,269.7,1.0,269.7,0.06,ito:ITO_00101,Vision process,Score
9,1,Continuous Control,Half-Cheetah,2016-04,TRPO,1914.0,100.0,1914,1.0,1914,0.39,ito:ITO_00101,Vision process,Score
10,1,Visual Question Answering,VQA-CP,2018-08,HAN,28.65,55.04,28.65,0.55,52.05,0.01,ito:ITO_00101,Vision process,Score
11,1,Visual Question Answering,VQA-CP,2019-02,MuRel,39.54,75.97,10.9,0.21,52.05,0.01,ito:ITO_00101,Vision process,Score
12,1,Visual Question Answering,VQA-CP,2019-05,UpDn+SCR (VQA-X),49.45,95.0,9.9,0.19,52.05,0.01,ito:ITO_00101,Vision process,Score
13,1,Visual Question Answering,VQA-CP,2019-09,Learned-Mixin +H,52.05,100.0,2.6,0.05,52.05,0.01,ito:ITO_00101,Vision process,Score
0,1,Temporal Action Localization,J-HMDB-21,2016-04,Actionness,39.9,53.63,39.9,0.54,74.4,0.46,ito:ITO_00101,Vision process,Frame\\-mAP
1,1,Temporal Action Localization,J-HMDB-21,2016-09,Peng w/ MR,58.5,78.63,18.6,0.25,74.4,0.67,ito:ITO_00101,Vision process,Frame\\-mAP
2,1,Temporal Action Localization,J-HMDB-21,2017-05,ACT,65.7,88.31,7.2,0.1,74.4,0.75,ito:ITO_00101,Vision process,Frame\\-mAP
3,1,Temporal Action Localization,J-HMDB-21,2017-05,Faster-RCNN + two-stream I3D conv,73.3,98.52,7.6,0.1,74.4,0.84,ito:ITO_00101,Vision process,Frame\\-mAP
4,1,Temporal Action Localization,J-HMDB-21,2019-11,YOWO (16-frame),74.4,100.0,1.1,0.01,74.4,0.85,ito:ITO_00101,Vision process,Frame\\-mAP
5,1,Temporal Action Localization,UCF101-24,2016-09,Peng w/o MR,64.8,74.31,64.8,0.74,87.2,0.74,ito:ITO_00101,Vision process,Frame\\-mAP
6,1,Temporal Action Localization,UCF101-24,2016-09,Peng w/ MR,65.7,75.34,0.9,0.01,87.2,0.75,ito:ITO_00101,Vision process,Frame\\-mAP
7,1,Temporal Action Localization,UCF101-24,2017-05,ACT,69.5,79.7,3.8,0.04,87.2,0.8,ito:ITO_00101,Vision process,Frame\\-mAP
8,1,Temporal Action Localization,UCF101-24,2017-05,Faster-RCNN + two-stream I3D conv,76.3,87.5,6.8,0.08,87.2,0.87,ito:ITO_00101,Vision process,Frame\\-mAP
9,1,Temporal Action Localization,UCF101-24,2019-11,YOWO (16-frame),87.2,100.0,10.9,0.12,87.2,1.0,ito:ITO_00101,Vision process,Frame\\-mAP
0,1,Playing Game of Doom,ViZDoom Basic Scenario,2016-05,DQN,82.2,100.0,82.2,1.0,82.2,1.0,ito:ITO_00101,Vision process,Average\\ Score
0,1,Visual Dialog,VisDial v0.9 val,2016-05,HieCoAtt-QI,57.88,83.98,57.88,0.84,68.92,0.84,ito:ITO_00101,Vision process,MRR
1,1,Visual Dialog,VisDial v0.9 val,2017-09,AMEM Seo et al. (2017),62.27,90.35,4.4,0.06,68.92,0.9,ito:ITO_00101,Vision process,MRR
2,1,Visual Dialog,VisDial v0.9 val,2017-11,CoAtt Wu et al. (2018),63.98,92.83,1.7,0.02,68.92,0.92,ito:ITO_00101,Vision process,MRR
3,1,Visual Dialog,VisDial v0.9 val,2018-09,CorefNMN (ResNet-152),64.1,93.01,0.1,0.0,68.92,0.92,ito:ITO_00101,Vision process,MRR
4,1,Visual Dialog,VisDial v0.9 val,2019-02,DAN,66.38,96.31,2.3,0.03,68.92,0.96,ito:ITO_00101,Vision process,MRR
5,1,Visual Dialog,VisDial v0.9 val,2019-04,9xFGA (VGG),68.92,100.0,2.5,0.04,68.92,0.99,ito:ITO_00101,Vision process,MRR
6,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),61.5,88.74,61.5,0.89,69.3,0.89,ito:ITO_00101,Vision process,MRR
7,1,Visual Dialog,VisDial v1.0 test-std,2019-02,DAN,63.2,91.2,1.7,0.02,69.3,0.91,ito:ITO_00101,Vision process,MRR
8,1,Visual Dialog,VisDial v1.0 test-std,2019-04,5xFGA (F-RCNNx101),69.3,100.0,6.1,0.09,69.3,1.0,ito:ITO_00101,Vision process,MRR
9,1,Visual Dialog,Visual Dialog v1.0,2019-02,HACAN,64.22,99.04,64.22,0.99,64.84,0.93,ito:ITO_00101,Vision process,MRR
10,1,Visual Dialog,Visual Dialog v1.0,2020-04,MVAN,64.84,100.0,0.6,0.01,64.84,0.94,ito:ITO_00101,Vision process,MRR
0,1,Visual Dialog,VisDial v0.9 val,2016-05,HieCoAtt-QI,5.84,100.0,5.84,1.0,5.84,0.49,ito:ITO_00101,Vision process,Mean\\ Rank
1,1,Few-Shot Image Classification,Meta-Dataset Rank,2016-06,Matching Networks,10.5,88.98,10.5,0.89,11.8,0.89,ito:ITO_00101,Vision process,Mean\\ Rank
2,1,Few-Shot Image Classification,Meta-Dataset Rank,2017-11,Relation Networks,11.8,100.0,1.3,0.11,11.8,1.0,ito:ITO_00101,Vision process,Mean\\ Rank
3,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),4.4,100.0,4.4,1.0,4.4,0.37,ito:ITO_00101,Vision process,Mean\\ Rank
4,1,Visual Dialog,Visual Dialog v1.0,2019-02,HACAN,4.2,97.67,4.2,0.98,4.3,0.36,ito:ITO_00101,Vision process,Mean\\ Rank
5,1,Visual Dialog,Visual Dialog v1.0,2019-02,DAN,4.3,100.0,0.1,0.02,4.3,0.36,ito:ITO_00101,Vision process,Mean\\ Rank
0,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2016-06,OFL,65.7,75.43,65.7,0.75,87.1,0.75,ito:ITO_00101,Vision process,J\\&F
1,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2016-11,OSVOS,80.2,92.08,14.5,0.17,87.1,0.92,ito:ITO_00101,Vision process,J\\&F
2,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2017-06,OnAVOS,85.5,98.16,5.3,0.06,87.1,0.98,ito:ITO_00101,Vision process,J\\&F
3,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2019-08,RANet+ (online learning),87.1,100.0,1.6,0.02,87.1,1.0,ito:ITO_00101,Vision process,J\\&F
4,1,Unsupervised Video Object Segmentation,DAVIS 2016,2017-09,SFL,67.05,83.81,67.05,0.84,80.0,0.77,ito:ITO_00101,Vision process,J\\&F
5,1,Unsupervised Video Object Segmentation,DAVIS 2016,2020-01,COSNet,80.0,100.0,13.0,0.16,80.0,0.92,ito:ITO_00101,Vision process,J\\&F
0,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2016-06,OFL,63.4,72.37,63.4,0.72,87.6,0.72,ito:ITO_00101,Vision process,F\\-measure\\ \\(Mean\\)
1,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2016-11,OSVOS,80.6,92.01,17.2,0.2,87.6,0.92,ito:ITO_00101,Vision process,F\\-measure\\ \\(Mean\\)
2,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2017-06,OnAVOS,84.9,96.92,4.3,0.05,87.6,0.97,ito:ITO_00101,Vision process,F\\-measure\\ \\(Mean\\)
3,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2018-03,CINM,85.0,97.03,0.1,0.0,87.6,0.97,ito:ITO_00101,Vision process,F\\-measure\\ \\(Mean\\)
4,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2019-08,RANet,85.4,97.49,0.4,0.0,87.6,0.97,ito:ITO_00101,Vision process,F\\-measure\\ \\(Mean\\)
5,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2019-08,RANet+ (online learning),87.6,100.0,2.2,0.03,87.6,1.0,ito:ITO_00101,Vision process,F\\-measure\\ \\(Mean\\)
6,1,Visual Object Tracking,DAVIS 2016,2016-06,+,67.1,76.6,67.1,0.77,87.6,0.77,ito:ITO_00101,Vision process,F\\-measure\\ \\(Mean\\)
7,1,Visual Object Tracking,DAVIS 2016,2016-12,MSK,75.4,86.07,8.3,0.09,87.6,0.86,ito:ITO_00101,Vision process,F\\-measure\\ \\(Mean\\)
8,1,Visual Object Tracking,DAVIS 2016,2017-06,OnAVOS,84.9,96.92,9.5,0.11,87.6,0.97,ito:ITO_00101,Vision process,F\\-measure\\ \\(Mean\\)
9,1,Visual Object Tracking,DAVIS 2016,2019-08,RANet+ (online learning),87.6,100.0,2.7,0.03,87.6,1.0,ito:ITO_00101,Vision process,F\\-measure\\ \\(Mean\\)
10,1,Visual Object Tracking,DAVIS-2017,2016-11,OSVOS,63.9,82.24,63.9,0.82,77.7,0.73,ito:ITO_00101,Vision process,F\\-measure\\ \\(Mean\\)
11,1,Visual Object Tracking,DAVIS-2017,2017-06,OnAVOS,69.1,88.93,5.2,0.07,77.7,0.79,ito:ITO_00101,Vision process,F\\-measure\\ \\(Mean\\)
12,1,Visual Object Tracking,DAVIS-2017,2019-07,PTSNet,77.7,100.0,8.6,0.11,77.7,0.89,ito:ITO_00101,Vision process,F\\-measure\\ \\(Mean\\)
13,1,Unsupervised Video Object Segmentation,DAVIS 2016,2017-09,SFL,66.7,83.9,66.7,0.84,79.5,0.76,ito:ITO_00101,Vision process,F\\-measure\\ \\(Mean\\)
14,1,Unsupervised Video Object Segmentation,DAVIS 2016,2020-01,COSNet,79.5,100.0,12.8,0.16,79.5,0.91,ito:ITO_00101,Vision process,F\\-measure\\ \\(Mean\\)
0,1,Low-Light Image Enhancement,MEF,2016-06,SRIE,3.22,77.97,3.22,0.78,4.13,0.78,ito:ITO_00101,Vision process,User\\ Study\\ Score
1,1,Low-Light Image Enhancement,MEF,2019-06,EnlightenGAN,3.75,90.8,0.5,0.12,4.13,0.91,ito:ITO_00101,Vision process,User\\ Study\\ Score
2,1,Low-Light Image Enhancement,MEF,2020-01,Zero-DCE,4.13,100.0,0.4,0.1,4.13,1.0,ito:ITO_00101,Vision process,User\\ Study\\ Score
3,1,Low-Light Image Enhancement,VV,2016-06,SRIE,2.8,86.42,2.8,0.86,3.24,0.68,ito:ITO_00101,Vision process,User\\ Study\\ Score
4,1,Low-Light Image Enhancement,VV,2019-06,Wang et al.,2.95,91.05,0.2,0.06,3.24,0.71,ito:ITO_00101,Vision process,User\\ Study\\ Score
5,1,Low-Light Image Enhancement,VV,2019-06,EnlightenGAN,3.17,97.84,0.2,0.06,3.24,0.77,ito:ITO_00101,Vision process,User\\ Study\\ Score
6,1,Low-Light Image Enhancement,VV,2020-01,Zero-DCE,3.24,100.0,0.1,0.03,3.24,0.78,ito:ITO_00101,Vision process,User\\ Study\\ Score
7,1,Low-Light Image Enhancement,DICM,2016-06,SRIE,3.42,97.16,3.42,0.97,3.52,0.83,ito:ITO_00101,Vision process,User\\ Study\\ Score
8,1,Low-Light Image Enhancement,DICM,2019-06,Wang et al.,3.44,97.73,0.0,0.0,3.52,0.83,ito:ITO_00101,Vision process,User\\ Study\\ Score
9,1,Low-Light Image Enhancement,DICM,2019-06,EnlightenGAN,3.5,99.43,0.1,0.03,3.52,0.85,ito:ITO_00101,Vision process,User\\ Study\\ Score
10,1,Low-Light Image Enhancement,DICM,2020-01,Zero-DCE,3.52,100.0,0.0,0.0,3.52,0.85,ito:ITO_00101,Vision process,User\\ Study\\ Score
11,1,Low-Light Image Enhancement,NPE,2020-01,Zero-DCE,3.81,100.0,3.81,1.0,3.81,0.92,ito:ITO_00101,Vision process,User\\ Study\\ Score
12,1,Low-Light Image Enhancement,LIME,2020-01,Zero-DCE,3.8,100.0,3.8,1.0,3.8,0.92,ito:ITO_00101,Vision process,User\\ Study\\ Score
0,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2016-06,OFL,27.2,100.0,27.2,1.0,27.2,1.0,ito:ITO_00101,Vision process,F\\-measure\\ \\(Decay\\)
1,1,Visual Object Tracking,DAVIS 2016,2016-06,+,0.3,2.04,0.3,0.02,14.7,0.01,ito:ITO_00101,Vision process,F\\-measure\\ \\(Decay\\)
2,1,Visual Object Tracking,DAVIS 2016,2016-12,MSK,9.0,61.22,8.7,0.59,14.7,0.33,ito:ITO_00101,Vision process,F\\-measure\\ \\(Decay\\)
3,1,Visual Object Tracking,DAVIS 2016,2016-12,VPN,14.4,97.96,5.4,0.37,14.7,0.53,ito:ITO_00101,Vision process,F\\-measure\\ \\(Decay\\)
4,1,Visual Object Tracking,DAVIS 2016,2017-08,PLM,14.7,100.0,0.3,0.02,14.7,0.54,ito:ITO_00101,Vision process,F\\-measure\\ \\(Decay\\)
5,1,Visual Object Tracking,DAVIS-2017,2016-11,OSVOS,27.0,100.0,27.0,1.0,27.0,0.99,ito:ITO_00101,Vision process,F\\-measure\\ \\(Decay\\)
6,1,Unsupervised Video Object Segmentation,DAVIS 2016,2017-09,SFL,5.1,100.0,5.1,1.0,5.1,0.19,ito:ITO_00101,Vision process,F\\-measure\\ \\(Decay\\)
0,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2016-06,OFL,70.4,73.26,70.4,0.73,96.1,0.73,ito:ITO_00101,Vision process,F\\-measure\\ \\(Recall\\)
1,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2016-11,OSVOS,92.6,96.36,22.2,0.23,96.1,0.96,ito:ITO_00101,Vision process,F\\-measure\\ \\(Recall\\)
2,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2018-04,PML,93.4,97.19,0.8,0.01,96.1,0.97,ito:ITO_00101,Vision process,F\\-measure\\ \\(Recall\\)
3,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2019-08,RANet,94.9,98.75,1.5,0.02,96.1,0.99,ito:ITO_00101,Vision process,F\\-measure\\ \\(Recall\\)
4,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2019-08,RANet+ (online learning),96.1,100.0,1.2,0.01,96.1,1.0,ito:ITO_00101,Vision process,F\\-measure\\ \\(Recall\\)
5,1,Visual Object Tracking,DAVIS 2016,2016-06,+,79.0,82.21,79.0,0.82,96.1,0.82,ito:ITO_00101,Vision process,F\\-measure\\ \\(Recall\\)
6,1,Visual Object Tracking,DAVIS 2016,2016-12,MSK,87.1,90.63,8.1,0.08,96.1,0.91,ito:ITO_00101,Vision process,F\\-measure\\ \\(Recall\\)
7,1,Visual Object Tracking,DAVIS 2016,2017-06,OnAVOS,89.7,93.34,2.6,0.03,96.1,0.93,ito:ITO_00101,Vision process,F\\-measure\\ \\(Recall\\)
8,1,Visual Object Tracking,DAVIS 2016,2018-04,PML,93.4,97.19,3.7,0.04,96.1,0.97,ito:ITO_00101,Vision process,F\\-measure\\ \\(Recall\\)
9,1,Visual Object Tracking,DAVIS 2016,2019-08,RANet+ (online learning),96.1,100.0,2.7,0.03,96.1,1.0,ito:ITO_00101,Vision process,F\\-measure\\ \\(Recall\\)
10,1,Visual Object Tracking,DAVIS-2017,2016-11,OSVOS,73.8,97.88,73.8,0.98,75.4,0.77,ito:ITO_00101,Vision process,F\\-measure\\ \\(Recall\\)
11,1,Visual Object Tracking,DAVIS-2017,2017-06,OnAVOS,75.4,100.0,1.6,0.02,75.4,0.78,ito:ITO_00101,Vision process,F\\-measure\\ \\(Recall\\)
12,1,Unsupervised Video Object Segmentation,DAVIS 2016,2017-09,SFL,77.1,86.15,77.1,0.86,89.5,0.8,ito:ITO_00101,Vision process,F\\-measure\\ \\(Recall\\)
13,1,Unsupervised Video Object Segmentation,DAVIS 2016,2020-01,COSNet,89.5,100.0,12.4,0.14,89.5,0.93,ito:ITO_00101,Vision process,F\\-measure\\ \\(Recall\\)
14,1,Video Object Segmentation,DAVIS 2016,2020-01,COSNet,90.4,100.0,90.4,1.0,90.4,0.94,ito:ITO_00101,Vision process,F\\-measure\\ \\(Recall\\)
0,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2016-06,OFL,75.6,77.78,75.6,0.78,97.2,0.78,ito:ITO_00101,Vision process,Jaccard\\ \\(Recall\\)
1,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2016-11,OSVOS,93.6,96.3,18.0,0.19,97.2,0.96,ito:ITO_00101,Vision process,Jaccard\\ \\(Recall\\)
2,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2017-06,OnAVOS,96.1,98.87,2.5,0.03,97.2,0.99,ito:ITO_00101,Vision process,Jaccard\\ \\(Recall\\)
3,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2018-06,FAVOS,96.5,99.28,0.4,0.0,97.2,0.99,ito:ITO_00101,Vision process,Jaccard\\ \\(Recall\\)
4,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2019-08,RANet,97.2,100.0,0.7,0.01,97.2,1.0,ito:ITO_00101,Vision process,Jaccard\\ \\(Recall\\)
5,1,Visual Object Tracking,DAVIS 2016,2016-06,+,86.0,88.48,86.0,0.88,97.2,0.88,ito:ITO_00101,Vision process,Jaccard\\ \\(Recall\\)
6,1,Visual Object Tracking,DAVIS 2016,2016-12,MSK,93.1,95.78,7.1,0.07,97.2,0.96,ito:ITO_00101,Vision process,Jaccard\\ \\(Recall\\)
7,1,Visual Object Tracking,DAVIS 2016,2017-06,OnAVOS,96.1,98.87,3.0,0.03,97.2,0.99,ito:ITO_00101,Vision process,Jaccard\\ \\(Recall\\)
8,1,Visual Object Tracking,DAVIS 2016,2018-06,FAVOS,96.5,99.28,0.4,0.0,97.2,0.99,ito:ITO_00101,Vision process,Jaccard\\ \\(Recall\\)
9,1,Visual Object Tracking,DAVIS 2016,2019-08,RANet+ (online learning),97.0,99.79,0.5,0.01,97.2,1.0,ito:ITO_00101,Vision process,Jaccard\\ \\(Recall\\)
10,1,Visual Object Tracking,DAVIS 2016,2019-08,RANet,97.2,100.0,0.2,0.0,97.2,1.0,ito:ITO_00101,Vision process,Jaccard\\ \\(Recall\\)
11,1,Visual Object Tracking,DAVIS-2017,2016-11,OSVOS,63.8,94.66,63.8,0.95,67.4,0.66,ito:ITO_00101,Vision process,Jaccard\\ \\(Recall\\)
12,1,Visual Object Tracking,DAVIS-2017,2017-06,OnAVOS,67.4,100.0,3.6,0.05,67.4,0.69,ito:ITO_00101,Vision process,Jaccard\\ \\(Recall\\)
13,1,Unsupervised Video Object Segmentation,DAVIS 2016,2017-09,SFL,81.4,87.43,81.4,0.87,93.1,0.84,ito:ITO_00101,Vision process,Jaccard\\ \\(Recall\\)
14,1,Unsupervised Video Object Segmentation,DAVIS 2016,2020-01,COSNet,93.1,100.0,11.7,0.13,93.1,0.96,ito:ITO_00101,Vision process,Jaccard\\ \\(Recall\\)
15,1,Video Object Segmentation,DAVIS 2016,2020-01,COSNet,94.0,100.0,94,1.0,94,0.97,ito:ITO_00101,Vision process,Jaccard\\ \\(Recall\\)
0,1,Semi-Supervised Video Object Segmentation,DAVIS 2016,2016-06,OFL,26.4,100.0,26.4,1.0,26.4,0.95,ito:ITO_00101,Vision process,Jaccard\\ \\(Decay\\)
1,1,Visual Object Tracking,DAVIS 2016,2016-06,+,0.8,6.45,0.8,0.06,12.4,0.03,ito:ITO_00101,Vision process,Jaccard\\ \\(Decay\\)
2,1,Visual Object Tracking,DAVIS 2016,2016-12,MSK,8.9,71.77,8.1,0.65,12.4,0.32,ito:ITO_00101,Vision process,Jaccard\\ \\(Decay\\)
3,1,Visual Object Tracking,DAVIS 2016,2016-12,VPN,12.4,100.0,3.5,0.28,12.4,0.44,ito:ITO_00101,Vision process,Jaccard\\ \\(Decay\\)
4,1,Visual Object Tracking,DAVIS-2017,2016-11,OSVOS,26.1,93.55,26.1,0.94,27.9,0.94,ito:ITO_00101,Vision process,Jaccard\\ \\(Decay\\)
5,1,Visual Object Tracking,DAVIS-2017,2017-06,OnAVOS,27.9,100.0,1.8,0.06,27.9,1.0,ito:ITO_00101,Vision process,Jaccard\\ \\(Decay\\)
6,1,Unsupervised Video Object Segmentation,DAVIS 2016,2017-09,SFL,6.2,100.0,6.2,1.0,6.2,0.22,ito:ITO_00101,Vision process,Jaccard\\ \\(Decay\\)
0,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-06,BiGAN,0.07,21.88,0.07,0.22,0.32,0.22,ito:ITO_00101,Vision process,Class\\ IOU
1,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-06,CoGAN,0.08,25.0,0.0,0.0,0.32,0.25,ito:ITO_00101,Vision process,Class\\ IOU
2,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-11,pix2pix,0.32,100.0,0.2,0.62,0.32,1.0,ito:ITO_00101,Vision process,Class\\ IOU
3,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,BiGAN,0.02,11.11,0.02,0.11,0.18,0.06,ito:ITO_00101,Vision process,Class\\ IOU
4,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,CoGAN,0.06,33.33,0.0,0.0,0.18,0.19,ito:ITO_00101,Vision process,Class\\ IOU
5,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-11,pix2pix,0.18,100.0,0.1,0.56,0.18,0.56,ito:ITO_00101,Vision process,Class\\ IOU
6,1,Image-to-Image Translation,Aerial-to-Map,2016-11,cGAN,0.26,100.0,0.26,1.0,0.26,0.81,ito:ITO_00101,Vision process,Class\\ IOU
0,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,BiGAN,19.0,23.09,19.0,0.23,82.3,0.21,ito:ITO_00101,Vision process,Per\\-pixel\\ Accuracy
1,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,CoGAN,40.0,48.6,21.0,0.26,82.3,0.43,ito:ITO_00101,Vision process,Per\\-pixel\\ Accuracy
2,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-11,pix2pix,71.0,86.27,31.0,0.38,82.3,0.77,ito:ITO_00101,Vision process,Per\\-pixel\\ Accuracy
3,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2017-07,CRN,77.1,93.68,6.1,0.07,82.3,0.84,ito:ITO_00101,Vision process,Per\\-pixel\\ Accuracy
4,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2017-11,pix2pixHD,81.4,98.91,4.3,0.05,82.3,0.88,ito:ITO_00101,Vision process,Per\\-pixel\\ Accuracy
5,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2019-03,SPADE,81.9,99.51,0.5,0.01,82.3,0.89,ito:ITO_00101,Vision process,Per\\-pixel\\ Accuracy
6,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2019-10,CC-FPSE,82.3,100.0,0.4,0.0,82.3,0.89,ito:ITO_00101,Vision process,Per\\-pixel\\ Accuracy
7,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-06,BiGAN,41.0,48.24,41,0.48,85,0.45,ito:ITO_00101,Vision process,Per\\-pixel\\ Accuracy
8,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-06,CoGAN,45.0,52.94,4,0.05,85,0.49,ito:ITO_00101,Vision process,Per\\-pixel\\ Accuracy
9,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-11,pix2pix,85.0,100.0,40,0.47,85,0.92,ito:ITO_00101,Vision process,Per\\-pixel\\ Accuracy
10,1,Image-to-Image Translation,Aerial-to-Map,2016-11,cGAN,70.0,100.0,70,1.0,70,0.76,ito:ITO_00101,Vision process,Per\\-pixel\\ Accuracy
11,1,Image-to-Image Translation,SYNTHIA Fall-to-Winter,2017-11,CyCADA,92.1,100.0,92.1,1.0,92.1,1.0,ito:ITO_00101,Vision process,Per\\-pixel\\ Accuracy
12,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2017-11,CyCADA pixel+feat,82.3,100.0,82.3,1.0,82.3,0.89,ito:ITO_00101,Vision process,Per\\-pixel\\ Accuracy
0,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,BiGAN,6.0,24.0,6,0.24,25,0.13,ito:ITO_00101,Vision process,Per\\-class\\ Accuracy
1,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,CoGAN,10.0,40.0,4,0.16,25,0.22,ito:ITO_00101,Vision process,Per\\-class\\ Accuracy
2,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-11,pix2pix,25.0,100.0,15,0.6,25,0.54,ito:ITO_00101,Vision process,Per\\-class\\ Accuracy
3,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-06,BiGAN,13.0,32.5,13,0.32,40,0.28,ito:ITO_00101,Vision process,Per\\-class\\ Accuracy
4,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-11,pix2pix,40.0,100.0,27,0.68,40,0.87,ito:ITO_00101,Vision process,Per\\-class\\ Accuracy
5,1,Image-to-Image Translation,Aerial-to-Map,2016-11,cGAN,46.0,100.0,46,1.0,46,1.0,ito:ITO_00101,Vision process,Per\\-class\\ Accuracy
0,1,Multivariate Time Series Imputation,MuJoCo,2016-06,RNN GRU-D,0.748,12.26,0.748,0.12,6.1,0.12,ito:ITO_00101,Vision process,"MSE\\ \\(10\\^2,\\ 50%\\ missing\\)"
1,1,Multivariate Time Series Imputation,MuJoCo,2018-06,RNN-VAE,6.1,100.0,5.4,0.89,6.1,1.0,ito:ITO_00101,Vision process,"MSE\\ \\(10\\^2,\\ 50%\\ missing\\)"
0,1,Image Generation,ImageNet 64x64,2016-06,"Gated PixelCNN (van den Oord et al., [2016c])",3.57,93.7,3.57,0.94,3.81,0.94,ito:ITO_00101,Vision process,Bits\\ per\\ byte
1,1,Image Generation,ImageNet 64x64,2017-03,Parallel Multiscale,3.7,97.11,0.1,0.03,3.81,0.97,ito:ITO_00101,Vision process,Bits\\ per\\ byte
2,1,Image Generation,ImageNet 64x64,2018-07,GLOW,3.81,100.0,0.1,0.03,3.81,1.0,ito:ITO_00101,Vision process,Bits\\ per\\ byte
0,1,Image Generation,ImageNet 64x64,2016-06,"Gated PixelCNN (van den Oord et al., [2016c])",3.57,93.7,3.57,0.94,3.81,0.94,ito:ITO_00101,Vision process,Bits\\ per\\ dim
1,1,Image Generation,ImageNet 64x64,2017-03,Parallel Multiscale,3.7,97.11,0.1,0.03,3.81,0.97,ito:ITO_00101,Vision process,Bits\\ per\\ dim
2,1,Image Generation,ImageNet 64x64,2018-07,"Glow (Kingma and Dhariwal, 2018)",3.81,100.0,0.1,0.03,3.81,1.0,ito:ITO_00101,Vision process,Bits\\ per\\ dim
0,1,Surgical Skills Evaluation,MISTIC-SIL,2016-06,Bidir. LSTM,19.5,100.0,19.5,1.0,19.5,1.0,ito:ITO_00101,Vision process,Edit\\ Distance
1,1,Handwritten Word Generation,Handwritten Word Generation,2016-06,Bidir. LSTM,19.5,100.0,19.5,1.0,19.5,1.0,ito:ITO_00101,Vision process,Edit\\ Distance
2,1,Surgical Skills Evaluation,JIGSAWS,2016-06,Bidir. LSTM,14.6,100.0,14.6,1.0,14.6,0.75,ito:ITO_00101,Vision process,Edit\\ Distance
3,1,Zero-Shot Text-to-Image Generation,Zero-Shot Text-to-Image Generation,2016-06,Bidir. LSTM,14.6,100.0,14.6,1.0,14.6,0.75,ito:ITO_00101,Vision process,Edit\\ Distance
0,1,3D Part Segmentation,ShapeNet-Part,2016-06,3D-UNet [Cicek:2016un],84.6,90.87,84.6,0.91,93.1,0.91,ito:ITO_00101,Vision process,Instance\\ Average\\ IoU
1,1,3D Part Segmentation,ShapeNet-Part,2016-12,SSCNN,84.7,90.98,0.1,0.0,93.1,0.91,ito:ITO_00101,Vision process,Instance\\ Average\\ IoU
2,1,3D Part Segmentation,ShapeNet-Part,2017-06,SSCN,86.0,92.37,1.3,0.01,93.1,0.92,ito:ITO_00101,Vision process,Instance\\ Average\\ IoU
3,1,3D Part Segmentation,ShapeNet-Part,2018-01,PointCNN,86.14,92.52,0.1,0.0,93.1,0.93,ito:ITO_00101,Vision process,Instance\\ Average\\ IoU
4,1,3D Part Segmentation,ShapeNet-Part,2019-04,ConvPoint,93.1,100.0,7.0,0.08,93.1,1.0,ito:ITO_00101,Vision process,Instance\\ Average\\ IoU
0,1,Scene Graph Generation,VRD,2016-07,VRD,18.16,99.13,18.16,0.99,18.32,0.57,ito:ITO_00101,Vision process,Recall\\-at\\-50
1,1,Scene Graph Generation,VRD,2018-06,FactorizableNet,18.32,100.0,0.2,0.01,18.32,0.57,ito:ITO_00101,Vision process,Recall\\-at\\-50
2,1,Scene Graph Generation,Visual Genome,2017-07,MSDN,10.72,33.57,10.72,0.34,31.93,0.34,ito:ITO_00101,Vision process,Recall\\-at\\-50
3,1,Scene Graph Generation,Visual Genome,2018-08,Graph-RCNN,11.4,35.7,0.7,0.02,31.93,0.36,ito:ITO_00101,Vision process,Recall\\-at\\-50
4,1,Scene Graph Generation,Visual Genome,2018-12,VCTree,27.9,87.38,16.5,0.52,31.93,0.87,ito:ITO_00101,Vision process,Recall\\-at\\-50
5,1,Scene Graph Generation,Visual Genome,2020-02,Causal-TDE,31.93,100.0,4.0,0.13,31.93,1.0,ito:ITO_00101,Vision process,Recall\\-at\\-50
0,1,Action Classification,Kinetics-400,2016-08,TSN,73.9,89.25,73.9,0.89,82.8,0.89,ito:ITO_00101,Vision process,Vid\\ acc@1
1,1,Action Classification,Kinetics-400,2017-11,I3D + NL,77.7,93.84,3.8,0.05,82.8,0.94,ito:ITO_00101,Vision process,Vid\\ acc@1
2,1,Action Classification,Kinetics-400,2018-10,"RepFlow-50 ([2+1]D CNN, FcF, Non-local block)",77.9,94.08,0.2,0.0,82.8,0.94,ito:ITO_00101,Vision process,Vid\\ acc@1
3,1,Action Classification,Kinetics-400,2018-12,SlowFast (ResNet-101 + NL),79.8,96.38,1.9,0.02,82.8,0.96,ito:ITO_00101,Vision process,Vid\\ acc@1
4,1,Action Classification,Kinetics-400,2019-04,ir-CSN-152 (IG-65M pretraining),82.6,99.76,2.8,0.03,82.8,1.0,ito:ITO_00101,Vision process,Vid\\ acc@1
5,1,Action Classification,Kinetics-400,2019-05,irCSN-152 (IG-Kinetics-65M pretrain),82.8,100.0,0.2,0.0,82.8,1.0,ito:ITO_00101,Vision process,Vid\\ acc@1
0,1,Action Classification,Kinetics-400,2016-08,TSN,91.1,95.59,91.1,0.96,95.3,0.96,ito:ITO_00101,Vision process,Vid\\ acc@5
1,1,Action Classification,Kinetics-400,2017-11,I3D + NL,93.3,97.9,2.2,0.02,95.3,0.98,ito:ITO_00101,Vision process,Vid\\ acc@5
2,1,Action Classification,Kinetics-400,2017-12,"S3D-G (RGB, ImageNet pretrained)",93.4,98.01,0.1,0.0,95.3,0.98,ito:ITO_00101,Vision process,Vid\\ acc@5
3,1,Action Classification,Kinetics-400,2018-12,SlowFast 16x8 (ResNet-101 + NL),93.9,98.53,0.5,0.01,95.3,0.99,ito:ITO_00101,Vision process,Vid\\ acc@5
4,1,Action Classification,Kinetics-400,2019-04,ip-CSN-152 (IG-65M pretraining),95.3,100.0,1.4,0.01,95.3,1.0,ito:ITO_00101,Vision process,Vid\\ acc@5
0,1,Disease Trajectory Forecasting,UK CF trust,2016-08,RETAIN,0.685,99.71,0.685,1.0,0.687,1.0,ito:ITO_00101,Vision process,AUC\\ \\(ABPA\\)
1,1,Disease Trajectory Forecasting,UK CF trust,2018-10,PASS,0.687,100.0,0.0,0.0,0.687,1.0,ito:ITO_00101,Vision process,AUC\\ \\(ABPA\\)
0,1,Disease Trajectory Forecasting,UK CF trust,2016-08,RETAIN,0.764,99.09,0.764,0.99,0.771,0.99,ito:ITO_00101,Vision process,AUC\\ \\(Diabetes\\)
1,1,Disease Trajectory Forecasting,UK CF trust,2018-10,PASS,0.771,100.0,0.0,0.0,0.771,1.0,ito:ITO_00101,Vision process,AUC\\ \\(Diabetes\\)
0,1,Disease Trajectory Forecasting,UK CF trust,2016-08,RETAIN,0.578,100.0,0.578,1.0,0.578,1.0,ito:ITO_00101,Vision process,AUC\\ \\(I\\.\\ Obstruction\\)
0,1,Disease Trajectory Forecasting,UK CF trust,2016-08,RETAIN,0.578,100.0,0.578,1.0,0.578,1.0,ito:ITO_00101,Vision process,I\\.\\ Obstruction
0,1,Disease Trajectory Forecasting,UK CF trust,2016-08,RETAIN,0.715,99.58,0.715,1.0,0.718,1.0,ito:ITO_00101,Vision process,AUC\\ \\(K\\.\\ Pneumonia\\)
1,1,Disease Trajectory Forecasting,UK CF trust,2018-10,PASS,0.718,100.0,0.0,0.0,0.718,1.0,ito:ITO_00101,Vision process,AUC\\ \\(K\\.\\ Pneumonia\\)
0,1,Disease Trajectory Forecasting,UK CF trust,2016-08,RETAIN,0.697,99.43,0.697,0.99,0.701,0.99,ito:ITO_00101,Vision process,AUC\\ \\(E\\.\\ Coli\\)
1,1,Disease Trajectory Forecasting,UK CF trust,2018-10,PASS,0.701,100.0,0.0,0.0,0.701,1.0,ito:ITO_00101,Vision process,AUC\\ \\(E\\.\\ Coli\\)
0,1,Disease Trajectory Forecasting,UK CF trust,2016-08,RETAIN,0.641,100.0,0.641,1.0,0.641,1.0,ito:ITO_00101,Vision process,AUC\\ \\(Aspergillus\\)
0,1,Domain Adaptation,Synth Objects-to-LINEMOD,2016-08,DSN (DANN),53.27,100.0,53.27,1.0,53.27,1.0,ito:ITO_00101,Vision process,Mean\\ Angle\\ Error
0,1,Video Generation,"UCF-101 16 frames, Unconditional, Single GPU",2016-09,VGAN,8.18,35.7,8.18,0.36,22.91,0.04,ito:ITO_00101,Vision process,Inception\\ Score
1,1,Video Generation,"UCF-101 16 frames, Unconditional, Single GPU",2016-11,TGAN-SVC,11.85,51.72,3.7,0.16,22.91,0.05,ito:ITO_00101,Vision process,Inception\\ Score
2,1,Video Generation,"UCF-101 16 frames, Unconditional, Single GPU",2017-07,MoCoGAN,12.42,54.21,0.6,0.03,22.91,0.06,ito:ITO_00101,Vision process,Inception\\ Score
3,1,Video Generation,"UCF-101 16 frames, Unconditional, Single GPU",2019-12,TGAN-F,22.91,100.0,10.5,0.46,22.91,0.1,ito:ITO_00101,Vision process,Inception\\ Score
4,1,Video Generation,"UCF-101 16 frames, 64x64, Unconditional",2016-09,VGAN,8.18,60.06,8.18,0.6,13.62,0.04,ito:ITO_00101,Vision process,Inception\\ Score
5,1,Video Generation,"UCF-101 16 frames, 64x64, Unconditional",2016-11,TGAN-SVC,11.85,87.0,3.7,0.27,13.62,0.05,ito:ITO_00101,Vision process,Inception\\ Score
6,1,Video Generation,"UCF-101 16 frames, 64x64, Unconditional",2017-07,MoCoGAN,12.42,91.19,0.6,0.04,13.62,0.06,ito:ITO_00101,Vision process,Inception\\ Score
7,1,Video Generation,"UCF-101 16 frames, 64x64, Unconditional",2019-12,TGAN-F,13.62,100.0,1.2,0.09,13.62,0.06,ito:ITO_00101,Vision process,Inception\\ Score
8,1,Layout-to-Image Generation,COCO-Stuff 64x64,2018-04,SG2Im,7.3,67.59,7.3,0.68,10.8,0.03,ito:ITO_00101,Vision process,Inception\\ Score
9,1,Layout-to-Image Generation,COCO-Stuff 64x64,2018-11,Layout2Im,9.1,84.26,1.8,0.17,10.8,0.04,ito:ITO_00101,Vision process,Inception\\ Score
10,1,Layout-to-Image Generation,COCO-Stuff 64x64,2019-08,LostGAN,9.8,90.74,0.7,0.06,10.8,0.04,ito:ITO_00101,Vision process,Inception\\ Score
11,1,Layout-to-Image Generation,COCO-Stuff 64x64,2019-09,SOARISG,10.3,95.37,0.5,0.05,10.8,0.05,ito:ITO_00101,Vision process,Inception\\ Score
12,1,Layout-to-Image Generation,COCO-Stuff 64x64,2020-03,OC-GAN,10.8,100.0,0.5,0.05,10.8,0.05,ito:ITO_00101,Vision process,Inception\\ Score
13,1,Layout-to-Image Generation,Visual Genome 64x64,2018-04,SG2Im,6.3,67.74,6.3,0.68,9.3,0.03,ito:ITO_00101,Vision process,Inception\\ Score
14,1,Layout-to-Image Generation,Visual Genome 64x64,2018-11,Layout2Im,8.1,87.1,1.8,0.19,9.3,0.04,ito:ITO_00101,Vision process,Inception\\ Score
15,1,Layout-to-Image Generation,Visual Genome 64x64,2019-08,LostGAN,8.7,93.55,0.6,0.06,9.3,0.04,ito:ITO_00101,Vision process,Inception\\ Score
16,1,Layout-to-Image Generation,Visual Genome 64x64,2020-03,OC-GAN,9.3,100.0,0.6,0.06,9.3,0.04,ito:ITO_00101,Vision process,Inception\\ Score
17,1,Video Generation,"UCF-101 16 frames, 128x128, Unconditional",2018-11,TGANv2,24.34,88.9,24.34,0.89,27.38,0.11,ito:ITO_00101,Vision process,Inception\\ Score
18,1,Video Generation,"UCF-101 16 frames, 128x128, Unconditional",2020-01,DVD-GAN,27.38,100.0,3.0,0.11,27.38,0.12,ito:ITO_00101,Vision process,Inception\\ Score
19,1,Image Generation,ImageNet 64x64,2019-07,BigBiGAN,19.4,74.73,19.4,0.75,25.96,0.09,ito:ITO_00101,Vision process,Inception\\ Score
20,1,Image Generation,ImageNet 64x64,2020-04,FQ-GAN,25.96,100.0,6.6,0.25,25.96,0.12,ito:ITO_00101,Vision process,Inception\\ Score
21,1,Video Generation,"Kinetics-600 48 frames, 64x64",2019-07,DVD-GAN,219.05,100.0,219.05,1.0,219.05,1.0,ito:ITO_00101,Vision process,Inception\\ Score
22,1,Video Generation,"Kinetics-600 12 frames, 64x64",2019-07,DVD-GAN,129.9,100.0,129.9,1.0,129.9,0.59,ito:ITO_00101,Vision process,Inception\\ Score
23,1,Layout-to-Image Generation,COCO-Stuff 128x128,2019-08,LostGAN,13.8,94.52,13.8,0.95,14.6,0.06,ito:ITO_00101,Vision process,Inception\\ Score
24,1,Layout-to-Image Generation,COCO-Stuff 128x128,2020-03,OC-GAN,14.6,100.0,0.8,0.05,14.6,0.07,ito:ITO_00101,Vision process,Inception\\ Score
25,1,Layout-to-Image Generation,Visual Genome 128x128,2019-08,LostGAN,11.1,90.24,11.1,0.9,12.3,0.05,ito:ITO_00101,Vision process,Inception\\ Score
26,1,Layout-to-Image Generation,Visual Genome 128x128,2020-03,OC-GAN,12.3,100.0,1.2,0.1,12.3,0.06,ito:ITO_00101,Vision process,Inception\\ Score
0,1,Monocular Depth Estimation,Mid-Air Dataset,2016-09,Monodepth,0.3136,43.74,0.3136,0.44,0.717,0.44,ito:ITO_00101,Vision process,Abs\\ Rel
1,1,Monocular Depth Estimation,Mid-Air Dataset,2018-06,Monodepth2,0.717,100.0,0.4,0.56,0.717,1.0,ito:ITO_00101,Vision process,Abs\\ Rel
2,1,Monocular Depth Estimation,Make3D,2018-06,Monodepth2,0.322,100.0,0.322,1.0,0.322,0.45,ito:ITO_00101,Vision process,Abs\\ Rel
0,1,Monocular Depth Estimation,Mid-Air Dataset,2016-09,Monodepth,0.438,49.66,0.438,0.5,0.882,0.5,ito:ITO_00101,Vision process,RMSE\\ log
1,1,Monocular Depth Estimation,Mid-Air Dataset,2018-06,Monodepth2,0.882,100.0,0.4,0.45,0.882,1.0,ito:ITO_00101,Vision process,RMSE\\ log
0,1,Monocular Depth Estimation,Mid-Air Dataset,2016-09,Monodepth,8.7127,23.44,8.7127,0.23,37.164,0.23,ito:ITO_00101,Vision process,SQ\\ Rel
1,1,Monocular Depth Estimation,Mid-Air Dataset,2018-06,Monodepth2,37.164,100.0,28.5,0.77,37.164,1.0,ito:ITO_00101,Vision process,SQ\\ Rel
0,1,Monocular Depth Estimation,KITTI Eigen split,2016-09,monodepth,0.114,59.07,0.114,0.59,0.193,0.59,ito:ITO_00101,Vision process,absolute\\ relative\\ error
1,1,Monocular Depth Estimation,KITTI Eigen split,2018-05,CC,0.14,72.54,0.0,0.0,0.193,0.73,ito:ITO_00101,Vision process,absolute\\ relative\\ error
2,1,Monocular Depth Estimation,KITTI Eigen split,2019-03,VDA,0.193,100.0,0.1,0.52,0.193,1.0,ito:ITO_00101,Vision process,absolute\\ relative\\ error
3,1,Monocular Depth Estimation,KITTI Eigen split unsupervised,2016-09,Monodepth S,0.133,100.0,0.133,1.0,0.133,0.69,ito:ITO_00101,Vision process,absolute\\ relative\\ error
0,1,Image Super-Resolution,PIRM-test,2016-09,SRGAN,2.71,100.0,2.71,1.0,2.71,0.18,ito:ITO_00101,Vision process,NIQE
1,1,Image Super-Resolution,FFHQ 512 x 512,2016-09,SRGAN,7.378,53.08,7.378,0.53,13.901,0.48,ito:ITO_00101,Vision process,NIQE
2,1,Image Super-Resolution,FFHQ 512 x 512,2017-07,EDSR,13.636,98.09,6.3,0.45,13.901,0.89,ito:ITO_00101,Vision process,NIQE
3,1,Image Super-Resolution,FFHQ 512 x 512,2019-03,SRFBN,13.901,100.0,0.3,0.02,13.901,0.9,ito:ITO_00101,Vision process,NIQE
4,1,Face Hallucination,FFHQ 512 x 512,2017-10,WaveletCNN,11.45,74.43,11.45,0.74,15.383,0.74,ito:ITO_00101,Vision process,NIQE
5,1,Face Hallucination,FFHQ 512 x 512,2018-09,ESRGAN,15.383,100.0,3.9,0.25,15.383,1.0,ito:ITO_00101,Vision process,NIQE
0,1,Image Super-Resolution,FFHQ 512 x 512,2016-09,SRGAN,2.269,83.97,2.269,0.84,2.702,0.84,ito:ITO_00101,Vision process,LLE
1,1,Image Super-Resolution,FFHQ 512 x 512,2017-10,WaveletCNN,2.702,100.0,0.4,0.15,2.702,1.0,ito:ITO_00101,Vision process,LLE
0,1,Image Super-Resolution,FFHQ 512 x 512,2016-09,SRGAN,0.1097,99.1,0.1097,0.99,0.1107,0.99,ito:ITO_00101,Vision process,FED
1,1,Image Super-Resolution,FFHQ 512 x 512,2018-09,ESRGAN,0.1107,100.0,0.0,0.0,0.1107,1.0,ito:ITO_00101,Vision process,FED
0,1,Image Super-Resolution,FFHQ 512 x 512,2016-09,SRGAN,0.1313,53.05,0.1313,0.53,0.2475,0.24,ito:ITO_00101,Vision process,LPIPS
1,1,Image Super-Resolution,FFHQ 512 x 512,2017-07,EDSR,0.2475,100.0,0.1,0.4,0.2475,0.45,ito:ITO_00101,Vision process,LPIPS
2,1,Image Reconstruction,Edge-to-Handbags,2016-11,pix2pix,0.234,100.0,0.234,1.0,0.234,0.43,ito:ITO_00101,Vision process,LPIPS
3,1,Image Reconstruction,Edge-to-Shoes,2016-11,pix2pix,0.238,100.0,0.238,1.0,0.238,0.44,ito:ITO_00101,Vision process,LPIPS
4,1,Face Hallucination,FFHQ 512 x 512,2017-10,WaveletCNN,0.4909,100.0,0.4909,1.0,0.4909,0.9,ito:ITO_00101,Vision process,LPIPS
5,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2017-11,AttnGAN,0.512,94.12,0.512,0.94,0.544,0.94,ito:ITO_00101,Vision process,LPIPS
6,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2019-04,DM-GAN,0.544,100.0,0.0,0.0,0.544,1.0,ito:ITO_00101,Vision process,LPIPS
7,1,Pose Transfer,Deep-Fashion,2017-12,Deformable GAN,0.233,100.0,0.233,1.0,0.233,0.43,ito:ITO_00101,Vision process,LPIPS
8,1,Image Reconstruction,Edge-to-Clothes,2019-10,bFT,0.1,100.0,0.1,1.0,0.1,0.18,ito:ITO_00101,Vision process,LPIPS
9,1,Image Enhancement,MIT-Adobe 5k,2019-11,"DIFAR (MSCA, level 1)",0.108,100.0,0.108,1.0,0.108,0.2,ito:ITO_00101,Vision process,LPIPS
10,1,Image-to-Image Translation,CelebA-HQ,2019-12,StarGAN v2,0.428,100.0,0.428,1.0,0.428,0.79,ito:ITO_00101,Vision process,LPIPS
11,1,Image-to-Image Translation,AFHQ,2019-12,StarGAN v2,0.524,100.0,0.524,1.0,0.524,0.96,ito:ITO_00101,Vision process,LPIPS
12,1,Facial Inpainting,FFHQ,2020-02,DMFN,0.0457,100.0,0.0457,1.0,0.0457,0.08,ito:ITO_00101,Vision process,LPIPS
0,1,Video Retrieval,MSR-VTT,2016-09,C+LSTM+SA+FC7,12.9,31.54,12.9,0.32,40.9,0.32,ito:ITO_00101,Vision process,video\\-to\\-text\\ R\\-at\\-5
1,1,Video Retrieval,MSR-VTT,2016-12,Kaufman,16.6,40.59,3.7,0.09,40.9,0.41,ito:ITO_00101,Vision process,video\\-to\\-text\\ R\\-at\\-5
2,1,Video Retrieval,MSR-VTT,2018-06,JEMC,32.1,78.48,15.5,0.38,40.9,0.78,ito:ITO_00101,Vision process,video\\-to\\-text\\ R\\-at\\-5
3,1,Video Retrieval,MSR-VTT,2019-06,Text-Video Embedding,40.2,98.29,8.1,0.2,40.9,0.98,ito:ITO_00101,Vision process,video\\-to\\-text\\ R\\-at\\-5
4,1,Video Retrieval,MSR-VTT,2019-07,Collaborative Experts,40.9,100.0,0.7,0.02,40.9,1.0,ito:ITO_00101,Vision process,video\\-to\\-text\\ R\\-at\\-5
0,1,Video Classification,YouTube-8M,2016-09,Mixture-of-2-Experts,70.1,79.93,70.1,0.8,87.7,0.8,ito:ITO_00101,Vision process,Hit\\-at\\-1
1,1,Video Classification,YouTube-8M,2019-06,DCGN (self-attention graph pooling),87.7,100.0,17.6,0.2,87.7,1.0,ito:ITO_00101,Vision process,Hit\\-at\\-1
0,1,Video Classification,YouTube-8M,2016-09,Mixture-of-2-Experts,84.8,100.0,84.8,1.0,84.8,1.0,ito:ITO_00101,Vision process,Hit\\-at\\-5
0,1,Video Classification,YouTube-8M,2016-09,Mixture-of-2-Experts,29.1,100.0,29.1,1.0,29.1,1.0,ito:ITO_00101,Vision process,PERR
0,1,Face Alignment,3DFAW,2016-09,3D Face alignment,3.4767,100.0,3.4767,1.0,3.4767,1.0,ito:ITO_00101,Vision process,CVGTCE
0,1,Face Alignment,3DFAW,2016-09,3D Face alignment,4.5623,100.0,4.5623,1.0,4.5623,1.0,ito:ITO_00101,Vision process,GTE
0,1,Anomaly Detection,CIFAR-10 model detecting CIFAR-10,2016-10,Wide ResNet,54.1,71.0,54.1,0.71,76.2,0.71,ito:ITO_00101,Vision process,AUPR
1,1,Anomaly Detection,CIFAR-10 model detecting CIFAR-10,2018-12,Wide ResNet + Outlier Exposure,76.2,100.0,22.1,0.29,76.2,1.0,ito:ITO_00101,Vision process,AUPR
2,1,Out-of-Distribution Detection,CIFAR-10 vs CIFAR-100,2018-12,WRN 40-2 (MSP Baseline),55.8,73.23,55.8,0.73,76.2,0.73,ito:ITO_00101,Vision process,AUPR
3,1,Out-of-Distribution Detection,CIFAR-10 vs CIFAR-100,2018-12,WRN 40-2 + OE,76.2,100.0,20.4,0.27,76.2,1.0,ito:ITO_00101,Vision process,AUPR
0,1,3D Shape Classification,Pix3D,2016-10,3D-VAE-GAN,0.12,15.38,0.12,0.15,0.78,0.15,ito:ITO_00101,Vision process,R\\-at\\-8
1,1,3D Shape Classification,Pix3D,2017-11,MarrNet,0.64,82.05,0.5,0.64,0.78,0.82,ito:ITO_00101,Vision process,R\\-at\\-8
2,1,3D Shape Classification,Pix3D,2018-04,MarrNet extension (w/o Pose),0.78,100.0,0.1,0.13,0.78,1.0,ito:ITO_00101,Vision process,R\\-at\\-8
3,1,3D Shape Retrieval,Pix3D,2016-10,3D-VAE-GAN,0.12,15.38,0.12,0.15,0.78,0.15,ito:ITO_00101,Vision process,R\\-at\\-8
4,1,3D Shape Retrieval,Pix3D,2017-11,MarrNet,0.64,82.05,0.5,0.64,0.78,0.82,ito:ITO_00101,Vision process,R\\-at\\-8
5,1,3D Shape Retrieval,Pix3D,2018-04,MarrNet extension (w/o Pose),0.78,100.0,0.1,0.13,0.78,1.0,ito:ITO_00101,Vision process,R\\-at\\-8
0,1,3D Shape Retrieval,Pix3D,2016-10,3D-VAE-GAN,0.21,24.71,0.21,0.25,0.85,0.25,ito:ITO_00101,Vision process,R\\-at\\-16
1,1,3D Shape Retrieval,Pix3D,2017-11,MarrNet,0.71,83.53,0.5,0.59,0.85,0.84,ito:ITO_00101,Vision process,R\\-at\\-16
2,1,3D Shape Retrieval,Pix3D,2018-04,MarrNet extension (w/o Pose),0.85,100.0,0.1,0.12,0.85,1.0,ito:ITO_00101,Vision process,R\\-at\\-16
3,1,3D Shape Classification,Pix3D,2016-10,3D-VAE-GAN,0.21,24.71,0.21,0.25,0.85,0.25,ito:ITO_00101,Vision process,R\\-at\\-16
4,1,3D Shape Classification,Pix3D,2017-11,MarrNet,0.71,83.53,0.5,0.59,0.85,0.84,ito:ITO_00101,Vision process,R\\-at\\-16
5,1,3D Shape Classification,Pix3D,2018-04,MarrNet extension (w/o Pose),0.85,100.0,0.1,0.12,0.85,1.0,ito:ITO_00101,Vision process,R\\-at\\-16
0,1,3D Shape Retrieval,Pix3D,2016-10,3D-VAE-GAN,0.03,4.84,0.03,0.05,0.62,0.05,ito:ITO_00101,Vision process,R\\-at\\-2
1,1,3D Shape Retrieval,Pix3D,2017-11,MarrNet,0.51,82.26,0.5,0.81,0.62,0.82,ito:ITO_00101,Vision process,R\\-at\\-2
2,1,3D Shape Retrieval,Pix3D,2018-04,MarrNet extension (w/o Pose),0.62,100.0,0.1,0.16,0.62,1.0,ito:ITO_00101,Vision process,R\\-at\\-2
3,1,3D Shape Classification,Pix3D,2016-10,3D-VAE-GAN,0.03,4.84,0.03,0.05,0.62,0.05,ito:ITO_00101,Vision process,R\\-at\\-2
4,1,3D Shape Classification,Pix3D,2017-11,MarrNet,0.51,82.26,0.5,0.81,0.62,0.82,ito:ITO_00101,Vision process,R\\-at\\-2
5,1,3D Shape Classification,Pix3D,2018-04,MarrNet extension (w/o Pose),0.62,100.0,0.1,0.16,0.62,1.0,ito:ITO_00101,Vision process,R\\-at\\-2
0,1,3D Shape Retrieval,Pix3D,2016-10,3D-VAE-GAN,0.34,37.78,0.34,0.38,0.9,0.38,ito:ITO_00101,Vision process,R\\-at\\-32
1,1,3D Shape Retrieval,Pix3D,2017-11,MarrNet,0.78,86.67,0.4,0.44,0.9,0.87,ito:ITO_00101,Vision process,R\\-at\\-32
2,1,3D Shape Retrieval,Pix3D,2018-04,MarrNet extension (w/o Pose),0.9,100.0,0.1,0.11,0.9,1.0,ito:ITO_00101,Vision process,R\\-at\\-32
3,1,3D Shape Classification,Pix3D,2016-10,3D-VAE-GAN,0.34,37.78,0.34,0.38,0.9,0.38,ito:ITO_00101,Vision process,R\\-at\\-32
4,1,3D Shape Classification,Pix3D,2017-11,MarrNet,0.78,86.67,0.4,0.44,0.9,0.87,ito:ITO_00101,Vision process,R\\-at\\-32
5,1,3D Shape Classification,Pix3D,2018-04,MarrNet extension (w/o Pose),0.9,100.0,0.1,0.11,0.9,1.0,ito:ITO_00101,Vision process,R\\-at\\-32
0,1,3D Shape Retrieval,Pix3D,2016-10,3D-VAE-GAN,0.07,9.86,0.07,0.1,0.71,0.1,ito:ITO_00101,Vision process,R\\-at\\-4
1,1,3D Shape Retrieval,Pix3D,2017-11,MarrNet,0.57,80.28,0.5,0.7,0.71,0.8,ito:ITO_00101,Vision process,R\\-at\\-4
2,1,3D Shape Retrieval,Pix3D,2018-04,MarrNet extension (w/o Pose),0.71,100.0,0.1,0.14,0.71,1.0,ito:ITO_00101,Vision process,R\\-at\\-4
3,1,3D Shape Classification,Pix3D,2016-10,3D-VAE-GAN,0.07,9.86,0.07,0.1,0.71,0.1,ito:ITO_00101,Vision process,R\\-at\\-4
4,1,3D Shape Classification,Pix3D,2017-11,MarrNet,0.57,80.28,0.5,0.7,0.71,0.8,ito:ITO_00101,Vision process,R\\-at\\-4
5,1,3D Shape Classification,Pix3D,2018-04,MarrNet extension (w/o Pose),0.71,100.0,0.1,0.14,0.71,1.0,ito:ITO_00101,Vision process,R\\-at\\-4
0,1,Optical Flow Estimation,Sintel-final,2016-11,Spynet,8.36,100.0,8.36,1.0,8.36,1.0,ito:ITO_00101,Vision process,Average\\ End\\-Point\\ Error
1,1,Optical Flow Estimation,Sintel-clean,2016-11,Spynet,6.64,100.0,6.64,1.0,6.64,0.79,ito:ITO_00101,Vision process,Average\\ End\\-Point\\ Error
2,1,Optical Flow Estimation,KITTI 2012,2018-09,PWC-Net + ft,1.5,93.75,1.5,0.94,1.6,0.18,ito:ITO_00101,Vision process,Average\\ End\\-Point\\ Error
3,1,Optical Flow Estimation,KITTI 2012,2019-04,IRR-PWC,1.6,100.0,0.1,0.06,1.6,0.19,ito:ITO_00101,Vision process,Average\\ End\\-Point\\ Error
4,1,Optical Flow Estimation,KITTI 2012 unsupervised,2020-03,ARFlow-MV,1.5,100.0,1.5,1.0,1.5,0.18,ito:ITO_00101,Vision process,Average\\ End\\-Point\\ Error
5,1,Optical Flow Estimation,Sintel Clean unsupervised,2020-03,ARFlow-MV,4.49,100.0,4.49,1.0,4.49,0.54,ito:ITO_00101,Vision process,Average\\ End\\-Point\\ Error
6,1,Optical Flow Estimation,Sintel Final unsupervised,2020-03,ARFlow-MV,5.67,100.0,5.67,1.0,5.67,0.68,ito:ITO_00101,Vision process,Average\\ End\\-Point\\ Error
0,1,Salient Object Detection,SBU,2016-11,DSS,7.0,76.92,7.0,0.77,9.1,0.61,ito:ITO_00101,Vision process,Balanced\\ Error\\ Rate
1,1,Salient Object Detection,SBU,2017-07,NLDF,7.02,77.14,0.0,0.0,9.1,0.61,ito:ITO_00101,Vision process,Balanced\\ Error\\ Rate
2,1,Salient Object Detection,SBU,2017-10,scGAN,9.1,100.0,2.1,0.23,9.1,0.79,ito:ITO_00101,Vision process,Balanced\\ Error\\ Rate
3,1,Salient Object Detection,UCF,2016-11,DSS,10.56,91.83,10.56,0.92,11.5,0.92,ito:ITO_00101,Vision process,Balanced\\ Error\\ Rate
4,1,Salient Object Detection,UCF,2017-10,scGAN,11.5,100.0,0.9,0.08,11.5,1.0,ito:ITO_00101,Vision process,Balanced\\ Error\\ Rate
5,1,Salient Object Detection,ISTD,2016-11,DSS,10.48,100.0,10.48,1.0,10.48,0.91,ito:ITO_00101,Vision process,Balanced\\ Error\\ Rate
6,1,RGB Salient Object Detection,SBU,2016-11,DSS,7.0,76.92,7.0,0.77,9.1,0.61,ito:ITO_00101,Vision process,Balanced\\ Error\\ Rate
7,1,RGB Salient Object Detection,SBU,2017-07,NLDF,7.02,77.14,0.0,0.0,9.1,0.61,ito:ITO_00101,Vision process,Balanced\\ Error\\ Rate
8,1,RGB Salient Object Detection,SBU,2017-10,scGAN,9.1,100.0,2.1,0.23,9.1,0.79,ito:ITO_00101,Vision process,Balanced\\ Error\\ Rate
9,1,RGB Salient Object Detection,UCF,2016-11,DSS,10.56,91.83,10.56,0.92,11.5,0.92,ito:ITO_00101,Vision process,Balanced\\ Error\\ Rate
10,1,RGB Salient Object Detection,UCF,2017-10,scGAN,11.5,100.0,0.9,0.08,11.5,1.0,ito:ITO_00101,Vision process,Balanced\\ Error\\ Rate
11,1,RGB Salient Object Detection,ISTD,2016-11,DSS,10.48,100.0,10.48,1.0,10.48,0.91,ito:ITO_00101,Vision process,Balanced\\ Error\\ Rate
0,1,Semi-Supervised Video Object Segmentation,YouTube-VOS,2016-11,OSVOS,0.1,1.4,0.1,0.01,7.14,0.0,ito:ITO_00101,Vision process,Speed\\ \\ \\(FPS\\)
1,1,Semi-Supervised Video Object Segmentation,YouTube-VOS,2018-02,OSMN,7.14,100.0,7.0,0.98,7.14,0.02,ito:ITO_00101,Vision process,Speed\\ \\ \\(FPS\\)
2,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,MFA-Net,361.0,100.0,361,1.0,361,1.0,ito:ITO_00101,Vision process,Speed\\ \\ \\(FPS\\)
3,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet-tiny,98.0,100.0,98,1.0,98,0.27,ito:ITO_00101,Vision process,Speed\\ \\ \\(FPS\\)
0,1,Semi-Supervised Video Object Segmentation,YouTube-VOS,2016-11,OSVOS,58.8,100.0,58.8,1.0,58.8,1.0,ito:ITO_00101,Vision process,Overall
0,1,Semi-Supervised Video Object Segmentation,YouTube-VOS,2016-11,OSVOS,60.5,100.0,60.5,1.0,60.5,0.96,ito:ITO_00101,Vision process,F\\-Measure\\ \\(Seen\\)
1,1,Visual Object Tracking,YouTube-VOS,2016-11,OSVOS,60.5,96.49,60.5,0.96,62.7,0.96,ito:ITO_00101,Vision process,F\\-Measure\\ \\(Seen\\)
2,1,Visual Object Tracking,YouTube-VOS,2017-06,OnAVOS,62.7,100.0,2.2,0.04,62.7,1.0,ito:ITO_00101,Vision process,F\\-Measure\\ \\(Seen\\)
3,1,One-shot visual object segmentation,YouTube-VOS,2016-11,OSVOS,60.5,100.0,60.5,1.0,60.5,0.96,ito:ITO_00101,Vision process,F\\-Measure\\ \\(Seen\\)
0,1,One-shot visual object segmentation,YouTube-VOS,2016-11,OSVOS,60.7,100.0,60.7,1.0,60.7,1.0,ito:ITO_00101,Vision process,F\\-Measure\\ \\(Unseen\\)
1,1,Visual Object Tracking,YouTube-VOS,2016-11,OSVOS,60.7,100.0,60.7,1.0,60.7,1.0,ito:ITO_00101,Vision process,F\\-Measure\\ \\(Unseen\\)
2,1,Semi-Supervised Video Object Segmentation,YouTube-VOS,2016-11,OSVOS,60.7,100.0,60.7,1.0,60.7,1.0,ito:ITO_00101,Vision process,F\\-Measure\\ \\(Unseen\\)
0,1,Visual Object Tracking,YouTube-VOS,2016-11,OSVOS,59.8,81.36,59.8,0.81,73.5,0.81,ito:ITO_00101,Vision process,Jaccard\\ \\(Seen\\)
1,1,Visual Object Tracking,YouTube-VOS,2017-06,OnAVOS,60.1,81.77,0.3,0.0,73.5,0.82,ito:ITO_00101,Vision process,Jaccard\\ \\(Seen\\)
2,1,Visual Object Tracking,YouTube-VOS,2019-07,PTSNet,73.5,100.0,13.4,0.18,73.5,1.0,ito:ITO_00101,Vision process,Jaccard\\ \\(Seen\\)
3,1,One-shot visual object segmentation,YouTube-VOS,2016-11,OSVOS,59.8,99.67,59.8,1.0,60.0,0.81,ito:ITO_00101,Vision process,Jaccard\\ \\(Seen\\)
4,1,One-shot visual object segmentation,YouTube-VOS,2018-02,OSMN,60.0,100.0,0.2,0.0,60.0,0.82,ito:ITO_00101,Vision process,Jaccard\\ \\(Seen\\)
5,1,Semi-Supervised Video Object Segmentation,YouTube-VOS,2016-11,OSVOS,59.8,99.67,59.8,1.0,60.0,0.81,ito:ITO_00101,Vision process,Jaccard\\ \\(Seen\\)
6,1,Semi-Supervised Video Object Segmentation,YouTube-VOS,2018-02,OSMN,60.0,100.0,0.2,0.0,60.0,0.82,ito:ITO_00101,Vision process,Jaccard\\ \\(Seen\\)
0,1,One-shot visual object segmentation,YouTube-VOS,2016-11,OSVOS,54.2,100.0,54.2,1.0,54.2,0.84,ito:ITO_00101,Vision process,Jaccard\\ \\(Unseen\\)
1,1,Visual Object Tracking,YouTube-VOS,2016-11,OSVOS,54.2,84.29,54.2,0.84,64.3,0.84,ito:ITO_00101,Vision process,Jaccard\\ \\(Unseen\\)
2,1,Visual Object Tracking,YouTube-VOS,2019-07,PTSNet,64.3,100.0,10.1,0.16,64.3,1.0,ito:ITO_00101,Vision process,Jaccard\\ \\(Unseen\\)
3,1,Semi-Supervised Video Object Segmentation,YouTube-VOS,2016-11,OSVOS,54.2,100.0,54.2,1.0,54.2,0.84,ito:ITO_00101,Vision process,Jaccard\\ \\(Unseen\\)
0,1,Keypoint Detection,COCO,2016-11,Pose-AE,62.8,81.88,62.8,0.82,76.7,0.82,ito:ITO_00101,Vision process,Test\\ AP
1,1,Keypoint Detection,COCO,2016-12,AlphaPose,73.3,95.57,10.5,0.14,76.7,0.96,ito:ITO_00101,Vision process,Test\\ AP
2,1,Keypoint Detection,COCO,2018-12,PoseFix,76.7,100.0,3.4,0.04,76.7,1.0,ito:ITO_00101,Vision process,Test\\ AP
3,1,Multi-Person Pose Estimation,COCO,2018-12,PoseFix,76.7,100.0,76.7,1.0,76.7,1.0,ito:ITO_00101,Vision process,Test\\ AP
0,1,Keypoint Detection,COCO test-dev,2016-11,AE,70.2,85.61,70.2,0.86,82.0,0.85,ito:ITO_00101,Vision process,AR
1,1,Keypoint Detection,COCO test-dev,2017-11,CPN,78.5,95.73,8.3,0.1,82.0,0.95,ito:ITO_00101,Vision process,AR
2,1,Keypoint Detection,COCO test-dev,2017-11,CPN+,79.0,96.34,0.5,0.01,82.0,0.96,ito:ITO_00101,Vision process,AR
3,1,Keypoint Detection,COCO test-dev,2018-04,Simple Base+*,81.5,99.39,2.5,0.03,82.0,0.99,ito:ITO_00101,Vision process,AR
4,1,Keypoint Detection,COCO test-dev,2019-01,MSPN,81.6,99.51,0.1,0.0,82.0,0.99,ito:ITO_00101,Vision process,AR
5,1,Keypoint Detection,COCO test-dev,2019-02,HRNet*,82.0,100.0,0.4,0.0,82.0,1.0,ito:ITO_00101,Vision process,AR
6,1,Pose Estimation,COCO test-dev,2016-11,CMU-Pose,66.5,80.8,66.5,0.81,82.3,0.81,ito:ITO_00101,Vision process,AR
7,1,Pose Estimation,COCO test-dev,2017-01,G-RMI,69.7,84.69,3.2,0.04,82.3,0.85,ito:ITO_00101,Vision process,AR
8,1,Pose Estimation,COCO test-dev,2017-11,CPN,78.5,95.38,8.8,0.11,82.3,0.95,ito:ITO_00101,Vision process,AR
9,1,Pose Estimation,COCO test-dev,2017-11,"CPN+ [6, 9]",79.0,95.99,0.5,0.01,82.3,0.96,ito:ITO_00101,Vision process,AR
10,1,Pose Estimation,COCO test-dev,2018-12,PoseFix,79.9,97.08,0.9,0.01,82.3,0.97,ito:ITO_00101,Vision process,AR
11,1,Pose Estimation,COCO test-dev,2019-01,MSPN,81.6,99.15,1.7,0.02,82.3,0.99,ito:ITO_00101,Vision process,AR
12,1,Pose Estimation,COCO test-dev,2019-02,HRNet-W48 + extra data,82.0,99.64,0.4,0.0,82.3,1.0,ito:ITO_00101,Vision process,AR
13,1,Pose Estimation,COCO test-dev,2019-10,DARK (extra data),82.3,100.0,0.3,0.0,82.3,1.0,ito:ITO_00101,Vision process,AR
14,1,Keypoint Detection,COCO test-challenge,2017-01,G-RMI*,75.1,91.36,75.1,0.91,82.2,0.91,ito:ITO_00101,Vision process,AR
15,1,Keypoint Detection,COCO test-challenge,2017-03,Mask R-CNN*,75.4,91.73,0.3,0.0,82.2,0.92,ito:ITO_00101,Vision process,AR
16,1,Keypoint Detection,COCO test-challenge,2017-11,CPN+,78.7,95.74,3.3,0.04,82.2,0.96,ito:ITO_00101,Vision process,AR
17,1,Keypoint Detection,COCO test-challenge,2018-04,Simple Base+*,80.5,97.93,1.8,0.02,82.2,0.98,ito:ITO_00101,Vision process,AR
18,1,Keypoint Detection,COCO test-challenge,2019-01,MSPN+*,82.2,100.0,1.7,0.02,82.2,1.0,ito:ITO_00101,Vision process,AR
19,1,3D Object Detection,nuScenes-F,2019-05,RRPN + R101,48.6,100.0,48.6,1.0,48.6,0.59,ito:ITO_00101,Vision process,AR
20,1,3D Object Detection,nuScenes-FB,2019-05,RRPN + R101,42.1,100.0,42.1,1.0,42.1,0.51,ito:ITO_00101,Vision process,AR
21,1,Multi-Person Pose Estimation,COCO test-dev,2019-11,Identity Mapping Hourglass,72.1,100.0,72.1,1.0,72.1,0.88,ito:ITO_00101,Vision process,AR
0,1,Keypoint Detection,COCO test-dev,2016-11,AE,89.5,92.94,89.5,0.93,96.3,0.93,ito:ITO_00101,Vision process,AR50
1,1,Keypoint Detection,COCO test-dev,2017-11,CPN,95.1,98.75,5.6,0.06,96.3,0.99,ito:ITO_00101,Vision process,AR50
2,1,Keypoint Detection,COCO test-dev,2018-04,Simple Base+*,95.8,99.48,0.7,0.01,96.3,0.99,ito:ITO_00101,Vision process,AR50
3,1,Keypoint Detection,COCO test-dev,2019-01,MSPN,96.3,100.0,0.5,0.01,96.3,1.0,ito:ITO_00101,Vision process,AR50
4,1,Keypoint Detection,COCO test-challenge,2017-01,G-RMI*,90.7,94.48,90.7,0.94,96.0,0.94,ito:ITO_00101,Vision process,AR50
5,1,Keypoint Detection,COCO test-challenge,2017-03,Mask R-CNN*,93.2,97.08,2.5,0.03,96.0,0.97,ito:ITO_00101,Vision process,AR50
6,1,Keypoint Detection,COCO test-challenge,2017-11,CPN+,94.7,98.65,1.5,0.02,96.0,0.98,ito:ITO_00101,Vision process,AR50
7,1,Keypoint Detection,COCO test-challenge,2018-04,Simple Base+*,95.1,99.06,0.4,0.0,96.0,0.99,ito:ITO_00101,Vision process,AR50
8,1,Keypoint Detection,COCO test-challenge,2019-01,MSPN+*,96.0,100.0,0.9,0.01,96.0,1.0,ito:ITO_00101,Vision process,AR50
9,1,Multi-Person Pose Estimation,COCO test-dev,2019-11,Identity Mapping Hourglass,88.2,100.0,88.2,1.0,88.2,0.92,ito:ITO_00101,Vision process,AR50
0,1,Keypoint Detection,COCO test-dev,2016-11,AE,76.0,86.17,76.0,0.86,88.2,0.86,ito:ITO_00101,Vision process,AR75
1,1,Keypoint Detection,COCO test-dev,2017-11,CPN,85.3,96.71,9.3,0.11,88.2,0.97,ito:ITO_00101,Vision process,AR75
2,1,Keypoint Detection,COCO test-dev,2017-11,CPN+,85.9,97.39,0.6,0.01,88.2,0.97,ito:ITO_00101,Vision process,AR75
3,1,Keypoint Detection,COCO test-dev,2018-04,Simple Base+*,88.2,100.0,2.3,0.03,88.2,1.0,ito:ITO_00101,Vision process,AR75
4,1,Keypoint Detection,COCO test-challenge,2017-01,G-RMI*,80.7,92.02,80.7,0.92,87.7,0.91,ito:ITO_00101,Vision process,AR75
5,1,Keypoint Detection,COCO test-challenge,2017-03,Mask R-CNN*,81.2,92.59,0.5,0.01,87.7,0.92,ito:ITO_00101,Vision process,AR75
6,1,Keypoint Detection,COCO test-challenge,2017-11,CPN+,84.8,96.69,3.6,0.04,87.7,0.96,ito:ITO_00101,Vision process,AR75
7,1,Keypoint Detection,COCO test-challenge,2018-04,Simple Base+*,86.3,98.4,1.5,0.02,87.7,0.98,ito:ITO_00101,Vision process,AR75
8,1,Keypoint Detection,COCO test-challenge,2019-01,MSPN+*,87.7,100.0,1.4,0.02,87.7,0.99,ito:ITO_00101,Vision process,AR75
0,1,Keypoint Detection,COCO test-dev,2016-11,AE,64.6,83.35,64.6,0.83,77.5,0.83,ito:ITO_00101,Vision process,ARM
1,1,Keypoint Detection,COCO test-dev,2017-11,CPN,74.2,95.74,9.6,0.12,77.5,0.96,ito:ITO_00101,Vision process,ARM
2,1,Keypoint Detection,COCO test-dev,2017-11,CPN+,74.8,96.52,0.6,0.01,77.5,0.97,ito:ITO_00101,Vision process,ARM
3,1,Keypoint Detection,COCO test-dev,2018-04,Simple Base+*,77.4,99.87,2.6,0.03,77.5,1.0,ito:ITO_00101,Vision process,ARM
4,1,Keypoint Detection,COCO test-dev,2019-01,MSPN,77.5,100.0,0.1,0.0,77.5,1.0,ito:ITO_00101,Vision process,ARM
5,1,Keypoint Detection,COCO test-challenge,2017-01,G-RMI*,69.7,89.94,69.7,0.9,77.5,0.9,ito:ITO_00101,Vision process,ARM
6,1,Keypoint Detection,COCO test-challenge,2017-03,Mask R-CNN*,70.2,90.58,0.5,0.01,77.5,0.91,ito:ITO_00101,Vision process,ARM
7,1,Keypoint Detection,COCO test-challenge,2017-11,CPN+,74.3,95.87,4.1,0.05,77.5,0.96,ito:ITO_00101,Vision process,ARM
8,1,Keypoint Detection,COCO test-challenge,2018-04,Simple Base+*,75.3,97.16,1.0,0.01,77.5,0.97,ito:ITO_00101,Vision process,ARM
9,1,Keypoint Detection,COCO test-challenge,2019-01,MSPN+*,77.5,100.0,2.2,0.03,77.5,1.0,ito:ITO_00101,Vision process,ARM
0,1,Visual Object Tracking,YouTube-VOS,2016-11,OSVOS,58.8,100.0,58.8,1.0,58.8,1.0,ito:ITO_00101,Vision process,O\\ \\(Average\\ of\\ Measures\\)
0,1,Keypoint Detection,COCO test-dev,2016-11,AE,78.1,89.56,78.1,0.9,87.2,0.9,ito:ITO_00101,Vision process,ARL
1,1,Keypoint Detection,COCO test-dev,2017-11,CPN,84.3,96.67,6.2,0.07,87.2,0.97,ito:ITO_00101,Vision process,ARL
2,1,Keypoint Detection,COCO test-dev,2017-11,CPN+,84.6,97.02,0.3,0.0,87.2,0.97,ito:ITO_00101,Vision process,ARL
3,1,Keypoint Detection,COCO test-dev,2018-04,Simple Base+*,87.2,100.0,2.6,0.03,87.2,1.0,ito:ITO_00101,Vision process,ARL
4,1,Keypoint Detection,COCO test-challenge,2017-01,G-RMI*,74.5,89.54,74.5,0.9,83.2,0.85,ito:ITO_00101,Vision process,ARL
5,1,Keypoint Detection,COCO test-challenge,2017-03,Mask R-CNN*,76.8,92.31,2.3,0.03,83.2,0.88,ito:ITO_00101,Vision process,ARL
6,1,Keypoint Detection,COCO test-challenge,2017-11,CPN+,78.1,93.87,1.3,0.02,83.2,0.9,ito:ITO_00101,Vision process,ARL
7,1,Keypoint Detection,COCO test-challenge,2018-04,Simple Base+*,82.9,99.64,4.8,0.06,83.2,0.95,ito:ITO_00101,Vision process,ARL
8,1,Keypoint Detection,COCO test-challenge,2019-01,MSPN+*,83.2,100.0,0.3,0.0,83.2,0.95,ito:ITO_00101,Vision process,ARL
0,1,Outdoor Light Source Estimation,SUN360,2016-11,ÇuNNy,1.25,100.0,1.25,1.0,1.25,1.0,ito:ITO_00101,Vision process,Median\\ Relighting\\ Error
0,1,Pose Tracking,Multi-Person PoseTrack,2016-11,PoseTrack,55.7,100.0,55.7,1.0,55.7,0.65,ito:ITO_00101,Vision process,MOTP
1,1,3D Multi-Object Tracking,KITTI,2018-02,BeyondPixels,85.73,100.0,85.73,1.0,85.73,1.0,ito:ITO_00101,Vision process,MOTP
0,1,Instance Segmentation,Cityscapes test,2016-11,Deep Watershed Transform,19.4,49.74,19.4,0.5,39.0,0.33,ito:ITO_00101,Vision process,Average\\ Precision
1,1,Instance Segmentation,Cityscapes test,2017-04,Dynamically Instantiated Network,23.4,60.0,4.0,0.1,39.0,0.4,ito:ITO_00101,Vision process,Average\\ Precision
2,1,Instance Segmentation,Cityscapes test,2019-06,Learnable Margin,27.6,70.77,4.2,0.11,39.0,0.47,ito:ITO_00101,Vision process,Average\\ Precision
3,1,Instance Segmentation,Cityscapes test,2019-06,Instance Segmentation by Jointly Optimizing Spatial Embeddings and Clustering Bandwidth,27.7,71.03,0.1,0.0,39.0,0.47,ito:ITO_00101,Vision process,Average\\ Precision
4,1,Instance Segmentation,Cityscapes test,2019-11,Panoptic-DeepLab [Mapillary Vistas],39.0,100.0,11.3,0.29,39.0,0.66,ito:ITO_00101,Vision process,Average\\ Precision
5,1,Object Detection,iSAID,2017-03,Mask-RCNN+,37.18,89.25,37.18,0.89,41.66,0.63,ito:ITO_00101,Vision process,Average\\ Precision
6,1,Object Detection,iSAID,2018-03,PANet,41.66,100.0,4.5,0.11,41.66,0.71,ito:ITO_00101,Vision process,Average\\ Precision
7,1,Long-tail Learning,EGTEA,2017-08,Focal loss (3D- ResNeXt101),59.09,100.0,59.09,1.0,59.09,1.0,ito:ITO_00101,Vision process,Average\\ Precision
8,1,Instance Segmentation,iSAID,2018-03,PANet,34.17,100.0,34.17,1.0,34.17,0.58,ito:ITO_00101,Vision process,Average\\ Precision
9,1,Anomaly Detection,Thyroid,2019-11,DevNet,0.274,100.0,0.274,1.0,0.274,0.0,ito:ITO_00101,Vision process,Average\\ Precision
10,1,Anomaly Detection,Census,2019-11,DevNet,0.321,100.0,0.321,1.0,0.321,0.01,ito:ITO_00101,Vision process,Average\\ Precision
0,1,Keypoint Detection,COCO,2016-11,Part Affinity Fields,60.5,78.27,60.5,0.78,77.3,0.78,ito:ITO_00101,Vision process,Validation\\ AP
1,1,Keypoint Detection,COCO,2017-03,Mask R-CNN,69.2,89.52,8.7,0.11,77.3,0.9,ito:ITO_00101,Vision process,Validation\\ AP
2,1,Keypoint Detection,COCO,2018-04,ResNet-50,72.2,93.4,3.0,0.04,77.3,0.93,ito:ITO_00101,Vision process,Validation\\ AP
3,1,Keypoint Detection,COCO,2018-12,PoseFix,77.3,100.0,5.1,0.07,77.3,1.0,ito:ITO_00101,Vision process,Validation\\ AP
4,1,Multi-Person Pose Estimation,COCO,2018-12,PoseFix,77.3,100.0,77.3,1.0,77.3,1.0,ito:ITO_00101,Vision process,Validation\\ AP
0,1,Visual Object Tracking,VOT2017/18,2016-11,CSRDCF,0.263,58.97,0.263,0.59,0.446,0.56,ito:ITO_00101,Vision process,Expected\\ Average\\ Overlap\\ \\(EAO\\)
1,1,Visual Object Tracking,VOT2017/18,2016-11,ECO,0.28,62.78,0.0,0.0,0.446,0.6,ito:ITO_00101,Vision process,Expected\\ Average\\ Overlap\\ \\(EAO\\)
2,1,Visual Object Tracking,VOT2017/18,2017-06,LSART,0.323,72.42,0.0,0.0,0.446,0.69,ito:ITO_00101,Vision process,Expected\\ Average\\ Overlap\\ \\(EAO\\)
3,1,Visual Object Tracking,VOT2017/18,2018-03,STRCF,0.345,77.35,0.0,0.0,0.446,0.74,ito:ITO_00101,Vision process,Expected\\ Average\\ Overlap\\ \\(EAO\\)
4,1,Visual Object Tracking,VOT2017/18,2018-06,SiamRPN,0.383,85.87,0.0,0.0,0.446,0.82,ito:ITO_00101,Vision process,Expected\\ Average\\ Overlap\\ \\(EAO\\)
5,1,Visual Object Tracking,VOT2017/18,2018-12,SiamRPN++,0.414,92.83,0.0,0.0,0.446,0.89,ito:ITO_00101,Vision process,Expected\\ Average\\ Overlap\\ \\(EAO\\)
6,1,Visual Object Tracking,VOT2017/18,2019-07,SiamMask_E,0.446,100.0,0.0,0.0,0.446,0.96,ito:ITO_00101,Vision process,Expected\\ Average\\ Overlap\\ \\(EAO\\)
7,1,Visual Object Tracking,VOT2016,2017-04,CFCF,0.3903,83.76,0.3903,0.84,0.466,0.84,ito:ITO_00101,Vision process,Expected\\ Average\\ Overlap\\ \\(EAO\\)
8,1,Visual Object Tracking,VOT2016,2019-07,SiamMask_E,0.466,100.0,0.1,0.21,0.466,1.0,ito:ITO_00101,Vision process,Expected\\ Average\\ Overlap\\ \\(EAO\\)
9,1,Visual Object Tracking,VOT2017,2019-01,SiamRPN+,0.3,75.57,0.3,0.76,0.397,0.64,ito:ITO_00101,Vision process,Expected\\ Average\\ Overlap\\ \\(EAO\\)
10,1,Visual Object Tracking,VOT2017,2019-07,GFS-DCF,0.397,100.0,0.1,0.25,0.397,0.85,ito:ITO_00101,Vision process,Expected\\ Average\\ Overlap\\ \\(EAO\\)
11,1,Visual Object Tracking,VOT2019,2019-07,SiamMask_E,0.309,100.0,0.309,1.0,0.309,0.66,ito:ITO_00101,Vision process,Expected\\ Average\\ Overlap\\ \\(EAO\\)
0,1,3D Human Pose Estimation,Leeds Sports Pose,2016-11,EDM,4.77,100.0,4.77,1.0,4.77,1.0,ito:ITO_00101,Vision process,Reprojection\\ Error\\ \\(CPM\\)
0,1,Saliency Prediction,2010 i2b2/VA,2016-11,as,32.0,100.0,32,1.0,32,1.0,ito:ITO_00101,Vision process,1\\ in\\ 10\\ R\\-at\\-1
1,1,3D Shape Analysis,2017_test set,2018-05,x,10.0,100.0,10,1.0,10,0.31,ito:ITO_00101,Vision process,1\\ in\\ 10\\ R\\-at\\-1
0,1,Visual Question Answering,VQA v2 test-std,2016-12,Prior,25.98,35.83,25.98,0.36,72.5,0.36,ito:ITO_00101,Vision process,overall
1,1,Visual Question Answering,VQA v2 test-std,2016-12,"MCB [11, 12]",62.27,85.89,36.3,0.5,72.5,0.86,ito:ITO_00101,Vision process,overall
2,1,Visual Question Answering,VQA v2 test-std,2017-05,MUTAN,67.4,92.97,5.1,0.07,72.5,0.93,ito:ITO_00101,Vision process,overall
3,1,Visual Question Answering,VQA v2 test-std,2017-07,Up-Down,70.34,97.02,2.9,0.04,72.5,0.97,ito:ITO_00101,Vision process,overall
4,1,Visual Question Answering,VQA v2 test-std,2018-05,BAN+Glove+Counter,70.4,97.1,0.1,0.0,72.5,0.97,ito:ITO_00101,Vision process,overall
5,1,Visual Question Answering,VQA v2 test-std,2019-06,MCANed-6,70.9,97.79,0.5,0.01,72.5,0.98,ito:ITO_00101,Vision process,overall
6,1,Visual Question Answering,VQA v2 test-std,2019-08,VisualBERT,71.0,97.93,0.1,0.0,72.5,0.98,ito:ITO_00101,Vision process,overall
7,1,Visual Question Answering,VQA v2 test-std,2019-08,LXMERT,72.5,100.0,1.5,0.02,72.5,1.0,ito:ITO_00101,Vision process,overall
8,1,Visual Question Answering,VizWiz 2018,2019-04,Pythia v0.3 ,54.72,98.77,54.72,0.99,55.4,0.75,ito:ITO_00101,Vision process,overall
9,1,Visual Question Answering,VizWiz 2018,2019-08,"LXR955, No Ensemble",55.4,100.0,0.7,0.01,55.4,0.76,ito:ITO_00101,Vision process,overall
0,1,3D Part Segmentation,ShapeNet-Part,2016-12,PointNet,80.4,94.48,80.4,0.94,85.1,0.94,ito:ITO_00101,Vision process,Class\\ Average\\ IoU
1,1,3D Part Segmentation,ShapeNet-Part,2016-12,SSCNN,82.0,96.36,1.6,0.02,85.1,0.96,ito:ITO_00101,Vision process,Class\\ Average\\ IoU
2,1,3D Part Segmentation,ShapeNet-Part,2017-11,SGPN,82.8,97.3,0.8,0.01,85.1,0.97,ito:ITO_00101,Vision process,Class\\ Average\\ IoU
3,1,3D Part Segmentation,ShapeNet-Part,2018-01,PointCNN,84.6,99.41,1.8,0.02,85.1,0.99,ito:ITO_00101,Vision process,Class\\ Average\\ IoU
4,1,3D Part Segmentation,ShapeNet-Part,2019-04,KPConv,85.1,100.0,0.5,0.01,85.1,1.0,ito:ITO_00101,Vision process,Class\\ Average\\ IoU
0,1,Semantic Segmentation,S3DIS Area5,2016-12,PointNet,49.0,67.31,49.0,0.67,72.8,0.56,ito:ITO_00101,Vision process,mAcc
1,1,Semantic Segmentation,S3DIS Area5,2017-10,SegCloud,57.4,78.85,8.4,0.12,72.8,0.66,ito:ITO_00101,Vision process,mAcc
2,1,Semantic Segmentation,S3DIS Area5,2017-11,SPG,66.5,91.35,9.1,0.12,72.8,0.76,ito:ITO_00101,Vision process,mAcc
3,1,Semantic Segmentation,S3DIS Area5,2019-04,MinkowskiNet,71.7,98.49,5.2,0.07,72.8,0.82,ito:ITO_00101,Vision process,mAcc
4,1,Semantic Segmentation,S3DIS Area5,2019-04,KPConv,72.8,100.0,1.1,0.02,72.8,0.84,ito:ITO_00101,Vision process,mAcc
5,1,Semantic Segmentation,S3DIS,2016-12,PointNet,66.2,80.73,66.2,0.81,82.0,0.76,ito:ITO_00101,Vision process,mAcc
6,1,Semantic Segmentation,S3DIS,2017-11,SPG,73.0,89.02,6.8,0.08,82.0,0.84,ito:ITO_00101,Vision process,mAcc
7,1,Semantic Segmentation,S3DIS,2018-12,PointCNN,75.6,92.2,2.6,0.03,82.0,0.87,ito:ITO_00101,Vision process,mAcc
8,1,Semantic Segmentation,S3DIS,2019-04,KPConv,79.1,96.46,3.5,0.04,82.0,0.91,ito:ITO_00101,Vision process,mAcc
9,1,Semantic Segmentation,S3DIS,2019-11,RandLA-Net,82.0,100.0,2.9,0.04,82.0,0.94,ito:ITO_00101,Vision process,mAcc
10,1,3D Instance Segmentation,S3DIS,2018-01,PointCNN,75.61,86.81,75.61,0.87,87.1,0.87,ito:ITO_00101,Vision process,mAcc
11,1,3D Instance Segmentation,S3DIS,2019-07,PVCNN++ (1xC) volumetric,87.1,100.0,11.5,0.13,87.1,1.0,ito:ITO_00101,Vision process,mAcc
12,1,3D Semantic Segmentation,S3DIS,2019-07,PVCNN++ (1xC) volumetric,87.12,100.0,87.12,1.0,87.12,1.0,ito:ITO_00101,Vision process,mAcc
0,1,Semantic Segmentation,S3DIS,2016-12,PointNet,78.5,88.4,78.5,0.88,88.8,0.83,ito:ITO_00101,Vision process,oAcc
1,1,Semantic Segmentation,S3DIS,2017-11,SPG,85.5,96.28,7.0,0.08,88.8,0.9,ito:ITO_00101,Vision process,oAcc
2,1,Semantic Segmentation,S3DIS,2018-12,PointCNN,88.1,99.21,2.6,0.03,88.8,0.93,ito:ITO_00101,Vision process,oAcc
3,1,Semantic Segmentation,S3DIS,2019-04,ConvPoint,88.8,100.0,0.7,0.01,88.8,0.94,ito:ITO_00101,Vision process,oAcc
4,1,Semantic Segmentation,S3DIS Area5,2017-11,SPG,86.38,100.0,86.38,1.0,86.38,0.91,ito:ITO_00101,Vision process,oAcc
5,1,Semantic Segmentation,Semantic3D,2017-11,SPG,92.9,98.0,92.9,0.98,94.8,0.98,ito:ITO_00101,Vision process,oAcc
6,1,Semantic Segmentation,Semantic3D,2019-11,RandLA-Net,94.8,100.0,1.9,0.02,94.8,1.0,ito:ITO_00101,Vision process,oAcc
0,1,3D Point Cloud Classification,ModelNet40,2016-12,PointNet,86.0,100.0,86,1.0,86,1.0,ito:ITO_00101,Vision process,Mean\\ Accuracy
1,1,Medical Object Detection,Barrett’s Esophagus,2017-03,Sliding Window,74.0,91.36,74,0.91,81,0.86,ito:ITO_00101,Vision process,Mean\\ Accuracy
2,1,Medical Object Detection,Barrett’s Esophagus,2018-11,Attention-based model,81.0,100.0,7,0.09,81,0.94,ito:ITO_00101,Vision process,Mean\\ Accuracy
0,1,Semantic Segmentation,ADE20K,2016-12,PSPNet,0.5538,0.98,0.5538,0.01,56.41,0.01,ito:ITO_00101,Vision process,Test\\ Score
1,1,Semantic Segmentation,ADE20K,2016-12,PSPNet,55.38,98.17,54.8,0.97,56.41,0.98,ito:ITO_00101,Vision process,Test\\ Score
2,1,Semantic Segmentation,ADE20K,2018-03,EncNet,55.67,98.69,0.3,0.01,56.41,0.99,ito:ITO_00101,Vision process,Test\\ Score
3,1,Semantic Segmentation,ADE20K,2019-03,EncNet + JPU,55.84,98.99,0.2,0.0,56.41,0.99,ito:ITO_00101,Vision process,Test\\ Score
4,1,Semantic Segmentation,ADE20K,2019-11,LaU-regression-loss,56.32,99.84,0.5,0.01,56.41,1.0,ito:ITO_00101,Vision process,Test\\ Score
5,1,Semantic Segmentation,ADE20K,2019-11,LaU-offset-loss,56.41,100.0,0.1,0.0,56.41,1.0,ito:ITO_00101,Vision process,Test\\ Score
0,1,Real-Time Semantic Segmentation,NYU Depth v2,2016-12,PSPNet101,72.0,100.0,72,1.0,72,1.0,ito:ITO_00101,Vision process,Speed\\(ms/f\\)
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,73.5,85.56,73.5,0.86,85.9,0.86,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.3
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,80.8,94.06,7.3,0.08,85.9,0.94,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.3
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,85.9,100.0,5.1,0.06,85.9,1.0,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.3
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,80.6,89.76,80.6,0.9,89.8,0.9,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.4
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,87.5,97.44,6.9,0.08,89.8,0.97,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.4
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,89.8,100.0,2.3,0.03,89.8,1.0,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.4
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,45.2,77.4,45.2,0.77,58.4,0.77,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.1
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,58.4,100.0,13.2,0.23,58.4,1.0,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.1
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,85.5,92.53,85.5,0.93,92.4,0.93,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.5
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,91.4,98.92,5.9,0.06,92.4,0.99,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.5
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,92.4,100.0,1.0,0.01,92.4,1.0,ito:ITO_00101,Vision process,PCK\\-at\\-0\\.5
0,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2016-12,FCNs in the wild,20.2,37.9,20.2,0.38,53.3,0.38,ito:ITO_00101,Vision process,mIoU\\ \\(13\\ classes\\)
1,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2017-07,CDA,29.0,54.41,8.8,0.17,53.3,0.54,ito:ITO_00101,Vision process,mIoU\\ \\(13\\ classes\\)
2,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2018-11,ADVENT,48.0,90.06,19.0,0.36,53.3,0.9,ito:ITO_00101,Vision process,mIoU\\ \\(13\\ classes\\)
3,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-03,SWD,48.1,90.24,0.1,0.0,53.3,0.9,ito:ITO_00101,Vision process,mIoU\\ \\(13\\ classes\\)
4,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-04,DADA (ResNet-101),49.8,93.43,1.7,0.03,53.3,0.93,ito:ITO_00101,Vision process,mIoU\\ \\(13\\ classes\\)
5,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-04,Bidirectional Learning (ResNet-101),51.4,96.44,1.6,0.03,53.3,0.96,ito:ITO_00101,Vision process,mIoU\\ \\(13\\ classes\\)
6,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-08,PyCDA (ResNet-101),53.3,100.0,1.9,0.04,53.3,1.0,ito:ITO_00101,Vision process,mIoU\\ \\(13\\ classes\\)
0,1,Rotated MNIST,Rotated MNIST,2016-12,H-net,1.69,100.0,1.69,1.0,1.69,1.0,ito:ITO_00101,Vision process,Test\\ error
1,1,Grasp Generation,Grasp Generation,2016-12,H-net,1.69,100.0,1.69,1.0,1.69,1.0,ito:ITO_00101,Vision process,Test\\ error
0,1,3D Face Reconstruction,Florence,2016-12,3DMM-CNN,1.93,100.0,1.93,1.0,1.93,0.02,ito:ITO_00101,Vision process,Average\\ 3D\\ Error
1,1,Hand Pose Estimation,MSRA Hands,2017-02,REN,9.8,100.0,9.8,1.0,9.8,0.09,ito:ITO_00101,Vision process,Average\\ 3D\\ Error
2,1,Hand Pose Estimation,ICVL Hands,2017-02,REN,7.5,7.14,7.5,0.07,105.06,0.07,ito:ITO_00101,Vision process,Average\\ 3D\\ Error
3,1,Hand Pose Estimation,ICVL Hands,2017-08,DeepPrior++,8.1,7.71,0.6,0.01,105.06,0.08,ito:ITO_00101,Vision process,Average\\ 3D\\ Error
4,1,Hand Pose Estimation,ICVL Hands,2019-08,A2J (Ours),105.06,100.0,97.0,0.92,105.06,1.0,ito:ITO_00101,Vision process,Average\\ 3D\\ Error
5,1,Hand Pose Estimation,NYU Hands,2017-02,REN,12.7,12.09,12.7,0.12,105.06,0.12,ito:ITO_00101,Vision process,Average\\ 3D\\ Error
6,1,Hand Pose Estimation,NYU Hands,2017-07,REN,15.6,14.85,2.9,0.03,105.06,0.15,ito:ITO_00101,Vision process,Average\\ 3D\\ Error
7,1,Hand Pose Estimation,NYU Hands,2019-08,A2J (Ours),105.06,100.0,89.5,0.85,105.06,1.0,ito:ITO_00101,Vision process,Average\\ 3D\\ Error
8,1,Hand Pose Estimation,HANDS 2017,2017-08,THU VCLab,11.7,98.24,11.7,0.98,11.91,0.11,ito:ITO_00101,Vision process,Average\\ 3D\\ Error
9,1,Hand Pose Estimation,HANDS 2017,2017-12,Vanora,11.91,100.0,0.2,0.02,11.91,0.11,ito:ITO_00101,Vision process,Average\\ 3D\\ Error
10,1,Hand Pose Estimation,HANDS 2019,2020-01,HandAugment,13.66,100.0,13.66,1.0,13.66,0.13,ito:ITO_00101,Vision process,Average\\ 3D\\ Error
0,1,Weakly-supervised 3D Human Pose Estimation,Human3.6M,2017-01,Tome et al.,1.0,50.0,1,0.5,2,0.5,ito:ITO_00101,Vision process,Number\\ of\\ Views
1,1,Weakly-supervised 3D Human Pose Estimation,Human3.6M,2019-03,Kocabas et al.,2.0,100.0,1,0.5,2,1.0,ito:ITO_00101,Vision process,Number\\ of\\ Views
0,1,Weakly-supervised 3D Human Pose Estimation,Human3.6M,2017-01,Tome et al.,1.0,0.41,1,0.0,243,0.0,ito:ITO_00101,Vision process,Number\\ of\\ Frames\\ Per\\ View
1,1,Weakly-supervised 3D Human Pose Estimation,Human3.6M,2018-11,Pavllo et al.,243.0,100.0,242,1.0,243,1.0,ito:ITO_00101,Vision process,Number\\ of\\ Frames\\ Per\\ View
0,1,Optical Character Recognition,FSNS,2017-02,STREET,27.54,100.0,27.54,1.0,27.54,1.0,ito:ITO_00101,Vision process,Sequence\\ error
0,1,Pedestrian Detection,CityPersons,2017-02,FRCNN+Seg,22.6,88.28,22.6,0.88,25.6,0.88,ito:ITO_00101,Vision process,Small\\ MR\\^\\-2
1,1,Pedestrian Detection,CityPersons,2017-02,FRCNN,25.6,100.0,3.0,0.12,25.6,1.0,ito:ITO_00101,Vision process,Small\\ MR\\^\\-2
0,1,Pedestrian Detection,CityPersons,2017-02,FRCNN+Seg,6.7,93.06,6.7,0.93,7.2,0.93,ito:ITO_00101,Vision process,Medium\\ MR\\^\\-2
1,1,Pedestrian Detection,CityPersons,2017-02,FRCNN,7.2,100.0,0.5,0.07,7.2,1.0,ito:ITO_00101,Vision process,Medium\\ MR\\^\\-2
0,1,Pedestrian Detection,CityPersons,2017-02,FRCNN+Seg,8.0,100.0,8.0,1.0,8.0,1.0,ito:ITO_00101,Vision process,Large\\ MR\\^\\-2
0,1,Pedestrian Detection,CityPersons,2017-02,FRCNN+Seg,14.8,95.48,14.8,0.95,15.5,0.95,ito:ITO_00101,Vision process,Reasonable\\ MR\\^\\-2
1,1,Pedestrian Detection,CityPersons,2017-02,FRCNN,15.4,99.35,0.6,0.04,15.5,0.99,ito:ITO_00101,Vision process,Reasonable\\ MR\\^\\-2
2,1,Pedestrian Detection,CityPersons,2018-07,TLL,15.5,100.0,0.1,0.01,15.5,1.0,ito:ITO_00101,Vision process,Reasonable\\ MR\\^\\-2
0,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2017-03,UNIT,0.023,13.14,0.023,0.13,0.175,0.13,ito:ITO_00101,Vision process,Diversity
1,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2017-11,BicycleGAN,0.14,80.0,0.1,0.57,0.175,0.8,ito:ITO_00101,Vision process,Diversity
2,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2018-04,MUNIT,0.175,100.0,0.0,0.0,0.175,1.0,ito:ITO_00101,Vision process,Diversity
3,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,2017-03,UNIT,0.011,10.09,0.011,0.1,0.109,0.06,ito:ITO_00101,Vision process,Diversity
4,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,2017-11,BicycleGAN,0.104,95.41,0.1,0.92,0.109,0.59,ito:ITO_00101,Vision process,Diversity
5,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,2018-04,MUNIT,0.109,100.0,0.0,0.0,0.109,0.62,ito:ITO_00101,Vision process,Diversity
0,1,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,2017-03,UNIT,0.826,78.67,0.826,0.79,1.05,0.01,ito:ITO_00101,Vision process,IS
1,1,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,2018-04,MUNIT,1.05,100.0,0.2,0.19,1.05,0.01,ito:ITO_00101,Vision process,IS
2,1,Pose Transfer,Deep-Fashion,2017-05,PG Squared,3.09,89.85,3.09,0.9,3.439,0.02,ito:ITO_00101,Vision process,IS
3,1,Pose Transfer,Deep-Fashion,2017-12,Disentangled PG,3.228,93.86,0.1,0.03,3.439,0.03,ito:ITO_00101,Vision process,IS
4,1,Pose Transfer,Deep-Fashion,2017-12,Deformable GAN,3.439,100.0,0.2,0.06,3.439,0.03,ito:ITO_00101,Vision process,IS
5,1,Gesture-to-Gesture Translation,Senz3D,2017-05,PG2,3.3699,98.8,3.3699,0.99,3.4107,0.03,ito:ITO_00101,Vision process,IS
6,1,Gesture-to-Gesture Translation,Senz3D,2017-12,DPIG,3.3874,99.32,0.0,0.0,3.4107,0.03,ito:ITO_00101,Vision process,IS
7,1,Gesture-to-Gesture Translation,Senz3D,2018-08,GestureGAN,3.4107,100.0,0.0,0.0,3.4107,0.03,ito:ITO_00101,Vision process,IS
8,1,Gesture-to-Gesture Translation,NTU Hand Digit,2017-05,PG2,2.4152,94.6,2.4152,0.95,2.5532,0.02,ito:ITO_00101,Vision process,IS
9,1,Gesture-to-Gesture Translation,NTU Hand Digit,2017-07,SAMG,2.4919,97.6,0.1,0.04,2.5532,0.02,ito:ITO_00101,Vision process,IS
10,1,Gesture-to-Gesture Translation,NTU Hand Digit,2018-08,GestureGAN,2.5532,100.0,0.1,0.04,2.5532,0.02,ito:ITO_00101,Vision process,IS
11,1,Image Generation,ImageNet 128x128,2018-09,BigGAN-deep,124.5,100.0,124.5,1.0,124.5,1.0,ito:ITO_00101,Vision process,IS
12,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,3.323,100.0,3.323,1.0,3.323,0.03,ito:ITO_00101,Vision process,IS
0,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2017-03,UNIT,37.3,72.85,37.3,0.73,51.2,0.66,ito:ITO_00101,Vision process,Quality
1,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2017-03,CycleGAN,40.8,79.69,3.5,0.07,51.2,0.72,ito:ITO_00101,Vision process,Quality
2,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2017-11,BicycleGAN,51.2,100.0,10.4,0.2,51.2,0.9,ito:ITO_00101,Vision process,Quality
3,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,2017-03,UNIT,37.4,65.96,37.4,0.66,56.7,0.66,ito:ITO_00101,Vision process,Quality
4,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,2017-11,BicycleGAN,56.7,100.0,19.3,0.34,56.7,1.0,ito:ITO_00101,Vision process,Quality
0,1,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,2017-03,UNIT,0.115,11.07,0.115,0.11,1.039,0.11,ito:ITO_00101,Vision process,CIS
1,1,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,2018-04,MUNIT,1.039,100.0,0.9,0.87,1.039,1.0,ito:ITO_00101,Vision process,CIS
0,1,Temporal Action Localization,THUMOS’14,2017-03,CDC,7.9,37.98,7.9,0.38,20.8,0.33,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.7
1,1,Temporal Action Localization,THUMOS’14,2017-05,CBR-TS,9.9,47.6,2.0,0.1,20.8,0.42,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.7
2,1,Temporal Action Localization,THUMOS’14,2018-04,TAL-Net,20.8,100.0,10.9,0.52,20.8,0.88,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.7
3,1,Temporal Action Localization,ActivityNet-1.3,2019-08,3C-Net,23.7,100.0,23.7,1.0,23.7,1.0,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.7
4,1,Temporal Action Localization,ActivityNet-1.2,2020-01,DeepMetricLearner,16.3,100.0,16.3,1.0,16.3,0.69,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.7
0,1,Temporal Action Localization,THUMOS’14,2017-03,CDC,13.1,38.76,13.1,0.39,33.8,0.39,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.6
1,1,Temporal Action Localization,THUMOS’14,2017-05,CBR-TS,19.1,56.51,6.0,0.18,33.8,0.57,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.6
2,1,Temporal Action Localization,THUMOS’14,2018-04,TAL-Net,33.8,100.0,14.7,0.43,33.8,1.0,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.6
0,1,Image Compression,ImageNet32,2017-03,MS-PixelCNN,3.95,61.53,3.95,0.62,6.42,0.62,ito:ITO_00101,Vision process,bpsp
1,1,Image Compression,ImageNet32,2018-11,L3C,4.76,74.14,0.8,0.12,6.42,0.74,ito:ITO_00101,Vision process,bpsp
2,1,Image Compression,ImageNet32,2018-11,JPEG2000,6.35,98.91,1.6,0.25,6.42,0.99,ito:ITO_00101,Vision process,bpsp
3,1,Image Compression,ImageNet32,2018-11,PNG,6.42,100.0,0.1,0.02,6.42,1.0,ito:ITO_00101,Vision process,bpsp
0,1,Real-Time Object Detection,COCO,2017-03,Mask R-CNN X-152-32x8d,333.0,100.0,333.0,1.0,333.0,1.0,ito:ITO_00101,Vision process,inference\\ time\\ \\(ms\\)
0,1,Real-Time Object Detection,COCO minival,2017-03,Mask R-CNN X-152-32x8d,45.2,100.0,45.2,1.0,45.2,1.0,ito:ITO_00101,Vision process,APbb75
0,1,Panoptic Segmentation,Cityscapes val,2017-03,Mask R-CNN+COCO,54.0,85.44,54.0,0.85,63.2,0.85,ito:ITO_00101,Vision process,PQth
1,1,Panoptic Segmentation,Cityscapes val,2018-12,"TASCNet (ResNet-50, multi-scale)",56.1,88.77,2.1,0.03,63.2,0.89,ito:ITO_00101,Vision process,PQth
2,1,Panoptic Segmentation,Cityscapes val,2019-01,"UPSNet (ResNet-101, multiscale)",57.6,91.14,1.5,0.02,63.2,0.91,ito:ITO_00101,Vision process,PQth
3,1,Panoptic Segmentation,Cityscapes val,2019-09,AdaptIS (ResNeXt-101),58.7,92.88,1.1,0.02,63.2,0.93,ito:ITO_00101,Vision process,PQth
4,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS,63.2,100.0,4.5,0.07,63.2,1.0,ito:ITO_00101,Vision process,PQth
5,1,Panoptic Segmentation,COCO test-dev,2018-09,JSIS-Net (ResNet-50),29.6,53.05,29.6,0.53,55.8,0.47,ito:ITO_00101,Vision process,PQth
6,1,Panoptic Segmentation,COCO test-dev,2018-12,AUNet (ResNeXt-152-FPN),55.8,100.0,26.2,0.47,55.8,0.88,ito:ITO_00101,Vision process,PQth
0,1,Multi-Person Pose Estimation,CrowdPose,2017-03,Mask R-CNN,60.3,89.2,60.3,0.89,67.6,0.71,ito:ITO_00101,Vision process,mAP\\ at\\-0\\.5:0\\.95
1,1,Multi-Person Pose Estimation,CrowdPose,2018-12,Joint-candidate SPPE +,66.0,97.63,5.7,0.08,67.6,0.78,ito:ITO_00101,Vision process,mAP\\ at\\-0\\.5:0\\.95
2,1,Multi-Person Pose Estimation,CrowdPose,2019-08,HigherHRNet(HR-Net-48),67.6,100.0,1.6,0.02,67.6,0.8,ito:ITO_00101,Vision process,mAP\\ at\\-0\\.5:0\\.95
3,1,Traffic Sign Recognition,DFG traffic-sign dataset,2019-04,Mask R-CNN with adaptations for traffic sings and augmentations (ResNet50),84.4,100.0,84.4,1.0,84.4,1.0,ito:ITO_00101,Vision process,mAP\\ at\\-0\\.5:0\\.95
0,1,Face Alignment,LS3D-W Balanced,2017-03,3D-FAN,72.3,100.0,72.3,1.0,72.3,1.0,ito:ITO_00101,Vision process,AUC0\\.07
0,1,Person Re-Identification,Market-1501,2017-03,LuNet (RK),91.89,92.91,91.89,0.93,98.9,0.92,ito:ITO_00101,Vision process,Rank\\-5
1,1,Person Re-Identification,Market-1501,2017-03,LuNet,92.34,93.37,0.5,0.01,98.9,0.93,ito:ITO_00101,Vision process,Rank\\-5
2,1,Person Re-Identification,Market-1501,2017-03,TriNet (RK),93.38,94.42,1.0,0.01,98.9,0.94,ito:ITO_00101,Vision process,Rank\\-5
3,1,Person Re-Identification,Market-1501,2017-03,TriNet,94.21,95.26,0.8,0.01,98.9,0.95,ito:ITO_00101,Vision process,Rank\\-5
4,1,Person Re-Identification,Market-1501,2018-12,"st-ReID(RE, RK)",98.9,100.0,4.7,0.05,98.9,0.99,ito:ITO_00101,Vision process,Rank\\-5
5,1,Person Re-Identification,MARS,2017-03,LuNet (RK),88.74,94.71,88.74,0.95,93.7,0.89,ito:ITO_00101,Vision process,Rank\\-5
6,1,Person Re-Identification,MARS,2017-03,TriNet,91.36,97.5,2.6,0.03,93.7,0.92,ito:ITO_00101,Vision process,Rank\\-5
7,1,Person Re-Identification,MARS,2019-08,TKP,93.7,100.0,2.3,0.02,93.7,0.94,ito:ITO_00101,Vision process,Rank\\-5
8,1,Person Re-Identification,CUHK03,2017-03,TriNet,99.01,99.41,99.01,0.99,99.6,0.99,ito:ITO_00101,Vision process,Rank\\-5
9,1,Person Re-Identification,CUHK03,2017-11,AlignedReID (RK),99.6,100.0,0.6,0.01,99.6,1.0,ito:ITO_00101,Vision process,Rank\\-5
10,1,Unsupervised Person Re-Identification,DukeMTMC-reID,2017-05,PUL,43.4,51.67,43.4,0.52,84.0,0.44,ito:ITO_00101,Vision process,Rank\\-5
11,1,Unsupervised Person Re-Identification,DukeMTMC-reID,2017-11,SPGAN+LMP,62.3,74.17,18.9,0.22,84.0,0.63,ito:ITO_00101,Vision process,Rank\\-5
12,1,Unsupervised Person Re-Identification,DukeMTMC-reID,2018-11,Self-Similarity Grouping (one shot),84.0,100.0,21.7,0.26,84.0,0.84,ito:ITO_00101,Vision process,Rank\\-5
13,1,Unsupervised Person Re-Identification,Market-1501,2017-05,PUL,60.7,63.76,60.7,0.64,95.2,0.61,ito:ITO_00101,Vision process,Rank\\-5
14,1,Unsupervised Person Re-Identification,Market-1501,2017-11,SPGAN+LMP,75.8,79.62,15.1,0.16,95.2,0.76,ito:ITO_00101,Vision process,Rank\\-5
15,1,Unsupervised Person Re-Identification,Market-1501,2018-11,Self-Similarity Grouping (one shot),95.2,100.0,19.4,0.2,95.2,0.96,ito:ITO_00101,Vision process,Rank\\-5
16,1,Person Re-Identification,PRID2011,2017-09,DGM+MLAPG+,92.5,93.15,92.5,0.93,99.3,0.93,ito:ITO_00101,Vision process,Rank\\-5
17,1,Person Re-Identification,PRID2011,2017-10,SMP*,95.6,96.27,3.1,0.03,99.3,0.96,ito:ITO_00101,Vision process,Rank\\-5
18,1,Person Re-Identification,PRID2011,2018-06,Snippet (Supervised),99.3,100.0,3.7,0.04,99.3,1.0,ito:ITO_00101,Vision process,Rank\\-5
19,1,Unsupervised Person Re-Identification,MSMT17->DukeMTMC-reID,2017-11,SPGAN,62.3,74.08,62.3,0.74,84.1,0.63,ito:ITO_00101,Vision process,Rank\\-5
20,1,Unsupervised Person Re-Identification,MSMT17->DukeMTMC-reID,2019-10,OSNet-AIN,84.1,100.0,21.8,0.26,84.1,0.84,ito:ITO_00101,Vision process,Rank\\-5
21,1,Person Re-Identification,UAV-Human,2017-11,PCB,83.9,99.43,83.9,0.99,84.38,0.84,ito:ITO_00101,Vision process,Rank\\-5
22,1,Person Re-Identification,UAV-Human,2019-03,Tricks,84.38,100.0,0.5,0.01,84.38,0.85,ito:ITO_00101,Vision process,Rank\\-5
23,1,Person Re-Identification,DukeTracklet,2018-09,TAUDL,42.0,66.88,42.0,0.67,62.8,0.42,ito:ITO_00101,Vision process,Rank\\-5
24,1,Person Re-Identification,DukeTracklet,2019-03,UTAL,62.8,100.0,20.8,0.33,62.8,0.63,ito:ITO_00101,Vision process,Rank\\-5
25,1,Person Re-Identification,iLIDS-VID,2019-03,UTAL,59.0,74.31,59.0,0.74,79.4,0.59,ito:ITO_00101,Vision process,Rank\\-5
26,1,Person Re-Identification,iLIDS-VID,2019-08,TKP,79.4,100.0,20.4,0.26,79.4,0.8,ito:ITO_00101,Vision process,Rank\\-5
27,1,Unsupervised Person Re-Identification,DukeMTMC-reID->Market-1501,2019-04,ECN,87.6,100.0,87.6,1.0,87.6,0.88,ito:ITO_00101,Vision process,Rank\\-5
28,1,Unsupervised Person Re-Identification,DukeMTMC-reID->MSMT17,2019-04,ECN,41.5,100.0,41.5,1.0,41.5,0.42,ito:ITO_00101,Vision process,Rank\\-5
29,1,Unsupervised Person Re-Identification,Market-1501->DukeMTMC-reID,2019-04,ECN,75.8,81.95,75.8,0.82,92.5,0.76,ito:ITO_00101,Vision process,Rank\\-5
30,1,Unsupervised Person Re-Identification,Market-1501->DukeMTMC-reID,2020-01,MMT-ResNet50,92.5,100.0,16.7,0.18,92.5,0.93,ito:ITO_00101,Vision process,Rank\\-5
31,1,Unsupervised Person Re-Identification,Market-1501->MSMT17,2019-04,ECN,36.3,100.0,36.3,1.0,36.3,0.36,ito:ITO_00101,Vision process,Rank\\-5
32,1,Person Re-Identification,DukeMTMC-reID,2019-06,Dispersion based Clustering,64.6,66.94,64.6,0.67,96.5,0.65,ito:ITO_00101,Vision process,Rank\\-5
33,1,Person Re-Identification,DukeMTMC-reID,2019-10,P2-Net (triplet loss),93.1,96.48,28.5,0.3,96.5,0.93,ito:ITO_00101,Vision process,Rank\\-5
34,1,Person Re-Identification,DukeMTMC-reID,2019-12,Viewpoint-Aware Loss(RK),96.5,100.0,3.4,0.04,96.5,0.97,ito:ITO_00101,Vision process,Rank\\-5
35,1,Unsupervised Person Re-Identification,MSMT17->Market-1501,2019-10,OSNet-AIN,83.3,100.0,83.3,1.0,83.3,0.84,ito:ITO_00101,Vision process,Rank\\-5
0,1,Video Object Detection,ImageNet VID,2017-03,FGFA + Seq-NMS,954.0,100.0,954,1.0,954,1.0,ito:ITO_00101,Vision process,runtime\\ \\(ms\\)
0,1,Object Proposal Generation,"PASCAL VOC 2012, 60 proposals per image",2017-03,inst-DML,0.667,81.94,0.667,0.82,0.814,0.01,ito:ITO_00101,Vision process,Average\\ Recall
1,1,Object Proposal Generation,"PASCAL VOC 2012, 60 proposals per image",2017-12,Recurrent Pixel Embedding,0.814,100.0,0.1,0.12,0.814,0.01,ito:ITO_00101,Vision process,Average\\ Recall
2,1,Long-tail Learning,EGTEA,2017-08,Focal loss (3D- ResNeXt101),59.17,100.0,59.17,1.0,59.17,1.0,ito:ITO_00101,Vision process,Average\\ Recall
3,1,Scene Recognition,ScanNet,2018-08,SSMA,54.28,100.0,54.28,1.0,54.28,0.92,ito:ITO_00101,Vision process,Average\\ Recall
4,1,3D Feature Matching,3DMatch Benchmark,2019-10,FCGF,0.9578,100.0,0.9578,1.0,0.9578,0.02,ito:ITO_00101,Vision process,Average\\ Recall
0,1,Action Detection,UCF101-24,2017-03,T-CNN,73.1,89.36,73.1,0.89,81.8,0.83,ito:ITO_00101,Vision process,Video\\-mAP\\ 0\\.2
1,1,Action Detection,UCF101-24,2019-04,STEP,76.6,93.64,3.5,0.04,81.8,0.87,ito:ITO_00101,Vision process,Video\\-mAP\\ 0\\.2
2,1,Action Detection,UCF101-24,2020-01,MOC,81.8,100.0,5.2,0.06,81.8,0.93,ito:ITO_00101,Vision process,Video\\-mAP\\ 0\\.2
3,1,Temporal Action Localization,J-HMDB-21,2019-11,YOWO (16-frame),87.8,100.0,87.8,1.0,87.8,1.0,ito:ITO_00101,Vision process,Video\\-mAP\\ 0\\.2
0,1,Action Detection,UCF101-24,2017-03,T-CNN,77.9,93.74,77.9,0.94,83.1,0.94,ito:ITO_00101,Vision process,Video\\-mAP\\ 0\\.1
1,1,Action Detection,UCF101-24,2019-04,STEP,83.1,100.0,5.2,0.06,83.1,1.0,ito:ITO_00101,Vision process,Video\\-mAP\\ 0\\.1
0,1,6D Pose Estimation using RGB,LineMOD,2017-03,BB8,43.6,45.8,43.6,0.46,95.2,0.44,ito:ITO_00101,Vision process,Mean\\ ADD
1,1,6D Pose Estimation using RGB,LineMOD,2017-11,Single-shot Deep CNN,55.95,58.77,12.4,0.13,95.2,0.56,ito:ITO_00101,Vision process,Mean\\ ADD
2,1,6D Pose Estimation using RGB,LineMOD,2017-11,SSD-6D,76.3,80.15,20.3,0.21,95.2,0.77,ito:ITO_00101,Vision process,Mean\\ ADD
3,1,6D Pose Estimation using RGB,LineMOD,2018-03,PoseCNN + DeepIM,88.6,93.07,12.3,0.13,95.2,0.89,ito:ITO_00101,Vision process,Mean\\ ADD
4,1,6D Pose Estimation using RGB,LineMOD,2019-02,DPOD,95.2,100.0,6.6,0.07,95.2,0.96,ito:ITO_00101,Vision process,Mean\\ ADD
5,1,6D Pose Estimation using RGBD,YCB-Video,2017-11,PoseCNN (ICP),79.3,84.99,79.3,0.85,93.3,0.8,ito:ITO_00101,Vision process,Mean\\ ADD
6,1,6D Pose Estimation using RGBD,YCB-Video,2018-03,PoseCNN + DeepIM,80.6,86.39,1.3,0.01,93.3,0.81,ito:ITO_00101,Vision process,Mean\\ ADD
7,1,6D Pose Estimation using RGBD,YCB-Video,2019-11,MaskedFusion,93.3,100.0,12.7,0.14,93.3,0.94,ito:ITO_00101,Vision process,Mean\\ ADD
8,1,6D Pose Estimation using RGB,YCB-Video,2017-11,PoseCNN,53.7,76.6,53.7,0.77,70.1,0.54,ito:ITO_00101,Vision process,Mean\\ ADD
9,1,6D Pose Estimation using RGB,YCB-Video,2018-03,PoseCNN + DeepIM,70.1,100.0,16.4,0.23,70.1,0.71,ito:ITO_00101,Vision process,Mean\\ ADD
10,1,6D Pose Estimation using RGB,Occlusion LineMOD,2017-11,Ours PoseCNN+ICP,78.0,98.48,78.0,0.98,79.2,0.78,ito:ITO_00101,Vision process,Mean\\ ADD
11,1,6D Pose Estimation using RGB,Occlusion LineMOD,2020-01,HybridPose,79.2,100.0,1.2,0.02,79.2,0.8,ito:ITO_00101,Vision process,Mean\\ ADD
12,1,6D Pose Estimation using RGBD,LineMOD,2017-11,SSD-6D,90.9,91.45,90.9,0.91,99.4,0.91,ito:ITO_00101,Vision process,Mean\\ ADD
13,1,6D Pose Estimation using RGBD,LineMOD,2019-01,DeepFusion,94.3,94.87,3.4,0.03,99.4,0.95,ito:ITO_00101,Vision process,Mean\\ ADD
14,1,6D Pose Estimation using RGBD,LineMOD,2019-11,PVN3D,99.4,100.0,5.1,0.05,99.4,1.0,ito:ITO_00101,Vision process,Mean\\ ADD
0,1,6D Pose Estimation using RGB,LineMOD,2017-03,BB8,43.6,45.82,43.6,0.46,95.15,0.44,ito:ITO_00101,Vision process,Accuracy\\ \\(ADD\\)
1,1,6D Pose Estimation using RGB,LineMOD,2018-03,PoseCNN + DeepIM,88.1,92.59,44.5,0.47,95.15,0.89,ito:ITO_00101,Vision process,Accuracy\\ \\(ADD\\)
2,1,6D Pose Estimation using RGB,LineMOD,2019-02,DPOD,95.15,100.0,7.1,0.07,95.15,0.96,ito:ITO_00101,Vision process,Accuracy\\ \\(ADD\\)
3,1,6D Pose Estimation using RGB,YCB-Video,2017-11,PoseCNN,21.3,54.62,21.3,0.55,39.0,0.21,ito:ITO_00101,Vision process,Accuracy\\ \\(ADD\\)
4,1,6D Pose Estimation using RGB,YCB-Video,2018-12,SegDriven,39.0,100.0,17.7,0.45,39.0,0.39,ito:ITO_00101,Vision process,Accuracy\\ \\(ADD\\)
5,1,6D Pose Estimation,LineMOD,2019-01,DenseFusion,94.3,94.87,94.3,0.95,99.4,0.95,ito:ITO_00101,Vision process,Accuracy\\ \\(ADD\\)
6,1,6D Pose Estimation,LineMOD,2019-11,PVN3D,99.4,100.0,5.1,0.05,99.4,1.0,ito:ITO_00101,Vision process,Accuracy\\ \\(ADD\\)
0,1,Depth Estimation,NYU-Depth V2,2017-04,MS-CRF,0.586,100.0,0.586,1.0,0.586,1.0,ito:ITO_00101,Vision process,RMS
0,1,Panoptic Segmentation,Cityscapes test,2017-04,Dynamically Instantiated Network,55.4,84.07,55.4,0.84,65.9,0.82,ito:ITO_00101,Vision process,PQ
1,1,Panoptic Segmentation,Cityscapes test,2019-10,Panoptic-Deeplab,65.5,99.39,10.1,0.15,65.9,0.97,ito:ITO_00101,Vision process,PQ
2,1,Panoptic Segmentation,Cityscapes test,2020-04,EfficientPS,65.9,100.0,0.4,0.01,65.9,0.98,ito:ITO_00101,Vision process,PQ
3,1,Panoptic Segmentation,Cityscapes val,2018-01,MRCNN + PSPNet (ResNet-101),61.2,90.94,61.2,0.91,67.3,0.91,ito:ITO_00101,Vision process,PQ
4,1,Panoptic Segmentation,Cityscapes val,2019-01,"UPSNet (ResNet-101, multiscale)",61.8,91.83,0.6,0.01,67.3,0.92,ito:ITO_00101,Vision process,PQ
5,1,Panoptic Segmentation,Cityscapes val,2019-09,AdaptIS (ResNeXt-101),62.0,92.12,0.2,0.0,67.3,0.92,ito:ITO_00101,Vision process,PQ
6,1,Panoptic Segmentation,Cityscapes val,2019-11,Panoptic-DeepLab (X71),64.1,95.25,2.1,0.03,67.3,0.95,ito:ITO_00101,Vision process,PQ
7,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS,67.3,100.0,3.2,0.05,67.3,1.0,ito:ITO_00101,Vision process,PQ
8,1,Panoptic Segmentation,COCO panoptic,2018-01,MobileNetV2,35.2,81.86,35.2,0.82,43.0,0.52,ito:ITO_00101,Vision process,PQ
9,1,Panoptic Segmentation,COCO panoptic,2019-01,Panoptic-FPN-ResNet-101,43.0,100.0,7.8,0.18,43.0,0.64,ito:ITO_00101,Vision process,PQ
10,1,Panoptic Segmentation,COCO test-dev,2018-09,JSIS-Net (ResNet-50),27.2,56.9,27.2,0.57,47.8,0.4,ito:ITO_00101,Vision process,PQ
11,1,Panoptic Segmentation,COCO test-dev,2018-12,AUNet (ResNeXt-152-FPN),46.5,97.28,19.3,0.4,47.8,0.69,ito:ITO_00101,Vision process,PQ
12,1,Panoptic Segmentation,COCO test-dev,2019-01,UPSNet (ResNet-101-FPN),46.6,97.49,0.1,0.0,47.8,0.69,ito:ITO_00101,Vision process,PQ
13,1,Panoptic Segmentation,COCO test-dev,2019-11,SOGNet (ResNet-101-FPN),47.8,100.0,1.2,0.03,47.8,0.71,ito:ITO_00101,Vision process,PQ
14,1,Panoptic Segmentation,Mapillary val,2018-09,JSIS-Net (ResNet-50),35.9,88.64,35.9,0.89,40.5,0.53,ito:ITO_00101,Vision process,PQ
15,1,Panoptic Segmentation,Mapillary val,2019-09,AdaptIS (ResNeXt-101),40.3,99.51,4.4,0.11,40.5,0.6,ito:ITO_00101,Vision process,PQ
16,1,Panoptic Segmentation,Mapillary val,2019-11,Panoptic-DeepLab (X71),40.5,100.0,0.2,0.0,40.5,0.6,ito:ITO_00101,Vision process,PQ
17,1,Panoptic Segmentation,KITTI Panoptic Segmentation,2019-01,Panoptic FPN,39.3,89.93,39.3,0.9,43.7,0.58,ito:ITO_00101,Vision process,PQ
18,1,Panoptic Segmentation,KITTI Panoptic Segmentation,2019-01,UPSNet,39.9,91.3,0.6,0.01,43.7,0.59,ito:ITO_00101,Vision process,PQ
19,1,Panoptic Segmentation,KITTI Panoptic Segmentation,2019-05,Seamless,42.2,96.57,2.3,0.05,43.7,0.63,ito:ITO_00101,Vision process,PQ
20,1,Panoptic Segmentation,KITTI Panoptic Segmentation,2020-04,EfficientPS,43.7,100.0,1.5,0.03,43.7,0.65,ito:ITO_00101,Vision process,PQ
21,1,Panoptic Segmentation,Indian Driving Dataset,2019-01,Panoptic FPN,46.7,91.39,46.7,0.91,51.1,0.69,ito:ITO_00101,Vision process,PQ
22,1,Panoptic Segmentation,Indian Driving Dataset,2019-01,UPSNet,47.1,92.17,0.4,0.01,51.1,0.7,ito:ITO_00101,Vision process,PQ
23,1,Panoptic Segmentation,Indian Driving Dataset,2019-05,Seamless,48.5,94.91,1.4,0.03,51.1,0.72,ito:ITO_00101,Vision process,PQ
24,1,Panoptic Segmentation,Indian Driving Dataset,2020-04,EfficientPS,51.1,100.0,2.6,0.05,51.1,0.76,ito:ITO_00101,Vision process,PQ
0,1,3D Human Pose Estimation,Geometric Pose Affordance ,2017-04,Baseline model,83.6,87.54,83.6,0.88,95.5,0.88,ito:ITO_00101,Vision process,PCK3D\\ \\(CA\\)
1,1,3D Human Pose Estimation,Geometric Pose Affordance ,2017-05,SIM-G-F,95.5,100.0,11.9,0.12,95.5,1.0,ito:ITO_00101,Vision process,PCK3D\\ \\(CA\\)
0,1,3D Human Pose Estimation,Geometric Pose Affordance ,2017-04,Baseline model,99.4,100.0,99.4,1.0,99.4,1.0,ito:ITO_00101,Vision process,MPJPE\\ \\(CS\\)
0,1,3D Human Pose Estimation,Geometric Pose Affordance ,2017-04,Baseline model,89.2,100.0,89.2,1.0,89.2,1.0,ito:ITO_00101,Vision process,MPJPE\\ \\(CA\\)
0,1,3D Human Pose Estimation,Geometric Pose Affordance ,2017-04,Baseline model,81.3,86.58,81.3,0.87,93.9,0.87,ito:ITO_00101,Vision process,PCK3D\\ \\(CS\\)
1,1,3D Human Pose Estimation,Geometric Pose Affordance ,2017-05,SIM-G-F,93.9,100.0,12.6,0.13,93.9,1.0,ito:ITO_00101,Vision process,PCK3D\\ \\(CS\\)
0,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,58.1,100.0,58.1,1.0,58.1,1.0,ito:ITO_00101,Vision process,NDCG\\ \\(x\\ 100\\)
0,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,58.8,84.85,58.8,0.85,69.3,0.85,ito:ITO_00101,Vision process,MRR\\ \\(x\\ 100\\)
1,1,Visual Dialog,Visual Dialog v1.0 test-std,2018-09,CorefNMN (ResNet-152),61.5,88.74,2.7,0.04,69.3,0.89,ito:ITO_00101,Vision process,MRR\\ \\(x\\ 100\\)
2,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,DAN,63.2,91.2,1.7,0.02,69.3,0.91,ito:ITO_00101,Vision process,MRR\\ \\(x\\ 100\\)
3,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,HACAN,64.22,92.67,1.0,0.01,69.3,0.93,ito:ITO_00101,Vision process,MRR\\ \\(x\\ 100\\)
4,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-04,5xFGA (F-RCNNx101),69.3,100.0,5.1,0.07,69.3,1.0,ito:ITO_00101,Vision process,MRR\\ \\(x\\ 100\\)
0,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,4.4,100.0,4.4,1.0,4.4,1.0,ito:ITO_00101,Vision process,Mean
0,1,Human-Object Interaction Detection,HICO-DET,2017-04,InteractNet,145.0,28.32,145,0.28,512,0.28,ito:ITO_00101,Vision process,Time\\ Per\\ Frame\\ \\(ms\\)
1,1,Human-Object Interaction Detection,HICO-DET,2018-11,Interactiveness (CVPR\'19),512.0,100.0,367,0.72,512,1.0,ito:ITO_00101,Vision process,Time\\ Per\\ Frame\\ \\(ms\\)
0,1,Skeleton Based Action Recognition,PKU-MMD,2017-04,Li et al. [[Li et al.2017b]],93.7,99.26,93.7,0.99,94.4,0.99,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.50\\ \\(CV\\)
1,1,Skeleton Based Action Recognition,PKU-MMD,2018-04,HCN,94.2,99.79,0.5,0.01,94.4,1.0,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.50\\ \\(CV\\)
2,1,Skeleton Based Action Recognition,PKU-MMD,2019-09,RF-Action,94.4,100.0,0.2,0.0,94.4,1.0,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.50\\ \\(CV\\)
0,1,Skeleton Based Action Recognition,PKU-MMD,2017-04,Li et al. [[Li et al.2017b]],90.4,97.31,90.4,0.97,92.9,0.97,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.50\\ \\(CS\\)
1,1,Skeleton Based Action Recognition,PKU-MMD,2018-04,HCN,92.6,99.68,2.2,0.02,92.9,1.0,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.50\\ \\(CS\\)
2,1,Skeleton Based Action Recognition,PKU-MMD,2019-09,RF-Action,92.9,100.0,0.3,0.0,92.9,1.0,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.50\\ \\(CS\\)
0,1,Defocus Estimation,CUHK,2017-04,DHDE,83.73,100.0,83.73,1.0,83.73,1.0,ito:ITO_00101,Vision process,Blur\\ Segmentation\\ Accuracy
1,1,Defocus Estimation,Blur Detection Dataset,2017-04,DHDE,83.73,100.0,83.73,1.0,83.73,1.0,ito:ITO_00101,Vision process,Blur\\ Segmentation\\ Accuracy
0,1,3D Human Pose Estimation,MPI-INF-3DHP,2017-05,VNect (Augm.),78.1,82.12,78.1,0.82,95.1,0.82,ito:ITO_00101,Vision process,3DPCK
1,1,3D Human Pose Estimation,MPI-INF-3DHP,2018-06,"MargiPose (Procrustes alignment, PA)",94.8,99.68,16.7,0.18,95.1,1.0,ito:ITO_00101,Vision process,3DPCK
2,1,3D Human Pose Estimation,MPI-INF-3DHP,2018-06,"MargiPose (Procrustes alignment, PA, multi-crop)",95.1,100.0,0.3,0.0,95.1,1.0,ito:ITO_00101,Vision process,3DPCK
3,1,3D Multi-Person Pose Estimation,MuPoTS-3D,2019-07,SelecSLS,75.8,100.0,75.8,1.0,75.8,0.8,ito:ITO_00101,Vision process,3DPCK
0,1,3D Human Pose Estimation,MPI-INF-3DHP,2017-05,VNect (Augm.),119.2,100.0,119.2,1.0,119.2,1.0,ito:ITO_00101,Vision process,MJPE
0,1,Action Classification,Toyota Smarthome dataset,2017-05,I3D,53.4,99.63,53.4,1.0,53.6,1.0,ito:ITO_00101,Vision process,CS
1,1,Action Classification,Toyota Smarthome dataset,2017-11,I3D + Non Local,53.6,100.0,0.2,0.0,53.6,1.0,ito:ITO_00101,Vision process,CS
0,1,Action Classification,Toyota Smarthome dataset,2017-05,I3D,34.9,100.0,34.9,1.0,34.9,1.0,ito:ITO_00101,Vision process,CV1
0,1,Action Classification,Toyota Smarthome dataset,2017-05,I3D,45.1,100.0,45.1,1.0,45.1,1.0,ito:ITO_00101,Vision process,CV2
0,1,Action Recognition,AVA v2.1,2017-05,S3D-G w/ ResNet RPN (Kinetics-400 pretraining(,22.0,77.74,22.0,0.78,28.3,0.78,ito:ITO_00101,Vision process,mAP\\ \\(Val\\)
1,1,Action Recognition,AVA v2.1,2018-12,I3D Tx HighRes,27.6,97.53,5.6,0.2,28.3,0.98,ito:ITO_00101,Vision process,mAP\\ \\(Val\\)
2,1,Action Recognition,AVA v2.1,2018-12,"SlowFast++ (Kinetics-600 pretraining, NL)",28.3,100.0,0.7,0.02,28.3,1.0,ito:ITO_00101,Vision process,mAP\\ \\(Val\\)
3,1,Action Recognition In Videos,AVA v2.1,2018-07,ARCN,17.4,61.7,17.4,0.62,28.2,0.61,ito:ITO_00101,Vision process,mAP\\ \\(Val\\)
4,1,Action Recognition In Videos,AVA v2.1,2018-12,I3D Tx HighRes,27.6,97.87,10.2,0.36,28.2,0.98,ito:ITO_00101,Vision process,mAP\\ \\(Val\\)
5,1,Action Recognition In Videos,AVA v2.1,2018-12,SlowFast,28.2,100.0,0.6,0.02,28.2,1.0,ito:ITO_00101,Vision process,mAP\\ \\(Val\\)
0,1,Temporal Action Localization,UCF101-24,2017-05,Faster-RCNN + two-stream I3D conv,59.9,100.0,59.9,1.0,59.9,0.7,ito:ITO_00101,Vision process,Video\\-mAP\\ 0\\.5
1,1,Temporal Action Localization,J-HMDB-21,2017-05,Faster-RCNN + two-stream I3D conv,78.6,91.72,78.6,0.92,85.7,0.92,ito:ITO_00101,Vision process,Video\\-mAP\\ 0\\.5
2,1,Temporal Action Localization,J-HMDB-21,2019-11,YOWO (16-frame),85.7,100.0,7.1,0.08,85.7,1.0,ito:ITO_00101,Vision process,Video\\-mAP\\ 0\\.5
3,1,Action Detection,UCF101-24,2020-01,Ours (MOC),53.9,100.0,53.9,1.0,53.9,0.63,ito:ITO_00101,Vision process,Video\\-mAP\\ 0\\.5
0,1,Gesture-to-Gesture Translation,Senz3D,2017-05,PG2,2.8,10.14,2.8,0.1,27.6,0.1,ito:ITO_00101,Vision process,AMT
1,1,Gesture-to-Gesture Translation,Senz3D,2017-12,DPIG,6.9,25.0,4.1,0.15,27.6,0.24,ito:ITO_00101,Vision process,AMT
2,1,Gesture-to-Gesture Translation,Senz3D,2017-12,PoseGAN,8.6,31.16,1.7,0.06,27.6,0.29,ito:ITO_00101,Vision process,AMT
3,1,Gesture-to-Gesture Translation,Senz3D,2018-08,GestureGAN,22.6,81.88,14.0,0.51,27.6,0.77,ito:ITO_00101,Vision process,AMT
4,1,Gesture-to-Gesture Translation,Senz3D,2019-12,UniGAN,27.6,100.0,5.0,0.18,27.6,0.94,ito:ITO_00101,Vision process,AMT
5,1,Gesture-to-Gesture Translation,NTU Hand Digit,2017-05,PG2,3.5,11.95,3.5,0.12,29.3,0.12,ito:ITO_00101,Vision process,AMT
6,1,Gesture-to-Gesture Translation,NTU Hand Digit,2017-12,DPIG,7.1,24.23,3.6,0.12,29.3,0.24,ito:ITO_00101,Vision process,AMT
7,1,Gesture-to-Gesture Translation,NTU Hand Digit,2017-12,PoseGAN,9.3,31.74,2.2,0.08,29.3,0.32,ito:ITO_00101,Vision process,AMT
8,1,Gesture-to-Gesture Translation,NTU Hand Digit,2018-08,GestureGAN,26.1,89.08,16.8,0.57,29.3,0.89,ito:ITO_00101,Vision process,AMT
9,1,Gesture-to-Gesture Translation,NTU Hand Digit,2019-12,UniGAN,29.3,100.0,3.2,0.11,29.3,1.0,ito:ITO_00101,Vision process,AMT
0,1,Edge Detection,SBD,2017-05,CASENet,71.4,100.0,71.4,1.0,71.4,1.0,ito:ITO_00101,Vision process,Maximum\\ F\\-measure
1,1,Edge Detection,Cityscapes test,2017-05,CASENet,71.3,100.0,71.3,1.0,71.3,1.0,ito:ITO_00101,Vision process,Maximum\\ F\\-measure
0,1,Unsupervised Person Re-Identification,Market-1501,2017-05,PUL,66.7,68.9,66.7,0.69,96.8,0.67,ito:ITO_00101,Vision process,Rank\\-10
1,1,Unsupervised Person Re-Identification,Market-1501,2017-11,SPGAN+LMP,82.4,85.12,15.7,0.16,96.8,0.83,ito:ITO_00101,Vision process,Rank\\-10
2,1,Unsupervised Person Re-Identification,Market-1501,2018-11,Self-Similarity Grouping (one shot),96.8,100.0,14.4,0.15,96.8,0.97,ito:ITO_00101,Vision process,Rank\\-10
3,1,Unsupervised Person Re-Identification,DukeMTMC-reID,2017-05,PUL,48.5,55.3,48.5,0.55,87.7,0.49,ito:ITO_00101,Vision process,Rank\\-10
4,1,Unsupervised Person Re-Identification,DukeMTMC-reID,2017-11,SPGAN+LMP,68.0,77.54,19.5,0.22,87.7,0.68,ito:ITO_00101,Vision process,Rank\\-10
5,1,Unsupervised Person Re-Identification,DukeMTMC-reID,2018-11,Self-Similarity Grouping (one shot),87.7,100.0,19.7,0.22,87.7,0.88,ito:ITO_00101,Vision process,Rank\\-10
6,1,Unsupervised Person Re-Identification,MSMT17->DukeMTMC-reID,2017-11,SPGAN,68.0,76.75,68.0,0.77,88.6,0.68,ito:ITO_00101,Vision process,Rank\\-10
7,1,Unsupervised Person Re-Identification,MSMT17->DukeMTMC-reID,2019-10,OSNet-AIN,88.6,100.0,20.6,0.23,88.6,0.89,ito:ITO_00101,Vision process,Rank\\-10
8,1,Person Re-Identification,CUHK03,2017-11,AlignedReID (RK),99.8,100.0,99.8,1.0,99.8,1.0,ito:ITO_00101,Vision process,Rank\\-10
9,1,Unsupervised Person Re-Identification,Market-1501->MSMT17,2018-11,Self-Similarity Grouping (one shot),45.7,100.0,45.7,1.0,45.7,0.46,ito:ITO_00101,Vision process,Rank\\-10
10,1,Unsupervised Person Re-Identification,DukeMTMC-reID->MSMT17,2018-11,Self-Similarity Grouping (one shot),61.8,100.0,61.8,1.0,61.8,0.62,ito:ITO_00101,Vision process,Rank\\-10
11,1,Person Re-Identification,Market-1501,2018-12,"st-ReID(RE, RK)",99.1,100.0,99.1,1.0,99.1,0.99,ito:ITO_00101,Vision process,Rank\\-10
12,1,Person Re-Identification,MARS,2019-03,UTAL,66.4,69.38,66.4,0.69,95.7,0.67,ito:ITO_00101,Vision process,Rank\\-10
13,1,Person Re-Identification,MARS,2019-08,TKP,95.7,100.0,29.3,0.31,95.7,0.96,ito:ITO_00101,Vision process,Rank\\-10
14,1,Unsupervised Person Re-Identification,DukeMTMC-reID->Market-1501,2019-04,ECN,91.6,100.0,91.6,1.0,91.6,0.92,ito:ITO_00101,Vision process,Rank\\-10
15,1,Unsupervised Person Re-Identification,Market-1501->DukeMTMC-reID,2019-04,ECN,80.4,90.54,80.4,0.91,88.8,0.81,ito:ITO_00101,Vision process,Rank\\-10
16,1,Unsupervised Person Re-Identification,Market-1501->DukeMTMC-reID,2020-01,MMT-ResNet50,88.8,100.0,8.4,0.09,88.8,0.89,ito:ITO_00101,Vision process,Rank\\-10
17,1,Person Re-Identification,DukeMTMC-reID,2019-06,Dispersion based Clustering,70.1,73.79,70.1,0.74,95.0,0.7,ito:ITO_00101,Vision process,Rank\\-10
18,1,Person Re-Identification,DukeMTMC-reID,2019-10,P2-Net (triplet loss),95.0,100.0,24.9,0.26,95.0,0.95,ito:ITO_00101,Vision process,Rank\\-10
19,1,Person Re-Identification,iLIDS-VID,2019-08,TKP,86.9,100.0,86.9,1.0,86.9,0.87,ito:ITO_00101,Vision process,Rank\\-10
20,1,Unsupervised Person Re-Identification,MSMT17->Market-1501,2019-10,OSNet-AIN,86.4,100.0,86.4,1.0,86.4,0.87,ito:ITO_00101,Vision process,Rank\\-10
0,1,Face Alignment,300W,2017-06,DAN-Menpo + inter-ocular normalization,50.84,66.67,50.84,0.67,76.26,0.67,ito:ITO_00101,Vision process,AUC0\\.08\\ private
1,1,Face Alignment,300W,2018-03,SIR-LAN,58.11,76.2,7.3,0.1,76.26,0.76,ito:ITO_00101,Vision process,AUC0\\.08\\ private
2,1,Face Alignment,300W,2018-05,LAB + Oracle + Inter-ocular Normalisation,76.26,100.0,18.2,0.24,76.26,1.0,ito:ITO_00101,Vision process,AUC0\\.08\\ private
0,1,Face Alignment,300W,2017-06,DAN-Menpo + inter-ocular normalization,3.44,61.1,3.44,0.61,5.63,0.61,ito:ITO_00101,Vision process,Fullset\\ \\(public\\)
1,1,Face Alignment,300W,2018-03,SIR-LAN,5.04,89.52,1.6,0.28,5.63,0.9,ito:ITO_00101,Vision process,Fullset\\ \\(public\\)
2,1,Face Alignment,300W,2018-04,3DDFA,5.63,100.0,0.6,0.11,5.63,1.0,ito:ITO_00101,Vision process,Fullset\\ \\(public\\)
0,1,Face Alignment,300W,2017-06,DAN-Menpo + inter-ocular normalization,1.83,100.0,1.83,1.0,1.83,1.0,ito:ITO_00101,Vision process,Failure\\ private
0,1,Face Alignment,300W,2017-06,DAN-Menpo + inter-ocular normalization,3.97,100.0,3.97,1.0,3.97,1.0,ito:ITO_00101,Vision process,Mean\\ Error\\ Rate\\ private
0,1,Action Recognition In Videos,Something-Something V2,2017-06,model3D_1 with left-right augmentation and fps jitter,80.46,88.03,80.46,0.88,91.4,0.81,ito:ITO_00101,Vision process,Top\\-5\\ Accuracy
1,1,Action Recognition In Videos,Something-Something V2,2017-11,2-Stream TRN,83.06,90.88,2.6,0.03,91.4,0.84,ito:ITO_00101,Vision process,Top\\-5\\ Accuracy
2,1,Action Recognition In Videos,Something-Something V2,2018-11,TSM (RGB + Flow),91.3,99.89,8.2,0.09,91.4,0.92,ito:ITO_00101,Vision process,Top\\-5\\ Accuracy
3,1,Action Recognition In Videos,Something-Something V2,2019-08,TRG (Inception-V3),91.4,100.0,0.1,0.0,91.4,0.92,ito:ITO_00101,Vision process,Top\\-5\\ Accuracy
4,1,Action Recognition,Something-Something V2,2017-06,model3D_1 with left-right augmentation and fps jitter,80.46,88.03,80.46,0.88,91.4,0.81,ito:ITO_00101,Vision process,Top\\-5\\ Accuracy
5,1,Action Recognition,Something-Something V2,2017-11,2-Stream TRN,83.06,90.88,2.6,0.03,91.4,0.84,ito:ITO_00101,Vision process,Top\\-5\\ Accuracy
6,1,Action Recognition,Something-Something V2,2018-11,TSM (RGB + Flow),91.3,99.89,8.2,0.09,91.4,0.92,ito:ITO_00101,Vision process,Top\\-5\\ Accuracy
7,1,Action Recognition,Something-Something V2,2019-08,TRG (Inception-V3),91.4,100.0,0.1,0.0,91.4,0.92,ito:ITO_00101,Vision process,Top\\-5\\ Accuracy
8,1,Action Classification,Kinetics-600,2018-12,SlowFast 16x8 (ResNet-101),95.1,98.86,95.1,0.99,96.2,0.96,ito:ITO_00101,Vision process,Top\\-5\\ Accuracy
9,1,Action Classification,Kinetics-600,2019-06,LGD-3D Two-stream* (ResNet-101),96.0,99.79,0.9,0.01,96.2,0.97,ito:ITO_00101,Vision process,Top\\-5\\ Accuracy
10,1,Action Classification,Kinetics-600,2019-06,LGD-3D Two-stream,96.2,100.0,0.2,0.0,96.2,0.97,ito:ITO_00101,Vision process,Top\\-5\\ Accuracy
11,1,Action Recognition In Videos,EgoGesture,2020-04,TSM+W3,99.2,100.0,99.2,1.0,99.2,1.0,ito:ITO_00101,Vision process,Top\\-5\\ Accuracy
12,1,Action Recognition,EgoGesture,2020-04,TSM+W3,99.2,100.0,99.2,1.0,99.2,1.0,ito:ITO_00101,Vision process,Top\\-5\\ Accuracy
0,1,RGB Salient Object Detection,SOC,2017-07,NLDF,0.837,96.88,0.837,0.97,0.864,0.93,ito:ITO_00101,Vision process,mean\\ E\\-Measure
1,1,RGB Salient Object Detection,SOC,2019-06,BASNet,0.864,100.0,0.0,0.0,0.864,0.96,ito:ITO_00101,Vision process,mean\\ E\\-Measure
2,1,RGB Salient Object Detection,DUTS-TE,2017-08,PiCANet,0.853,95.2,0.853,0.95,0.896,0.95,ito:ITO_00101,Vision process,mean\\ E\\-Measure
3,1,RGB Salient Object Detection,DUTS-TE,2018-06,DGRL,0.887,99.0,0.0,0.0,0.896,0.99,ito:ITO_00101,Vision process,mean\\ E\\-Measure
4,1,RGB Salient Object Detection,DUTS-TE,2019-06,BASNet,0.896,100.0,0.0,0.0,0.896,1.0,ito:ITO_00101,Vision process,mean\\ E\\-Measure
0,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,bc-LSTM+Att,56.19,87.55,56.19,0.88,64.18,0.88,ito:ITO_00101,Vision process,Weighted\\-F1
1,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,ICON,58.54,91.21,2.4,0.04,64.18,0.91,ito:ITO_00101,Vision process,Weighted\\-F1
2,1,Emotion Recognition in Conversation,IEMOCAP,2018-11,DialogueRNN,62.75,97.77,4.2,0.07,64.18,0.98,ito:ITO_00101,Vision process,Weighted\\-F1
3,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,DialogueGCN,64.18,100.0,1.4,0.02,64.18,1.0,ito:ITO_00101,Vision process,Weighted\\-F1
4,1,Emotion Recognition in Conversation,MELD,2017-07,bc-LSTM+Att,56.44,97.01,56.44,0.97,58.18,0.88,ito:ITO_00101,Vision process,Weighted\\-F1
5,1,Emotion Recognition in Conversation,MELD,2018-11,DialogueRNN,57.03,98.02,0.6,0.01,58.18,0.89,ito:ITO_00101,Vision process,Weighted\\-F1
6,1,Emotion Recognition in Conversation,MELD,2019-08,DialogueGCN,58.1,99.86,1.1,0.02,58.18,0.91,ito:ITO_00101,Vision process,Weighted\\-F1
7,1,Emotion Recognition in Conversation,MELD,2019-09,KET,58.18,100.0,0.1,0.0,58.18,0.91,ito:ITO_00101,Vision process,Weighted\\-F1
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,bc-LSTM+Att,0.189,98.44,0.189,0.98,0.192,0.98,ito:ITO_00101,Vision process,MAE\\ \\(Valence\\)
1,1,Emotion Recognition in Conversation,SEMAINE,2018-06,CMN,0.192,100.0,0.0,0.0,0.192,1.0,ito:ITO_00101,Vision process,MAE\\ \\(Valence\\)
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,bc-LSTM+Att,0.213,100.0,0.213,1.0,0.213,1.0,ito:ITO_00101,Vision process,MAE\\ \\(Arousal\\)
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,bc-LSTM+Att,0.19,97.44,0.19,0.97,0.195,0.97,ito:ITO_00101,Vision process,MAE\\ \\(Expectancy\\)
1,1,Emotion Recognition in Conversation,SEMAINE,2018-06,CMN,0.195,100.0,0.0,0.0,0.195,1.0,ito:ITO_00101,Vision process,MAE\\ \\(Expectancy\\)
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,bc-LSTM+Att,8.67,99.2,8.67,0.99,8.74,0.99,ito:ITO_00101,Vision process,MAE\\ \\(Power\\)
1,1,Emotion Recognition in Conversation,SEMAINE,2018-06,CMN,8.74,100.0,0.1,0.01,8.74,1.0,ito:ITO_00101,Vision process,MAE\\ \\(Power\\)
0,1,3D Absolute Human Pose Estimation,Human3.6M,2017-10,Fang,60.4,100.0,60.4,1.0,60.4,0.46,ito:ITO_00101,Vision process,MPJPE
1,1,3D Human Pose Estimation,Surreal,2017-12,self-supervised mocap,64.4,100.0,64.4,1.0,64.4,0.5,ito:ITO_00101,Vision process,MPJPE
2,1,3D Human Pose Estimation,3DPW,2017-12,HMR,130.0,100.0,130.0,1.0,130.0,1.0,ito:ITO_00101,Vision process,MPJPE
3,1,3D Human Pose Estimation,CHALL H80K,2018-09,ResNet,55.3,100.0,55.3,1.0,55.3,0.43,ito:ITO_00101,Vision process,MPJPE
4,1,3D Human Pose Estimation,3D Poses in the Wild Challenge,2019-07,RootNet,84.28,82.18,84.28,0.82,102.56,0.65,ito:ITO_00101,Vision process,MPJPE
5,1,3D Human Pose Estimation,3D Poses in the Wild Challenge,2019-09,SPIN,102.56,100.0,18.3,0.18,102.56,0.79,ito:ITO_00101,Vision process,MPJPE
6,1,3D Absolute Human Pose Estimation,Total Capture,2020-03,GeoFuse,24.6,100.0,24.6,1.0,24.6,0.19,ito:ITO_00101,Vision process,MPJPE
0,1,Multimodal Emotion Recognition,IEMOCAP,2017-07,bc-LSTM ,0.741,96.86,0.741,0.97,0.765,0.93,ito:ITO_00101,Vision process,UA
1,1,Multimodal Emotion Recognition,IEMOCAP,2018-06,CHFusion (A+T+V),0.765,100.0,0.0,0.0,0.765,0.96,ito:ITO_00101,Vision process,UA
2,1,Speech Emotion Recognition,IEMOCAP,2018-02,CNN+LSTM,0.8,100.0,0.8,1.0,0.8,1.0,ito:ITO_00101,Vision process,UA
0,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,bc-LSTM+Att,54.84,86.46,54.84,0.86,63.43,0.86,ito:ITO_00101,Vision process,Macro\\-F1
1,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,ICON,56.52,89.11,1.7,0.03,63.43,0.89,ito:ITO_00101,Vision process,Macro\\-F1
2,1,Emotion Recognition in Conversation,IEMOCAP,2018-11,DialogueRNN,60.66,95.63,4.1,0.06,63.43,0.96,ito:ITO_00101,Vision process,Macro\\-F1
3,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,DialogueGCN,63.43,100.0,2.8,0.04,63.43,1.0,ito:ITO_00101,Vision process,Macro\\-F1
0,1,Image Cropping,AVA,2017-07,Crop,1.0,100.0,1,1.0,1,1.0,ito:ITO_00101,Vision process,Bounding\\ Box\\ AP
0,1,Temporal Action Proposal Generation,ActivityNet-1.3,2017-07,Lin et al.,64.4,95.98,64.4,0.96,67.1,0.96,ito:ITO_00101,Vision process,AUC\\ \\(val\\)
1,1,Temporal Action Proposal Generation,ActivityNet-1.3,2018-06,BSN,66.17,98.61,1.8,0.03,67.1,0.99,ito:ITO_00101,Vision process,AUC\\ \\(val\\)
2,1,Temporal Action Proposal Generation,ActivityNet-1.3,2018-11,MGG,66.43,99.0,0.3,0.0,67.1,0.99,ito:ITO_00101,Vision process,AUC\\ \\(val\\)
3,1,Temporal Action Proposal Generation,ActivityNet-1.3,2019-07,BMN,67.1,100.0,0.7,0.01,67.1,1.0,ito:ITO_00101,Vision process,AUC\\ \\(val\\)
0,1,Temporal Action Proposal Generation,ActivityNet-1.3,2017-07,Lin et al.,64.8,97.8,64.8,0.98,66.26,0.98,ito:ITO_00101,Vision process,AUC\\ \\(test\\)
1,1,Temporal Action Proposal Generation,ActivityNet-1.3,2018-06,BSN,66.26,100.0,1.5,0.02,66.26,1.0,ito:ITO_00101,Vision process,AUC\\ \\(test\\)
0,1,Temporal Action Proposal Generation,ActivityNet-1.3,2017-07,Lin et al.,73.01,97.33,73.01,0.97,75.01,0.97,ito:ITO_00101,Vision process,AR@100
1,1,Temporal Action Proposal Generation,ActivityNet-1.3,2018-06,BSN,74.16,98.87,1.1,0.01,75.01,0.99,ito:ITO_00101,Vision process,AR@100
2,1,Temporal Action Proposal Generation,ActivityNet-1.3,2018-11,MGG,74.54,99.37,0.4,0.01,75.01,0.99,ito:ITO_00101,Vision process,AR@100
3,1,Temporal Action Proposal Generation,ActivityNet-1.3,2019-07,BMN,75.01,100.0,0.5,0.01,75.01,1.0,ito:ITO_00101,Vision process,AR@100
4,1,Temporal Action Proposal Generation,THUMOS' 14,2018-06,BSN + Soft-NMS,46.06,100.0,46.06,1.0,46.06,0.61,ito:ITO_00101,Vision process,AR@100
0,1,Visual Question Answering,GQA Test2019,2017-07,BottomUp,78.71,84.54,78.71,0.85,93.1,0.85,ito:ITO_00101,Vision process,Consistency
1,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Single Model",89.59,96.23,10.9,0.12,93.1,0.96,ito:ITO_00101,Vision process,Consistency
2,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Ensemble",93.1,100.0,3.5,0.04,93.1,1.0,ito:ITO_00101,Vision process,Consistency
3,1,Classification Consistency,ImageNet,2019-04,ResNet50,91.31,100.0,91.31,1.0,91.31,0.98,ito:ITO_00101,Vision process,Consistency
0,1,Visual Question Answering,GQA Test2019,2017-07,BottomUp,66.64,83.52,66.64,0.84,79.79,0.84,ito:ITO_00101,Vision process,Binary
1,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Single Model",77.16,96.7,10.5,0.13,79.79,0.97,ito:ITO_00101,Vision process,Binary
2,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Ensemble",79.79,100.0,2.6,0.03,79.79,1.0,ito:ITO_00101,Vision process,Binary
0,1,Visual Question Answering,GQA Test2019,2017-07,BottomUp,34.83,73.11,34.83,0.73,47.64,0.73,ito:ITO_00101,Vision process,Open
1,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Single Model",45.47,95.45,10.6,0.22,47.64,0.95,ito:ITO_00101,Vision process,Open
2,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Ensemble",47.64,100.0,2.2,0.05,47.64,1.0,ito:ITO_00101,Vision process,Open
0,1,Visual Question Answering,GQA Test2019,2017-07,BottomUp,84.57,99.25,84.57,0.99,85.21,0.99,ito:ITO_00101,Vision process,Plausibility
1,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Ensemble",85.21,100.0,0.6,0.01,85.21,1.0,ito:ITO_00101,Vision process,Plausibility
0,1,Visual Question Answering,GQA Test2019,2017-07,BottomUp,96.18,99.81,96.18,1.0,96.36,1.0,ito:ITO_00101,Vision process,Validity
1,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Single Model",96.35,99.99,0.2,0.0,96.36,1.0,ito:ITO_00101,Vision process,Validity
2,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Ensemble",96.36,100.0,0.0,0.0,96.36,1.0,ito:ITO_00101,Vision process,Validity
0,1,Visual Question Answering,GQA Test2019,2017-07,BottomUp,5.98,93.15,5.98,0.93,6.42,0.93,ito:ITO_00101,Vision process,Distribution
1,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Ensemble",6.42,100.0,0.4,0.06,6.42,1.0,ito:ITO_00101,Vision process,Distribution
0,1,Crowd Counting,ShanghaiTech B,2017-07,Proposed method,31.1,100.0,31.1,1.0,31.1,0.06,ito:ITO_00101,Vision process,MSE
1,1,Crowd Counting,UCF CC 50,2017-07,Proposed method,397.9,100.0,397.9,1.0,397.9,0.8,ito:ITO_00101,Vision process,MSE
2,1,Crowd Counting,ShanghaiTech A,2017-07,Proposed method,152.4,100.0,152.4,1.0,152.4,0.31,ito:ITO_00101,Vision process,MSE
3,1,Video Prediction,Human3.6M,2017-12,PredRNN,484.1,97.27,484.1,0.97,497.7,0.97,ito:ITO_00101,Vision process,MSE
4,1,Video Prediction,Human3.6M,2017-12,FRNN,497.7,100.0,13.6,0.03,497.7,1.0,ito:ITO_00101,Vision process,MSE
5,1,Gesture-to-Gesture Translation,Senz3D,2018-08,GestureGAN,169.9219,100.0,169.9219,1.0,169.9219,0.34,ito:ITO_00101,Vision process,MSE
6,1,Gesture-to-Gesture Translation,NTU Hand Digit,2018-08,GestureGAN,105.7286,100.0,105.7286,1.0,105.7286,0.21,ito:ITO_00101,Vision process,MSE
7,1,Horizon Line Estimation,KITTI Horizon,2019-07,"ConvLSTM (Huber Loss, naive residual path)",6.731,100.0,6.731,1.0,6.731,0.01,ito:ITO_00101,Vision process,MSE
8,1,Image Matting,Composition-1K,2019-08,IndexNet-Matting,13.0,100.0,13.0,1.0,13.0,0.03,ito:ITO_00101,Vision process,MSE
0,1,Audio Super-Resolution,VCTK Multi-Speaker,2017-08,U-Net,3.1,100.0,3.1,1.0,3.1,0.91,ito:ITO_00101,Vision process,Log\\-Spectral\\ Distance
1,1,Audio Super-Resolution,Piano,2017-08,U-Net,3.4,100.0,3.4,1.0,3.4,1.0,ito:ITO_00101,Vision process,Log\\-Spectral\\ Distance
0,1,Video Frame Interpolation,Middlebury,2017-08,SepConv-L1,5.61,100.0,5.61,1.0,5.61,1.0,ito:ITO_00101,Vision process,Interpolation\\ Error
0,1,Face Verification,Oulu-CASIA NIR-VIS,2017-08,W-CNN He et al. (2018),54.6,58.77,54.6,0.59,92.9,0.55,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.001
1,1,Face Verification,Oulu-CASIA NIR-VIS,2018-09,DVR Wu et al. (2019),84.9,91.39,30.3,0.33,92.9,0.85,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.001
2,1,Face Verification,Oulu-CASIA NIR-VIS,2019-03,LightCNN-29 + DVG,92.9,100.0,8.0,0.09,92.9,0.93,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.001
3,1,Face Verification,BUAA-VisNir,2017-08,W-CNN He et al. (2018),91.9,94.45,91.9,0.94,97.3,0.92,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.001
4,1,Face Verification,BUAA-VisNir,2018-09,DVR Wu et al. (2019),96.9,99.59,5.0,0.05,97.3,0.97,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.001
5,1,Face Verification,BUAA-VisNir,2019-03,LightCNN-29 + DVG,97.3,100.0,0.4,0.0,97.3,0.97,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.001
6,1,Face Verification,CASIA NIR-VIS 2.0,2017-08,W-CNN He et al. (2018),98.4,98.6,98.4,0.99,99.8,0.99,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.001
7,1,Face Verification,CASIA NIR-VIS 2.0,2018-09,DVR Wu et al. (2019),99.6,99.8,1.2,0.01,99.8,1.0,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.001
8,1,Face Verification,CASIA NIR-VIS 2.0,2019-03,LightCNN-29 + DVG,99.8,100.0,0.2,0.0,99.8,1.0,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.001
9,1,Face Verification,IJB-C,2017-10,VGGFace2_ft,92.7,97.08,92.7,0.97,95.49,0.93,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.001
10,1,Face Verification,IJB-C,2019-04,PFEfuse + match,95.49,100.0,2.8,0.03,95.49,0.96,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.001
11,1,Face Verification,IJB-B,2017-10,VGGFace2_ft,90.8,100.0,90.8,1.0,90.8,0.91,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.001
12,1,Face Verification,IJB-A,2017-10,VGGFace2_ft,92.1,96.69,92.1,0.97,95.25,0.92,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.001
13,1,Face Verification,IJB-A,2019-04,PFEfuse + match,95.25,100.0,3.2,0.03,95.25,0.95,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.001
0,1,Action Recognition,ActionNet-VE,2017-08,Baseline,90.27,100.0,90.27,1.0,90.27,0.97,ito:ITO_00101,Vision process,F\\-measure\\ \\(%\\)
1,1,Action Recognition In Videos,ActionNet-VE,2017-08,Baseline,90.27,100.0,90.27,1.0,90.27,0.97,ito:ITO_00101,Vision process,F\\-measure\\ \\(%\\)
2,1,Point Cloud Super Resolution,SHREC15,2018-01,PU-NET,56.4,60.58,56.4,0.61,93.1,0.61,ito:ITO_00101,Vision process,F\\-measure\\ \\(%\\)
3,1,Point Cloud Super Resolution,SHREC15,2019-08,AR-GCN,93.1,100.0,36.7,0.39,93.1,1.0,ito:ITO_00101,Vision process,F\\-measure\\ \\(%\\)
0,1,Facial Expression Recognition,AffectNet,2017-08,Up-Sampling,47.0,78.99,47.0,0.79,59.5,0.79,ito:ITO_00101,Vision process,Accuracy\\ \\(8\\ emotion\\)
1,1,Facial Expression Recognition,AffectNet,2017-08,Weighted-Loss,58.0,97.48,11.0,0.18,59.5,0.97,ito:ITO_00101,Vision process,Accuracy\\ \\(8\\ emotion\\)
2,1,Facial Expression Recognition,AffectNet,2019-05,RAN (ResNet-18+),59.5,100.0,1.5,0.03,59.5,1.0,ito:ITO_00101,Vision process,Accuracy\\ \\(8\\ emotion\\)
0,1,RGB Salient Object Detection,DUTS-TE,2017-08,PiCANet,0.757,91.98,0.757,0.92,0.823,0.92,ito:ITO_00101,Vision process,mean\\ F\\-Measure
1,1,RGB Salient Object Detection,DUTS-TE,2018-06,DGRL,0.79,95.99,0.0,0.0,0.823,0.96,ito:ITO_00101,Vision process,mean\\ F\\-Measure
2,1,RGB Salient Object Detection,DUTS-TE,2019-06,BASNet,0.823,100.0,0.0,0.0,0.823,1.0,ito:ITO_00101,Vision process,mean\\ F\\-Measure
0,1,Depth Completion,KITTI Depth Completion,2017-08,SparseConvs,10.0,14.29,10,0.14,70,0.14,ito:ITO_00101,Vision process,Runtime\\ \\[ms\\]
1,1,Depth Completion,KITTI Depth Completion,2018-08,Spade-sD,40.0,57.14,30,0.43,70,0.57,ito:ITO_00101,Vision process,Runtime\\ \\[ms\\]
2,1,Depth Completion,KITTI Depth Completion,2018-08,Spade-RGBsD,70.0,100.0,30,0.43,70,1.0,ito:ITO_00101,Vision process,Runtime\\ \\[ms\\]
0,1,Facial Landmark Detection,300W,2017-08,FPN,0.1043,100.0,0.1043,1.0,0.1043,0.0,ito:ITO_00101,Vision process,Mean\\ Error\\ Rate
1,1,Face Alignment,COFW,2018-02,PCD-CNNCVPR 18,5.77,100.0,5.77,1.0,5.77,0.05,ito:ITO_00101,Vision process,Mean\\ Error\\ Rate
2,1,Face Alignment,IBUG,2018-12,DenseU-Net + Dual Transformer,6.73,100.0,6.73,1.0,6.73,0.05,ito:ITO_00101,Vision process,Mean\\ Error\\ Rate
3,1,Visual Odometry,KITTI2015,2019-12,abc,123.0,100.0,123,1.0,123,1.0,ito:ITO_00101,Vision process,Mean\\ Error\\ Rate
0,1,Semi-supervised Anomaly Detection,UBI-Fights,2017-08,Adversarial Generator,0.147,100.0,0.147,1.0,0.147,1.0,ito:ITO_00101,Vision process,Decidability
1,1,Abnormal Event Detection In Video,UBI-Fights,2017-08,Adversarial Generator,0.011,100.0,0.011,1.0,0.011,0.07,ito:ITO_00101,Vision process,Decidability
0,1,Video Summarization,TvSum,2017-08,M-AVS,61.0,99.32,61.0,0.99,61.42,0.99,ito:ITO_00101,Vision process,F1\\-score\\ \\(Canonical\\)
1,1,Video Summarization,TvSum,2018-12,VASNet,61.42,100.0,0.4,0.01,61.42,1.0,ito:ITO_00101,Vision process,F1\\-score\\ \\(Canonical\\)
2,1,Video Summarization,SumMe,2017-08,M-AVS,44.4,89.32,44.4,0.89,49.71,0.72,ito:ITO_00101,Vision process,F1\\-score\\ \\(Canonical\\)
3,1,Video Summarization,SumMe,2018-12,VASNet,49.71,100.0,5.3,0.11,49.71,0.81,ito:ITO_00101,Vision process,F1\\-score\\ \\(Canonical\\)
4,1,Supervised Video Summarization,TvSum,2017-12,DR-DSN,58.1,99.32,58.1,0.99,58.5,0.95,ito:ITO_00101,Vision process,F1\\-score\\ \\(Canonical\\)
5,1,Supervised Video Summarization,TvSum,2018-11,CSNet,58.5,100.0,0.4,0.01,58.5,0.95,ito:ITO_00101,Vision process,F1\\-score\\ \\(Canonical\\)
6,1,Supervised Video Summarization,SumMe,2017-12,DR-DSN,42.1,86.63,42.1,0.87,48.6,0.69,ito:ITO_00101,Vision process,F1\\-score\\ \\(Canonical\\)
7,1,Supervised Video Summarization,SumMe,2018-11,CSNet,48.6,100.0,6.5,0.13,48.6,0.79,ito:ITO_00101,Vision process,F1\\-score\\ \\(Canonical\\)
0,1,Video Summarization,TvSum,2017-08,M-AVS,61.8,99.09,61.8,0.99,62.37,0.99,ito:ITO_00101,Vision process,F1\\-score\\ \\(Augmented\\)
1,1,Video Summarization,TvSum,2018-12,VASNet,62.37,100.0,0.6,0.01,62.37,1.0,ito:ITO_00101,Vision process,F1\\-score\\ \\(Augmented\\)
2,1,Video Summarization,SumMe,2017-08,M-AVS,46.1,90.23,46.1,0.9,51.09,0.74,ito:ITO_00101,Vision process,F1\\-score\\ \\(Augmented\\)
3,1,Video Summarization,SumMe,2018-12,VASNet,51.09,100.0,5.0,0.1,51.09,0.82,ito:ITO_00101,Vision process,F1\\-score\\ \\(Augmented\\)
4,1,Supervised Video Summarization,SumMe,2017-12,DR-DSN,43.9,90.14,43.9,0.9,48.7,0.7,ito:ITO_00101,Vision process,F1\\-score\\ \\(Augmented\\)
5,1,Supervised Video Summarization,SumMe,2018-11,CSNet,48.7,100.0,4.8,0.1,48.7,0.78,ito:ITO_00101,Vision process,F1\\-score\\ \\(Augmented\\)
6,1,Supervised Video Summarization,TvSum,2017-12,DR-DSN,59.8,100.0,59.8,1.0,59.8,0.96,ito:ITO_00101,Vision process,F1\\-score\\ \\(Augmented\\)
0,1,Scene Text Detection,ICDAR 2015,2017-09,FTSN + MNMS,84.1,96.78,84.1,0.97,86.9,0.88,ito:ITO_00101,Vision process,H\\-Mean
1,1,Scene Text Detection,ICDAR 2015,2018-01,SLPR,84.5,97.24,0.4,0.0,86.9,0.89,ito:ITO_00101,Vision process,H\\-Mean
2,1,Scene Text Detection,ICDAR 2015,2019-04,CRAFT,86.9,100.0,2.4,0.03,86.9,0.91,ito:ITO_00101,Vision process,H\\-Mean
3,1,Scene Text Detection,Total-Text,2017-09,FTSN,81.3,97.25,81.3,0.97,83.6,0.85,ito:ITO_00101,Vision process,H\\-Mean
4,1,Scene Text Detection,Total-Text,2019-04,CRAFT,83.6,100.0,2.3,0.03,83.6,0.88,ito:ITO_00101,Vision process,H\\-Mean
5,1,Scene Text Detection,MSRA-TD500,2017-09,FTSN + MNMS,82.0,98.91,82.0,0.99,82.9,0.86,ito:ITO_00101,Vision process,H\\-Mean
6,1,Scene Text Detection,MSRA-TD500,2019-04,CRAFT,82.9,100.0,0.9,0.01,82.9,0.87,ito:ITO_00101,Vision process,H\\-Mean
7,1,Scene Text Detection,SCUT-CTW1500,2018-01,SLPR,74.8,89.58,74.8,0.9,83.5,0.79,ito:ITO_00101,Vision process,H\\-Mean
8,1,Scene Text Detection,SCUT-CTW1500,2019-04,CRAFT,83.5,100.0,8.7,0.1,83.5,0.88,ito:ITO_00101,Vision process,H\\-Mean
9,1,Scene Text Detection,ICDAR 2013,2019-04,CRAFT,95.2,100.0,95.2,1.0,95.2,1.0,ito:ITO_00101,Vision process,H\\-Mean
10,1,Scene Text Detection,ICDAR 2017 MLT,2019-04,CRAFT,73.9,100.0,73.9,1.0,73.9,0.78,ito:ITO_00101,Vision process,H\\-Mean
11,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,16.1,100.0,16.1,1.0,16.1,0.17,ito:ITO_00101,Vision process,H\\-Mean
0,1,Person Re-Identification,PRID2011,2017-09,DGM+MLAPG+,99.0,99.0,99.0,0.99,100.0,0.99,ito:ITO_00101,Vision process,Rank\\-20
1,1,Person Re-Identification,PRID2011,2017-10,SMP*,99.4,99.4,0.4,0.0,100.0,0.99,ito:ITO_00101,Vision process,Rank\\-20
2,1,Person Re-Identification,PRID2011,2018-06,Snippet (Supervised),100.0,100.0,0.6,0.01,100.0,1.0,ito:ITO_00101,Vision process,Rank\\-20
3,1,Person Re-Identification,DukeTracklet,2018-09,TAUDL,57.2,74.77,57.2,0.75,76.5,0.57,ito:ITO_00101,Vision process,Rank\\-20
4,1,Person Re-Identification,DukeTracklet,2019-03,UTAL,76.5,100.0,19.3,0.25,76.5,0.76,ito:ITO_00101,Vision process,Rank\\-20
5,1,Person Re-Identification,MARS,2019-03,UTAL,77.8,100.0,77.8,1.0,77.8,0.78,ito:ITO_00101,Vision process,Rank\\-20
6,1,Person Re-Identification,iLIDS-VID,2019-03,UTAL,83.8,89.63,83.8,0.9,93.5,0.84,ito:ITO_00101,Vision process,Rank\\-20
7,1,Person Re-Identification,iLIDS-VID,2019-08,TKP,93.5,100.0,9.7,0.1,93.5,0.94,ito:ITO_00101,Vision process,Rank\\-20
8,1,Unsupervised Person Re-Identification,Market-1501->DukeMTMC-reID,2019-04,ECN,84.2,100.0,84.2,1.0,84.2,0.84,ito:ITO_00101,Vision process,Rank\\-20
9,1,Unsupervised Person Re-Identification,DukeMTMC-reID->Market-1501,2019-04,ECN,94.5,100.0,94.5,1.0,94.5,0.94,ito:ITO_00101,Vision process,Rank\\-20
0,1,Sign Language Recognition,RWTH-PHOENIX-Weather 2014,2017-10,SubUNets,40.7,100.0,40.7,1.0,40.7,1.0,ito:ITO_00101,Vision process,Word\\ Error\\ Rate\\ \\(WER\\)
1,1,Plan2Scene,Plan2Scene,2017-10,SubUNets,40.7,100.0,40.7,1.0,40.7,1.0,ito:ITO_00101,Vision process,Word\\ Error\\ Rate\\ \\(WER\\)
0,1,Head Pose Estimation,BIWI,2017-10,Multi-Loss ResNet50,4.895,100.0,4.895,1.0,4.895,1.0,ito:ITO_00101,Vision process,MAE\\ \\(trained\\ with\\ BIWI\\ data\\)
0,1,Face Verification,IJB-A,2017-10,VGGFace2_ft,0.99,100.0,0.99,1.0,0.99,1.0,ito:ITO_00101,Vision process,TAR\\ at\\ FAR=0\\.1
0,1,Face Sketch Synthesis,CUHK,2017-10,PS2-MAN,73.61,99.16,73.61,0.99,74.23,0.99,ito:ITO_00101,Vision process,FSIM
1,1,Face Sketch Synthesis,CUHK,2018-12,Residual net + Pseudo Sketch Feature Loss + LSGAN,74.23,100.0,0.6,0.01,74.23,1.0,ito:ITO_00101,Vision process,FSIM
2,1,Face Sketch Synthesis,CUFSF,2018-12,Residual net + Pseudo Sketch Feature Loss + LSGAN,71.59,100.0,71.59,1.0,71.59,0.96,ito:ITO_00101,Vision process,FSIM
3,1,Face Sketch Synthesis,CUFS,2018-12,Residual net + Pseudo Sketch Feature Loss + LSGAN,72.56,100.0,72.56,1.0,72.56,0.98,ito:ITO_00101,Vision process,FSIM
0,1,Skeleton Based Action Recognition,J-HMBD Early Action,2017-10,GAT,58.1,95.87,58.1,0.96,60.6,0.48,ito:ITO_00101,Vision process,10%
1,1,Skeleton Based Action Recognition,J-HMBD Early Action,2018-02,DR^2N,60.6,100.0,2.5,0.04,60.6,0.5,ito:ITO_00101,Vision process,10%
2,1,Face Anonymization,2019_test set,2019-09,sm,122.0,100.0,122,1.0,122,1.0,ito:ITO_00101,Vision process,10%
0,1,6D Pose Estimation,YCB-Video,2017-11,PoseCNN+ICP,93.0,96.77,93.0,0.97,96.1,0.97,ito:ITO_00101,Vision process,ADDS\\ AUC
1,1,6D Pose Estimation,YCB-Video,2019-01,DenseFusion,93.1,96.88,0.1,0.0,96.1,0.97,ito:ITO_00101,Vision process,ADDS\\ AUC
2,1,6D Pose Estimation,YCB-Video,2019-11,PVN3D,96.1,100.0,3.0,0.03,96.1,1.0,ito:ITO_00101,Vision process,ADDS\\ AUC
0,1,6D Pose Estimation using RGBD,YCB-Video,2017-11,ALL PoseCNN+ICP,93.0,97.38,93.0,0.97,95.5,0.97,ito:ITO_00101,Vision process,Mean\\ ADD\\-S
1,1,6D Pose Estimation using RGBD,YCB-Video,2019-11,PVN3D,95.5,100.0,2.5,0.03,95.5,1.0,ito:ITO_00101,Vision process,Mean\\ ADD\\-S
2,1,6D Pose Estimation using RGB,YCB-Video,2017-11,PoseCNN,75.9,100.0,75.9,1.0,75.9,0.79,ito:ITO_00101,Vision process,Mean\\ ADD\\-S
0,1,Image-to-Image Translation,SYNTHIA Fall-to-Winter,2017-11,CyCADA,85.7,100.0,85.7,1.0,85.7,1.0,ito:ITO_00101,Vision process,fwIOU
1,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2017-11,CyCADA pixel+feat,72.4,100.0,72.4,1.0,72.4,0.84,ito:ITO_00101,Vision process,fwIOU
0,1,Unsupervised Domain Adaptation,Duke to Market,2017-11,SPGAN,51.5,58.72,51.5,0.59,87.7,0.59,ito:ITO_00101,Vision process,rank\\-1
1,1,Unsupervised Domain Adaptation,Duke to Market,2018-11,SSG,80.0,91.22,28.5,0.32,87.7,0.91,ito:ITO_00101,Vision process,rank\\-1
2,1,Unsupervised Domain Adaptation,Duke to Market,2020-01,MMT,87.7,100.0,7.7,0.09,87.7,1.0,ito:ITO_00101,Vision process,rank\\-1
3,1,Unsupervised Domain Adaptation,Market to Duke,2017-11,SPGAN,41.1,52.69,41.1,0.53,78.0,0.47,ito:ITO_00101,Vision process,rank\\-1
4,1,Unsupervised Domain Adaptation,Market to Duke,2018-11,SSG,73.0,93.59,31.9,0.41,78.0,0.83,ito:ITO_00101,Vision process,rank\\-1
5,1,Unsupervised Domain Adaptation,Market to Duke,2020-01,MMT,78.0,100.0,5.0,0.06,78.0,0.89,ito:ITO_00101,Vision process,rank\\-1
6,1,Unsupervised Domain Adaptation,Market to MSMT,2017-11,PTGAN,10.2,20.73,10.2,0.21,49.2,0.12,ito:ITO_00101,Vision process,rank\\-1
7,1,Unsupervised Domain Adaptation,Market to MSMT,2018-11,SSG,31.6,64.23,21.4,0.43,49.2,0.36,ito:ITO_00101,Vision process,rank\\-1
8,1,Unsupervised Domain Adaptation,Market to MSMT,2020-01,MMT,49.2,100.0,17.6,0.36,49.2,0.56,ito:ITO_00101,Vision process,rank\\-1
9,1,Unsupervised Domain Adaptation,Duke to MSMT,2017-11,PTGAN,11.8,23.55,11.8,0.24,50.1,0.13,ito:ITO_00101,Vision process,rank\\-1
10,1,Unsupervised Domain Adaptation,Duke to MSMT,2018-11,SSG,32.2,64.27,20.4,0.41,50.1,0.37,ito:ITO_00101,Vision process,rank\\-1
11,1,Unsupervised Domain Adaptation,Duke to MSMT,2020-01,MMT,50.1,100.0,17.9,0.36,50.1,0.57,ito:ITO_00101,Vision process,rank\\-1
0,1,Unsupervised Domain Adaptation,Duke to Market,2017-11,SPGAN,70.1,73.87,70.1,0.74,94.9,0.74,ito:ITO_00101,Vision process,rank\\-5
1,1,Unsupervised Domain Adaptation,Duke to Market,2018-11,SSG,90.0,94.84,19.9,0.21,94.9,0.95,ito:ITO_00101,Vision process,rank\\-5
2,1,Unsupervised Domain Adaptation,Duke to Market,2020-01,MMT,94.9,100.0,4.9,0.05,94.9,1.0,ito:ITO_00101,Vision process,rank\\-5
3,1,Unsupervised Domain Adaptation,Market to Duke,2017-11,SPGAN,56.6,63.74,56.6,0.64,88.8,0.6,ito:ITO_00101,Vision process,rank\\-5
4,1,Unsupervised Domain Adaptation,Market to Duke,2018-11,SSG,80.6,90.77,24.0,0.27,88.8,0.85,ito:ITO_00101,Vision process,rank\\-5
5,1,Unsupervised Domain Adaptation,Market to Duke,2020-01,MMT,88.8,100.0,8.2,0.09,88.8,0.94,ito:ITO_00101,Vision process,rank\\-5
6,1,Unsupervised Domain Adaptation,Duke to MSMT,2019-04,ECN,41.5,64.95,41.5,0.65,63.9,0.44,ito:ITO_00101,Vision process,rank\\-5
7,1,Unsupervised Domain Adaptation,Duke to MSMT,2020-01,MMT,63.9,100.0,22.4,0.35,63.9,0.67,ito:ITO_00101,Vision process,rank\\-5
8,1,Unsupervised Domain Adaptation,Market to MSMT,2019-04,ECN,36.3,57.53,36.3,0.58,63.1,0.38,ito:ITO_00101,Vision process,rank\\-5
9,1,Unsupervised Domain Adaptation,Market to MSMT,2020-01,MMT,63.1,100.0,26.8,0.42,63.1,0.66,ito:ITO_00101,Vision process,rank\\-5
0,1,Unsupervised Domain Adaptation,Duke to Market,2017-11,SPGAN,76.8,79.26,76.8,0.79,96.9,0.79,ito:ITO_00101,Vision process,rank\\-10
1,1,Unsupervised Domain Adaptation,Duke to Market,2018-11,SSG,92.4,95.36,15.6,0.16,96.9,0.95,ito:ITO_00101,Vision process,rank\\-10
2,1,Unsupervised Domain Adaptation,Duke to Market,2020-01,MMT,96.9,100.0,4.5,0.05,96.9,1.0,ito:ITO_00101,Vision process,rank\\-10
3,1,Unsupervised Domain Adaptation,Market to Duke,2017-11,SPGAN,63.0,68.11,63.0,0.68,92.5,0.65,ito:ITO_00101,Vision process,rank\\-10
4,1,Unsupervised Domain Adaptation,Market to Duke,2018-11,SSG,83.2,89.95,20.2,0.22,92.5,0.86,ito:ITO_00101,Vision process,rank\\-10
5,1,Unsupervised Domain Adaptation,Market to Duke,2020-01,MMT,92.5,100.0,9.3,0.1,92.5,0.95,ito:ITO_00101,Vision process,rank\\-10
6,1,Unsupervised Domain Adaptation,Duke to MSMT,2017-11,PTGAN,27.4,39.26,27.4,0.39,69.8,0.28,ito:ITO_00101,Vision process,rank\\-10
7,1,Unsupervised Domain Adaptation,Duke to MSMT,2018-11,SSG,51.2,73.35,23.8,0.34,69.8,0.53,ito:ITO_00101,Vision process,rank\\-10
8,1,Unsupervised Domain Adaptation,Duke to MSMT,2020-01,MMT,69.8,100.0,18.6,0.27,69.8,0.72,ito:ITO_00101,Vision process,rank\\-10
9,1,Unsupervised Domain Adaptation,Market to MSMT,2017-11,PTGAN,24.4,35.47,24.4,0.35,68.8,0.25,ito:ITO_00101,Vision process,rank\\-10
10,1,Unsupervised Domain Adaptation,Market to MSMT,2018-11,SSG,49.6,72.09,25.2,0.37,68.8,0.51,ito:ITO_00101,Vision process,rank\\-10
11,1,Unsupervised Domain Adaptation,Market to MSMT,2020-01,MMT,68.8,100.0,19.2,0.28,68.8,0.71,ito:ITO_00101,Vision process,rank\\-10
0,1,Pedestrian Detection,CityPersons,2017-11,RepLoss,56.9,100.0,56.9,1.0,56.9,1.0,ito:ITO_00101,Vision process,Heavy\\ MR\\^\\-2
0,1,Pedestrian Detection,CityPersons,2017-11,RepLoss,16.8,97.67,16.8,0.98,17.2,0.98,ito:ITO_00101,Vision process,Partial\\ MR\\^\\-2
1,1,Pedestrian Detection,CityPersons,2018-07,TLL,17.2,100.0,0.4,0.02,17.2,1.0,ito:ITO_00101,Vision process,Partial\\ MR\\^\\-2
0,1,Pedestrian Detection,CityPersons,2017-11,RepLoss,7.6,76.0,7.6,0.76,10.0,0.76,ito:ITO_00101,Vision process,Bare\\ MR\\^\\-2
1,1,Pedestrian Detection,CityPersons,2018-07,TLL,10.0,100.0,2.4,0.24,10.0,1.0,ito:ITO_00101,Vision process,Bare\\ MR\\^\\-2
0,1,Action Recognition In Videos,Jester,2017-11,MultiScale TRN,95.31,98.56,95.31,0.99,96.7,0.99,ito:ITO_00101,Vision process,Val
1,1,Action Recognition In Videos,Jester,2018-07,MFNet,96.68,99.98,1.4,0.01,96.7,1.0,ito:ITO_00101,Vision process,Val
2,1,Action Recognition In Videos,Jester,2019-05,"CPNet Res34, 5 CP",96.7,100.0,0.0,0.0,96.7,1.0,ito:ITO_00101,Vision process,Val
3,1,Action Recognition,Jester,2017-11,MultiScale TRN,95.31,98.56,95.31,0.99,96.7,0.99,ito:ITO_00101,Vision process,Val
4,1,Action Recognition,Jester,2018-07,MFNet,96.68,99.98,1.4,0.01,96.7,1.0,ito:ITO_00101,Vision process,Val
5,1,Action Recognition,Jester,2019-05,"CPNet Res34, 5 CP",96.7,100.0,0.0,0.0,96.7,1.0,ito:ITO_00101,Vision process,Val
0,1,3D Semantic Instance Segmentation,ScanNetV2,2017-11,SGPN,14.3,23.4,14.3,0.23,61.1,0.15,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.50
1,1,3D Semantic Instance Segmentation,ScanNetV2,2018-12,3D-SIS,36.2,59.25,21.9,0.36,61.1,0.38,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.50
2,1,3D Semantic Instance Segmentation,ScanNetV2,2018-12,3D-SIS,38.2,62.52,2.0,0.03,61.1,0.4,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.50
3,1,3D Semantic Instance Segmentation,ScanNetV2,2020-03,3D-MPA,61.1,100.0,22.9,0.37,61.1,0.64,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.50
4,1,Traffic Sign Recognition,DFG traffic-sign dataset,2019-04,Mask R-CNN with adaptations for traffic sings and augmentations (ResNet50),95.5,100.0,95.5,1.0,95.5,1.0,ito:ITO_00101,Vision process,mAP\\-at\\-0\\.50
0,1,6D Pose Estimation using RGBD,Tejani,2017-11,SSD-6D,0.988,100.0,0.988,1.0,0.988,1.0,ito:ITO_00101,Vision process,IoU\\-2D
0,1,6D Pose Estimation using RGBD,Tejani,2017-11,SSD-6D,0.963,100.0,0.963,1.0,0.963,1.0,ito:ITO_00101,Vision process,IoU\\-3D
0,1,6D Pose Estimation using RGBD,Tejani,2017-11,SSD-6D,0.724,100.0,0.724,1.0,0.724,1.0,ito:ITO_00101,Vision process,VSS\\-2D
0,1,6D Pose Estimation using RGBD,Tejani,2017-11,SSD-6D,0.854,100.0,0.854,1.0,0.854,1.0,ito:ITO_00101,Vision process,VSS\\-3D
0,1,Text-to-Image Generation,COCO,2017-11,AttnGAN,25.88,72.19,25.88,0.72,35.85,0.72,ito:ITO_00101,Vision process,SOA\\-C
1,1,Text-to-Image Generation,COCO,2019-04,DM-GAN,33.44,93.28,7.6,0.21,35.85,0.93,ito:ITO_00101,Vision process,SOA\\-C
2,1,Text-to-Image Generation,COCO,2019-10,OP-GAN,35.85,100.0,2.4,0.07,35.85,1.0,ito:ITO_00101,Vision process,SOA\\-C
0,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2017-11,AttnGAN,11.9,70.41,11.9,0.7,16.9,0.23,ito:ITO_00101,Vision process,Real
1,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2019-04,DM-GAN,16.9,100.0,5.0,0.3,16.9,0.32,ito:ITO_00101,Vision process,Real
2,1,DeepFake Detection,FaceForensics,2019-01,XceptionNet,52.4,100.0,52.4,1.0,52.4,1.0,ito:ITO_00101,Vision process,Real
0,1,Fundus to Angiography Generation,Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients,2017-11,pix2pixHD,0.00258,100.0,0.00258,1.0,0.00258,0.0,ito:ITO_00101,Vision process,Kernel\\ Inception\\ Distance
1,1,Image-to-Image Translation,cat2dog,2019-07,U-GAT-IT,7.07,100.0,7.07,1.0,7.07,0.61,ito:ITO_00101,Vision process,Kernel\\ Inception\\ Distance
2,1,Image-to-Image Translation,zebra2horse,2019-07,U-GAT-IT,7.47,100.0,7.47,1.0,7.47,0.64,ito:ITO_00101,Vision process,Kernel\\ Inception\\ Distance
3,1,Image-to-Image Translation,anime-to-selfie,2019-07,U-GAT-IT,11.52,100.0,11.52,1.0,11.52,0.99,ito:ITO_00101,Vision process,Kernel\\ Inception\\ Distance
4,1,Image-to-Image Translation,selfie-to-anime,2019-07,U-GAT-IT,11.61,100.0,11.61,1.0,11.61,1.0,ito:ITO_00101,Vision process,Kernel\\ Inception\\ Distance
5,1,Image-to-Image Translation,portrait2photo,2019-07,U-GAT-IT,1.69,100.0,1.69,1.0,1.69,0.15,ito:ITO_00101,Vision process,Kernel\\ Inception\\ Distance
6,1,Image-to-Image Translation,photo2portrait,2019-07,U-GAT-IT,1.79,100.0,1.79,1.0,1.79,0.15,ito:ITO_00101,Vision process,Kernel\\ Inception\\ Distance
7,1,Image-to-Image Translation,vangogh2photo,2019-07,U-GAT-IT,5.61,100.0,5.61,1.0,5.61,0.48,ito:ITO_00101,Vision process,Kernel\\ Inception\\ Distance
8,1,Image-to-Image Translation,photo2vangogh,2019-07,U-GAT-IT,4.28,100.0,4.28,1.0,4.28,0.37,ito:ITO_00101,Vision process,Kernel\\ Inception\\ Distance
9,1,Image-to-Image Translation,horse2zebra,2019-07,U-GAT-IT,7.06,100.0,7.06,1.0,7.06,0.61,ito:ITO_00101,Vision process,Kernel\\ Inception\\ Distance
10,1,Image-to-Image Translation,dog2cat,2019-07,U-GAT-IT,8.15,100.0,8.15,1.0,8.15,0.7,ito:ITO_00101,Vision process,Kernel\\ Inception\\ Distance
0,1,Shadow Detection,SBU,2017-12,A+DNet,5.4,66.34,5.4,0.66,8.14,0.66,ito:ITO_00101,Vision process,BER
1,1,Shadow Detection,SBU,2017-12,ST-CGAN,8.14,100.0,2.7,0.33,8.14,1.0,ito:ITO_00101,Vision process,BER
0,1,Weakly Supervised Action Localization,THUMOS 2014,2017-12,STPN,27.0,76.49,27.0,0.76,35.3,0.76,ito:ITO_00101,Vision process,mAP@0\\.1:0\\.7
1,1,Weakly Supervised Action Localization,THUMOS 2014,2019-05,MAAN,31.6,89.52,4.6,0.13,35.3,0.9,ito:ITO_00101,Vision process,mAP@0\\.1:0\\.7
2,1,Weakly Supervised Action Localization,THUMOS 2014,2019-06,CMCS,32.4,91.78,0.8,0.02,35.3,0.92,ito:ITO_00101,Vision process,mAP@0\\.1:0\\.7
3,1,Weakly Supervised Action Localization,THUMOS 2014,2019-11,BaS-Net,35.3,100.0,2.9,0.08,35.3,1.0,ito:ITO_00101,Vision process,mAP@0\\.1:0\\.7
0,1,3D Human Pose Estimation,3DPW,2017-12,HMR,37.4,100.0,37.4,1.0,37.4,1.0,ito:ITO_00101,Vision process,acceleration\\ error
0,1,3D Human Pose Estimation,3DPW,2017-12,HMR,76.7,94.34,76.7,0.94,81.3,0.94,ito:ITO_00101,Vision process,PA\\-MPJPE
1,1,3D Human Pose Estimation,3DPW,2017-12,HMR,81.3,100.0,4.6,0.06,81.3,1.0,ito:ITO_00101,Vision process,PA\\-MPJPE
0,1,Pose Transfer,Deep-Fashion,2017-12,Deformable GAN,30.07,100.0,30.07,1.0,30.07,1.0,ito:ITO_00101,Vision process,Retrieval\\ Top10\\ Recall
0,1,Multivariate Time Series Imputation,PEMS-SF,2018-01,MaskGAN,6.02,39.5,6.02,0.4,15.24,0.4,ito:ITO_00101,Vision process,L2\\ Loss\\ \\(10\\^\\-4\\)
1,1,Multivariate Time Series Imputation,PEMS-SF,2018-12,GRUI,15.24,100.0,9.2,0.6,15.24,1.0,ito:ITO_00101,Vision process,L2\\ Loss\\ \\(10\\^\\-4\\)
0,1,Panoptic Segmentation,Cityscapes val,2018-01,MRCNN + PSPNet (ResNet-101),66.4,94.45,66.4,0.94,70.3,0.94,ito:ITO_00101,Vision process,PQst
1,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS,70.3,100.0,3.9,0.06,70.3,1.0,ito:ITO_00101,Vision process,PQst
2,1,Panoptic Segmentation,COCO test-dev,2018-09,JSIS-Net (ResNet-50),23.4,53.06,23.4,0.53,44.1,0.33,ito:ITO_00101,Vision process,PQst
3,1,Panoptic Segmentation,COCO test-dev,2018-12,AUNet (ResNeXt-152-FPN),32.5,73.7,9.1,0.21,44.1,0.46,ito:ITO_00101,Vision process,PQst
4,1,Panoptic Segmentation,COCO test-dev,2019-01,UPSNet (ResNet-101-FPN),36.7,83.22,4.2,0.1,44.1,0.52,ito:ITO_00101,Vision process,PQst
5,1,Panoptic Segmentation,COCO test-dev,2020-03,EPSNet (ResNet-101-FPN),44.1,100.0,7.4,0.17,44.1,0.63,ito:ITO_00101,Vision process,PQst
0,1,Multimodal Activity Recognition,Moments in Time Dataset,2018-01,Ensemble (SVM),57.67,91.96,57.67,0.92,62.71,0.92,ito:ITO_00101,Vision process,Top\\-5\\ \\(%\\)
1,1,Multimodal Activity Recognition,Moments in Time Dataset,2019-05,AssembleNet,62.71,100.0,5.0,0.08,62.71,1.0,ito:ITO_00101,Vision process,Top\\-5\\ \\(%\\)
0,1,Multimodal Activity Recognition,Moments in Time Dataset,2018-01,Ensemble (SVM),31.16,90.93,31.16,0.91,34.27,0.36,ito:ITO_00101,Vision process,Top\\-1\\ \\(%\\)
1,1,Multimodal Activity Recognition,Moments in Time Dataset,2019-05,AssembleNet,34.27,100.0,3.1,0.09,34.27,0.39,ito:ITO_00101,Vision process,Top\\-1\\ \\(%\\)
2,1,Unsupervised Person Re-Identification,Market-1501->DukeMTMC-reID,2020-01,MMT-ResNet50,78.0,100.0,78,1.0,78,0.89,ito:ITO_00101,Vision process,Top\\-1\\ \\(%\\)
3,1,Unsupervised Person Re-Identification,DukeMTMC-reID->MSMT17,2020-01,MMT-ResNet50,50.0,100.0,50,1.0,50,0.57,ito:ITO_00101,Vision process,Top\\-1\\ \\(%\\)
4,1,Unsupervised Person Re-Identification,Market-1501->MSMT17,2020-01,MMT-ResNet50,49.2,100.0,49.2,1.0,49.2,0.56,ito:ITO_00101,Vision process,Top\\-1\\ \\(%\\)
5,1,Unsupervised Person Re-Identification,DukeMTMC-reID->Market-1501,2020-01,MMT-ResNet50,87.7,100.0,87.7,1.0,87.7,1.0,ito:ITO_00101,Vision process,Top\\-1\\ \\(%\\)
0,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-01,MaskGAN,0.793,69.5,0.793,0.7,1.141,0.7,ito:ITO_00101,Vision process,Path\\ Length
1,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-12,GRUI,1.141,100.0,0.3,0.26,1.141,1.0,ito:ITO_00101,Vision process,Path\\ Length
0,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-01,MaskGAN,9.622,64.36,9.622,0.64,14.95,0.64,ito:ITO_00101,Vision process,Step\\ Change\\ \\(10\\^−3\\)
1,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-12,GRUI,14.95,100.0,5.3,0.35,14.95,1.0,ito:ITO_00101,Vision process,Step\\ Change\\ \\(10\\^−3\\)
0,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-01,MaskGAN,0.68,98.55,0.68,0.99,0.69,0.99,ito:ITO_00101,Vision process,Path\\ Difference
1,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-12,GRUI,0.69,100.0,0.0,0.0,0.69,1.0,ito:ITO_00101,Vision process,Path\\ Difference
0,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-01,MaskGAN,0.427,100.0,0.427,1.0,0.427,1.0,ito:ITO_00101,Vision process,Player\\ Distance
0,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-01,MaskGAN,4.592,97.64,4.592,0.98,4.703,0.98,ito:ITO_00101,Vision process,OOB\\ Rate\\ \\(10\\^−3\\)
1,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-12,GRUI,4.703,100.0,0.1,0.02,4.703,1.0,ito:ITO_00101,Vision process,OOB\\ Rate\\ \\(10\\^−3\\)
0,1,Image Inpainting,Places2 val,2018-01,ContextAttention,2.1,100.0,2.1,1.0,2.1,1.0,ito:ITO_00101,Vision process,rect\\ mask\\ l2\\ err
0,1,Image Inpainting,Places2 val,2018-01,ContextAttention,4.7,100.0,4.7,1.0,4.7,1.0,ito:ITO_00101,Vision process,free\\-form\\ mask\\ l2\\ err
0,1,Image Inpainting,Places2 val,2018-01,ContextAttention,8.6,100.0,8.6,1.0,8.6,1.0,ito:ITO_00101,Vision process,rect\\ mask\\ l1\\ error
0,1,Image Inpainting,Places2 val,2018-01,ContextAttention,17.2,100.0,17.2,1.0,17.2,1.0,ito:ITO_00101,Vision process,free\\-form\\ mask\\ l1\\ err
0,1,Video Instance Segmentation,YouTube-VIS validation,2018-02,OSMN,28.6,100.0,28.6,1.0,28.6,1.0,ito:ITO_00101,Vision process,AR1
0,1,Video Instance Segmentation,YouTube-VIS validation,2018-02,OSMN,33.1,100.0,33.1,1.0,33.1,1.0,ito:ITO_00101,Vision process,AR10
0,1,Music Modeling,Nottingham,2018-03,TCN,3.07,75.8,3.07,0.76,4.05,0.76,ito:ITO_00101,Vision process,NLL
1,1,Music Modeling,Nottingham,2018-03,LSTM,3.29,81.23,0.2,0.05,4.05,0.81,ito:ITO_00101,Vision process,NLL
2,1,Music Modeling,Nottingham,2018-03,GRU,3.46,85.43,0.2,0.05,4.05,0.85,ito:ITO_00101,Vision process,NLL
3,1,Music Modeling,Nottingham,2018-03,RNN,4.05,100.0,0.6,0.15,4.05,1.0,ito:ITO_00101,Vision process,NLL
4,1,Image Relighting,Image Relighting,2018-03,TCN,3.07,75.8,3.07,0.76,4.05,0.76,ito:ITO_00101,Vision process,NLL
5,1,Image Relighting,Image Relighting,2018-03,LSTM,3.29,81.23,0.2,0.05,4.05,0.81,ito:ITO_00101,Vision process,NLL
6,1,Image Relighting,Image Relighting,2018-03,GRU,3.46,85.43,0.2,0.05,4.05,0.85,ito:ITO_00101,Vision process,NLL
7,1,Image Relighting,Image Relighting,2018-03,RNN,4.05,100.0,0.6,0.15,4.05,1.0,ito:ITO_00101,Vision process,NLL
8,1,Music Modeling,JSB Chorales,2018-09,Music Transformer,0.335,100.0,0.335,1.0,0.335,0.08,ito:ITO_00101,Vision process,NLL
9,1,person reposing,person reposing,2018-09,Music Transformer,0.335,100.0,0.335,1.0,0.335,0.08,ito:ITO_00101,Vision process,NLL
0,1,Facial Beauty Prediction,ECCV HotOrNot,2018-03,CNN features + Bayesian ridge regression,0.468,100.0,0.468,1.0,0.468,1.0,ito:ITO_00101,Vision process,Pearson\\ Correlation
0,1,One-Shot Segmentation,Cluttered Omniglot,2018-03,MaskNet,65.6,100.0,65.6,1.0,65.6,1.0,ito:ITO_00101,Vision process,IoU\\ \\[32\\ distractors\\]
0,1,One-Shot Segmentation,Cluttered Omniglot,2018-03,MaskNet,95.8,98.66,95.8,0.99,97.1,0.99,ito:ITO_00101,Vision process,IoU\\ \\[4\\ distractors\\]
1,1,One-Shot Segmentation,Cluttered Omniglot,2018-03,Siamese-U-Net,97.1,100.0,1.3,0.01,97.1,1.0,ito:ITO_00101,Vision process,IoU\\ \\[4\\ distractors\\]
0,1,One-Shot Segmentation,Cluttered Omniglot,2018-03,MaskNet,43.7,100.0,43.7,1.0,43.7,1.0,ito:ITO_00101,Vision process,IoU\\ \\[256\\ distractors\\]
0,1,6D Pose Estimation using RGB,YCB-Video,2018-03,PoseCNN + DeepIM,84.2,100.0,84.2,1.0,84.2,0.91,ito:ITO_00101,Vision process,Mean\\ ADI
1,1,6D Pose Estimation using RGBD,YCB-Video,2018-03,PoseCNN + DeepIM,92.4,100.0,92.4,1.0,92.4,1.0,ito:ITO_00101,Vision process,Mean\\ ADI
0,1,Video Captioning,YouCook2,2018-04,Zhou,11.55,96.73,11.55,0.97,11.94,0.32,ito:ITO_00101,Vision process,METEOR
1,1,Video Captioning,YouCook2,2019-04,VideoBERT + S3D,11.94,100.0,0.4,0.03,11.94,0.33,ito:ITO_00101,Vision process,METEOR
2,1,Image Captioning,COCO,2019-05,"NIC (ResNet-50, CutMix)",23.1,100.0,23.1,1.0,23.1,0.63,ito:ITO_00101,Vision process,METEOR
3,1,Image Captioning,Flickr30k Captions test,2019-09,Unified VLP,23.0,100.0,23,1.0,23,0.63,ito:ITO_00101,Vision process,METEOR
4,1,Image Captioning,COCO Captions test,2019-09,Unified VLP,28.4,100.0,28.4,1.0,28.4,0.78,ito:ITO_00101,Vision process,METEOR
5,1,Video Captioning,VATEX,2020-02,ORG-TRL,22.2,100.0,22.2,1.0,22.2,0.61,ito:ITO_00101,Vision process,METEOR
6,1,Video Captioning,MSR-VTT,2020-02,ORG-TRL,28.8,100.0,28.8,1.0,28.8,0.79,ito:ITO_00101,Vision process,METEOR
7,1,Video Captioning,MSVD,2020-02,ORG-TRL,36.4,100.0,36.4,1.0,36.4,1.0,ito:ITO_00101,Vision process,METEOR
8,1,Dense Video Captioning,ActivityNet Captions,2020-03,MDVC,7.31,100.0,7.31,1.0,7.31,0.2,ito:ITO_00101,Vision process,METEOR
0,1,Video Captioning,YouCook2,2018-04,Zhou,3.84,87.67,3.84,0.88,4.38,0.05,ito:ITO_00101,Vision process,BLEU\\-4
1,1,Video Captioning,YouCook2,2018-04,Zhou,4.38,100.0,0.5,0.11,4.38,0.05,ito:ITO_00101,Vision process,BLEU\\-4
2,1,Sign Language Translation,RWTH-PHOENIX-Weather 2014 T,2018-06,Sign2Gloss2Text,19.26,75.83,19.26,0.76,25.4,0.23,ito:ITO_00101,Vision process,BLEU\\-4
3,1,Sign Language Translation,RWTH-PHOENIX-Weather 2014 T,2020-04,STMC+Transformer,25.4,100.0,6.1,0.24,25.4,0.31,ito:ITO_00101,Vision process,BLEU\\-4
4,1,Image Captioning,COCO,2019-05,"NIC (ResNet-50, CutMix)",24.9,100.0,24.9,1.0,24.9,0.3,ito:ITO_00101,Vision process,BLEU\\-4
5,1,Image Captioning,Flickr30k Captions test,2019-09,Unified VLP,30.1,100.0,30.1,1.0,30.1,0.36,ito:ITO_00101,Vision process,BLEU\\-4
6,1,Image Captioning,COCO Captions test,2019-09,Unified VLP,36.5,100.0,36.5,1.0,36.5,0.44,ito:ITO_00101,Vision process,BLEU\\-4
7,1,Video Captioning,MSVD,2020-02,ORG-TRL,54.3,100.0,54.3,1.0,54.3,0.66,ito:ITO_00101,Vision process,BLEU\\-4
8,1,Video Captioning,VATEX,2020-02,ORG-TRL,32.1,100.0,32.1,1.0,32.1,0.39,ito:ITO_00101,Vision process,BLEU\\-4
9,1,Video Captioning,MSR-VTT,2020-02,ORG-TRL,43.6,100.0,43.6,1.0,43.6,0.53,ito:ITO_00101,Vision process,BLEU\\-4
10,1,Dense Video Captioning,ActivityNet Captions,2020-03,MDVC,1.07,100.0,1.07,1.0,1.07,0.01,ito:ITO_00101,Vision process,BLEU\\-4
11,1,Sign Language Translation,ASLG-PC12,2020-04,Transformer Ens.,82.87,100.0,82.87,1.0,82.87,1.0,ito:ITO_00101,Vision process,BLEU\\-4
0,1,Video Captioning,YouCook2,2018-04,Zhou,7.53,99.21,7.53,0.99,7.59,0.22,ito:ITO_00101,Vision process,BLEU\\-3
1,1,Video Captioning,YouCook2,2019-04,VideoBERT + S3D,7.59,100.0,0.1,0.01,7.59,0.23,ito:ITO_00101,Vision process,BLEU\\-3
2,1,Image Captioning,COCO,2019-05,"NIC (ResNet-50, CutMix)",33.6,100.0,33.6,1.0,33.6,1.0,ito:ITO_00101,Vision process,BLEU\\-3
3,1,Dense Video Captioning,ActivityNet Captions,2020-03,MDVC,2.6,100.0,2.6,1.0,2.6,0.08,ito:ITO_00101,Vision process,BLEU\\-3
0,1,Video Captioning,YouCook2,2018-04,Zhou,0.38,1.32,0.38,0.01,28.8,0.01,ito:ITO_00101,Vision process,ROUGE\\-L
1,1,Video Captioning,YouCook2,2018-04,Zhou,27.44,95.28,27.1,0.94,28.8,0.37,ito:ITO_00101,Vision process,ROUGE\\-L
2,1,Video Captioning,YouCook2,2019-04,VideoBERT + S3D,28.8,100.0,1.4,0.05,28.8,0.39,ito:ITO_00101,Vision process,ROUGE\\-L
3,1,Video Captioning,VATEX,2020-02,ORG-TRL,48.9,100.0,48.9,1.0,48.9,0.66,ito:ITO_00101,Vision process,ROUGE\\-L
4,1,Video Captioning,MSR-VTT,2020-02,ORG-TRL,62.1,100.0,62.1,1.0,62.1,0.84,ito:ITO_00101,Vision process,ROUGE\\-L
5,1,Video Captioning,MSVD,2020-02,ORG-TRL,73.9,100.0,73.9,1.0,73.9,1.0,ito:ITO_00101,Vision process,ROUGE\\-L
0,1,Video Captioning,YouCook2,2018-04,Zhou,0.38,69.09,0.38,0.69,0.55,0.0,ito:ITO_00101,Vision process,CIDEr
1,1,Video Captioning,YouCook2,2019-04,VideoBERT + S3D,0.55,100.0,0.2,0.36,0.55,0.0,ito:ITO_00101,Vision process,CIDEr
2,1,Image Captioning,COCO,2019-05,"NIC (ResNet-50, CutMix)",77.6,100.0,77.6,1.0,77.6,0.66,ito:ITO_00101,Vision process,CIDEr
3,1,Image Captioning,Flickr30k Captions test,2019-09,Unified VLP,67.4,100.0,67.4,1.0,67.4,0.58,ito:ITO_00101,Vision process,CIDEr
4,1,Image Captioning,COCO Captions test,2019-09,Unified VLP,116.9,100.0,116.9,1.0,116.9,1.0,ito:ITO_00101,Vision process,CIDEr
5,1,Video Captioning,MSR-VTT,2020-02,ORG-TRL,50.9,100.0,50.9,1.0,50.9,0.44,ito:ITO_00101,Vision process,CIDEr
6,1,Video Captioning,MSVD,2020-02,ORG-TRL,95.2,100.0,95.2,1.0,95.2,0.81,ito:ITO_00101,Vision process,CIDEr
7,1,Video Captioning,VATEX,2020-02,ORG-TRL,49.7,100.0,49.7,1.0,49.7,0.43,ito:ITO_00101,Vision process,CIDEr
0,1,Motion Segmentation,KT3DMoSeg,2018-04,MultiViewClustering,7.92,100.0,7.92,1.0,7.92,1.0,ito:ITO_00101,Vision process,Error
1,1,Image Classification,Kuzushiji-MNIST,2019-01,VGG8B(2x) + LocalLearning + CO,0.99,100.0,0.99,1.0,0.99,0.12,ito:ITO_00101,Vision process,Error
0,1,3D Shape Reconstruction,Pix3D,2018-04,MarrNet extension (w/ Pose),0.119,100.0,0.119,1.0,0.119,1.0,ito:ITO_00101,Vision process,CD
0,1,3D Shape Reconstruction,Pix3D,2018-04,MarrNet extension (w/ Pose),0.118,100.0,0.118,1.0,0.118,1.0,ito:ITO_00101,Vision process,EMD
0,1,RF-based Pose Estimation,RF-MMD,2018-04,HCN,78.5,90.75,78.5,0.91,86.5,0.35,ito:ITO_00101,Vision process,"mAP\\ \\(at\\-0\\.1,\\ Through\\-wall\\)"
1,1,RF-based Pose Estimation,RF-MMD,2019-09,RF-Action,86.5,100.0,8.0,0.09,86.5,0.39,ito:ITO_00101,Vision process,"mAP\\ \\(at\\-0\\.1,\\ Through\\-wall\\)"
2,1,Low-Light Image Enhancement,3DMatch Benchmark,2019-08,nnh,224.0,100.0,224,1.0,224,1.0,ito:ITO_00101,Vision process,"mAP\\ \\(at\\-0\\.1,\\ Through\\-wall\\)"
0,1,Temporal Action Localization,ActivityNet-1.3,2018-04,TAL-Net,18.3,52.62,18.3,0.53,34.78,0.53,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.75
1,1,Temporal Action Localization,ActivityNet-1.3,2018-06,BSN,29.96,86.14,11.7,0.34,34.78,0.86,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.75
2,1,Temporal Action Localization,ActivityNet-1.3,2019-07,BMN,34.78,100.0,4.8,0.14,34.78,1.0,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.75
0,1,Temporal Action Localization,ActivityNet-1.3,2018-04,TAL-Net,1.3,14.41,1.3,0.14,9.02,0.14,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.95
1,1,Temporal Action Localization,ActivityNet-1.3,2018-06,BSN,8.02,88.91,6.7,0.74,9.02,0.89,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.95
2,1,Temporal Action Localization,ActivityNet-1.3,2019-07,BMN,8.29,91.91,0.3,0.03,9.02,0.92,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.95
3,1,Temporal Action Localization,ActivityNet-1.3,2019-11,G-TAD,9.02,100.0,0.7,0.08,9.02,1.0,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.95
0,1,Disguised Face Verification,Disguised Faces in the Wild,2018-04,DisguiseNet,23.25,100.0,23.25,1.0,23.25,1.0,ito:ITO_00101,Vision process,GAR\\ at\\-0\\.1%\\ FAR
0,1,Disguised Face Verification,Disguised Faces in the Wild,2018-04,DisguiseNet,60.89,100.0,60.89,1.0,60.89,1.0,ito:ITO_00101,Vision process,GAR\\ at\\-1%\\ FAR
0,1,Disguised Face Verification,Disguised Faces in the Wild,2018-04,DisguiseNet,98.99,100.0,98.99,1.0,98.99,1.0,ito:ITO_00101,Vision process,GAR\\ at\\-10%\\ FAR
0,1,Facial Expression Recognition,AffectNet,2018-04,CNNs and BOVW + local SVM,59.58,96.85,59.58,0.97,61.52,0.97,ito:ITO_00101,Vision process,Accuracy\\ \\(7\\ emotion\\)
1,1,Facial Expression Recognition,AffectNet,2019-02,Facial Motion Prior Network,61.52,100.0,1.9,0.03,61.52,1.0,ito:ITO_00101,Vision process,Accuracy\\ \\(7\\ emotion\\)
0,1,Pulmonary Artery–Vein Classification,LUMC,2018-05,CNN3D,0.693,93.9,0.693,0.94,0.738,0.89,ito:ITO_00101,Vision process,Accuracy\\ \\(median\\)
1,1,Pulmonary Artery–Vein Classification,LUMC,2019-09,CNN-GCNt,0.738,100.0,0.0,0.0,0.738,0.95,ito:ITO_00101,Vision process,Accuracy\\ \\(median\\)
2,1,Pulmonary Artery–Vein Classification,SunYs,2018-05,CNN3D,0.727,93.44,0.727,0.93,0.778,0.93,ito:ITO_00101,Vision process,Accuracy\\ \\(median\\)
3,1,Pulmonary Artery–Vein Classification,SunYs,2019-09,CNN-GCNt,0.778,100.0,0.1,0.13,0.778,1.0,ito:ITO_00101,Vision process,Accuracy\\ \\(median\\)
0,1,Gaze Estimation,MPII Gaze,2018-10,RT-GENE 4 model ensemble,4.3,89.58,4.3,0.9,4.8,0.56,ito:ITO_00101,Vision process,Angular\\ Error
1,1,Gaze Estimation,MPII Gaze,2018-10,RT-GENE 2 model ensemble,4.6,95.83,0.3,0.06,4.8,0.6,ito:ITO_00101,Vision process,Angular\\ Error
2,1,Gaze Estimation,MPII Gaze,2018-10,RT-GENE single model,4.8,100.0,0.2,0.04,4.8,0.62,ito:ITO_00101,Vision process,Angular\\ Error
3,1,Gaze Estimation,UT Multi-view,2018-10,RT-GENE 4 model ensemble,5.1,100.0,5.1,1.0,5.1,0.66,ito:ITO_00101,Vision process,Angular\\ Error
4,1,Gaze Estimation,RT-GENE,2018-10,RT-GENE 4 model ensemble,7.7,100.0,7.7,1.0,7.7,1.0,ito:ITO_00101,Vision process,Angular\\ Error
0,1,Brain Image Segmentation,CREMI,2018-05,U-NET MALA,0.289,100.0,0.289,1.0,0.289,1.0,ito:ITO_00101,Vision process,CREMI\\ Score
0,1,Brain Image Segmentation,CREMI,2018-05,U-NET MALA,0.606,100.0,0.606,1.0,0.606,0.28,ito:ITO_00101,Vision process,VOI
1,1,Brain Image Segmentation,FIB-25 Whole Test,2018-05,U-NET MALA,1.071,100.0,1.071,1.0,1.071,0.5,ito:ITO_00101,Vision process,VOI
2,1,Brain Image Segmentation,FIB-25 Synaptic Sites,2018-05,U-NET MALA,2.151,100.0,2.151,1.0,2.151,1.0,ito:ITO_00101,Vision process,VOI
0,1,Brain Image Segmentation,SegEM,2018-05,U-NET MALA,4.839,100.0,4.839,1.0,4.839,1.0,ito:ITO_00101,Vision process,IED
0,1,Self-Supervised Image Classification,ImageNet,2018-06,InstDisc (ResNet-50),46.5,98.73,46.5,0.99,47.1,0.99,ito:ITO_00101,Vision process,"Top\\ 1\\ Accuracy\\ \\(kNN,\\ k=20\\)"
1,1,Self-Supervised Image Classification,ImageNet,2019-11,MoCo (ResNet-50),47.1,100.0,0.6,0.01,47.1,1.0,ito:ITO_00101,Vision process,"Top\\ 1\\ Accuracy\\ \\(kNN,\\ k=20\\)"
0,1,Action Segmentation,GTEA,2018-06,TDRN,74.1,85.96,74.1,0.86,86.2,0.86,ito:ITO_00101,Vision process,Edit
1,1,Action Segmentation,GTEA,2019-03,MS-TCN,81.4,94.43,7.3,0.08,86.2,0.94,ito:ITO_00101,Vision process,Edit
2,1,Action Segmentation,GTEA,2020-03,SSTDA,86.2,100.0,4.8,0.06,86.2,1.0,ito:ITO_00101,Vision process,Edit
3,1,Action Segmentation,50 Salads,2019-03,MS-TCN,67.9,89.58,67.9,0.9,75.8,0.79,ito:ITO_00101,Vision process,Edit
4,1,Action Segmentation,50 Salads,2020-03,SSTDA,75.8,100.0,7.9,0.1,75.8,0.88,ito:ITO_00101,Vision process,Edit
5,1,Action Segmentation,Breakfast,2019-03,MS-TCN (IDT),61.4,83.31,61.4,0.83,73.7,0.71,ito:ITO_00101,Vision process,Edit
6,1,Action Segmentation,Breakfast,2019-03,MS-TCN (I3D),61.7,83.72,0.3,0.0,73.7,0.72,ito:ITO_00101,Vision process,Edit
7,1,Action Segmentation,Breakfast,2020-03,SSTDA,73.7,100.0,12.0,0.16,73.7,0.85,ito:ITO_00101,Vision process,Edit
0,1,Monocular Depth Estimation,Make3D,2018-06,Monodepth2,3.589,100.0,3.589,1.0,3.589,1.0,ito:ITO_00101,Vision process,Sq\\ Rel
0,1,Temporal Action Proposal Generation,THUMOS' 14,2018-06,BSN + Soft-NMS,64.52,100.0,64.52,1.0,64.52,1.0,ito:ITO_00101,Vision process,AR@1000
0,1,Temporal Action Proposal Generation,THUMOS' 14,2018-06,BSN + Soft-NMS,53.21,100.0,53.21,1.0,53.21,1.0,ito:ITO_00101,Vision process,AR@200
0,1,Temporal Action Proposal Generation,THUMOS' 14,2018-06,BSN + Soft-NMS,37.46,100.0,37.46,1.0,37.46,1.0,ito:ITO_00101,Vision process,AR@50
0,1,Temporal Action Proposal Generation,THUMOS' 14,2018-06,BSN + Soft-NMS,60.64,100.0,60.64,1.0,60.64,1.0,ito:ITO_00101,Vision process,AR@500
0,1,Video Retrieval,MSR-VTT,2018-06,JEMC,213.8,100.0,213.8,1.0,213.8,1.0,ito:ITO_00101,Vision process,text\\-to\\-video\\ Mean\\ Rank
1,1,Video Retrieval,DiDeMo,2019-07,Collaborative Experts,43.7,100.0,43.7,1.0,43.7,0.2,ito:ITO_00101,Vision process,text\\-to\\-video\\ Mean\\ Rank
2,1,Video Retrieval,MSVD,2019-07,Collaborative Experts,23.1,100.0,23.1,1.0,23.1,0.11,ito:ITO_00101,Vision process,text\\-to\\-video\\ Mean\\ Rank
3,1,Video Retrieval,ActivityNet,2019-07,Collaborative Experts,23.1,100.0,23.1,1.0,23.1,0.11,ito:ITO_00101,Vision process,text\\-to\\-video\\ Mean\\ Rank
4,1,Video Retrieval,MSR-VTT-1kA,2019-07,Collaborative Experts,28.2,100.0,28.2,1.0,28.2,0.13,ito:ITO_00101,Vision process,text\\-to\\-video\\ Mean\\ Rank
0,1,Video Retrieval,MSR-VTT,2018-06,JEMC,134.0,100.0,134.0,1.0,134.0,1.0,ito:ITO_00101,Vision process,video\\-to\\-text\\ Mean\\ Rank
0,1,Video Retrieval,MSR-VTT,2018-06,JEMC,16.0,100.0,16.0,1.0,16.0,1.0,ito:ITO_00101,Vision process,video\\-to\\-text\\ Median\\ Rank
0,1,Video Retrieval,MSR-VTT,2018-06,JEMC,12.5,80.13,12.5,0.8,15.6,0.8,ito:ITO_00101,Vision process,video\\-to\\-text\\ R\\-at\\-1
1,1,Video Retrieval,MSR-VTT,2019-07,Collaborative Experts,15.6,100.0,3.1,0.2,15.6,1.0,ito:ITO_00101,Vision process,video\\-to\\-text\\ R\\-at\\-1
0,1,Video Retrieval,MSR-VTT,2018-06,JEMC,42.2,76.45,42.2,0.76,55.2,0.76,ito:ITO_00101,Vision process,video\\-to\\-text\\ R\\-at\\-10
1,1,Video Retrieval,MSR-VTT,2019-07,Collaborative Experts,55.2,100.0,13.0,0.24,55.2,1.0,ito:ITO_00101,Vision process,video\\-to\\-text\\ R\\-at\\-10
0,1,Multivariate Time Series Imputation,PhysioNet Challenge 2012,2018-06,Latent ODE (RNN enc.),3.907,65.89,3.907,0.66,5.93,0.66,ito:ITO_00101,Vision process,mse\\ \\(10\\^\\-3\\)
1,1,Multivariate Time Series Imputation,PhysioNet Challenge 2012,2018-06,RNN-VAE,5.93,100.0,2.0,0.34,5.93,1.0,ito:ITO_00101,Vision process,mse\\ \\(10\\^\\-3\\)
0,1,Object Localization,Plant,2018-06,Hausdorff Loss,88.6,100.0,88.6,1.0,88.6,1.0,ito:ITO_00101,Vision process,F\\-Score
0,1,License Plate Recognition,Chinese License Plates,2018-06,LPRNet basic,0.34,36.17,0.34,0.36,0.94,0.36,ito:ITO_00101,Vision process,GFLOPs
1,1,License Plate Recognition,Chinese License Plates,2018-06,LPRNet reduced,0.94,100.0,0.6,0.64,0.94,1.0,ito:ITO_00101,Vision process,GFLOPs
0,1,Stroke Classification from CT data,CT Lesion Stroke Dataset,2018-07,"PSO+CNN (Cifar-10, 75/25, Cranium Segmented)",98.86,100.0,98.86,1.0,98.86,1.0,ito:ITO_00101,Vision process,Average\\ Class\\ Accuracy
0,1,Domain Adaptation,Office-Caltech-10,2018-07,MEDA,92.8,100.0,92.8,1.0,92.8,1.0,ito:ITO_00101,Vision process,Accuracy\\ \\(%\\)
1,1,Partial Domain Adaptation,Office-Home,2018-11,SAFN,71.8,100.0,71.8,1.0,71.8,0.77,ito:ITO_00101,Vision process,Accuracy\\ \\(%\\)
0,1,Generating 3D Point Clouds,ShapeNet,2018-08,PCN,0.009636,100.0,0.009636,1.0,0.009636,0.0,ito:ITO_00101,Vision process,Chamfer\\ Distance
1,1,Point Cloud Completion,Completion3D,2018-08,PCN,18.22,100.0,18.22,1.0,18.22,1.0,ito:ITO_00101,Vision process,Chamfer\\ Distance
2,1,Point Cloud Completion,ShapeNet,2018-08,PCN,9.636,100.0,9.636,1.0,9.636,0.53,ito:ITO_00101,Vision process,Chamfer\\ Distance
0,1,Point Cloud Completion,ShapeNet,2018-08,PCN,0.695,100.0,0.695,1.0,0.695,1.0,ito:ITO_00101,Vision process,F\\-Score@1%
0,1,Multi-Frame Super-Resolution,PROBA-V,2018-08,WDSR-MFSR,0.941182788312268,99.19,0.941182788312268,0.99,0.948844910272775,0.99,ito:ITO_00101,Vision process,Normalized\\ cPSNR
1,1,Multi-Frame Super-Resolution,PROBA-V,2018-08,3DWDSR,0.9462525077016232,99.73,0.0,0.0,0.948844910272775,1.0,ito:ITO_00101,Vision process,Normalized\\ cPSNR
2,1,Multi-Frame Super-Resolution,PROBA-V,2019-07,DeepSUM,0.948844910272775,100.0,0.0,0.0,0.948844910272775,1.0,ito:ITO_00101,Vision process,Normalized\\ cPSNR
0,1,RF-based Pose Estimation,RF-MMD,2018-09,Aryokee,78.3,86.9,78.3,0.87,90.1,0.87,ito:ITO_00101,Vision process,"mAP\\ \\(at\\-0\\.1,\\ Visible\\)"
1,1,RF-based Pose Estimation,RF-MMD,2019-09,RF-Action,90.1,100.0,11.8,0.13,90.1,1.0,ito:ITO_00101,Vision process,"mAP\\ \\(at\\-0\\.1,\\ Visible\\)"
0,1,Age-Invariant Face Recognition,MORPH Album2,2018-09,AIM + CAFR,99.65,100.0,99.65,1.0,99.65,1.0,ito:ITO_00101,Vision process,Rank\\-1\\ Recognition\\ Rate
0,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),54.7,94.98,54.7,0.95,57.59,0.92,ito:ITO_00101,Vision process,NDCG
1,1,Visual Dialog,VisDial v1.0 test-std,2019-02,DAN,57.59,100.0,2.9,0.05,57.59,0.97,ito:ITO_00101,Vision process,NDCG
2,1,Visual Dialog,Visual Dialog v1.0,2019-02,HACAN,57.17,96.29,57.17,0.96,59.37,0.96,ito:ITO_00101,Vision process,NDCG
3,1,Visual Dialog,Visual Dialog v1.0,2019-02,DAN,57.59,97.0,0.4,0.01,59.37,0.97,ito:ITO_00101,Vision process,NDCG
4,1,Visual Dialog,Visual Dialog v1.0,2020-04,MVAN,59.37,100.0,1.8,0.03,59.37,1.0,ito:ITO_00101,Vision process,NDCG
0,1,Optical Flow Estimation,KITTI 2015,2018-09,PWC-Net + ft,7.72,91.69,7.72,0.92,8.42,0.65,ito:ITO_00101,Vision process,Fl\\-all
1,1,Optical Flow Estimation,KITTI 2015,2019-04,SelFlow,8.42,100.0,0.7,0.08,8.42,0.71,ito:ITO_00101,Vision process,Fl\\-all
2,1,Optical Flow Estimation,KITTI 2015 unsupervised,2020-03,ARFlow-MV,11.79,100.0,11.79,1.0,11.79,1.0,ito:ITO_00101,Vision process,Fl\\-all
0,1,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,2018-09,CLAN,47.8,88.85,47.8,0.89,53.8,0.89,ito:ITO_00101,Vision process,MIoU\\ \\(13\\ classes\\)
1,1,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,2019-10,CAG-UDA,52.6,97.77,4.8,0.09,53.8,0.98,ito:ITO_00101,Vision process,MIoU\\ \\(13\\ classes\\)
2,1,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,2019-12,MRNet(ResNet-101),53.8,100.0,1.2,0.02,53.8,1.0,ito:ITO_00101,Vision process,MIoU\\ \\(13\\ classes\\)
0,1,Multimodal Emotion Recognition,IEMOCAP,2018-10,Multimodal Dual Recurrent Encoder (MDRE) / (A+T),0.718,100.0,0.718,1.0,0.718,1.0,ito:ITO_00101,Vision process,WAP
1,1,Speech Emotion Recognition,IEMOCAP,2018-10,Multimodal Dual Recurrent Encoder (MDRE) / (A+T),0.718,100.0,0.718,1.0,0.718,1.0,ito:ITO_00101,Vision process,WAP
0,1,Stereo Depth Estimation,KITTI2015,2018-10,AnyNet,6.2,100.0,6.2,1.0,6.2,1.0,ito:ITO_00101,Vision process,three\\ pixel\\ error
1,1,Stereo Depth Estimation,KITTI2012,2018-10,AnyNet,6.1,100.0,6.1,1.0,6.1,0.98,ito:ITO_00101,Vision process,three\\ pixel\\ error
0,1,Visual Object Tracking,GOT-10k,2018-11,ATOM,55.6,100.0,55.6,1.0,55.6,1.0,ito:ITO_00101,Vision process,Average\\ Overlap
0,1,Visual Object Tracking,GOT-10k,2018-11,ATOM,63.4,100.0,63.4,1.0,63.4,1.0,ito:ITO_00101,Vision process,Success\\ Rate\\ 0\\.5
0,1,Human-Object Interaction Detection,V-COCO,2018-11,Interactiveness,513.0,100.0,513,1.0,513,1.0,ito:ITO_00101,Vision process,Time\\ Per\\ Frame\\(ms\\)
0,1,Scene Text Detection,SCUT-CTW1500,2018-11,PAN,65.2,100.0,65.2,1.0,65.2,1.0,ito:ITO_00101,Vision process,TIoU
0,1,Vision-Language Navigation,Room2Room,2018-11,RCM + SIL,0.59,96.72,0.59,0.97,0.61,0.64,ito:ITO_00101,Vision process,spl
1,1,Vision-Language Navigation,Room2Room,2019-04,R2R+EnvDrop,0.61,100.0,0.0,0.0,0.61,0.67,ito:ITO_00101,Vision process,spl
2,1,PointGoal Navigation,Gibson PointGoal Navigation,2019-04,Depth PPO,0.79,86.15,0.79,0.86,0.917,0.86,ito:ITO_00101,Vision process,spl
3,1,PointGoal Navigation,Gibson PointGoal Navigation,2020-01,Depth DDPPO,0.917,100.0,0.1,0.11,0.917,1.0,ito:ITO_00101,Vision process,spl
0,1,Egocentric Activity Recognition,EPIC-Kitchens,2018-11,LSTA,15.9,62.11,15.9,0.62,25.6,0.62,ito:ITO_00101,Vision process,Actions\\ Top\\-1\\ \\(S2\\)
1,1,Egocentric Activity Recognition,EPIC-Kitchens,2018-12,LFB Max,21.2,82.81,5.3,0.21,25.6,0.83,ito:ITO_00101,Vision process,Actions\\ Top\\-1\\ \\(S2\\)
2,1,Egocentric Activity Recognition,EPIC-Kitchens,2019-05,R(2+1)D-152-SE (ig),25.6,100.0,4.4,0.17,25.6,1.0,ito:ITO_00101,Vision process,Actions\\ Top\\-1\\ \\(S2\\)
3,1,Egocentric Activity Recognition,EPIC-KITCHENS-55,2018-11,LSTA,16.63,64.96,16.63,0.65,25.6,0.65,ito:ITO_00101,Vision process,Actions\\ Top\\-1\\ \\(S2\\)
4,1,Egocentric Activity Recognition,EPIC-KITCHENS-55,2018-12,LFB Max,21.2,82.81,4.6,0.18,25.6,0.83,ito:ITO_00101,Vision process,Actions\\ Top\\-1\\ \\(S2\\)
5,1,Egocentric Activity Recognition,EPIC-KITCHENS-55,2019-05,R(2+1)D-152-SE (ig),25.6,100.0,4.4,0.17,25.6,1.0,ito:ITO_00101,Vision process,Actions\\ Top\\-1\\ \\(S2\\)
0,1,Phrase Grounding,Visual Genome,2018-11,VG_ELMo_PNASNet,55.16,100.0,55.16,1.0,55.16,0.8,ito:ITO_00101,Vision process,Pointing\\ Game\\ Accuracy
1,1,Phrase Grounding,Flickr30k,2018-11,COCO_ELMo_PNASNet,69.19,100.0,69.19,1.0,69.19,1.0,ito:ITO_00101,Vision process,Pointing\\ Game\\ Accuracy
2,1,Phrase Grounding,ReferIt,2018-11,VG_BiLSTM_VGG,62.76,100.0,62.76,1.0,62.76,0.91,ito:ITO_00101,Vision process,Pointing\\ Game\\ Accuracy
0,1,Domain Generalization,ImageNet-C,2018-11,ResNet-50+Stylized ImageNet,69.3,90.35,69.3,0.9,76.7,0.9,ito:ITO_00101,Vision process,mean\\ Corruption\\ Error\\ \\(mCE\\)
1,1,Domain Generalization,ImageNet-C,2019-03,ResNet-50,76.7,100.0,7.4,0.1,76.7,1.0,ito:ITO_00101,Vision process,mean\\ Corruption\\ Error\\ \\(mCE\\)
0,1,Multi-Person Pose Estimation,CrowdPose,2018-12,Joint-candidate SPPE +,75.5,86.38,75.5,0.86,87.4,0.86,ito:ITO_00101,Vision process,AP\\ Easy
1,1,Multi-Person Pose Estimation,CrowdPose,2019-08,HigherHRNet(HR-Net-48),87.4,100.0,11.9,0.14,87.4,1.0,ito:ITO_00101,Vision process,AP\\ Easy
0,1,Multi-Person Pose Estimation,CrowdPose,2018-12,Joint-candidate SPPE +,66.3,91.32,66.3,0.91,72.6,0.91,ito:ITO_00101,Vision process,AP\\ Medium
1,1,Multi-Person Pose Estimation,CrowdPose,2019-07,OccNet,66.6,91.74,0.3,0.0,72.6,0.92,ito:ITO_00101,Vision process,AP\\ Medium
2,1,Multi-Person Pose Estimation,CrowdPose,2019-08,HigherHRNet(HR-Net-48),72.6,100.0,6.0,0.08,72.6,1.0,ito:ITO_00101,Vision process,AP\\ Medium
0,1,Multi-Person Pose Estimation,CrowdPose,2018-12,Joint-candidate SPPE +,57.4,75.73,57.4,0.76,75.8,0.76,ito:ITO_00101,Vision process,AP\\ Hard
1,1,Multi-Person Pose Estimation,CrowdPose,2019-08,HigherHRNet(HR-Net-48),75.8,100.0,18.4,0.24,75.8,1.0,ito:ITO_00101,Vision process,AP\\ Hard
0,1,Action Recognition,AVA v2.1,2018-12,I3D Tx HighRes,39.6,100.0,39.6,1.0,39.6,1.0,ito:ITO_00101,Vision process,GFlops
1,1,Action Recognition In Videos,AVA v2.1,2018-12,I3D Tx HighRes,39.6,100.0,39.6,1.0,39.6,1.0,ito:ITO_00101,Vision process,GFlops
0,1,Action Recognition In Videos,AVA v2.1,2018-12,I3D Tx HighRes,19.3,100.0,19.3,1.0,19.3,1.0,ito:ITO_00101,Vision process,Params\\ \\(M\\)
1,1,Action Recognition,AVA v2.1,2018-12,I3D Tx HighRes,19.3,100.0,19.3,1.0,19.3,1.0,ito:ITO_00101,Vision process,Params\\ \\(M\\)
0,1,Out-of-Distribution Detection,CIFAR-10 vs CIFAR-100,2018-12,WRN 40-2 (MSP Baseline),87.9,94.21,87.9,0.94,93.3,0.9,ito:ITO_00101,Vision process,AUROC
1,1,Out-of-Distribution Detection,CIFAR-10 vs CIFAR-100,2018-12,WRN 40-2 + OE,93.3,100.0,5.4,0.06,93.3,0.95,ito:ITO_00101,Vision process,AUROC
2,1,Out-of-Distribution Detection,CIFAR-10,2018-12,WRN 40-2 + OE,97.8,100.0,97.8,1.0,97.8,1.0,ito:ITO_00101,Vision process,AUROC
3,1,Synthetic Data Generation,UCI Epileptic Seizure Recognition,2019-05,GAN,0.87,94.57,0.87,0.95,0.92,0.01,ito:ITO_00101,Vision process,AUROC
4,1,Synthetic Data Generation,UCI Epileptic Seizure Recognition,2020-01,corGAN,0.92,100.0,0.1,0.11,0.92,0.01,ito:ITO_00101,Vision process,AUROC
5,1,Emotion-Cause Pair Extraction,Emotion-Cause Pair Extraction,2019-05,GAN,0.87,94.57,0.87,0.95,0.92,0.01,ito:ITO_00101,Vision process,AUROC
6,1,Emotion-Cause Pair Extraction,Emotion-Cause Pair Extraction,2020-01,corGAN,0.92,100.0,0.1,0.11,0.92,0.01,ito:ITO_00101,Vision process,AUROC
7,1,Anomaly Detection,One-class CIFAR-10,2019-06,GOAD,88.2,100.0,88.2,1.0,88.2,0.9,ito:ITO_00101,Vision process,AUROC
8,1,Anomaly Detection,One-class ImageNet-30,2019-06,RotNet,65.3,76.2,65.3,0.76,85.7,0.67,ito:ITO_00101,Vision process,AUROC
9,1,Anomaly Detection,One-class ImageNet-30,2019-06,RotNet + Translation,77.9,90.9,12.6,0.15,85.7,0.8,ito:ITO_00101,Vision process,AUROC
10,1,Anomaly Detection,One-class ImageNet-30,2019-06,RotNet + Translation + Self-Attention + Resize,85.7,100.0,7.8,0.09,85.7,0.88,ito:ITO_00101,Vision process,AUROC
0,1,Out-of-Distribution Detection,CIFAR-100,2018-12,WRN 40-2 + OE,38.5,61.44,38.5,0.61,62.66,0.61,ito:ITO_00101,Vision process,FPR95
1,1,Out-of-Distribution Detection,CIFAR-100,2018-12,WRN 40-2 (MSP Baseline),62.66,100.0,24.2,0.39,62.66,1.0,ito:ITO_00101,Vision process,FPR95
2,1,Out-of-Distribution Detection,CIFAR-10,2018-12,WRN 40-2 + OE,9.5,27.19,9.5,0.27,34.94,0.15,ito:ITO_00101,Vision process,FPR95
3,1,Out-of-Distribution Detection,CIFAR-10,2018-12,WRN 40-2 (MSP Baseline),34.94,100.0,25.4,0.73,34.94,0.56,ito:ITO_00101,Vision process,FPR95
0,1,Image Generation,LSUN Bedroom,2018-12,StyleGAN,2.65,100.0,2.65,1.0,2.65,1.0,ito:ITO_00101,Vision process,FID\\-50k
0,1,Egocentric Activity Recognition,EPIC-KITCHENS-55,2018-12,LFB Max,32.7,93.97,32.7,0.94,34.8,0.94,ito:ITO_00101,Vision process,Actions\\ Top\\-1\\ \\(S1\\)
1,1,Egocentric Activity Recognition,EPIC-KITCHENS-55,2019-08,TBN,34.8,100.0,2.1,0.06,34.8,1.0,ito:ITO_00101,Vision process,Actions\\ Top\\-1\\ \\(S1\\)
0,1,6D Pose Estimation using RGB,YCB-Video,2018-12,PVNet,73.4,78.84,73.4,0.79,93.1,0.79,ito:ITO_00101,Vision process,Mean\\ AUC
1,1,6D Pose Estimation using RGB,YCB-Video,2019-01,DenseFusion,93.1,100.0,19.7,0.21,93.1,1.0,ito:ITO_00101,Vision process,Mean\\ AUC
0,1,6D Pose Estimation using RGBD,REAL275,2019-01,NOCS (128 bins),26.7,100.0,26.7,1.0,26.7,0.43,ito:ITO_00101,Vision process,"mAP\\ 10,\\ 10cm"
1,1,6D Pose Estimation using RGBD,CAMERA25,2019-01,NOCS (128 bins),62.2,100.0,62.2,1.0,62.2,1.0,ito:ITO_00101,Vision process,"mAP\\ 10,\\ 10cm"
0,1,6D Pose Estimation using RGBD,REAL275,2019-01,NOCS (128 bins),26.7,100.0,26.7,1.0,26.7,0.43,ito:ITO_00101,Vision process,"mAP\\ 10,\\ 5cm"
1,1,6D Pose Estimation using RGBD,CAMERA25,2019-01,NOCS (128 bins),61.7,100.0,61.7,1.0,61.7,1.0,ito:ITO_00101,Vision process,"mAP\\ 10,\\ 5cm"
0,1,6D Pose Estimation using RGBD,CAMERA25,2019-01,NOCS (128 bins),91.4,100.0,91.4,1.0,91.4,1.0,ito:ITO_00101,Vision process,mAP\\ 3DIou\\-at\\-25
1,1,6D Pose Estimation using RGBD,REAL275,2019-01,NOCS (128 bins),84.9,100.0,84.9,1.0,84.9,0.93,ito:ITO_00101,Vision process,mAP\\ 3DIou\\-at\\-25
0,1,6D Pose Estimation using RGBD,REAL275,2019-01,NOCS (128 bins),80.5,100.0,80.5,1.0,80.5,0.94,ito:ITO_00101,Vision process,mAP\\ 3DIou\\-at\\-50
1,1,6D Pose Estimation using RGBD,CAMERA25,2019-01,NOCS (128 bins),85.3,100.0,85.3,1.0,85.3,1.0,ito:ITO_00101,Vision process,mAP\\ 3DIou\\-at\\-50
0,1,6D Pose Estimation using RGBD,REAL275,2019-01,NOCS (128 bins),9.5,100.0,9.5,1.0,9.5,0.24,ito:ITO_00101,Vision process,"mAP\\ 5,\\ 5cm"
1,1,6D Pose Estimation using RGBD,CAMERA25,2019-01,NOCS (128 bins),38.8,100.0,38.8,1.0,38.8,1.0,ito:ITO_00101,Vision process,"mAP\\ 5,\\ 5cm"
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,MFA-Net,86.6,94.23,86.6,0.94,91.9,0.94,ito:ITO_00101,Vision process,28\\ gestures\\ accuracy
1,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,STA-Res-TCN,90.7,98.69,4.1,0.04,91.9,0.99,ito:ITO_00101,Vision process,28\\ gestures\\ accuracy
2,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,91.9,100.0,1.2,0.01,91.9,1.0,ito:ITO_00101,Vision process,28\\ gestures\\ accuracy
3,1,Hand Gesture Recognition,SHREC 2017,2019-07,DG-STA,90.7,100.0,90.7,1.0,90.7,0.99,ito:ITO_00101,Vision process,28\\ gestures\\ accuracy
0,1,Semantic Segmentation,ADE20K val,2019-01,Auto-DeepLab-L,81.72,100.0,81.72,1.0,81.72,1.0,ito:ITO_00101,Vision process,Pixel\\ Accuracy
0,1,DeepFake Detection,FaceForensics,2019-01,XceptionNet,86.86,100.0,86.86,1.0,86.86,1.0,ito:ITO_00101,Vision process,FSF
0,1,DeepFake Detection,FaceForensics,2019-01,XceptionNet,70.1,100.0,70.1,1.0,70.1,1.0,ito:ITO_00101,Vision process,Total\\ Accuracy
0,1,DeepFake Detection,FaceForensics,2019-01,XceptionNet,96.36,100.0,96.36,1.0,96.36,1.0,ito:ITO_00101,Vision process,DF
0,1,DeepFake Detection,FaceForensics,2019-01,XceptionNet,90.29,100.0,90.29,1.0,90.29,1.0,ito:ITO_00101,Vision process,FS
0,1,DeepFake Detection,FaceForensics,2019-01,XceptionNet,80.67,100.0,80.67,1.0,80.67,1.0,ito:ITO_00101,Vision process,NT
0,1,6D Pose Estimation using RGBD,T-LESS,2019-02,Augmented Autoencoder,72.76,100.0,72.76,1.0,72.76,1.0,ito:ITO_00101,Vision process,Mean\\ Recall
1,1,6D Pose Estimation using RGB,T-LESS,2019-02,Augmented Autoencoder,36.8,100.0,36.8,1.0,36.8,0.51,ito:ITO_00101,Vision process,Mean\\ Recall
0,1,Trajectory Prediction,ActEV,2019-02,Next,17.99,100.0,17.99,1.0,17.99,1.0,ito:ITO_00101,Vision process,ADE\\-8/12
1,1,Trajectory Prediction,ETH/UCY,2019-02,Next,0.46,100.0,0.46,1.0,0.46,0.03,ito:ITO_00101,Vision process,ADE\\-8/12
2,1,Trajectory Forecasting,ActEV,2019-02,Next,17.99,100.0,17.99,1.0,17.99,1.0,ito:ITO_00101,Vision process,ADE\\-8/12
3,1,Trajectory Prediction,Hotel BIWI Walking Pedestrians dataset,2019-04,Social Ways,0.39,100.0,0.39,1.0,0.39,0.02,ito:ITO_00101,Vision process,ADE\\-8/12
4,1,Trajectory Prediction,ETH BIWI Walking Pedestrians dataset,2019-04,Social Ways,0.39,100.0,0.39,1.0,0.39,0.02,ito:ITO_00101,Vision process,ADE\\-8/12
0,1,Trajectory Prediction,ActEV,2019-02,Next,37.24,100.0,37.24,1.0,37.24,1.0,ito:ITO_00101,Vision process,FDE\\-8/12
0,1,Depth Completion,KITTI Depth Completion,2019-02,FusionNet (RGB_guide&certainty),0.93,77.5,0.93,0.78,1.2,0.02,ito:ITO_00101,Vision process,iMAE
1,1,Depth Completion,KITTI Depth Completion,2019-05,VOICED,1.2,100.0,0.3,0.25,1.2,0.02,ito:ITO_00101,Vision process,iMAE
2,1,Depth Completion,VOID,2019-05,VOICED,48.92,100.0,48.92,1.0,48.92,1.0,ito:ITO_00101,Vision process,iMAE
0,1,Person Retrieval,SoftBioSearch,2019-02,SSD,0.503,100.0,0.503,1.0,0.503,1.0,ito:ITO_00101,Vision process,Average\\ IOU
0,1,Depth Completion,KITTI Depth Completion,2019-02,FusionNet (RGB_guide&certainty),2.19,61.52,2.19,0.62,3.56,0.02,ito:ITO_00101,Vision process,iRMSE
1,1,Depth Completion,KITTI Depth Completion,2019-05,VOICED,3.56,100.0,1.4,0.39,3.56,0.03,ito:ITO_00101,Vision process,iRMSE
2,1,Depth Completion,VOID,2019-05,VOICED,104.02,100.0,104.02,1.0,104.02,1.0,ito:ITO_00101,Vision process,iRMSE
0,1,3D Instance Segmentation,S3DIS,2019-02,ASIS (PN++),47.5,68.64,47.5,0.69,69.2,0.69,ito:ITO_00101,Vision process,mRec
1,1,3D Instance Segmentation,S3DIS,2019-06,3D-BoNet,47.6,68.79,0.1,0.0,69.2,0.69,ito:ITO_00101,Vision process,mRec
2,1,3D Instance Segmentation,S3DIS,2019-12,JSNet,53.9,77.89,6.3,0.09,69.2,0.78,ito:ITO_00101,Vision process,mRec
3,1,3D Instance Segmentation,S3DIS,2020-03,OccuSeg,60.3,87.14,6.4,0.09,69.2,0.87,ito:ITO_00101,Vision process,mRec
4,1,3D Instance Segmentation,S3DIS,2020-03,3D-MPA,64.1,92.63,3.8,0.05,69.2,0.93,ito:ITO_00101,Vision process,mRec
5,1,3D Instance Segmentation,S3DIS,2020-04,PointGroup,69.2,100.0,5.1,0.07,69.2,1.0,ito:ITO_00101,Vision process,mRec
0,1,3D Instance Segmentation,S3DIS,2019-02,ASIS (PN++),63.6,87.36,63.6,0.87,72.8,0.87,ito:ITO_00101,Vision process,mPrec
1,1,3D Instance Segmentation,S3DIS,2019-06,3D-BoNet,65.6,90.11,2.0,0.03,72.8,0.9,ito:ITO_00101,Vision process,mPrec
2,1,3D Instance Segmentation,S3DIS,2019-12,JSNet,66.9,91.9,1.3,0.02,72.8,0.92,ito:ITO_00101,Vision process,mPrec
3,1,3D Instance Segmentation,S3DIS,2020-03,OccuSeg,72.8,100.0,5.9,0.08,72.8,1.0,ito:ITO_00101,Vision process,mPrec
0,1,Node Classification,YouTube,2019-03,LINE,70.09,100.0,70.09,1.0,70.09,1.0,ito:ITO_00101,Vision process,runtime\\ \\(s\\)
1,1,Human motion prediction,Human motion prediction,2019-03,LINE,70.09,100.0,70.09,1.0,70.09,1.0,ito:ITO_00101,Vision process,runtime\\ \\(s\\)
0,1,Node Classification,YouTube,2019-03,LINE,40.61,100.0,40.61,1.0,40.61,1.0,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-2%
1,1,Human motion prediction,Human motion prediction,2019-03,LINE,40.61,100.0,40.61,1.0,40.61,1.0,ito:ITO_00101,Vision process,Micro\\-F1\\-at\\-2%
0,1,Node Classification,YouTube,2019-03,LINE,33.69,100.0,33.69,1.0,33.69,1.0,ito:ITO_00101,Vision process,Macro\\-F1\\-at\\-2%
1,1,Human motion prediction,Human motion prediction,2019-03,LINE,33.69,100.0,33.69,1.0,33.69,1.0,ito:ITO_00101,Vision process,Macro\\-F1\\-at\\-2%
0,1,4D Spatio Temporal Semantic Segmentation,4,2019-03,4,7.0,100.0,7,1.0,7,1.0,ito:ITO_00101,Vision process,4
0,1,Medical Image Segmentation,ISBI 2012 EM Segmentation,2019-03,CE-Net,0.9878,100.0,0.9878,1.0,0.9878,1.0,ito:ITO_00101,Vision process,VInfo
0,1,Medical Image Segmentation,ISBI 2012 EM Segmentation,2019-03,CE-Net,0.9743,100.0,0.9743,1.0,0.9743,1.0,ito:ITO_00101,Vision process,VRand
0,1,Image Reconstruction,Edge-to-Shoes,2019-03,PI-REC,0.081,100.0,0.081,1.0,0.081,0.72,ito:ITO_00101,Vision process,MMD
1,1,Image Reconstruction,Edge-to-Handbags,2019-03,PI-REC,0.112,100.0,0.112,1.0,0.112,1.0,ito:ITO_00101,Vision process,MMD
0,1,Image Reconstruction,Edge-to-Shoes,2019-03,PI-REC,62.3,100.0,62.3,1.0,62.3,1.0,ito:ITO_00101,Vision process,HP
1,1,Image Reconstruction,Edge-to-Handbags,2019-03,PI-REC,57.1,100.0,57.1,1.0,57.1,0.92,ito:ITO_00101,Vision process,HP
0,1,3D Object Detection,nuScenes,2019-03,PointPillars (ImageNet),44.9,70.93,44.9,0.71,63.3,0.71,ito:ITO_00101,Vision process,NDS
1,1,3D Object Detection,nuScenes,2019-08,MEGVII,63.3,100.0,18.4,0.29,63.3,1.0,ito:ITO_00101,Vision process,NDS
0,1,Unsupervised Anomaly Detection,Reuters-21578,2019-03,RSRAE,0.849,100.0,0.849,1.0,0.849,1.0,ito:ITO_00101,Vision process,AUC\\ \\(outlier\\ ratio\\ =\\ 0\\.5\\)
1,1,Unsupervised Anomaly Detection,Caltech-101,2019-03,RSRAE,0.772,100.0,0.772,1.0,0.772,0.91,ito:ITO_00101,Vision process,AUC\\ \\(outlier\\ ratio\\ =\\ 0\\.5\\)
2,1,Unsupervised Anomaly Detection,20NEWS,2019-03,RSRAE,0.831,100.0,0.831,1.0,0.831,0.98,ito:ITO_00101,Vision process,AUC\\ \\(outlier\\ ratio\\ =\\ 0\\.5\\)
3,1,Unsupervised Anomaly Detection,Fashion-MNIST,2019-03,RSRAE,0.833,100.0,0.833,1.0,0.833,0.98,ito:ITO_00101,Vision process,AUC\\ \\(outlier\\ ratio\\ =\\ 0\\.5\\)
0,1,Video Frame Interpolation,X4K1000FPS,2019-04,DAIN_f,3.47,90.6,3.47,0.91,3.83,0.91,ito:ITO_00101,Vision process,tOF
1,1,Video Frame Interpolation,X4K1000FPS,2019-04,DAIN,3.83,100.0,0.4,0.1,3.83,1.0,ito:ITO_00101,Vision process,tOF
0,1,Action Classification,YouCook2,2019-04,VideoBERT (cross modal),33.7,100.0,33.7,1.0,33.7,1.0,ito:ITO_00101,Vision process,Object\\ Top\\ 5\\ Accuracy
0,1,Action Classification,YouCook2,2019-04,VideoBERT (cross modal),13.1,100.0,13.1,1.0,13.1,1.0,ito:ITO_00101,Vision process,Object\\ Top\\-1\\ Accuracy
0,1,Action Classification,YouCook2,2019-04,VideoBERT (cross modal),3.2,100.0,3.2,1.0,3.2,1.0,ito:ITO_00101,Vision process,Verb\\ Top\\-1\\ Accuracy
0,1,Action Classification,YouCook2,2019-04,VideoBERT (cross modal),43.3,100.0,43.3,1.0,43.3,1.0,ito:ITO_00101,Vision process,Verb\\ Top\\-5\\ Accuracy
0,1,LIDAR Semantic Segmentation,Paris-Lille-3D,2019-04,ConvPoint_Keras,0.72,94.86,0.72,0.95,0.759,0.95,ito:ITO_00101,Vision process,mIOU
1,1,LIDAR Semantic Segmentation,Paris-Lille-3D,2019-04,ConvPoint,0.759,100.0,0.0,0.0,0.759,1.0,ito:ITO_00101,Vision process,mIOU
0,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,0.94,100.0,0.94,1.0,0.94,0.98,ito:ITO_00101,Vision process,PCKh
1,1,Pose Transfer,Deep-Fashion,2019-04,Progressive Pose Attention,0.96,100.0,0.96,1.0,0.96,1.0,ito:ITO_00101,Vision process,PCKh
0,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,0.811,100.0,0.811,1.0,0.811,1.0,ito:ITO_00101,Vision process,mask\\-SSIM
0,1,Pose Transfer,Deep-Fashion,2019-04,Progressive Pose Attention,0.976,100.0,0.976,1.0,0.976,1.0,ito:ITO_00101,Vision process,DS
1,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,0.74,100.0,0.74,1.0,0.74,0.76,ito:ITO_00101,Vision process,DS
0,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,3.773,100.0,3.773,1.0,3.773,1.0,ito:ITO_00101,Vision process,mask\\-IS
0,1,Camouflaged Object Segmentation,COD,2019-04,CPD,77.0,100.0,77.0,1.0,77.0,1.0,ito:ITO_00101,Vision process,E\\-Measure
1,1,Camouflaged Object Segmentation,CAMO,2019-06,BASNet,66.1,100.0,66.1,1.0,66.1,0.86,ito:ITO_00101,Vision process,E\\-Measure
0,1,Camouflaged Object Segmentation,COD,2019-04,CPD,50.8,100.0,50.8,1.0,50.8,1.0,ito:ITO_00101,Vision process,Weighted\\ F\\-Measure
1,1,Camouflaged Object Segmentation,CAMO,2019-06,BASNet,41.3,100.0,41.3,1.0,41.3,0.81,ito:ITO_00101,Vision process,Weighted\\ F\\-Measure
0,1,Lung Nodule Segmentation,NIH,2019-04,U-Net+R+A4,0.262,100.0,0.262,1.0,0.262,1.0,ito:ITO_00101,Vision process,AVD
0,1,Lung Nodule Segmentation,NIH,2019-04,U-Net+R+A4,0.985,100.0,0.985,1.0,0.985,0.01,ito:ITO_00101,Vision process,VS
1,1,Medical Image Segmentation,HSVM,2019-06,MS-Dual-Guided,94.45,100.0,94.45,1.0,94.45,1.0,ito:ITO_00101,Vision process,VS
2,1,Medical Image Segmentation,CHAOS MRI Dataset,2019-06,MS-Dual-Guided,93.85,100.0,93.85,1.0,93.85,0.99,ito:ITO_00101,Vision process,VS
3,1,Brain Tumor Segmentation,BRATS 2018,2019-06,MS-Dual-Guided,93.08,100.0,93.08,1.0,93.08,0.99,ito:ITO_00101,Vision process,VS
0,1,Trajectory Prediction,Stanford Drone,2019-04,Social-Ways,0.62,100.0,0.62,1.0,0.62,1.0,ito:ITO_00101,Vision process,ADE\\ \\(in\\ world\\ coordinates\\)
0,1,Trajectory Prediction,Stanford Drone,2019-04,Social-Ways,1.16,100.0,1.16,1.0,1.16,1.0,ito:ITO_00101,Vision process,FDE\\ \\(in\\ world\\ coordinates\\)
0,1,Image Classification,Tiny ImageNet Classification,2019-04,DenseNet + Residual Networks,60.0,100.0,60,1.0,60,1.0,ito:ITO_00101,Vision process,Validation
0,1,Arabic Text Diacritization,Tashkeela,2019-04,Shakkala,0.0373,100.0,0.0373,1.0,0.0373,1.0,ito:ITO_00101,Vision process,Diacritic\\ Error\\ Rate
1,1,EEG Emotion Recognition,EEG Emotion Recognition,2019-04,Shakkala,0.0373,100.0,0.0373,1.0,0.0373,1.0,ito:ITO_00101,Vision process,Diacritic\\ Error\\ Rate
0,1,3D Object Detection,nuScenes-F,2019-05,RRPN + R101,41.2,100.0,41.2,1.0,41.2,1.0,ito:ITO_00101,Vision process,ARm
1,1,3D Object Detection,nuScenes-FB,2019-05,RRPN + R101,39.1,100.0,39.1,1.0,39.1,0.95,ito:ITO_00101,Vision process,ARm
0,1,3D Object Detection,nuScenes-F,2019-05,RRPN + R101,4.0,100.0,4,1.0,4,0.19,ito:ITO_00101,Vision process,ARs
1,1,3D Object Detection,nuScenes-FB,2019-05,RRPN + R101,21.1,100.0,21.1,1.0,21.1,1.0,ito:ITO_00101,Vision process,ARs
0,1,Image Captioning,COCO,2019-05,"NIC (ResNet-50, CutMix)",64.2,100.0,64.2,1.0,64.2,1.0,ito:ITO_00101,Vision process,BLEU\\-1
0,1,Image Captioning,COCO,2019-05,"NIC (ResNet-50, CutMix)",46.3,100.0,46.3,1.0,46.3,1.0,ito:ITO_00101,Vision process,BLEU\\-2
0,1,Image Captioning,COCO,2019-05,"NIC (ResNet-50, CutMix)",49.0,100.0,49,1.0,49,1.0,ito:ITO_00101,Vision process,ROUGE
0,1,Unsupervised Domain Adaptation,PreSIL to KITTI,2019-05,CycleGAN,16.5,96.49,16.5,0.96,17.1,0.96,ito:ITO_00101,Vision process,AP\\-at\\-0\\.7
1,1,Unsupervised Domain Adaptation,PreSIL to KITTI,2019-11,PointDAN,17.1,100.0,0.6,0.04,17.1,1.0,ito:ITO_00101,Vision process,AP\\-at\\-0\\.7
0,1,Homography Estimation,COCO 2014,2019-05,PFNet,0.92,100.0,0.92,1.0,0.92,1.0,ito:ITO_00101,Vision process,MACE
0,1,Materials Screening,OQMD v1.2,2019-05,CGNN Ensemble,96.0,100.0,96,1.0,96,1.0,ito:ITO_00101,Vision process,EaH\\-at\\-95
0,1,Materials Screening,OQMD v1.2,2019-05,CGNN Ensemble,215.0,100.0,215,1.0,215,1.0,ito:ITO_00101,Vision process,EaH\\-at\\-99
0,1,Video Prediction,CMU Mocap-1,2019-05,ODE2VAE-KL,15.99,17.18,15.99,0.17,93.07,0.17,ito:ITO_00101,Vision process,Test\\ Error
1,1,Video Prediction,CMU Mocap-1,2019-05,ODE2VAE,93.07,100.0,77.1,0.83,93.07,1.0,ito:ITO_00101,Vision process,Test\\ Error
2,1,Video Prediction,CMU Mocap-2,2019-05,ODE2VAE-KL,8.09,80.42,8.09,0.8,10.06,0.09,ito:ITO_00101,Vision process,Test\\ Error
3,1,Video Prediction,CMU Mocap-2,2019-05,ODE2VAE,10.06,100.0,2.0,0.2,10.06,0.11,ito:ITO_00101,Vision process,Test\\ Error
0,1,Image Inpainting,Paris StreetView,2019-05,Coherent Semantic Attention for Image Inpainting,23.1,100.0,23.1,1.0,23.1,1.0,ito:ITO_00101,Vision process,40\\-50%\\ Mask\\ PSNR
0,1,Image Inpainting,Paris StreetView,2019-05,Coherent Semantic Attention for Image Inpainting,32.67,100.0,32.67,1.0,32.67,1.0,ito:ITO_00101,Vision process,10\\-20%\\ Mask\\ PSNR
0,1,Image Inpainting,Paris StreetView,2019-05,Coherent Semantic Attention for Image Inpainting,30.32,100.0,30.32,1.0,30.32,1.0,ito:ITO_00101,Vision process,20\\-30%\\ Mask\\ PSNR
0,1,Image Inpainting,Paris StreetView,2019-05,Coherent Semantic Attention for Image Inpainting,24.85,100.0,24.85,1.0,24.85,1.0,ito:ITO_00101,Vision process,30\\-40%\\ Mask\\ PSNR
0,1,Salient Object Detection,DUTS-TE,2019-06,BASNET (ResNet-34),0.803,100.0,0.803,1.0,0.803,0.89,ito:ITO_00101,Vision process,Fwβ
1,1,Salient Object Detection,ECSSD,2019-06,BASNet (ResNet-34),0.904,100.0,0.904,1.0,0.904,1.0,ito:ITO_00101,Vision process,Fwβ
0,1,Salient Object Detection,ECSSD,2019-06,BASNet (ResNet-34),0.916,100.0,0.916,1.0,0.916,1.0,ito:ITO_00101,Vision process,Sm
1,1,Salient Object Detection,DUTS-TE,2019-06,BASNET (ResNet-34),0.853,100.0,0.853,1.0,0.853,0.93,ito:ITO_00101,Vision process,Sm
0,1,Salient Object Detection,DUTS-TE,2019-06,BASNET (ResNet-34),0.758,100.0,0.758,1.0,0.758,0.92,ito:ITO_00101,Vision process,relaxFbβ
1,1,Salient Object Detection,ECSSD,2019-06,BASNet (ResNet-34),0.826,100.0,0.826,1.0,0.826,1.0,ito:ITO_00101,Vision process,relaxFbβ
0,1,Salient Object Detection,DUTS-TE,2019-06,BASNET (ResNet-34),0.86,100.0,0.86,1.0,0.86,0.91,ito:ITO_00101,Vision process,\\{max\\}Fβ
1,1,Salient Object Detection,ECSSD,2019-06,BASNet (ResNet-34),0.942,100.0,0.942,1.0,0.942,1.0,ito:ITO_00101,Vision process,\\{max\\}Fβ
0,1,Salient Object Detection,ECSSD,2019-06,BASNet (ResNet-34),348.5,100.0,348.5,1.0,348.5,1.0,ito:ITO_00101,Vision process,Model\\ Size\\ \\(MB\\)
0,1,Face Presentation Attack Detection,WMCA,2019-06,MCCNN,0.3,100.0,0.3,1.0,0.3,1.0,ito:ITO_00101,Vision process,ACER
0,1,Electron Microscopy Image Segmentation,SNEMI3D,2019-06,Waterz (3D U-Net),0.807,100.0,0.807,1.0,0.807,1.0,ito:ITO_00101,Vision process,Total\\ Variation\\ of\\ Information
0,1,Electron Microscopy Image Segmentation,SNEMI3D,2019-06,Waterz (3D U-Net) + Refinement,0.438,76.71,0.438,0.77,0.571,0.77,ito:ITO_00101,Vision process,VI\\ Split
1,1,Electron Microscopy Image Segmentation,SNEMI3D,2019-06,Waterz (3D U-Net),0.571,100.0,0.1,0.18,0.571,1.0,ito:ITO_00101,Vision process,VI\\ Split
0,1,Electron Microscopy Image Segmentation,SNEMI3D,2019-06,Waterz (3D U-Net),0.236,100.0,0.236,1.0,0.236,1.0,ito:ITO_00101,Vision process,VI\\ Merge
0,1,Self-Supervised Image Classification,ImageNet,2019-06,AMDIM (large),626000000.0,100.0,626000000,1.0,626000000,1.0,ito:ITO_00101,Vision process,Number\\ of\\ Params
0,1,3D Shape Modeling,Pix3D S2,2019-06,Mesh R-CNN,28.8,100.0,28.8,1.0,28.8,0.56,ito:ITO_00101,Vision process,mesh\\ AP
1,1,UNET Segmentation,UNET Segmentation,2019-06,Mesh R-CNN,28.8,100.0,28.8,1.0,28.8,0.56,ito:ITO_00101,Vision process,mesh\\ AP
2,1,3D Shape Modeling,Pix3D S1,2019-06,Mesh R-CNN,51.1,100.0,51.1,1.0,51.1,1.0,ito:ITO_00101,Vision process,mesh\\ AP
3,1,Road Segementation,Road Segementation,2019-06,Mesh R-CNN,51.1,100.0,51.1,1.0,51.1,1.0,ito:ITO_00101,Vision process,mesh\\ AP
0,1,Zero-Shot Learning,CUB-200,2019-06,zsl_ADA,70.9,100.0,70.9,1.0,70.9,0.81,ito:ITO_00101,Vision process,Average\\ Per\\-Class\\ Accuracy
1,1,Image Classification,Imbalanced CUB-200-2011,2019-11,PC-Softmax,87.69,100.0,87.69,1.0,87.69,1.0,ito:ITO_00101,Vision process,Average\\ Per\\-Class\\ Accuracy
2,1,Fine-Grained Image Classification,Imbalanced CUB-200-2011,2019-11,PC-Softmax,87.69,100.0,87.69,1.0,87.69,1.0,ito:ITO_00101,Vision process,Average\\ Per\\-Class\\ Accuracy
0,1,Medical Image Segmentation,CHAOS MRI Dataset,2019-06,MS-Dual-Guided,66.0,100.0,66,1.0,66,1.0,ito:ITO_00101,Vision process,MSD
1,1,Medical Image Segmentation,HSVM,2019-06,MS-Dual-Guided,1.19,100.0,1.19,1.0,1.19,0.02,ito:ITO_00101,Vision process,MSD
2,1,Brain Tumor Segmentation,BRATS 2018,2019-06,MS-Dual-Guided,0.9,100.0,0.9,1.0,0.9,0.01,ito:ITO_00101,Vision process,MSD
0,1,Image Classification,ImageNet ReaL,2019-06,FixResNeXt-101 32x48d,829000000.0,89.33,829000000,0.89,928000000,0.89,ito:ITO_00101,Vision process,Params
1,1,Image Classification,ImageNet ReaL,2019-12,BiT-L,928000000.0,100.0,99000000,0.11,928000000,1.0,ito:ITO_00101,Vision process,Params
0,1,Point Cloud Generation,ShapeNet Chair,2019-06,PointFlow,60.88,100.0,60.88,1.0,60.88,0.8,ito:ITO_00101,Vision process,1\\-NNA\\-CD
1,1,Point Cloud Generation,ShapeNet Airplane,2019-06,PointFlow,75.68,100.0,75.68,1.0,75.68,1.0,ito:ITO_00101,Vision process,1\\-NNA\\-CD
2,1,Point Cloud Generation,ShapeNet Car,2019-06,PointFlow,60.65,100.0,60.65,1.0,60.65,0.8,ito:ITO_00101,Vision process,1\\-NNA\\-CD
0,1,Point Cloud Generation,ShapeNet Airplane,2019-06,PointFlow,0.217,100.0,0.217,1.0,0.217,0.09,ito:ITO_00101,Vision process,MMD\\-CD
1,1,Point Cloud Generation,ShapeNet Car,2019-06,PointFlow,0.91,100.0,0.91,1.0,0.91,0.38,ito:ITO_00101,Vision process,MMD\\-CD
2,1,Point Cloud Generation,ShapeNet Chair,2019-06,PointFlow,2.42,100.0,2.42,1.0,2.42,1.0,ito:ITO_00101,Vision process,MMD\\-CD
0,1,Image Generation,ImageNet 64x64,2019-07,BigBiGAN,47.51,100.0,47.51,1.0,47.51,1.0,ito:ITO_00101,Vision process,Cls
0,1,Video Generation,BAIR Robot Pushing,2019-07,DVD-GAN-FP,109.8,100.0,109.8,1.0,109.8,1.0,ito:ITO_00101,Vision process,FVD\\ score
0,1,Robust Object Detection,PASCAL VOC 2007,2019-07,Faster R-CNN with Stylized Training Data,56.2,100.0,56.2,1.0,56.2,1.0,ito:ITO_00101,Vision process,mPC\\ \\[AP50\\]
0,1,Robust Object Detection,Cityscapes test,2019-07,Faster R-CNN with Stylized Training Data,17.2,100.0,17.2,1.0,17.2,0.84,ito:ITO_00101,Vision process,mPC\\ \\[AP\\]
1,1,Robust Object Detection,COCO,2019-07,Faster R-CNN with Stylized Training Data,20.4,100.0,20.4,1.0,20.4,1.0,ito:ITO_00101,Vision process,mPC\\ \\[AP\\]
0,1,Robust Object Detection,COCO,2019-07,Faster R-CNN with Stylized Training Data,58.9,100.0,58.9,1.0,58.9,0.84,ito:ITO_00101,Vision process,rPC\\ \\[%\\]
1,1,Robust Object Detection,PASCAL VOC 2007,2019-07,Faster R-CNN with Stylized Training Data,69.9,100.0,69.9,1.0,69.9,1.0,ito:ITO_00101,Vision process,rPC\\ \\[%\\]
2,1,Robust Object Detection,Cityscapes test,2019-07,Faster R-CNN with Stylized Training Data,47.4,100.0,47.4,1.0,47.4,0.68,ito:ITO_00101,Vision process,rPC\\ \\[%\\]
0,1,Horizon Line Estimation,KITTI Horizon,2019-07,"ConvLSTM (Huber Loss, naive residual path)",4.984,100.0,4.984,1.0,4.984,1.0,ito:ITO_00101,Vision process,ATV
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,1820000.0,100.0,1820000,1.0,1820000,1.0,ito:ITO_00101,Vision process,No\\.\\ parameters
0,1,3D Human Pose Estimation,3D Poses in the Wild Challenge,2019-07,RootNet,21.25,83.6,21.25,0.84,25.42,0.84,ito:ITO_00101,Vision process,MPJAE
1,1,3D Human Pose Estimation,3D Poses in the Wild Challenge,2019-09,SPIN,25.42,100.0,4.2,0.17,25.42,1.0,ito:ITO_00101,Vision process,MPJAE
0,1,3D Absolute Human Pose Estimation,Human3.6M,2019-07,RootNet,120.0,100.0,120,1.0,120,1.0,ito:ITO_00101,Vision process,MRPE
0,1,Video Retrieval,DiDeMo,2019-07,Collaborative Experts,82.7,100.0,82.7,1.0,82.7,0.9,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-50
1,1,Video Retrieval,MSVD,2019-07,Collaborative Experts,89.0,100.0,89,1.0,89,0.97,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-50
2,1,Video Retrieval,ActivityNet,2019-07,Collaborative Experts,91.4,100.0,91.4,1.0,91.4,1.0,ito:ITO_00101,Vision process,text\\-to\\-video\\ R\\-at\\-50
0,1,Semantic Image Matting,Semantic Image Matting Dataset,2019-08,IndexNet,51.29,100.0,51.29,1.0,51.29,1.0,ito:ITO_00101,Vision process,SAD
1,1,Image Matting,Composition-1K,2019-08,IndexNet-Matting,45.8,100.0,45.8,1.0,45.8,0.89,ito:ITO_00101,Vision process,SAD
0,1,Image Matting,Composition-1K,2019-08,IndexNet-Matting,43.7,100.0,43.7,1.0,43.7,0.9,ito:ITO_00101,Vision process,Conn
1,1,Semantic Image Matting,Semantic Image Matting Dataset,2019-08,IndexNet,48.77,100.0,48.77,1.0,48.77,1.0,ito:ITO_00101,Vision process,Conn
0,1,Image Matting,Composition-1K,2019-08,IndexNet-Matting,25.9,100.0,25.9,1.0,25.9,0.76,ito:ITO_00101,Vision process,Grad
1,1,Semantic Image Matting,Semantic Image Matting Dataset,2019-08,IndexNet,34.19,100.0,34.19,1.0,34.19,1.0,ito:ITO_00101,Vision process,Grad
0,1,Semantic Image Matting,Semantic Image Matting Dataset,2019-08,IndexNet,14.0,100.0,14,1.0,14,1.0,ito:ITO_00101,Vision process,MSE\\(10\\^3\\)
0,1,Visual Reasoning,NLVR,2019-08,VisualBERT,67.4,100.0,67.4,1.0,67.4,1.0,ito:ITO_00101,Vision process,Accuracy\\ \\(Dev\\)
0,1,Visual Reasoning,NLVR,2019-08,VisualBERT,67.0,100.0,67,1.0,67,1.0,ito:ITO_00101,Vision process,Accuracy\\ \\(Test\\-P\\)
0,1,Visual Reasoning,NLVR,2019-08,VisualBERT,67.3,100.0,67.3,1.0,67.3,1.0,ito:ITO_00101,Vision process,Accuracy\\ \\(Test\\-U\\)
0,1,Monocular Depth Estimation,NYU Depth v2,2019-08,Index Network,0.787,100.0,0.787,1.0,0.787,1.0,ito:ITO_00101,Vision process,Delta1
0,1,Layout-to-Image Generation,Visual Genome 128x128,2019-08,LostGAN,13.17,100.0,13.17,1.0,13.17,0.39,ito:ITO_00101,Vision process,SceneFID
1,1,Layout-to-Image Generation,COCO-Stuff 128x128,2019-08,LostGAN,20.03,59.86,20.03,0.6,33.46,0.6,ito:ITO_00101,Vision process,SceneFID
2,1,Layout-to-Image Generation,COCO-Stuff 128x128,2019-09,SOARISG,33.46,100.0,13.4,0.4,33.46,1.0,ito:ITO_00101,Vision process,SceneFID
0,1,Visual Question Answering,VizWiz 2018,2019-08,"LXR955, No Ensemble",74.0,100.0,74,1.0,74,1.0,ito:ITO_00101,Vision process,yes/no
0,1,Visual Question Answering,VizWiz 2018,2019-08,"LXR955, No Ensemble",24.76,100.0,24.76,1.0,24.76,1.0,ito:ITO_00101,Vision process,number
0,1,Visual Question Answering,VizWiz 2018,2019-08,"LXR955, No Ensemble",39.0,100.0,39,1.0,39,1.0,ito:ITO_00101,Vision process,other
0,1,Visual Question Answering,VizWiz 2018,2019-08,"LXR955, No Ensemble",82.26,100.0,82.26,1.0,82.26,1.0,ito:ITO_00101,Vision process,unanswerable
0,1,6D Pose Estimation using RGB,T-LESS,2019-08,Pix2Pose without ICP,29.5,100.0,29.5,1.0,29.5,1.0,ito:ITO_00101,Vision process,Recall\\ \\(VSD\\)
0,1,Temporal Action Localization,ActivityNet-1.3,2019-08,3C-Net,9.2,100.0,9.2,1.0,9.2,1.0,ito:ITO_00101,Vision process,mAP\\ IOU\\-at\\-0\\.9
0,1,Image Retrieval,DeepFashion,2019-08,RCCapsNet,84.6,100.0,84.6,1.0,84.6,1.0,ito:ITO_00101,Vision process,Recall\\-at\\-20
0,1,Hand Pose Estimation,K2HPD,2019-08,A2J,76.3,100.0,76.3,1.0,76.3,1.0,ito:ITO_00101,Vision process,PDJ@5mm
0,1,Lesion Segmentation,ISIC 2018,2019-08,BCDU-Net (d=3),0.851,100.0,0.851,1.0,0.851,1.0,ito:ITO_00101,Vision process,F1\\-Score
0,1,Edge Detection,BIPED,2019-09,DexiNed (WACV'2020),0.859,100.0,0.859,1.0,0.859,1.0,ito:ITO_00101,Vision process,ODS
1,1,Edge Detection,CID,2019-09,DexiNed (WACV\'2020),0.65,100.0,0.65,1.0,0.65,0.76,ito:ITO_00101,Vision process,ODS
0,1,Multimodal Activity Recognition,Nurse Care Activity Recognition Challenge,2019-09,ST-GCN,52.9,100.0,52.9,1.0,52.9,1.0,ito:ITO_00101,Vision process,Train\\ F\\-measure
0,1,Image Super-Resolution,USR-248,2019-09,SRDRM-GAN,2.48,100.0,2.48,1.0,2.48,1.0,ito:ITO_00101,Vision process,UIQM
0,1,Heterogeneous Face Recognition,Disguised Faces in the Wild,2019-09,A-LINK,75.38,100.0,75.38,1.0,75.38,1.0,ito:ITO_00101,Vision process,GAR\\ at\\-0\\.1%\\ FAR\\ Impersonation
0,1,Heterogeneous Face Recognition,Disguised Faces in the Wild,2019-09,A-LINK,72.13,100.0,72.13,1.0,72.13,1.0,ito:ITO_00101,Vision process,GAR\\ at\\-0\\.1%\\ FAR\\ Obfuscation
0,1,Heterogeneous Face Recognition,Disguised Faces in the Wild,2019-09,A-LINK,72.72,100.0,72.72,1.0,72.72,1.0,ito:ITO_00101,Vision process,GAR\\ at\\-0\\.1%\\ FAR\\ Overall
0,1,Heterogeneous Face Recognition,Disguised Faces in the Wild,2019-09,A-LINK,95.73,100.0,95.73,1.0,95.73,1.0,ito:ITO_00101,Vision process,GAR\\ at\\-1%\\ FAR\\ Impersonation
0,1,Heterogeneous Face Recognition,Disguised Faces in the Wild,2019-09,A-LINK,88.97,100.0,88.97,1.0,88.97,1.0,ito:ITO_00101,Vision process,GAR\\ at\\-1%\\ FAR\\ Obfuscation
0,1,Heterogeneous Face Recognition,Disguised Faces in the Wild,2019-09,A-LINK,89.3,100.0,89.3,1.0,89.3,1.0,ito:ITO_00101,Vision process,GAR\\ at\\-1%\\ FAR\\ Overall
0,1,Heterogeneous Face Recognition,CMU-MPIE,2019-09,A-LINK,92.4,100.0,92.4,1.0,92.4,1.0,ito:ITO_00101,Vision process,16x16\\ Accuracy
0,1,Heterogeneous Face Recognition,CMU-MPIE,2019-09,A-LINK,92.6,100.0,92.6,1.0,92.6,1.0,ito:ITO_00101,Vision process,24x24\\ Accuracy
0,1,Heterogeneous Face Recognition,CMU-MPIE,2019-09,A-LINK,92.8,100.0,92.8,1.0,92.8,1.0,ito:ITO_00101,Vision process,32x32\\ Accuracy
0,1,Heterogeneous Face Recognition,CMU-MPIE,2019-09,A-LINK,92.9,100.0,92.9,1.0,92.9,1.0,ito:ITO_00101,Vision process,48x48\\ Accuracy
0,1,Image Captioning,Flickr30k Captions test,2019-09,Unified VLP,17.0,100.0,17,1.0,17,0.8,ito:ITO_00101,Vision process,SPICE
1,1,Image Captioning,COCO Captions test,2019-09,Unified VLP,21.2,100.0,21.2,1.0,21.2,1.0,ito:ITO_00101,Vision process,SPICE
0,1,Emotion Recognition in Conversation,EmoryNLP,2019-09,KET,34.39,100.0,34.39,1.0,34.39,1.0,ito:ITO_00101,Vision process,Weighted\\ Macro\\-F1
0,1,Multiple Object Forecasting,Citywalks,2019-09,STED,26.7,100.0,26.7,1.0,26.7,1.0,ito:ITO_00101,Vision process,ADE
1,1,Trajectory Prediction,Argoverse,2019-12,SpectralCows,0.005,100.0,0.005,1.0,0.005,0.0,ito:ITO_00101,Vision process,ADE
2,1,Trajectory Prediction,Lyft Level 5,2019-12,SpectralCows,0.008,100.0,0.008,1.0,0.008,0.0,ito:ITO_00101,Vision process,ADE
3,1,Trajectory Prediction,Apolloscape,2019-12,SpectralCows,0.005,100.0,0.005,1.0,0.005,0.0,ito:ITO_00101,Vision process,ADE
0,1,Multiple Object Forecasting,Citywalks,2019-09,STED,54.3,100.0,54.3,1.0,54.3,1.0,ito:ITO_00101,Vision process,AIOU
0,1,3D Human Pose Estimation,3DPW,2019-09,SPIN (SMPL oPtimization IN the loop),116.4,100.0,116.4,1.0,116.4,1.0,ito:ITO_00101,Vision process,MPVPE
0,1,Gesture Recognition,GesturePod,2019-10,GesturePod,92.0,100.0,92,1.0,92,1.0,ito:ITO_00101,Vision process,Real\\ World\\ Accuracy
0,1,Talking Face Generation,LRW,2019-10,LipGAN,0.6,100.0,0.6,1.0,0.6,1.0,ito:ITO_00101,Vision process,LMD
0,1,6D Pose Estimation,NOCS-REAL275,2019-10,6-PACK,94.2,100.0,94.2,1.0,94.2,1.0,ito:ITO_00101,Vision process,IOU25
0,1,6D Pose Estimation,NOCS-REAL275,2019-10,6-PACK,33.3,100.0,33.3,1.0,33.3,1.0,ito:ITO_00101,Vision process,5°5\\ cm
0,1,6D Pose Estimation,NOCS-REAL275,2019-10,6-PACK,16.0,100.0,16,1.0,16,1.0,ito:ITO_00101,Vision process,Rerr
0,1,6D Pose Estimation,NOCS-REAL275,2019-10,6-PACK,3.5,100.0,3.5,1.0,3.5,1.0,ito:ITO_00101,Vision process,Terr
0,1,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,2019-10,CAG-UDA,44.5,95.7,44.5,0.96,46.5,0.96,ito:ITO_00101,Vision process,MIoU\\ \\(16\\ classes\\)
1,1,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,2019-12,MRNet(ResNet-101),46.5,100.0,2.0,0.04,46.5,1.0,ito:ITO_00101,Vision process,MIoU\\ \\(16\\ classes\\)
0,1,Temporal Action Localization,J-HMDB-21,2019-11,YOWO (16-frame),58.1,100.0,58.1,1.0,58.1,1.0,ito:ITO_00101,Vision process,Video\\-mAP\\ 0\\.75
1,1,Action Detection,UCF101-24,2020-01,Ours (MOC),28.5,100.0,28.5,1.0,28.5,0.49,ito:ITO_00101,Vision process,Video\\-mAP\\ 0\\.75
0,1,Weakly Supervised Action Localization,THUMOS 2014,2019-11,BaS-Net,43.6,100.0,43.6,1.0,43.6,1.0,ito:ITO_00101,Vision process,mAP@0\\.1:0\\.5
0,1,Video Reconstruction,Tai-Chi-HD,2019-12,First Order Motion,0.063,100.0,0.063,1.0,0.063,1.0,ito:ITO_00101,Vision process,L1
1,1,Aerial Video Semantic Segmentation,Aerial Video Semantic Segmentation,2019-12,First Order Motion,0.063,100.0,0.063,1.0,0.063,1.0,ito:ITO_00101,Vision process,L1
0,1,Camera Localization,Aachen Day-Night benchmark,2019-12,"R2D2 WASF N8 (full scale, 10K kpts)",45.9,100.0,45.9,1.0,45.9,1.0,ito:ITO_00101,Vision process,"Acc\\-at\\-0\\.5m,\\ 2°"
0,1,Camera Localization,Aachen Day-Night benchmark,2019-12,"R2D2 WASF N8 (full scale, 10K kpts)",66.3,100.0,66.3,1.0,66.3,1.0,ito:ITO_00101,Vision process,"Acc\\-at\\-1m,\\ 5°"
0,1,Camera Localization,Aachen Day-Night benchmark,2019-12,"R2D2 WASF N8 (full scale, 10K kpts)",88.8,100.0,88.8,1.0,88.8,1.0,ito:ITO_00101,Vision process,"Acc\\-at\\-5m,\\ 10°"
0,1,Cross-View Image-to-Image Translation,cvusa,2019-12,UniGAN,2.6,100.0,2.6,1.0,2.6,1.0,ito:ITO_00101,Vision process,KL
0,1,Cross-View Image-to-Image Translation,cvusa,2019-12,UniGAN,19.8276,100.0,19.8276,1.0,19.8276,1.0,ito:ITO_00101,Vision process,SD
0,1,Gesture-to-Gesture Translation,Senz3D,2019-12,UniGAN,2.2104,100.0,2.2104,1.0,2.2104,1.0,ito:ITO_00101,Vision process,FRD
1,1,Gesture-to-Gesture Translation,NTU Hand Digit,2019-12,UniGAN,1.7401,100.0,1.7401,1.0,1.7401,0.79,ito:ITO_00101,Vision process,FRD
0,1,Semantic Segmentation,Cityscapes test,2019-12,LightSeg-DarkNet19,88.29,100.0,88.29,1.0,88.29,1.0,ito:ITO_00101,Vision process,Category\\ mIoU
0,1,Node Classification,Wiki,2019-12,DAOR,15.97,100.0,15.97,1.0,15.97,1.0,ito:ITO_00101,Vision process,Macro\\ F1
1,1,Micro-Expression Recognition,Micro-Expression Recognition,2019-12,DAOR,15.97,100.0,15.97,1.0,15.97,1.0,ito:ITO_00101,Vision process,Macro\\ F1
0,1,Node Classification,Wiki,2019-12,DAOR,53.24,100.0,53.24,1.0,53.24,1.0,ito:ITO_00101,Vision process,Micro\\ F1
1,1,Micro-Expression Recognition,Micro-Expression Recognition,2019-12,DAOR,53.24,100.0,53.24,1.0,53.24,1.0,ito:ITO_00101,Vision process,Micro\\ F1
0,1,3D Instance Segmentation,S3DIS,2019-12,JSNet,58.0,100.0,58,1.0,58,1.0,ito:ITO_00101,Vision process,mWCov
0,1,3D Instance Segmentation,S3DIS,2019-12,JSNet,54.1,100.0,54.1,1.0,54.1,1.0,ito:ITO_00101,Vision process,mCov
0,1,Fine-Grained Image Classification,SOP,2020-01,Assemble-ResNet-FGVC-50,85.9,100.0,85.9,1.0,85.9,1.0,ito:ITO_00101,Vision process,Recall\\-at\\-1
0,1,Video Question Answering,SUTD-TrafficQA,2020-02,HCRN,36.49,100.0,36.49,1.0,36.49,1.0,ito:ITO_00101,Vision process,1/4
0,1,Video Question Answering,SUTD-TrafficQA,2020-02,HCRN,63.79,100.0,63.79,1.0,63.79,1.0,ito:ITO_00101,Vision process,1/2
0,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet-tiny,0.44,11.08,0.44,0.11,3.97,0.11,ito:ITO_00101,Vision process,Parameters\\ \\(M\\)
1,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet,3.97,100.0,3.5,0.88,3.97,1.0,ito:ITO_00101,Vision process,Parameters\\ \\(M\\)
0,1,Scene Graph Generation,Visual Genome,2020-02,Causal-TDE,6.9,100.0,6.9,1.0,6.9,1.0,ito:ITO_00101,Vision process,mean\\ Recall\\ @20
0,1,Image-Based Localization,cvusa,2020-02,Instance Loss,43.91,100.0,43.91,1.0,43.91,0.62,ito:ITO_00101,Vision process,recall\\-at\\-1
1,1,Drone navigation,University-1652,2020-02,Instance Loss,71.18,100.0,71.18,1.0,71.18,1.0,ito:ITO_00101,Vision process,recall\\-at\\-1
2,1,Drone-view target localization,University-1652,2020-02,Instance Loss,58.49,100.0,58.49,1.0,58.49,0.82,ito:ITO_00101,Vision process,recall\\-at\\-1
0,1,Image-Based Localization,cvusa,2020-02,Instance Loss,66.38,100.0,66.38,1.0,66.38,1.0,ito:ITO_00101,Vision process,recall\\-at\\-5
0,1,Image-Based Localization,cvusa,2020-02,Instance Loss,91.78,100.0,91.78,1.0,91.78,1.0,ito:ITO_00101,Vision process,recall\\-at\\-top1%
0,1,Image Denoising,"ultracold fermions Technion system, pixelfly",2020-03,absDL,0.0711,100.0,0.0711,1.0,0.0711,1.0,ito:ITO_00101,Vision process,ODRMSE
0,1,Action Segmentation,Breakfast,2020-03,SSTDA,70.2,100.0,70.2,1.0,70.2,1.0,ito:ITO_00101,Vision process,Accuracy\\ \\(MoF\\)
0,1,Few-Shot Semantic Segmentation,Pascal5i,2020-03,DoG-BConvLSTM,60.6,100.0,60.6,1.0,60.6,1.0,ito:ITO_00101,Vision process,meanIOU
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,3.0,100.0,3,1.0,3,1.0,ito:ITO_00101,Vision process,Test\\ AUC\\ top\\ 1
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,7.6,100.0,7.6,1.0,7.6,1.0,ito:ITO_00101,Vision process,Test\\ AUC\\ top\\ 2
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,12.3,100.0,12.3,1.0,12.3,1.0,ito:ITO_00101,Vision process,Test\\ AUC\\ top\\ 3
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,4.3,100.0,4.3,1.0,4.3,1.0,ito:ITO_00101,Vision process,Val\\ AUC\\ top\\ 1
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,9.8,100.0,9.8,1.0,9.8,1.0,ito:ITO_00101,Vision process,Val\\ AUC\\ top\\ 2
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,14.8,100.0,14.8,1.0,14.8,1.0,ito:ITO_00101,Vision process,Val\\ AUC\\ top\\ 3
0,1,Compositional Zero-Shot Learning,UT-Zappos,2020-04,SymNet,67.8,100.0,67.8,1.0,67.8,1.0,ito:ITO_00101,Vision process,Top\\-2\\ accuracy\\ %
1,1,Compositional Zero-Shot Learning,MIT-States,2020-04,SymNet,28.2,100.0,28.2,1.0,28.2,0.42,ito:ITO_00101,Vision process,Top\\-2\\ accuracy\\ %
0,1,Compositional Zero-Shot Learning,UT-Zappos,2020-04,SymNet,76.0,100.0,76,1.0,76,1.0,ito:ITO_00101,Vision process,Top\\-3\\ accuracy\\ %
1,1,Compositional Zero-Shot Learning,MIT-States,2020-04,SymNet,33.8,100.0,33.8,1.0,33.8,0.44,ito:ITO_00101,Vision process,Top\\-3\\ accuracy\\ %
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,24.4,100.0,24.4,1.0,24.4,1.0,ito:ITO_00101,Vision process,Seen\\ accuracy
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,25.2,100.0,25.2,1.0,25.2,1.0,ito:ITO_00101,Vision process,Unseen\\ accuracy
0,1,3D Human Pose Estimation,Surreal,2020-04,Cross Dataset Generalization,97.3,100.0,97.3,1.0,97.3,1.0,ito:ITO_00101,Vision process,PCK3D
0,1,Skeleton Based Action Recognition,UWA3D,2012-07,HOJ3D,17.7,21.74,17.7,0.22,81.4,0.18,ito:ITO_00113,Miscellaneous process,Accuracy
1,1,Skeleton Based Action Recognition,UWA3D,2017-08,ESV (Synthesized + Pre-trained),73.8,90.66,56.1,0.69,81.4,0.74,ito:ITO_00113,Miscellaneous process,Accuracy
2,1,Skeleton Based Action Recognition,UWA3D,2018-04,VA-fusion (aug.),81.4,100.0,7.6,0.09,81.4,0.82,ito:ITO_00113,Miscellaneous process,Accuracy
3,1,Skeleton Based Action Recognition,CAD-120,2012-10,KGS,86.0,96.3,86.0,0.96,89.3,0.87,ito:ITO_00113,Miscellaneous process,Accuracy
4,1,Skeleton Based Action Recognition,CAD-120,2013-02,All Features (w ground truth),89.3,100.0,3.3,0.04,89.3,0.9,ito:ITO_00113,Miscellaneous process,Accuracy
5,1,Trajectory Prediction,GPS,2012-11,Support Vector Machines,88.0,100.0,88,1.0,88,0.89,ito:ITO_00113,Miscellaneous process,Accuracy
6,1,Skeleton Based Action Recognition,UT-Kinect,2014-06,Lie Group,97.1,98.58,97.1,0.99,98.5,0.98,ito:ITO_00113,Miscellaneous process,Accuracy
7,1,Skeleton Based Action Recognition,UT-Kinect,2018-06,DPRL,98.5,100.0,1.4,0.01,98.5,0.99,ito:ITO_00113,Miscellaneous process,Accuracy
8,1,Skeleton Based Action Recognition,Florence 3D,2014-06,Lie Group,90.9,91.73,90.9,0.92,99.1,0.92,ito:ITO_00113,Miscellaneous process,Accuracy
9,1,Skeleton Based Action Recognition,Florence 3D,2016-06,Rolling Rotations (FTP),91.4,92.23,0.5,0.01,99.1,0.92,ito:ITO_00113,Miscellaneous process,Accuracy
10,1,Skeleton Based Action Recognition,Florence 3D,2018-02,Deep STGC_K,99.1,100.0,7.7,0.08,99.1,1.0,ito:ITO_00113,Miscellaneous process,Accuracy
11,1,Malware Detection,Android Malware Dataset,2015-08,Deep WL kernel,98.16,99.12,98.16,0.99,99.03,0.99,ito:ITO_00113,Miscellaneous process,Accuracy
12,1,Malware Detection,Android Malware Dataset,2017-07,Graph2Vec,99.03,100.0,0.9,0.01,99.03,1.0,ito:ITO_00113,Miscellaneous process,Accuracy
13,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2015-09,GCN-FP,61.5,82.0,61.5,0.82,75.0,0.62,ito:ITO_00113,Miscellaneous process,Accuracy
14,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2015-11,DCNN,69.4,92.53,7.9,0.11,75.0,0.7,ito:ITO_00113,Miscellaneous process,Accuracy
15,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2016-06,ChebyNet,70.1,93.47,0.7,0.01,75.0,0.71,ito:ITO_00113,Miscellaneous process,Accuracy
16,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2017-10,GAT,72.5,96.67,2.4,0.03,75.0,0.73,ito:ITO_00113,Miscellaneous process,Accuracy
17,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2019-02,H-GCN,72.8,97.07,0.3,0.0,75.0,0.73,ito:ITO_00113,Miscellaneous process,Accuracy
18,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2019-03,LDS-GNN,75.0,100.0,2.2,0.03,75.0,0.76,ito:ITO_00113,Miscellaneous process,Accuracy
19,1,Trajectory Forecasting,Trajectory Forecasting,2015-09,GCN-FP,61.5,82.0,61.5,0.82,75.0,0.62,ito:ITO_00113,Miscellaneous process,Accuracy
20,1,Trajectory Forecasting,Trajectory Forecasting,2015-11,DCNN,69.4,92.53,7.9,0.11,75.0,0.7,ito:ITO_00113,Miscellaneous process,Accuracy
21,1,Trajectory Forecasting,Trajectory Forecasting,2016-06,ChebyNet,70.1,93.47,0.7,0.01,75.0,0.71,ito:ITO_00113,Miscellaneous process,Accuracy
22,1,Trajectory Forecasting,Trajectory Forecasting,2017-10,GAT,72.5,96.67,2.4,0.03,75.0,0.73,ito:ITO_00113,Miscellaneous process,Accuracy
23,1,Trajectory Forecasting,Trajectory Forecasting,2019-02,H-GCN,72.8,97.07,0.3,0.0,75.0,0.73,ito:ITO_00113,Miscellaneous process,Accuracy
24,1,Trajectory Forecasting,Trajectory Forecasting,2019-03,LDS-GNN,75.0,100.0,2.2,0.03,75.0,0.76,ito:ITO_00113,Miscellaneous process,Accuracy
25,1,Skeleton Based Action Recognition,SBU,2016-06,ChebyNet,96.0,96.95,96.0,0.97,99.02,0.97,ito:ITO_00113,Miscellaneous process,Accuracy
26,1,Skeleton Based Action Recognition,SBU,2017-03,Joint Line Distance,99.02,100.0,3.0,0.03,99.02,1.0,ito:ITO_00113,Miscellaneous process,Accuracy
27,1,Skeleton Based Action Recognition,SYSU 3D,2016-12,Dynamic Skeletons,75.5,86.88,75.5,0.87,86.9,0.76,ito:ITO_00113,Miscellaneous process,Accuracy
28,1,Skeleton Based Action Recognition,SYSU 3D,2017-03,VA-LSTM,77.5,89.18,2.0,0.02,86.9,0.78,ito:ITO_00113,Miscellaneous process,Accuracy
29,1,Skeleton Based Action Recognition,SYSU 3D,2018-04,VA-fusion (aug.),86.7,99.77,9.2,0.11,86.9,0.87,ito:ITO_00113,Miscellaneous process,Accuracy
30,1,Skeleton Based Action Recognition,SYSU 3D,2019-04,SGN,86.9,100.0,0.2,0.0,86.9,0.88,ito:ITO_00113,Miscellaneous process,Accuracy
31,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2017-04,Res-TCN,20.3,52.59,20.3,0.53,38.6,0.2,ito:ITO_00113,Miscellaneous process,Accuracy
32,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2018-01,ST-GCN,30.7,79.53,10.4,0.27,38.6,0.31,ito:ITO_00113,Miscellaneous process,Accuracy
33,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2018-05,2s-AGCN,36.1,93.52,5.4,0.14,38.6,0.36,ito:ITO_00113,Miscellaneous process,Accuracy
34,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2018-11,SLnL-rFA,36.6,94.82,0.5,0.01,38.6,0.37,ito:ITO_00113,Miscellaneous process,Accuracy
35,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-06,DGNN,36.9,95.6,0.3,0.01,38.6,0.37,ito:ITO_00113,Miscellaneous process,Accuracy
36,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-11,GCN-NAS,37.1,96.11,0.2,0.01,38.6,0.37,ito:ITO_00113,Miscellaneous process,Accuracy
37,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-12,MS-AAGCN,37.8,97.93,0.7,0.02,38.6,0.38,ito:ITO_00113,Miscellaneous process,Accuracy
38,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2020-03,2s-AGCN+TEM,38.6,100.0,0.8,0.02,38.6,0.39,ito:ITO_00113,Miscellaneous process,Accuracy
39,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,bc-LSTM+Att,56.32,86.31,56.32,0.86,65.25,0.57,ito:ITO_00113,Miscellaneous process,Accuracy
40,1,Emotion Recognition in Conversation,IEMOCAP,2018-06,CMN,56.56,86.68,0.2,0.0,65.25,0.57,ito:ITO_00113,Miscellaneous process,Accuracy
41,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,ICON,59.09,90.56,2.5,0.04,65.25,0.6,ito:ITO_00113,Miscellaneous process,Accuracy
42,1,Emotion Recognition in Conversation,IEMOCAP,2018-11,DialogueRNN,63.4,97.16,4.3,0.07,65.25,0.64,ito:ITO_00113,Miscellaneous process,Accuracy
43,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,DialogueGCN,65.25,100.0,1.9,0.03,65.25,0.66,ito:ITO_00113,Miscellaneous process,Accuracy
44,1,Emotion Recognition in Conversation,MELD,2017-07,bc-LSTM+Att,57.5,96.57,57.5,0.97,59.54,0.58,ito:ITO_00113,Miscellaneous process,Accuracy
45,1,Emotion Recognition in Conversation,MELD,2018-11,DialogueRNN,59.54,100.0,2.0,0.03,59.54,0.6,ito:ITO_00113,Miscellaneous process,Accuracy
46,1,Multimodal Emotion Recognition,Monologue,2017-07,bc-LSTM,74.1,100.0,74.1,1.0,74.1,0.75,ito:ITO_00113,Miscellaneous process,Accuracy
47,1,Skeleton Based Action Recognition,N-UCLA,2018-02,Glimpse Clouds,87.6,94.7,87.6,0.95,92.5,0.88,ito:ITO_00113,Miscellaneous process,Accuracy
48,1,Skeleton Based Action Recognition,N-UCLA,2018-04,VA-fusion (aug.),88.1,95.24,0.5,0.01,92.5,0.89,ito:ITO_00113,Miscellaneous process,Accuracy
49,1,Skeleton Based Action Recognition,N-UCLA,2018-12,Action Machine,92.3,99.78,4.2,0.05,92.5,0.93,ito:ITO_00113,Miscellaneous process,Accuracy
50,1,Skeleton Based Action Recognition,N-UCLA,2019-04,SGN,92.5,100.0,0.2,0.0,92.5,0.93,ito:ITO_00113,Miscellaneous process,Accuracy
51,1,Click-Through Rate Prediction,MovieLens 1M,2018-03,RippleNet,84.4,100.0,84.4,1.0,84.4,0.85,ito:ITO_00113,Miscellaneous process,Accuracy
52,1,Weakly-Supervised Action Recognition,Weakly-Supervised Action Recognition,2018-03,RippleNet,84.4,100.0,84.4,1.0,84.4,0.85,ito:ITO_00113,Miscellaneous process,Accuracy
53,1,Click-Through Rate Prediction,Book-Crossing,2018-03,RippleNet,0.662,100.0,0.662,1.0,0.662,0.01,ito:ITO_00113,Miscellaneous process,Accuracy
54,1,Click-Through Rate Prediction,Bing News,2018-03,RippleNet,63.2,100.0,63.2,1.0,63.2,0.64,ito:ITO_00113,Miscellaneous process,Accuracy
55,1,Replay Grounding,Replay Grounding,2018-03,RippleNet,63.2,100.0,63.2,1.0,63.2,0.64,ito:ITO_00113,Miscellaneous process,Accuracy
56,1,Unsupervised Domain Expansion,Unsupervised Domain Expansion,2018-03,RippleNet,0.662,100.0,0.662,1.0,0.662,0.01,ito:ITO_00113,Miscellaneous process,Accuracy
57,1,Network Intrusion Detection,KDD ,2018-10,DNN-3,93.0,100.0,93,1.0,93,0.94,ito:ITO_00113,Miscellaneous process,Accuracy
58,1,Click-Through Rate Prediction,Last.FM,2019-01,MKR,64.5,100.0,64.5,1.0,64.5,0.65,ito:ITO_00113,Miscellaneous process,Accuracy
59,1,Click-Through Rate Prediction,Children's Book Test Common noun,2019-01,MKR,70.4,100.0,70.4,1.0,70.4,0.71,ito:ITO_00113,Miscellaneous process,Accuracy
60,1,Generalized Zero Shot skeletal action recognition,Generalized Zero Shot skeletal action recognition,2019-01,MKR,70.4,100.0,70.4,1.0,70.4,0.71,ito:ITO_00113,Miscellaneous process,Accuracy
61,1,Recommendation Systems,Polyvore,2019-02,NGNN,0.7813,100.0,0.7813,1.0,0.7813,0.01,ito:ITO_00113,Miscellaneous process,Accuracy
62,1,Emotion Recognition,MPED,2019-05,BiHDM,40.34,100.0,40.34,1.0,40.34,0.41,ito:ITO_00113,Miscellaneous process,Accuracy
63,1,Skeleton Based Action Recognition,MSR Action3D,2019-06,HDM-BG,86.1,100.0,86.1,1.0,86.1,0.87,ito:ITO_00113,Miscellaneous process,Accuracy
64,1,Skeleton Based Action Recognition,UPenn Action,2019-06,HDM-BG,93.4,94.06,93.4,0.94,99.3,0.94,ito:ITO_00113,Miscellaneous process,Accuracy
65,1,Skeleton Based Action Recognition,UPenn Action,2020-01,UniPose-LSTM,99.3,100.0,5.9,0.06,99.3,1.0,ito:ITO_00113,Miscellaneous process,Accuracy
66,1,Emotion Recognition,SEED-IV,2019-07,RGNN,79.37,100.0,79.37,1.0,79.37,0.8,ito:ITO_00113,Miscellaneous process,Accuracy
67,1,Twitter Bot Detection,MIB Datasets,2019-12,DNA String Compression,0.984,100.0,0.984,1.0,0.984,0.01,ito:ITO_00113,Miscellaneous process,Accuracy
68,1,Drug–drug Interaction Extraction,Drug–drug Interaction Extraction,2019-12,DNA String Compression,0.984,100.0,0.984,1.0,0.984,0.01,ito:ITO_00113,Miscellaneous process,Accuracy
0,1,Robotic Grasping,Cornell Grasp Dataset,2013-01,Fast Search,60.5,61.92,60.5,0.62,97.7,0.62,ito:ITO_00113,Miscellaneous process,5\\ fold\\ cross\\ validation
1,1,Robotic Grasping,Cornell Grasp Dataset,2014-12,"AlexNet, MultiGrasp",88.0,90.07,27.5,0.28,97.7,0.9,ito:ITO_00113,Miscellaneous process,5\\ fold\\ cross\\ validation
2,1,Robotic Grasping,Cornell Grasp Dataset,2016-11,Multi-Modal Grasp Predictor,89.21,91.31,1.2,0.01,97.7,0.91,ito:ITO_00113,Miscellaneous process,5\\ fold\\ cross\\ validation
3,1,Robotic Grasping,Cornell Grasp Dataset,2018-10,ResNet50 multi-grasp predictor,96.0,98.26,6.8,0.07,97.7,0.98,ito:ITO_00113,Miscellaneous process,5\\ fold\\ cross\\ validation
4,1,Robotic Grasping,Cornell Grasp Dataset,2019-09,GR-ConvNet,97.7,100.0,1.7,0.02,97.7,1.0,ito:ITO_00113,Miscellaneous process,5\\ fold\\ cross\\ validation
0,1,Latent Variable Models,200k Short Texts for Humor Detection,2014-01,meto,0.987,100.0,0.987,1.0,0.987,1.0,ito:ITO_00113,Miscellaneous process,10\\-20%\\ Mask\\ PSNR
1,1,Grasp Contact Prediction,Grasp Contact Prediction,2014-01,meto,0.987,100.0,0.987,1.0,0.987,1.0,ito:ITO_00113,Miscellaneous process,10\\-20%\\ Mask\\ PSNR
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,60.0,78.95,60,0.79,76,0.79,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(CS\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-04,Res-TCN,63.0,82.89,3,0.04,76,0.83,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(CS\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2018-01,ST-GCN,71.0,93.42,8,0.11,76,0.93,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(CS\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,76.0,100.0,5,0.07,76,1.0,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(CS\\)
0,1,Recommendation Systems,MovieLens 100K,2014-08,GMC,0.996,100.0,0.996,1.0,0.996,1.0,ito:ITO_00113,Miscellaneous process,RMSE\\ \\(u1\\ Splits\\)
0,1,Recommendation Systems,MovieLens 100K,2014-08,GMC,0.996,100.0,0.996,1.0,0.996,0.03,ito:ITO_00113,Miscellaneous process,RMSE
1,1,Recommendation Systems,MovieLens 1M,2015-05,I-AutoRec,0.831,95.96,0.831,0.96,0.866,0.02,ito:ITO_00113,Miscellaneous process,RMSE
2,1,Recommendation Systems,MovieLens 1M,2015-11,NNMF,0.843,97.34,0.0,0.0,0.866,0.02,ito:ITO_00113,Miscellaneous process,RMSE
3,1,Recommendation Systems,MovieLens 1M,2016-05,Factorization with dictionary learning,0.866,100.0,0.0,0.0,0.866,0.02,ito:ITO_00113,Miscellaneous process,RMSE
4,1,Recommendation Systems,MovieLens 10M,2015-05,I-AutoRec,0.782,95.02,0.782,0.95,0.823,0.02,ito:ITO_00113,Miscellaneous process,RMSE
5,1,Recommendation Systems,MovieLens 10M,2016-05,Factorization with dictionary learning,0.799,97.08,0.0,0.0,0.823,0.02,ito:ITO_00113,Miscellaneous process,RMSE
6,1,Recommendation Systems,MovieLens 10M,2019-05,U-RBM,0.823,100.0,0.0,0.0,0.823,0.02,ito:ITO_00113,Miscellaneous process,RMSE
7,1,Recommendation Systems,Flixster Monti,2015-12,GRALS,1.2447,100.0,1.2447,1.0,1.2447,0.03,ito:ITO_00113,Miscellaneous process,RMSE
8,1,Recommendation Systems,YahooMusic,2015-12,GRALS,22.872,100.0,22.872,1.0,22.872,0.6,ito:ITO_00113,Miscellaneous process,RMSE
9,1,Recommendation Systems,YahooMusic Monti,2015-12,GRALS,38.0423,100.0,38.0423,1.0,38.0423,1.0,ito:ITO_00113,Miscellaneous process,RMSE
10,1,Recommendation Systems,Douban,2015-12,GRALS,0.714,89.14,0.714,0.89,0.801,0.02,ito:ITO_00113,Miscellaneous process,RMSE
11,1,Recommendation Systems,Douban,2017-04,sRGCNN,0.801,100.0,0.1,0.12,0.801,0.02,ito:ITO_00113,Miscellaneous process,RMSE
12,1,Recommendation Systems,Flixster,2015-12,GRALS,0.845,91.25,0.845,0.91,0.926,0.02,ito:ITO_00113,Miscellaneous process,RMSE
13,1,Recommendation Systems,Flixster,2017-04,sRGCNN,0.926,100.0,0.1,0.11,0.926,0.02,ito:ITO_00113,Miscellaneous process,RMSE
14,1,Recommendation Systems,Douban Monti,2015-12,GRALS,0.8326,100.0,0.8326,1.0,0.8326,0.02,ito:ITO_00113,Miscellaneous process,RMSE
15,1,Recommendation Systems,Epinions,2017-06,"NSCR (Wang et al., 2017)",1.0425,100.0,1.0425,1.0,1.0425,0.03,ito:ITO_00113,Miscellaneous process,RMSE
16,1,Recommendation Systems,Frappe,2019-02,INN,0.3071,100.0,0.3071,1.0,0.3071,0.01,ito:ITO_00113,Miscellaneous process,RMSE
17,1,Trajectory Prediction,TRAF,2019-06,TraPHic,0.78,100.0,0.78,1.0,0.78,0.02,ito:ITO_00113,Miscellaneous process,RMSE
18,1,Trajectory Prediction,NGSIM,2019-06,TraPHic,5.63,100.0,5.63,1.0,5.63,0.15,ito:ITO_00113,Miscellaneous process,RMSE
0,1,Skeleton Based Action Recognition,J-HMDB,2014-11,Action Tubes,62.5,69.14,62.5,0.69,90.4,0.69,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(RGB\\+pose\\)
1,1,Skeleton Based Action Recognition,J-HMDB,2016-09,MR Two-Sream R-CNN,71.1,78.65,8.6,0.1,90.4,0.79,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(RGB\\+pose\\)
2,1,Skeleton Based Action Recognition,J-HMDB,2017-04,Chained (RGB+Flow +Pose),76.1,84.18,5.0,0.06,90.4,0.84,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(RGB\\+pose\\)
3,1,Skeleton Based Action Recognition,J-HMDB,2017-05,I3D,84.1,93.03,8.0,0.09,90.4,0.93,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(RGB\\+pose\\)
4,1,Skeleton Based Action Recognition,J-HMDB,2018-06,I3D + Potion,85.5,94.58,1.4,0.02,90.4,0.95,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(RGB\\+pose\\)
5,1,Skeleton Based Action Recognition,J-HMDB,2018-06,Potion,90.4,100.0,4.9,0.05,90.4,1.0,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(RGB\\+pose\\)
0,1,Cross-Modal Retrieval,COCO 2014,2014-12,Dual-Path (ResNet),25.3,65.54,25.3,0.66,38.6,0.52,ito:ITO_00113,Miscellaneous process,Text\\-to\\-image\\ R@1
1,1,Cross-Modal Retrieval,COCO 2014,2017-12,SCO (ResNet),33.1,85.75,7.8,0.2,38.6,0.68,ito:ITO_00113,Miscellaneous process,Text\\-to\\-image\\ R@1
2,1,Cross-Modal Retrieval,COCO 2014,2018-03,SCAN,38.6,100.0,5.5,0.14,38.6,0.79,ito:ITO_00113,Miscellaneous process,Text\\-to\\-image\\ R@1
3,1,Cross-Modal Retrieval,Flickr30k,2017-12,SCO\n  (ResNet),41.1,84.57,41.1,0.85,48.6,0.85,ito:ITO_00113,Miscellaneous process,Text\\-to\\-image\\ R@1
4,1,Cross-Modal Retrieval,Flickr30k,2018-03,SCAN,48.6,100.0,7.5,0.15,48.6,1.0,ito:ITO_00113,Miscellaneous process,Text\\-to\\-image\\ R@1
0,1,Cross-Modal Retrieval,COCO 2014,2014-12,Dual-Path (ResNet),53.4,77.06,53.4,0.77,69.3,0.69,ito:ITO_00113,Miscellaneous process,Text\\-to\\-image\\ R@5
1,1,Cross-Modal Retrieval,COCO 2014,2017-12,SCO (ResNet),62.9,90.76,9.5,0.14,69.3,0.81,ito:ITO_00113,Miscellaneous process,Text\\-to\\-image\\ R@5
2,1,Cross-Modal Retrieval,COCO 2014,2018-03,SCAN,69.3,100.0,6.4,0.09,69.3,0.89,ito:ITO_00113,Miscellaneous process,Text\\-to\\-image\\ R@5
3,1,Cross-Modal Retrieval,Flickr30k,2017-12,SCO\n  (ResNet),70.5,90.73,70.5,0.91,77.7,0.91,ito:ITO_00113,Miscellaneous process,Text\\-to\\-image\\ R@5
4,1,Cross-Modal Retrieval,Flickr30k,2018-03,SCAN,77.7,100.0,7.2,0.09,77.7,1.0,ito:ITO_00113,Miscellaneous process,Text\\-to\\-image\\ R@5
0,1,Cross-Modal Retrieval,COCO 2014,2014-12,Dual-Path (ResNet),66.4,82.59,66.4,0.83,80.4,0.78,ito:ITO_00113,Miscellaneous process,Text\\-to\\-image\\ R@10
1,1,Cross-Modal Retrieval,COCO 2014,2017-12,SCO (ResNet),75.5,93.91,9.1,0.11,80.4,0.89,ito:ITO_00113,Miscellaneous process,Text\\-to\\-image\\ R@10
2,1,Cross-Modal Retrieval,COCO 2014,2018-03,SCAN,80.4,100.0,4.9,0.06,80.4,0.94,ito:ITO_00113,Miscellaneous process,Text\\-to\\-image\\ R@10
3,1,Cross-Modal Retrieval,Flickr30k,2017-12,SCO\n  (ResNet),80.1,94.01,80.1,0.94,85.2,0.94,ito:ITO_00113,Miscellaneous process,Text\\-to\\-image\\ R@10
4,1,Cross-Modal Retrieval,Flickr30k,2018-03,SCAN,85.2,100.0,5.1,0.06,85.2,1.0,ito:ITO_00113,Miscellaneous process,Text\\-to\\-image\\ R@10
0,1,Cross-Modal Retrieval,COCO 2014,2014-12,"DVSA (R-CNN, AlexNet)",38.4,68.82,38.4,0.69,55.8,0.57,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-1
1,1,Cross-Modal Retrieval,COCO 2014,2014-12,Dual-Path (ResNet),41.2,73.84,2.8,0.05,55.8,0.61,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-1
2,1,Cross-Modal Retrieval,COCO 2014,2016-08,2WayNet (VGG),55.8,100.0,14.6,0.26,55.8,0.83,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-1
3,1,Cross-Modal Retrieval,Flickr30k,2017-12,SCO\n  (ResNet),55.5,82.34,55.5,0.82,67.4,0.82,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-1
4,1,Cross-Modal Retrieval,Flickr30k,2018-03,SCAN,67.4,100.0,11.9,0.18,67.4,1.0,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-1
0,1,Cross-Modal Retrieval,COCO 2014,2014-12,"DVSA (R-CNN, AlexNet)",80.5,89.44,80.5,0.89,90.0,0.84,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-10
1,1,Cross-Modal Retrieval,COCO 2014,2014-12,Dual-Path (ResNet),81.1,90.11,0.6,0.01,90.0,0.85,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-10
2,1,Cross-Modal Retrieval,COCO 2014,2015-11,Order-embeddings (VGG),84.7,94.11,3.6,0.04,90.0,0.88,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-10
3,1,Cross-Modal Retrieval,COCO 2014,2018-03,SCAN,90.0,100.0,5.3,0.06,90.0,0.94,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-10
4,1,Cross-Modal Retrieval,Flickr30k,2017-12,SCO\n  (ResNet),89.3,93.22,89.3,0.93,95.8,0.93,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-10
5,1,Cross-Modal Retrieval,Flickr30k,2018-03,SCAN,95.8,100.0,6.5,0.07,95.8,1.0,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-10
0,1,Cross-Modal Retrieval,COCO 2014,2014-12,"DVSA (R-CNN, AlexNet)",69.9,85.04,69.9,0.85,82.2,0.77,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-5
1,1,Cross-Modal Retrieval,COCO 2014,2014-12,Dual-Path (ResNet),70.5,85.77,0.6,0.01,82.2,0.78,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-5
2,1,Cross-Modal Retrieval,COCO 2014,2016-08,2WayNet (VGG),75.2,91.48,4.7,0.06,82.2,0.83,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-5
3,1,Cross-Modal Retrieval,COCO 2014,2018-03,SCAN,82.2,100.0,7.0,0.09,82.2,0.91,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-5
4,1,Cross-Modal Retrieval,Flickr30k,2017-12,SCO\n  (ResNet),82.0,90.81,82.0,0.91,90.3,0.91,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-5
5,1,Cross-Modal Retrieval,Flickr30k,2018-03,SCAN,90.3,100.0,8.3,0.09,90.3,1.0,ito:ITO_00113,Miscellaneous process,Image\\-to\\-text\\ R\\-at\\-5
0,1,Anomaly Detection,Numenta Anomaly Benchmark,2015-10,Numenta HTM,64.7,92.3,64.7,0.92,70.1,0.92,ito:ITO_00113,Miscellaneous process,NAB\\ score
1,1,Anomaly Detection,Numenta Anomaly Benchmark,2017-06,HTM AL,70.1,100.0,5.4,0.08,70.1,1.0,ito:ITO_00113,Miscellaneous process,NAB\\ score
0,1,Topic modeling,20 Newsgroups,2015-11,NVDM,836.0,100.0,836,1.0,836,1.0,ito:ITO_00113,Miscellaneous process,Test\\ perplexity
0,1,Click-Through Rate Prediction,Criteo,2016-01,FNN,0.7963,98.03,0.7963,0.98,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
1,1,Click-Through Rate Prediction,Criteo,2016-06,Wide & Deep (LR & DNN),0.7981,98.25,0.0,0.0,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
2,1,Click-Through Rate Prediction,Criteo,2016-11,OPNN,0.7982,98.26,0.0,0.0,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
3,1,Click-Through Rate Prediction,Criteo,2016-11,PNN*,0.7987,98.33,0.0,0.0,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
4,1,Click-Through Rate Prediction,Criteo,2017-03,DeepFM,0.8007,98.57,0.0,0.0,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
5,1,Click-Through Rate Prediction,Criteo,2018-03,xDeepFM,0.8052,99.13,0.0,0.0,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
6,1,Click-Through Rate Prediction,Criteo,2018-10,AutoInt,0.8061,99.24,0.0,0.0,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
7,1,Click-Through Rate Prediction,Criteo,2019-10,Fi-GNN,0.8082,99.5,0.0,0.0,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
8,1,Click-Through Rate Prediction,Criteo,2020-02,Sparse DeepFwFM,0.8123,100.0,0.0,0.0,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
9,1,Sequential skip prediction,Sequential skip prediction,2016-01,FNN,0.7963,98.03,0.7963,0.98,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
10,1,Sequential skip prediction,Sequential skip prediction,2016-06,Wide & Deep (LR & DNN),0.7981,98.25,0.0,0.0,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
11,1,Sequential skip prediction,Sequential skip prediction,2016-11,PNN*,0.7987,98.33,0.0,0.0,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
12,1,Sequential skip prediction,Sequential skip prediction,2017-03,DeepFM,0.8007,98.57,0.0,0.0,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
13,1,Sequential skip prediction,Sequential skip prediction,2018-03,xDeepFM,0.8052,99.13,0.0,0.0,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
14,1,Sequential skip prediction,Sequential skip prediction,2018-10,AutoInt,0.8061,99.24,0.0,0.0,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
15,1,Sequential skip prediction,Sequential skip prediction,2019-10,Fi-GNN,0.8082,99.5,0.0,0.0,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
16,1,Sequential skip prediction,Sequential skip prediction,2020-02,Sparse DeepFwFM,0.8123,100.0,0.0,0.0,0.8123,0.01,ito:ITO_00113,Miscellaneous process,AUC
17,1,Click-Through Rate Prediction,Company_,2016-01,FNN,0.8683,99.63,0.8683,1.0,0.8715,0.01,ito:ITO_00113,Miscellaneous process,AUC
18,1,Click-Through Rate Prediction,Company_,2017-03,DeepFM,0.8715,100.0,0.0,0.0,0.8715,0.01,ito:ITO_00113,Miscellaneous process,AUC
19,1,Bilingual Lexicon Induction,Bilingual Lexicon Induction,2016-01,FNN,0.8683,99.63,0.8683,1.0,0.8715,0.01,ito:ITO_00113,Miscellaneous process,AUC
20,1,Bilingual Lexicon Induction,Bilingual Lexicon Induction,2017-03,DeepFM,0.8715,100.0,0.0,0.0,0.8715,0.01,ito:ITO_00113,Miscellaneous process,AUC
21,1,Click-Through Rate Prediction,iPinYou,2016-01,FNN,0.7619,93.21,0.7619,0.93,0.8174,0.01,ito:ITO_00113,Miscellaneous process,AUC
22,1,Click-Through Rate Prediction,iPinYou,2016-11,OPNN,0.8174,100.0,0.1,0.12,0.8174,0.01,ito:ITO_00113,Miscellaneous process,AUC
23,1,Few-Shot Video Object Detection,Few-Shot Video Object Detection,2016-01,FNN,0.7619,93.21,0.7619,0.93,0.8174,0.01,ito:ITO_00113,Miscellaneous process,AUC
24,1,Few-Shot Video Object Detection,Few-Shot Video Object Detection,2016-11,OPNN,0.8174,100.0,0.1,0.12,0.8174,0.01,ito:ITO_00113,Miscellaneous process,AUC
25,1,Click-Through Rate Prediction,Bing News,2016-06,Wide & Deep,0.8377,99.73,0.8377,1.0,0.84,0.01,ito:ITO_00113,Miscellaneous process,AUC
26,1,Click-Through Rate Prediction,Bing News,2018-03,xDeepFM,0.84,100.0,0.0,0.0,0.84,0.01,ito:ITO_00113,Miscellaneous process,AUC
27,1,Click-Through Rate Prediction,Dianping,2016-06,Wide & Deep,0.8361,96.78,0.8361,0.97,0.8639,0.01,ito:ITO_00113,Miscellaneous process,AUC
28,1,Click-Through Rate Prediction,Dianping,2016-11,PNN,0.8445,97.75,0.0,0.0,0.8639,0.01,ito:ITO_00113,Miscellaneous process,AUC
29,1,Click-Through Rate Prediction,Dianping,2017-03,DeepFM,0.8481,98.17,0.0,0.0,0.8639,0.01,ito:ITO_00113,Miscellaneous process,AUC
30,1,Click-Through Rate Prediction,Dianping,2018-03,xDeepFM,0.8639,100.0,0.0,0.0,0.8639,0.01,ito:ITO_00113,Miscellaneous process,AUC
31,1,3D Action Recognition,3D Action Recognition,2016-06,Wide & Deep,0.8361,96.78,0.8361,0.97,0.8639,0.01,ito:ITO_00113,Miscellaneous process,AUC
32,1,3D Action Recognition,3D Action Recognition,2016-11,PNN,0.8445,97.75,0.0,0.0,0.8639,0.01,ito:ITO_00113,Miscellaneous process,AUC
33,1,3D Action Recognition,3D Action Recognition,2017-03,DeepFM,0.8481,98.17,0.0,0.0,0.8639,0.01,ito:ITO_00113,Miscellaneous process,AUC
34,1,3D Action Recognition,3D Action Recognition,2018-03,xDeepFM,0.8639,100.0,0.0,0.0,0.8639,0.01,ito:ITO_00113,Miscellaneous process,AUC
35,1,Replay Grounding,Replay Grounding,2016-06,Wide & Deep,0.8377,99.73,0.8377,1.0,0.84,0.01,ito:ITO_00113,Miscellaneous process,AUC
36,1,Replay Grounding,Replay Grounding,2018-03,xDeepFM,0.84,100.0,0.0,0.0,0.84,0.01,ito:ITO_00113,Miscellaneous process,AUC
37,1,Click-Through Rate Prediction,Amazon,2016-06,Wide & Deep,0.8637,97.36,0.8637,0.97,0.8871,0.01,ito:ITO_00113,Miscellaneous process,AUC
38,1,Click-Through Rate Prediction,Amazon,2016-11,PNN,0.8679,97.84,0.0,0.0,0.8871,0.01,ito:ITO_00113,Miscellaneous process,AUC
39,1,Click-Through Rate Prediction,Amazon,2017-03,DeepFM,0.8683,97.88,0.0,0.0,0.8871,0.01,ito:ITO_00113,Miscellaneous process,AUC
40,1,Click-Through Rate Prediction,Amazon,2017-06,DIN + Dice Activation,0.8871,100.0,0.0,0.0,0.8871,0.01,ito:ITO_00113,Miscellaneous process,AUC
41,1,Click-Through Rate Prediction,MovieLens 20M,2016-06,Wide & Deep,0.7304,74.68,0.7304,0.75,0.978,0.01,ito:ITO_00113,Miscellaneous process,AUC
42,1,Click-Through Rate Prediction,MovieLens 20M,2016-11,PNN,0.7321,74.86,0.0,0.0,0.978,0.01,ito:ITO_00113,Miscellaneous process,AUC
43,1,Click-Through Rate Prediction,MovieLens 20M,2017-03,DeepFM,0.7324,74.89,0.0,0.0,0.978,0.01,ito:ITO_00113,Miscellaneous process,AUC
44,1,Click-Through Rate Prediction,MovieLens 20M,2017-06,DIN + Dice Activation,0.7348,75.13,0.0,0.0,0.978,0.01,ito:ITO_00113,Miscellaneous process,AUC
45,1,Click-Through Rate Prediction,MovieLens 20M,2019-03,KGCN-sum,0.978,100.0,0.2,0.2,0.978,0.01,ito:ITO_00113,Miscellaneous process,AUC
46,1,Multi-Animal Tracking with identification,Multi-Animal Tracking with identification,2016-06,Wide & Deep,0.7304,74.68,0.7304,0.75,0.978,0.01,ito:ITO_00113,Miscellaneous process,AUC
47,1,Multi-Animal Tracking with identification,Multi-Animal Tracking with identification,2016-11,PNN,0.7321,74.86,0.0,0.0,0.978,0.01,ito:ITO_00113,Miscellaneous process,AUC
48,1,Multi-Animal Tracking with identification,Multi-Animal Tracking with identification,2017-03,DeepFM,0.7324,74.89,0.0,0.0,0.978,0.01,ito:ITO_00113,Miscellaneous process,AUC
49,1,Multi-Animal Tracking with identification,Multi-Animal Tracking with identification,2017-06,DIN + Dice Activation,0.7348,75.13,0.0,0.0,0.978,0.01,ito:ITO_00113,Miscellaneous process,AUC
50,1,Multi-Animal Tracking with identification,Multi-Animal Tracking with identification,2019-03,KGCN-sum,0.978,100.0,0.2,0.2,0.978,0.01,ito:ITO_00113,Miscellaneous process,AUC
51,1,Generalized Zero-Shot Learning,Generalized Zero-Shot Learning,2016-06,Wide & Deep,0.8637,97.36,0.8637,0.97,0.8871,0.01,ito:ITO_00113,Miscellaneous process,AUC
52,1,Generalized Zero-Shot Learning,Generalized Zero-Shot Learning,2016-11,PNN,0.8679,97.84,0.0,0.0,0.8871,0.01,ito:ITO_00113,Miscellaneous process,AUC
53,1,Generalized Zero-Shot Learning,Generalized Zero-Shot Learning,2017-03,DeepFM,0.8683,97.88,0.0,0.0,0.8871,0.01,ito:ITO_00113,Miscellaneous process,AUC
54,1,Generalized Zero-Shot Learning,Generalized Zero-Shot Learning,2017-06,DIN + Dice Activation,0.8871,100.0,0.0,0.0,0.8871,0.01,ito:ITO_00113,Miscellaneous process,AUC
55,1,Recommendation Systems,WeChat,2017-06,"NSCR (Wang et al., 2017)",0.7727,94.64,0.7727,0.95,0.8165,0.01,ito:ITO_00113,Miscellaneous process,AUC
56,1,Recommendation Systems,WeChat,2019-03,DANSER,0.8165,100.0,0.0,0.0,0.8165,0.01,ito:ITO_00113,Miscellaneous process,AUC
57,1,Abnormal Event Detection In Video,UCSD,2017-08,Adversarial Generator,97.4,100.0,97.4,1.0,97.4,1.0,ito:ITO_00113,Miscellaneous process,AUC
58,1,Semi-supervised Anomaly Detection,UBI-Fights,2017-08,Adversarial Generator,0.533,100.0,0.533,1.0,0.533,0.01,ito:ITO_00113,Miscellaneous process,AUC
59,1,Abnormal Event Detection In Video,UBI-Fights,2017-08,Adversarial Generator,0.523,100.0,0.523,1.0,0.523,0.01,ito:ITO_00113,Miscellaneous process,AUC
60,1,Weakly-Supervised Action Recognition,Weakly-Supervised Action Recognition,2018-03,RippleNet,0.921,97.47,0.921,0.97,0.9449,0.01,ito:ITO_00113,Miscellaneous process,AUC
61,1,Weakly-Supervised Action Recognition,Weakly-Supervised Action Recognition,2019-08,KNI,0.9449,100.0,0.0,0.0,0.9449,0.01,ito:ITO_00113,Miscellaneous process,AUC
62,1,Click-Through Rate Prediction,Book-Crossing,2018-03,RippleNet,0.729,98.78,0.729,0.99,0.738,0.01,ito:ITO_00113,Miscellaneous process,AUC
63,1,Click-Through Rate Prediction,Book-Crossing,2019-03,KGCN-sum,0.738,100.0,0.0,0.0,0.738,0.01,ito:ITO_00113,Miscellaneous process,AUC
64,1,Click-Through Rate Prediction,MovieLens 1M,2018-03,RippleNet,0.921,97.47,0.921,0.97,0.9449,0.01,ito:ITO_00113,Miscellaneous process,AUC
65,1,Click-Through Rate Prediction,MovieLens 1M,2019-08,KNI,0.9449,100.0,0.0,0.0,0.9449,0.01,ito:ITO_00113,Miscellaneous process,AUC
66,1,Unsupervised Domain Expansion,Unsupervised Domain Expansion,2018-03,RippleNet,0.729,98.78,0.729,0.99,0.738,0.01,ito:ITO_00113,Miscellaneous process,AUC
67,1,Unsupervised Domain Expansion,Unsupervised Domain Expansion,2019-03,KGCN-sum,0.738,100.0,0.0,0.0,0.738,0.01,ito:ITO_00113,Miscellaneous process,AUC
68,1,Click-Through Rate Prediction,KDD12,2018-10,AutoInt,0.7881,100.0,0.7881,1.0,0.7881,0.01,ito:ITO_00113,Miscellaneous process,AUC
69,1,Video-Text Retrieval,Video-Text Retrieval,2018-10,AutoInt,0.7881,100.0,0.7881,1.0,0.7881,0.01,ito:ITO_00113,Miscellaneous process,AUC
70,1,Click-Through Rate Prediction,Avazu,2018-10,AutoInt,0.7752,95.47,0.7752,0.95,0.812,0.01,ito:ITO_00113,Miscellaneous process,AUC
71,1,Click-Through Rate Prediction,Avazu,2019-04,FGCNN+IPNN,0.7883,97.08,0.0,0.0,0.812,0.01,ito:ITO_00113,Miscellaneous process,AUC
72,1,Click-Through Rate Prediction,Avazu,2019-10,Fi-GNN,0.812,100.0,0.0,0.0,0.812,0.01,ito:ITO_00113,Miscellaneous process,AUC
73,1,Logical Reasoning Reading Comprehension,Logical Reasoning Reading Comprehension,2018-10,AutoInt,0.7752,95.47,0.7752,0.95,0.812,0.01,ito:ITO_00113,Miscellaneous process,AUC
74,1,Logical Reasoning Reading Comprehension,Logical Reasoning Reading Comprehension,2019-04,FGCNN+IPNN,0.7883,97.08,0.0,0.0,0.812,0.01,ito:ITO_00113,Miscellaneous process,AUC
75,1,Logical Reasoning Reading Comprehension,Logical Reasoning Reading Comprehension,2019-10,Fi-GNN,0.812,100.0,0.0,0.0,0.812,0.01,ito:ITO_00113,Miscellaneous process,AUC
76,1,Click-Through Rate Prediction,Children's Book Test Common noun,2019-01,MKR,0.734,100.0,0.734,1.0,0.734,0.01,ito:ITO_00113,Miscellaneous process,AUC
77,1,Generalized Zero Shot skeletal action recognition,Generalized Zero Shot skeletal action recognition,2019-01,MKR,0.734,100.0,0.734,1.0,0.734,0.01,ito:ITO_00113,Miscellaneous process,AUC
78,1,Click-Through Rate Prediction,Last.FM,2019-01,MKR,0.689,86.56,0.689,0.87,0.796,0.01,ito:ITO_00113,Miscellaneous process,AUC
79,1,Click-Through Rate Prediction,Last.FM,2019-03,KGCN-concat,0.796,100.0,0.1,0.13,0.796,0.01,ito:ITO_00113,Miscellaneous process,AUC
80,1,Unsupervised Anomaly Detection,ECG5000,2019-04,VRAE+SVM,0.9836,100.0,0.9836,1.0,0.9836,0.01,ito:ITO_00113,Miscellaneous process,AUC
81,1,Click-Through Rate Prediction,Huawei App Store,2019-04,FGCNN+IPNN,0.9407,100.0,0.9407,1.0,0.9407,0.01,ito:ITO_00113,Miscellaneous process,AUC
82,1,Multi-label zero-shot learning,Multi-label zero-shot learning,2019-04,FGCNN+IPNN,0.9407,100.0,0.9407,1.0,0.9407,0.01,ito:ITO_00113,Miscellaneous process,AUC
83,1,Click-Through Rate Prediction,Avito,2019-06,DSTN-I,0.8395,100.0,0.8395,1.0,0.8395,0.01,ito:ITO_00113,Miscellaneous process,AUC
84,1,Fraud Detection,Kaggle-Credit Card Fraud Dataset,2019-11,DevNet,0.98,100.0,0.98,1.0,0.98,0.01,ito:ITO_00113,Miscellaneous process,AUC
85,1,Anomaly Detection,Thyroid,2019-11,DevNet,0.783,100.0,0.783,1.0,0.783,0.01,ito:ITO_00113,Miscellaneous process,AUC
86,1,Anomaly Detection,Census,2019-11,DevNet,0.828,100.0,0.828,1.0,0.828,0.01,ito:ITO_00113,Miscellaneous process,AUC
87,1,Network Intrusion Detection,NB15-Backdoor,2019-11,DevNet,0.969,100.0,0.969,1.0,0.969,0.01,ito:ITO_00113,Miscellaneous process,AUC
0,1,Click-Through Rate Prediction,Criteo,2016-01,FNN,0.45738,84.89,0.45738,0.85,0.5388,0.85,ito:ITO_00113,Miscellaneous process,Log\\ Loss
1,1,Click-Through Rate Prediction,Criteo,2016-06,Wide & Deep (LR & DNN),0.46772,86.81,0.0,0.0,0.5388,0.87,ito:ITO_00113,Miscellaneous process,Log\\ Loss
2,1,Click-Through Rate Prediction,Criteo,2019-04,FGCNN+IPNN,0.5388,100.0,0.1,0.19,0.5388,1.0,ito:ITO_00113,Miscellaneous process,Log\\ Loss
3,1,Click-Through Rate Prediction,Company_,2016-01,FNN,0.02629,11.23,0.02629,0.11,0.2341,0.05,ito:ITO_00113,Miscellaneous process,Log\\ Loss
4,1,Click-Through Rate Prediction,Company_,2016-06,Wide & Deep (FM & DNN),0.0264,11.28,0.0,0.0,0.2341,0.05,ito:ITO_00113,Miscellaneous process,Log\\ Loss
5,1,Click-Through Rate Prediction,Company_,2016-11,OPNN,0.02641,11.28,0.0,0.0,0.2341,0.05,ito:ITO_00113,Miscellaneous process,Log\\ Loss
6,1,Click-Through Rate Prediction,Company_,2019-06,DeepMCP,0.2341,100.0,0.2,0.85,0.2341,0.43,ito:ITO_00113,Miscellaneous process,Log\\ Loss
7,1,Bilingual Lexicon Induction,Bilingual Lexicon Induction,2016-01,FNN,0.02629,11.23,0.02629,0.11,0.2341,0.05,ito:ITO_00113,Miscellaneous process,Log\\ Loss
8,1,Bilingual Lexicon Induction,Bilingual Lexicon Induction,2016-06,Wide & Deep (LR & DNN),0.02634,11.25,0.0,0.0,0.2341,0.05,ito:ITO_00113,Miscellaneous process,Log\\ Loss
9,1,Bilingual Lexicon Induction,Bilingual Lexicon Induction,2016-06,Wide & Deep (FM & DNN),0.0264,11.28,0.0,0.0,0.2341,0.05,ito:ITO_00113,Miscellaneous process,Log\\ Loss
10,1,Bilingual Lexicon Induction,Bilingual Lexicon Induction,2016-11,OPNN,0.02641,11.28,0.0,0.0,0.2341,0.05,ito:ITO_00113,Miscellaneous process,Log\\ Loss
11,1,Bilingual Lexicon Induction,Bilingual Lexicon Induction,2019-06,DeepMCP,0.2341,100.0,0.2,0.85,0.2341,0.43,ito:ITO_00113,Miscellaneous process,Log\\ Loss
12,1,Sequential skip prediction,Sequential skip prediction,2016-01,FNN,0.45738,84.89,0.45738,0.85,0.5388,0.85,ito:ITO_00113,Miscellaneous process,Log\\ Loss
13,1,Sequential skip prediction,Sequential skip prediction,2016-06,Wide & Deep (LR & DNN),0.46772,86.81,0.0,0.0,0.5388,0.87,ito:ITO_00113,Miscellaneous process,Log\\ Loss
14,1,Sequential skip prediction,Sequential skip prediction,2019-04,FGCNN+IPNN,0.5388,100.0,0.1,0.19,0.5388,1.0,ito:ITO_00113,Miscellaneous process,Log\\ Loss
15,1,Click-Through Rate Prediction,Bing News,2016-06,Wide & Deep,0.2668,78.89,0.2668,0.79,0.3382,0.5,ito:ITO_00113,Miscellaneous process,Log\\ Loss
16,1,Click-Through Rate Prediction,Bing News,2016-11,PNN,0.2775,82.05,0.0,0.0,0.3382,0.52,ito:ITO_00113,Miscellaneous process,Log\\ Loss
17,1,Click-Through Rate Prediction,Bing News,2018-03,DNN,0.3382,100.0,0.1,0.3,0.3382,0.63,ito:ITO_00113,Miscellaneous process,Log\\ Loss
18,1,Click-Through Rate Prediction,Dianping,2016-06,Wide & Deep,0.3364,98.25,0.3364,0.98,0.3424,0.62,ito:ITO_00113,Miscellaneous process,Log\\ Loss
19,1,Click-Through Rate Prediction,Dianping,2016-11,PNN,0.3424,100.0,0.0,0.0,0.3424,0.64,ito:ITO_00113,Miscellaneous process,Log\\ Loss
20,1,3D Action Recognition,3D Action Recognition,2016-06,Wide & Deep,0.3364,98.25,0.3364,0.98,0.3424,0.62,ito:ITO_00113,Miscellaneous process,Log\\ Loss
21,1,3D Action Recognition,3D Action Recognition,2016-11,PNN,0.3424,100.0,0.0,0.0,0.3424,0.64,ito:ITO_00113,Miscellaneous process,Log\\ Loss
22,1,Replay Grounding,Replay Grounding,2016-06,Wide & Deep,0.2668,96.14,0.2668,0.96,0.2775,0.5,ito:ITO_00113,Miscellaneous process,Log\\ Loss
23,1,Replay Grounding,Replay Grounding,2016-11,PNN,0.2775,100.0,0.0,0.0,0.2775,0.52,ito:ITO_00113,Miscellaneous process,Log\\ Loss
24,1,Click-Through Rate Prediction,KDD12,2018-10,AutoInt,0.1545,100.0,0.1545,1.0,0.1545,0.29,ito:ITO_00113,Miscellaneous process,Log\\ Loss
25,1,Click-Through Rate Prediction,MovieLens 1M,2018-10,AutoInt,0.3784,100.0,0.3784,1.0,0.3784,0.7,ito:ITO_00113,Miscellaneous process,Log\\ Loss
26,1,Weakly-Supervised Action Recognition,Weakly-Supervised Action Recognition,2018-10,AutoInt,0.3784,100.0,0.3784,1.0,0.3784,0.7,ito:ITO_00113,Miscellaneous process,Log\\ Loss
27,1,Video-Text Retrieval,Video-Text Retrieval,2018-10,AutoInt,0.1545,100.0,0.1545,1.0,0.1545,0.29,ito:ITO_00113,Miscellaneous process,Log\\ Loss
28,1,Click-Through Rate Prediction,Huawei App Store,2019-04,FGCNN+IPNN,0.1134,100.0,0.1134,1.0,0.1134,0.21,ito:ITO_00113,Miscellaneous process,Log\\ Loss
29,1,Multi-label zero-shot learning,Multi-label zero-shot learning,2019-04,FGCNN+IPNN,0.1134,100.0,0.1134,1.0,0.1134,0.21,ito:ITO_00113,Miscellaneous process,Log\\ Loss
30,1,Click-Through Rate Prediction,Avito,2019-06,DSTN-I,0.05448,98.73,0.05448,0.99,0.05518,0.1,ito:ITO_00113,Miscellaneous process,Log\\ Loss
31,1,Click-Through Rate Prediction,Avito,2019-06,DeepMCP,0.05518,100.0,0.0,0.0,0.05518,0.1,ito:ITO_00113,Miscellaneous process,Log\\ Loss
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,LSTM,31.0,54.39,31,0.54,57,0.54,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(AV\\ I\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,33.0,57.89,2,0.04,57,0.58,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(AV\\ I\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-11,TCN,43.0,75.44,10,0.18,57,0.75,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(AV\\ I\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-04,Res-TCN,48.0,84.21,5,0.09,57,0.84,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(AV\\ I\\)
4,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2018-01,ST-GCN,53.0,92.98,5,0.09,57,0.93,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(AV\\ I\\)
5,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,57.0,100.0,4,0.07,57,1.0,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(AV\\ I\\)
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,LSTM,68.0,88.31,68,0.88,77,0.88,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(AV\\ II\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-08,SK-CNN,77.0,100.0,9,0.12,77,1.0,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(AV\\ II\\)
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,LSTM,16.0,55.17,16,0.55,29,0.55,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(CV\\ I\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-08,SK-CNN,26.0,89.66,10,0.34,29,0.9,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(CV\\ I\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,29.0,100.0,3,0.1,29,1.0,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(CV\\ I\\)
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,33.0,46.48,33,0.46,71,0.46,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(CV\\ II\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-11,TCN,43.0,60.56,10,0.14,71,0.61,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(CV\\ II\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-04,Res-TCN,48.0,67.61,5,0.07,71,0.68,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(CV\\ II\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-08,SK-CNN,68.0,95.77,20,0.28,71,0.96,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(CV\\ II\\)
4,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,71.0,100.0,3,0.04,71,1.0,ito:ITO_00113,Miscellaneous process,Accuracy\\ \\(CV\\ II\\)
0,1,Causal Inference,IDHP,2016-06,Counterfactual Regression + WASS,0.27,28.13,0.27,0.28,0.96,0.28,ito:ITO_00113,Miscellaneous process,Average\\ Treatment\\ Effect\\ Error
1,1,Causal Inference,IDHP,2016-06,Random Forest,0.96,100.0,0.7,0.73,0.96,1.0,ito:ITO_00113,Miscellaneous process,Average\\ Treatment\\ Effect\\ Error
0,1,Automated Theorem Proving,Metamath set.mm,2016-08,Holophrasm (\'16),14.26,67.58,14.26,0.68,21.1,0.29,ito:ITO_00113,Miscellaneous process,Percentage\\ correct
1,1,Automated Theorem Proving,Metamath set.mm,2020-01,MetaGen-IL + Holophrasm ('19),21.1,100.0,6.8,0.32,21.1,0.42,ito:ITO_00113,Miscellaneous process,Percentage\\ correct
2,1,Automated Theorem Proving,HOList benchmark,2019-04,Deeper Wider WaveNet,32.65,65.37,32.65,0.65,49.95,0.65,ito:ITO_00113,Miscellaneous process,Percentage\\ correct
3,1,Automated Theorem Proving,HOList benchmark,2019-04,Tactic Dependent Loop,38.88,77.84,6.2,0.12,49.95,0.78,ito:ITO_00113,Miscellaneous process,Percentage\\ correct
4,1,Automated Theorem Proving,HOList benchmark,2019-05,"4-hop GNN, sub-expression sharing",49.95,100.0,11.1,0.22,49.95,1.0,ito:ITO_00113,Miscellaneous process,Percentage\\ correct
5,1,Automated Theorem Proving,CoqGym,2019-05,ASTactic,12.2,100.0,12.2,1.0,12.2,0.24,ito:ITO_00113,Miscellaneous process,Percentage\\ correct
6,1,Automated Theorem Proving,CompCert,2019-07,ProverBot9001,15.77,100.0,15.77,1.0,15.77,0.32,ito:ITO_00113,Miscellaneous process,Percentage\\ correct
0,1,Anomaly Detection,CIFAR-10 model detecting CIFAR-10,2016-10,Wide ResNet,54.1,71.0,54.1,0.71,76.2,0.71,ito:ITO_00113,Miscellaneous process,AUPR
1,1,Anomaly Detection,CIFAR-10 model detecting CIFAR-10,2018-12,Wide ResNet + Outlier Exposure,76.2,100.0,22.1,0.29,76.2,1.0,ito:ITO_00113,Miscellaneous process,AUPR
0,1,Recipe Generation,allrecipes.com,2016-11,Latent Variable Model,4.97,100.0,4.97,1.0,4.97,0.51,ito:ITO_00113,Miscellaneous process,Perplexity
1,1,Recipe Generation,Now You're Cooking!,2018-05,Entity Type Model,9.67,100.0,9.67,1.0,9.67,1.0,ito:ITO_00113,Miscellaneous process,Perplexity
0,1,Recipe Generation,allrecipes.com,2016-11,Latent Variable Model,15.41,100.0,15.41,1.0,15.41,1.0,ito:ITO_00113,Miscellaneous process,BLEU
0,1,3D Semantic Segmentation,SemanticKITTI,2016-12,PointNet,14.6,24.83,14.6,0.25,58.8,0.25,ito:ITO_00113,Miscellaneous process,mIoU
1,1,3D Semantic Segmentation,SemanticKITTI,2017-06,PointNet++,20.1,34.18,5.5,0.09,58.8,0.34,ito:ITO_00113,Miscellaneous process,mIoU
2,1,3D Semantic Segmentation,SemanticKITTI,2017-10,SqueezeSeg,29.5,50.17,9.4,0.16,58.8,0.5,ito:ITO_00113,Miscellaneous process,mIoU
3,1,3D Semantic Segmentation,SemanticKITTI,2018-07,TangentConv,35.9,61.05,6.4,0.11,58.8,0.61,ito:ITO_00113,Miscellaneous process,mIoU
4,1,3D Semantic Segmentation,SemanticKITTI,2018-07,TagentConv,40.9,69.56,5.0,0.09,58.8,0.69,ito:ITO_00113,Miscellaneous process,mIoU
5,1,3D Semantic Segmentation,SemanticKITTI,2019-04,KPConv,58.8,100.0,17.9,0.3,58.8,1.0,ito:ITO_00113,Miscellaneous process,mIoU
6,1,3D Semantic Segmentation,S3DIS,2019-07,PVCNN++,58.98,100.0,58.98,1.0,58.98,1.0,ito:ITO_00113,Miscellaneous process,mIoU
7,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet-tiny,46.9,84.05,46.9,0.84,55.8,0.8,ito:ITO_00113,Miscellaneous process,mIoU
8,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet,55.8,100.0,8.9,0.16,55.8,0.95,ito:ITO_00113,Miscellaneous process,mIoU
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,80.6,89.76,80.6,0.9,89.8,0.9,ito:ITO_00113,Miscellaneous process,PCK\\-at\\-0\\.4
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,87.5,97.44,6.9,0.08,89.8,0.97,ito:ITO_00113,Miscellaneous process,PCK\\-at\\-0\\.4
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,89.8,100.0,2.3,0.03,89.8,1.0,ito:ITO_00113,Miscellaneous process,PCK\\-at\\-0\\.4
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,85.5,92.53,85.5,0.93,92.4,0.93,ito:ITO_00113,Miscellaneous process,PCK\\-at\\-0\\.5
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,91.4,98.92,5.9,0.06,92.4,0.99,ito:ITO_00113,Miscellaneous process,PCK\\-at\\-0\\.5
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,92.4,100.0,1.0,0.01,92.4,1.0,ito:ITO_00113,Miscellaneous process,PCK\\-at\\-0\\.5
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,62.9,80.54,62.9,0.81,78.1,0.81,ito:ITO_00113,Miscellaneous process,PCK\\-at\\-0\\.2
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,69.6,89.12,6.7,0.09,78.1,0.89,ito:ITO_00113,Miscellaneous process,PCK\\-at\\-0\\.2
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,78.1,100.0,8.5,0.11,78.1,1.0,ito:ITO_00113,Miscellaneous process,PCK\\-at\\-0\\.2
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,73.5,85.56,73.5,0.86,85.9,0.86,ito:ITO_00113,Miscellaneous process,PCK\\-at\\-0\\.3
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,80.8,94.06,7.3,0.08,85.9,0.94,ito:ITO_00113,Miscellaneous process,PCK\\-at\\-0\\.3
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,85.9,100.0,5.1,0.06,85.9,1.0,ito:ITO_00113,Miscellaneous process,PCK\\-at\\-0\\.3
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,45.2,77.4,45.2,0.77,58.4,0.77,ito:ITO_00113,Miscellaneous process,PCK\\-at\\-0\\.1
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,58.4,100.0,13.2,0.23,58.4,1.0,ito:ITO_00113,Miscellaneous process,PCK\\-at\\-0\\.1
0,1,Formation Energy,QM9,2017-02,HDAD+KRR,0.58,100.0,0.58,1.0,0.58,0.01,ito:ITO_00113,Miscellaneous process,MAE
1,1,Recommendation Systems,Epinions,2017-06,"NSCR (Wang et al., 2017)",0.8044,100.0,0.8044,1.0,0.8044,0.02,ito:ITO_00113,Miscellaneous process,MAE
2,1,Formation Energy,Materials Project,2017-10,CGCNN,39.0,95.12,39.0,0.95,41.0,0.95,ito:ITO_00113,Miscellaneous process,MAE
3,1,Formation Energy,Materials Project,2018-11,MT-CGCNN,41.0,100.0,2.0,0.05,41.0,1.0,ito:ITO_00113,Miscellaneous process,MAE
4,1,Formation Energy,OQMD v1.2,2019-05,CGNN-192,34.6,96.92,34.6,0.97,35.7,0.84,ito:ITO_00113,Miscellaneous process,MAE
5,1,Formation Energy,OQMD v1.2,2019-05,CGNN-160,35.1,98.32,0.5,0.01,35.7,0.86,ito:ITO_00113,Miscellaneous process,MAE
6,1,Formation Energy,OQMD v1.2,2019-05,CGNN-128,35.7,100.0,0.6,0.02,35.7,0.87,ito:ITO_00113,Miscellaneous process,MAE
0,1,Recommendation Systems,MovieLens 20M,2017-04,CML,0.5301,82.78,0.5301,0.83,0.6404,0.83,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
1,1,Recommendation Systems,MovieLens 20M,2017-07,LRML,0.6152,96.06,0.1,0.16,0.6404,0.96,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
2,1,Recommendation Systems,MovieLens 20M,2018-09,HyperML,0.6404,100.0,0.0,0.0,0.6404,1.0,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
3,1,Recommendation Systems,MovieLens 1M,2017-04,CML,0.5413,91.67,0.5413,0.92,0.5905,0.85,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
4,1,Recommendation Systems,MovieLens 1M,2017-07,LRML,0.5453,92.35,0.0,0.0,0.5905,0.85,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
5,1,Recommendation Systems,MovieLens 1M,2018-08,SASRec,0.5905,100.0,0.0,0.0,0.5905,0.92,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
6,1,Recommendation Systems,Netflix,2017-04,CML,0.2948,82.39,0.2948,0.82,0.3578,0.46,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
7,1,Recommendation Systems,Netflix,2017-07,LRML,0.3578,100.0,0.1,0.28,0.3578,0.56,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
8,1,Recommendation Systems,Pinterest,2017-08,NeuMF,0.555,100.0,0.555,1.0,0.555,0.87,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
9,1,Recommendation Systems,Amazon Games,2018-08,SASRec,0.536,100.0,0.536,1.0,0.536,0.84,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
10,1,Recommendation Systems,Amazon Beauty,2018-08,SASRec,0.3219,100.0,0.3219,1.0,0.3219,0.5,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
11,1,Recommendation Systems,Steam,2018-08,SASRec,0.6306,100.0,0.6306,1.0,0.6306,0.98,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
12,1,Recommendation Systems,Declicious,2019-06,TransCF,0.1475,100.0,0.1475,1.0,0.1475,0.23,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
13,1,Recommendation Systems,Tradesy,2019-06,TransCF,0.1767,100.0,0.1767,1.0,0.1767,0.28,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
14,1,Recommendation Systems,Ciao,2019-06,TransCF,0.1167,100.0,0.1167,1.0,0.1167,0.18,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
15,1,Recommendation Systems,Flixster,2019-06,TransCF,0.4986,100.0,0.4986,1.0,0.4986,0.78,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
16,1,Recommendation Systems,Amazon C&A,2019-06,TransCF,0.2019,100.0,0.2019,1.0,0.2019,0.32,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
17,1,Recommendation Systems,Book-Crossing,2019-06,TransCF,0.1865,100.0,0.1865,1.0,0.1865,0.29,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
18,1,Recommendation Systems,Amazon-Book,2019-06,HGN,0.0298,100.0,0.0298,1.0,0.0298,0.05,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
19,1,Recommendation Systems,Amazon-CDs,2019-06,HGN,0.0233,100.0,0.0233,1.0,0.0233,0.04,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
20,1,Recommendation Systems,GoodReads-Comics,2019-06,HGN,0.1927,100.0,0.1927,1.0,0.1927,0.3,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
21,1,Recommendation Systems,GoodReads-Children,2019-06,HGN,0.113,100.0,0.113,1.0,0.113,0.18,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
22,1,Recommendation Systems,Last.FM,2019-06,Ekar*,0.1766,100.0,0.1766,1.0,0.1766,0.28,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
23,1,Recommendation Systems,DBbook2014,2019-06,Ekar*,0.1371,100.0,0.1371,1.0,0.1371,0.21,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-10
0,1,Recommendation Systems,Million Song Dataset,2017-04,CML,0.246,57.48,0.246,0.57,0.428,0.44,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-50
1,1,Recommendation Systems,Million Song Dataset,2018-02,Mult-VAE PR,0.364,85.05,0.1,0.23,0.428,0.66,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-50
2,1,Recommendation Systems,Million Song Dataset,2019-05,EASE,0.428,100.0,0.1,0.23,0.428,0.77,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-50
3,1,Recommendation Systems,MovieLens 20M,2017-04,CML,0.4665,84.36,0.4665,0.84,0.553,0.84,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-50
4,1,Recommendation Systems,MovieLens 20M,2018-02,Mult-VAE PR,0.537,97.11,0.1,0.18,0.553,0.97,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-50
5,1,Recommendation Systems,MovieLens 20M,2019-06,RaCT,0.543,98.19,0.0,0.0,0.553,0.98,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-50
6,1,Recommendation Systems,MovieLens 20M,2019-11,H+Vamp Gated,0.55109,99.65,0.0,0.0,0.553,1.0,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-50
7,1,Recommendation Systems,MovieLens 20M,2019-12,RecVAE,0.553,100.0,0.0,0.0,0.553,1.0,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-50
8,1,Recommendation Systems,Netflix,2018-02,Mult-VAE PR,0.444,96.0,0.444,0.96,0.46252,0.8,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-50
9,1,Recommendation Systems,Netflix,2019-05,EASE,0.445,96.21,0.0,0.0,0.46252,0.8,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-50
10,1,Recommendation Systems,Netflix,2019-06,RaCT,0.45,97.29,0.0,0.0,0.46252,0.81,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-50
11,1,Recommendation Systems,Netflix,2019-11,H+Vamp Gated,0.46252,100.0,0.0,0.0,0.46252,0.84,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-50
12,1,Recommendation Systems,Dianping-Food,2019-05,KGNN-LS,0.34,100.0,0.34,1.0,0.34,0.61,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-50
13,1,Recommendation Systems,Book-Crossing,2019-05,KGNN-LS,0.117,100.0,0.117,1.0,0.117,0.21,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-50
14,1,Recommendation Systems,Last.FM,2019-05,KGNN-LS,0.277,100.0,0.277,1.0,0.277,0.5,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-50
0,1,Recommendation Systems,MovieLens 20M,2017-04,CML,0.6022,100.0,0.6022,1.0,0.6022,1.0,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-100
1,1,Recommendation Systems,Million Song Dataset,2017-04,CML,0.3022,100.0,0.3022,1.0,0.3022,0.5,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-100
2,1,Recommendation Systems,Last.FM,2019-05,KGNN-LS,0.37,100.0,0.37,1.0,0.37,0.61,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-100
3,1,Recommendation Systems,Dianping-Food,2019-05,KGNN-LS,0.487,100.0,0.487,1.0,0.487,0.81,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-100
4,1,Recommendation Systems,Book-Crossing,2019-05,KGNN-LS,0.149,100.0,0.149,1.0,0.149,0.25,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-100
0,1,Recommendation Systems,MovieLens 20M,2017-04,CML,0.7764,88.87,0.7764,0.89,0.8736,0.87,ito:ITO_00113,Miscellaneous process,HR\\-at\\-10
1,1,Recommendation Systems,MovieLens 20M,2017-07,LRML,0.8447,96.69,0.1,0.11,0.8736,0.95,ito:ITO_00113,Miscellaneous process,HR\\-at\\-10
2,1,Recommendation Systems,MovieLens 20M,2018-09,HyperML,0.8736,100.0,0.0,0.0,0.8736,0.98,ito:ITO_00113,Miscellaneous process,HR\\-at\\-10
3,1,Recommendation Systems,MovieLens 1M,2017-04,CML,0.7216,81.05,0.7216,0.81,0.8903,0.81,ito:ITO_00113,Miscellaneous process,HR\\-at\\-10
4,1,Recommendation Systems,MovieLens 1M,2017-07,LRML,0.7397,83.08,0.0,0.0,0.8903,0.83,ito:ITO_00113,Miscellaneous process,HR\\-at\\-10
5,1,Recommendation Systems,MovieLens 1M,2018-08,SASRec,0.8245,92.61,0.1,0.11,0.8903,0.93,ito:ITO_00113,Miscellaneous process,HR\\-at\\-10
6,1,Recommendation Systems,MovieLens 1M,2019-02,KTUP (soft),0.8903,100.0,0.1,0.11,0.8903,1.0,ito:ITO_00113,Miscellaneous process,HR\\-at\\-10
7,1,Recommendation Systems,Netflix,2017-04,CML,0.4612,85.87,0.4612,0.86,0.5371,0.52,ito:ITO_00113,Miscellaneous process,HR\\-at\\-10
8,1,Recommendation Systems,Netflix,2017-07,LRML,0.5371,100.0,0.1,0.19,0.5371,0.6,ito:ITO_00113,Miscellaneous process,HR\\-at\\-10
9,1,Recommendation Systems,Pinterest,2017-08,NeuMF,0.879,100.0,0.879,1.0,0.879,0.99,ito:ITO_00113,Miscellaneous process,HR\\-at\\-10
10,1,Recommendation Systems,DBbook2014,2019-02,KTUP (soft),0.3461,100.0,0.3461,1.0,0.3461,0.39,ito:ITO_00113,Miscellaneous process,HR\\-at\\-10
11,1,Recommendation Systems,Last.FM,2019-06,Ekar*,0.2483,100.0,0.2483,1.0,0.2483,0.28,ito:ITO_00113,Miscellaneous process,HR\\-at\\-10
0,1,Skeleton Based Action Recognition,PKU-MMD,2017-04,Li et al. [[Li et al.2017b]],93.7,99.26,93.7,0.99,94.4,0.99,ito:ITO_00113,Miscellaneous process,mAP\\-at\\-0\\.50\\ \\(CV\\)
1,1,Skeleton Based Action Recognition,PKU-MMD,2018-04,HCN,94.2,99.79,0.5,0.01,94.4,1.0,ito:ITO_00113,Miscellaneous process,mAP\\-at\\-0\\.50\\ \\(CV\\)
2,1,Skeleton Based Action Recognition,PKU-MMD,2019-09,RF-Action,94.4,100.0,0.2,0.0,94.4,1.0,ito:ITO_00113,Miscellaneous process,mAP\\-at\\-0\\.50\\ \\(CV\\)
0,1,Skeleton Based Action Recognition,PKU-MMD,2017-04,Li et al. [[Li et al.2017b]],90.4,97.31,90.4,0.97,92.9,0.97,ito:ITO_00113,Miscellaneous process,mAP\\-at\\-0\\.50\\ \\(CS\\)
1,1,Skeleton Based Action Recognition,PKU-MMD,2018-04,HCN,92.6,99.68,2.2,0.02,92.9,1.0,ito:ITO_00113,Miscellaneous process,mAP\\-at\\-0\\.50\\ \\(CS\\)
2,1,Skeleton Based Action Recognition,PKU-MMD,2019-09,RF-Action,92.9,100.0,0.3,0.0,92.9,1.0,ito:ITO_00113,Miscellaneous process,mAP\\-at\\-0\\.50\\ \\(CS\\)
0,1,Recommendation Systems,WeChat,2017-06,"NSCR (Wang et al., 2017)",0.0736,89.43,0.0736,0.89,0.0823,0.89,ito:ITO_00113,Miscellaneous process,P\\-at\\-10
1,1,Recommendation Systems,WeChat,2019-03,DANSER,0.0823,100.0,0.0,0.0,0.0823,1.0,ito:ITO_00113,Miscellaneous process,P\\-at\\-10
0,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,bc-LSTM+Att,56.19,87.55,56.19,0.88,64.18,0.88,ito:ITO_00113,Miscellaneous process,Weighted\\-F1
1,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,ICON,58.54,91.21,2.4,0.04,64.18,0.91,ito:ITO_00113,Miscellaneous process,Weighted\\-F1
2,1,Emotion Recognition in Conversation,IEMOCAP,2018-11,DialogueRNN,62.75,97.77,4.2,0.07,64.18,0.98,ito:ITO_00113,Miscellaneous process,Weighted\\-F1
3,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,DialogueGCN,64.18,100.0,1.4,0.02,64.18,1.0,ito:ITO_00113,Miscellaneous process,Weighted\\-F1
4,1,Emotion Recognition in Conversation,MELD,2017-07,bc-LSTM+Att,56.44,97.01,56.44,0.97,58.18,0.88,ito:ITO_00113,Miscellaneous process,Weighted\\-F1
5,1,Emotion Recognition in Conversation,MELD,2018-11,DialogueRNN,57.03,98.02,0.6,0.01,58.18,0.89,ito:ITO_00113,Miscellaneous process,Weighted\\-F1
6,1,Emotion Recognition in Conversation,MELD,2019-08,DialogueGCN,58.1,99.86,1.1,0.02,58.18,0.91,ito:ITO_00113,Miscellaneous process,Weighted\\-F1
7,1,Emotion Recognition in Conversation,MELD,2019-09,KET,58.18,100.0,0.1,0.0,58.18,0.91,ito:ITO_00113,Miscellaneous process,Weighted\\-F1
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,bc-LSTM+Att,0.189,98.44,0.189,0.98,0.192,0.98,ito:ITO_00113,Miscellaneous process,MAE\\ \\(Valence\\)
1,1,Emotion Recognition in Conversation,SEMAINE,2018-06,CMN,0.192,100.0,0.0,0.0,0.192,1.0,ito:ITO_00113,Miscellaneous process,MAE\\ \\(Valence\\)
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,bc-LSTM+Att,0.213,100.0,0.213,1.0,0.213,1.0,ito:ITO_00113,Miscellaneous process,MAE\\ \\(Arousal\\)
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,bc-LSTM+Att,0.19,97.44,0.19,0.97,0.195,0.97,ito:ITO_00113,Miscellaneous process,MAE\\ \\(Expectancy\\)
1,1,Emotion Recognition in Conversation,SEMAINE,2018-06,CMN,0.195,100.0,0.0,0.0,0.195,1.0,ito:ITO_00113,Miscellaneous process,MAE\\ \\(Expectancy\\)
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,bc-LSTM+Att,8.67,99.2,8.67,0.99,8.74,0.99,ito:ITO_00113,Miscellaneous process,MAE\\ \\(Power\\)
1,1,Emotion Recognition in Conversation,SEMAINE,2018-06,CMN,8.74,100.0,0.1,0.01,8.74,1.0,ito:ITO_00113,Miscellaneous process,MAE\\ \\(Power\\)
0,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,bc-LSTM+Att,56.19,87.55,56.19,0.88,64.18,0.88,ito:ITO_00113,Miscellaneous process,F1
1,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,ICON,58.54,91.21,2.4,0.04,64.18,0.91,ito:ITO_00113,Miscellaneous process,F1
2,1,Emotion Recognition in Conversation,IEMOCAP,2019-05,DialogueRNN,62.75,97.77,4.2,0.07,64.18,0.98,ito:ITO_00113,Miscellaneous process,F1
3,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,DialogueGCN,64.18,100.0,1.4,0.02,64.18,1.0,ito:ITO_00113,Miscellaneous process,F1
4,1,Multimodal Emotion Recognition,IEMOCAP,2018-06,CHFusion (A+T+V),0.768,100.0,0.768,1.0,0.768,0.01,ito:ITO_00113,Miscellaneous process,F1
5,1,Recipe Generation,Recipe1M,2018-12,Set Transformer,48.61,100.0,48.61,1.0,48.61,0.76,ito:ITO_00113,Miscellaneous process,F1
6,1,Click-Through Rate Prediction,MovieLens 20M,2019-03,KGCN-sum,0.932,100.0,0.932,1.0,0.932,0.01,ito:ITO_00113,Miscellaneous process,F1
7,1,Multi-Animal Tracking with identification,Multi-Animal Tracking with identification,2019-03,KGCN-sum,0.932,100.0,0.932,1.0,0.932,0.01,ito:ITO_00113,Miscellaneous process,F1
8,1,Click-Through Rate Prediction,Last.FM,2019-03,KGCN-concat,0.721,100.0,0.721,1.0,0.721,0.01,ito:ITO_00113,Miscellaneous process,F1
9,1,Click-Through Rate Prediction,Book-Crossing,2019-03,KGCN-sum,0.688,100.0,0.688,1.0,0.688,0.01,ito:ITO_00113,Miscellaneous process,F1
10,1,Unsupervised Domain Expansion,Unsupervised Domain Expansion,2019-03,KGCN-sum,0.688,100.0,0.688,1.0,0.688,0.01,ito:ITO_00113,Miscellaneous process,F1
11,1,Speech Emotion Recognition,IEMOCAP,2019-04,Ensemble (Random Forests + Gradient Boosted Trees + Multi Layer Perceptron + Multinomial Naive Bayes + Logistic Regression) / (A+T),0.718,100.0,0.718,1.0,0.718,0.01,ito:ITO_00113,Miscellaneous process,F1
0,1,Multimodal Emotion Recognition,IEMOCAP,2017-07,bc-LSTM ,0.741,96.86,0.741,0.97,0.765,0.93,ito:ITO_00113,Miscellaneous process,UA
1,1,Multimodal Emotion Recognition,IEMOCAP,2018-06,CHFusion (A+T+V),0.765,100.0,0.0,0.0,0.765,0.96,ito:ITO_00113,Miscellaneous process,UA
2,1,Speech Emotion Recognition,IEMOCAP,2018-02,CNN+LSTM,0.8,100.0,0.8,1.0,0.8,1.0,ito:ITO_00113,Miscellaneous process,UA
0,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,bc-LSTM+Att,54.84,86.46,54.84,0.86,63.43,0.86,ito:ITO_00113,Miscellaneous process,Macro\\-F1
1,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,ICON,56.52,89.11,1.7,0.03,63.43,0.89,ito:ITO_00113,Miscellaneous process,Macro\\-F1
2,1,Emotion Recognition in Conversation,IEMOCAP,2018-11,DialogueRNN,60.66,95.63,4.1,0.06,63.43,0.96,ito:ITO_00113,Miscellaneous process,Macro\\-F1
3,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,DialogueGCN,63.43,100.0,2.8,0.04,63.43,1.0,ito:ITO_00113,Miscellaneous process,Macro\\-F1
0,1,Abnormal Event Detection In Video,UBI-Fights,2017-08,Adversarial Generator,0.011,100.0,0.011,1.0,0.011,0.07,ito:ITO_00113,Miscellaneous process,Decidability
1,1,Semi-supervised Anomaly Detection,UBI-Fights,2017-08,Adversarial Generator,0.147,100.0,0.147,1.0,0.147,1.0,ito:ITO_00113,Miscellaneous process,Decidability
0,1,Abnormal Event Detection In Video,UBI-Fights,2017-08,Adversarial Generator,0.504,100.0,0.504,1.0,0.504,1.0,ito:ITO_00113,Miscellaneous process,EER
1,1,Semi-supervised Anomaly Detection,UBI-Fights,2017-08,Adversarial Generator,0.484,100.0,0.484,1.0,0.484,0.96,ito:ITO_00113,Miscellaneous process,EER
0,1,Skeleton Based Action Recognition,J-HMBD Early Action,2017-10,GAT,58.1,95.87,58.1,0.96,60.6,0.96,ito:ITO_00113,Miscellaneous process,10%
1,1,Skeleton Based Action Recognition,J-HMBD Early Action,2018-02,DR^2N,60.6,100.0,2.5,0.04,60.6,1.0,ito:ITO_00113,Miscellaneous process,10%
0,1,Stress-Strain Relation,Non-Linear Elasticity Benchmark,2017-11,NLP,13.8,4.46,13.8,0.04,309.4,0.04,ito:ITO_00113,Miscellaneous process,Time\\ \\(ms\\)
1,1,Stress-Strain Relation,Non-Linear Elasticity Benchmark,2018-02,Mixed-integer Programming (MIP),309.4,100.0,295.6,0.96,309.4,1.0,ito:ITO_00113,Miscellaneous process,Time\\ \\(ms\\)
0,1,Skeleton Based Action Recognition,UAV-Human,2018-01,ST-GCN,30.25,86.83,30.25,0.87,34.84,0.87,ito:ITO_00113,Miscellaneous process,Average\\ Accuracy
1,1,Skeleton Based Action Recognition,UAV-Human,2018-05,2S-AGCN,34.84,100.0,4.6,0.13,34.84,1.0,ito:ITO_00113,Miscellaneous process,Average\\ Accuracy
0,1,Recommendation Systems,Million Song Dataset,2018-02,Mult-VAE PR,0.316,81.23,0.316,0.81,0.389,0.71,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-100
1,1,Recommendation Systems,Million Song Dataset,2019-05,EASE,0.389,100.0,0.1,0.26,0.389,0.87,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-100
2,1,Recommendation Systems,MovieLens 20M,2018-02,Mult-DAE,0.419,94.11,0.419,0.94,0.44522,0.94,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-100
3,1,Recommendation Systems,MovieLens 20M,2018-02,Mult-VAE PR,0.426,95.68,0.0,0.0,0.44522,0.96,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-100
4,1,Recommendation Systems,MovieLens 20M,2019-06,RaCT,0.434,97.48,0.0,0.0,0.44522,0.97,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-100
5,1,Recommendation Systems,MovieLens 20M,2019-11,H+Vamp Gated,0.44522,100.0,0.0,0.0,0.44522,1.0,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-100
6,1,Recommendation Systems,Netflix,2018-02,Mult-VAE PR,0.386,94.47,0.386,0.94,0.40861,0.87,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-100
7,1,Recommendation Systems,Netflix,2019-05,EASE,0.393,96.18,0.0,0.0,0.40861,0.88,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-100
8,1,Recommendation Systems,Netflix,2019-11,H+Vamp Gated,0.40861,100.0,0.0,0.0,0.40861,0.92,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-100
0,1,Recommendation Systems,Million Song Dataset,2018-02,Mult-VAE PR,0.266,79.88,0.266,0.8,0.333,0.64,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-20
1,1,Recommendation Systems,Million Song Dataset,2019-05,EASE,0.333,100.0,0.1,0.3,0.333,0.8,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-20
2,1,Recommendation Systems,MovieLens 20M,2018-02,Mult-DAE,0.387,93.48,0.387,0.93,0.414,0.93,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-20
3,1,Recommendation Systems,MovieLens 20M,2018-02,Mult-VAE PR,0.395,95.41,0.0,0.0,0.414,0.95,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-20
4,1,Recommendation Systems,MovieLens 20M,2019-06,RaCT,0.403,97.34,0.0,0.0,0.414,0.97,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-20
5,1,Recommendation Systems,MovieLens 20M,2019-11,H+Vamp Gated,0.41308,99.78,0.0,0.0,0.414,1.0,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-20
6,1,Recommendation Systems,MovieLens 20M,2019-12,RecVAE,0.414,100.0,0.0,0.0,0.414,1.0,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-20
7,1,Recommendation Systems,Netflix,2018-02,Mult-DAE,0.344,91.3,0.344,0.91,0.37678,0.83,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-20
8,1,Recommendation Systems,Netflix,2018-02,Mult-VAE PR,0.351,93.16,0.0,0.0,0.37678,0.85,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-20
9,1,Recommendation Systems,Netflix,2019-05,EASE,0.362,96.08,0.0,0.0,0.37678,0.87,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-20
10,1,Recommendation Systems,Netflix,2019-11,H+Vamp Gated,0.37678,100.0,0.0,0.0,0.37678,0.91,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-20
11,1,Recommendation Systems,Yelp,2019-02,DGRec,0.0842,100.0,0.0842,1.0,0.0842,0.2,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-20
12,1,Recommendation Systems,Delicious,2019-02,DGRec,0.4066,100.0,0.4066,1.0,0.4066,0.98,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-20
13,1,Recommendation Systems,Douban,2019-02,DGRec,0.1861,100.0,0.1861,1.0,0.1861,0.45,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-20
0,1,Multi-Armed Bandits,Mushroom,2018-02,Linear FullPosterior-MR,1.82,94.79,1.82,0.95,1.92,0.95,ito:ITO_00113,Miscellaneous process,Cumulative\\ regret
1,1,Multi-Armed Bandits,Mushroom,2018-02,NeuralLinear FullPosterior-MR,1.92,100.0,0.1,0.05,1.92,1.0,ito:ITO_00113,Miscellaneous process,Cumulative\\ regret
0,1,Recommendation Systems,Amazon Games,2018-08,SASRec,0.741,100.0,0.741,1.0,0.741,0.85,ito:ITO_00113,Miscellaneous process,Hit\\-at\\-10
1,1,Recommendation Systems,Steam,2018-08,SASRec,0.8729,100.0,0.8729,1.0,0.8729,1.0,ito:ITO_00113,Miscellaneous process,Hit\\-at\\-10
2,1,Recommendation Systems,Amazon Beauty,2018-08,SASRec,0.4854,100.0,0.4854,1.0,0.4854,0.56,ito:ITO_00113,Miscellaneous process,Hit\\-at\\-10
0,1,Multimodal Emotion Recognition,IEMOCAP,2018-10,Multimodal Dual Recurrent Encoder (MDRE) / (A+T),0.718,100.0,0.718,1.0,0.718,1.0,ito:ITO_00113,Miscellaneous process,WAP
1,1,Speech Emotion Recognition,IEMOCAP,2018-10,Multimodal Dual Recurrent Encoder (MDRE) / (A+T),0.718,100.0,0.718,1.0,0.718,1.0,ito:ITO_00113,Miscellaneous process,WAP
0,1,Click-Through Rate Prediction,Avazu,2018-10,AutoInt,0.3823,100.0,0.3823,1.0,0.3823,1.0,ito:ITO_00113,Miscellaneous process,LogLoss
1,1,Logical Reasoning Reading Comprehension,Logical Reasoning Reading Comprehension,2018-10,AutoInt,0.3823,100.0,0.3823,1.0,0.3823,1.0,ito:ITO_00113,Miscellaneous process,LogLoss
0,1,Recipe Generation,Recipe1M,2018-12,Set Transformer,32.11,100.0,32.11,1.0,32.11,1.0,ito:ITO_00113,Miscellaneous process,Mean\\ IoU
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,MFA-Net,361.0,100.0,361,1.0,361,1.0,ito:ITO_00113,Miscellaneous process,Speed\\ \\ \\(FPS\\)
1,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet-tiny,98.0,100.0,98,1.0,98,0.27,ito:ITO_00113,Miscellaneous process,Speed\\ \\ \\(FPS\\)
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,MFA-Net,91.3,96.51,91.3,0.97,94.6,0.97,ito:ITO_00113,Miscellaneous process,14\\ gestures\\ accuracy
1,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,STA-Res-TCN,93.6,98.94,2.3,0.02,94.6,0.99,ito:ITO_00113,Miscellaneous process,14\\ gestures\\ accuracy
2,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,94.6,100.0,1.0,0.01,94.6,1.0,ito:ITO_00113,Miscellaneous process,14\\ gestures\\ accuracy
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,MFA-Net,86.6,94.23,86.6,0.94,91.9,0.94,ito:ITO_00113,Miscellaneous process,28\\ gestures\\ accuracy
1,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,STA-Res-TCN,90.7,98.69,4.1,0.04,91.9,0.99,ito:ITO_00113,Miscellaneous process,28\\ gestures\\ accuracy
2,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,91.9,100.0,1.2,0.01,91.9,1.0,ito:ITO_00113,Miscellaneous process,28\\ gestures\\ accuracy
0,1,Neural Network Compression,ImageNet,2019-01,ImageNet,0.1,100.0,0.1,1.0,0.1,1.0,ito:ITO_00113,Miscellaneous process,All
0,1,Trajectory Prediction,ActEV,2019-02,Next,37.24,100.0,37.24,1.0,37.24,1.0,ito:ITO_00113,Miscellaneous process,FDE\\-8/12
0,1,Trajectory Prediction,ETH/UCY,2019-02,Next,0.46,100.0,0.46,1.0,0.46,0.03,ito:ITO_00113,Miscellaneous process,ADE\\-8/12
1,1,Trajectory Prediction,ActEV,2019-02,Next,17.99,100.0,17.99,1.0,17.99,1.0,ito:ITO_00113,Miscellaneous process,ADE\\-8/12
2,1,Trajectory Forecasting,ActEV,2019-02,Next,17.99,100.0,17.99,1.0,17.99,1.0,ito:ITO_00113,Miscellaneous process,ADE\\-8/12
3,1,Trajectory Prediction,ETH BIWI Walking Pedestrians dataset,2019-04,Social Ways,0.39,100.0,0.39,1.0,0.39,0.02,ito:ITO_00113,Miscellaneous process,ADE\\-8/12
4,1,Trajectory Prediction,Hotel BIWI Walking Pedestrians dataset,2019-04,Social Ways,0.39,100.0,0.39,1.0,0.39,0.02,ito:ITO_00113,Miscellaneous process,ADE\\-8/12
0,1,Recommendation Systems,DBbook2014,2019-02,KTUP (soft),0.2762,100.0,0.2762,1.0,0.2762,0.4,ito:ITO_00113,Miscellaneous process,NDCG
1,1,Recommendation Systems,MovieLens 1M,2019-02,KTUP (soft),0.6992,100.0,0.6992,1.0,0.6992,1.0,ito:ITO_00113,Miscellaneous process,NDCG
2,1,Recommendation Systems,Yelp,2019-02,DGRec,0.1427,100.0,0.1427,1.0,0.1427,0.2,ito:ITO_00113,Miscellaneous process,NDCG
3,1,Recommendation Systems,Douban,2019-02,DGRec,0.195,100.0,0.195,1.0,0.195,0.28,ito:ITO_00113,Miscellaneous process,NDCG
4,1,Recommendation Systems,Delicious,2019-02,DGRec,0.2944,100.0,0.2944,1.0,0.2944,0.42,ito:ITO_00113,Miscellaneous process,NDCG
0,1,Recommendation Systems,Netflix,2019-02,RATE-CSE,0.2014,100.0,0.2014,1.0,0.2014,0.01,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-10
1,1,Recommendation Systems,Frappe,2019-02,RATE-CSE,33.47,100.0,33.47,1.0,33.47,1.0,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-10
2,1,Recommendation Systems,Amazon-Book,2019-02,RANK-CSE,0.0625,100.0,0.0625,1.0,0.0625,0.0,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-10
3,1,Recommendation Systems,MovieLens-Latest,2019-02,RATE-CSE,0.3225,100.0,0.3225,1.0,0.3225,0.01,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-10
4,1,Recommendation Systems,Echonest,2019-02,RANK-CSE,0.1358,100.0,0.1358,1.0,0.1358,0.0,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-10
5,1,Recommendation Systems,Last.FM-360k,2019-02,RANK-CSE,0.1762,100.0,0.1762,1.0,0.1762,0.01,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-10
6,1,Recommendation Systems,CiteULike,2019-02,RATE-CSE,0.2362,100.0,0.2362,1.0,0.2362,0.01,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-10
7,1,Recommendation Systems,Epinions-Extend,2019-02,RANK-CSE,0.1767,100.0,0.1767,1.0,0.1767,0.01,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-10
8,1,Recommendation Systems,Book-Crossing,2019-05,KGNN-LS,0.082,100.0,0.082,1.0,0.082,0.0,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-10
9,1,Recommendation Systems,Last.FM,2019-05,KGNN-LS,0.122,100.0,0.122,1.0,0.122,0.0,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-10
10,1,Recommendation Systems,Dianping-Food,2019-05,KGNN-LS,0.17,100.0,0.17,1.0,0.17,0.01,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-10
11,1,Recommendation Systems,MovieLens 20M,2019-05,KGNN-LS,0.155,100.0,0.155,1.0,0.155,0.0,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-10
12,1,Recommendation Systems,GoodReads-Comics,2019-06,HGN,0.1743,100.0,0.1743,1.0,0.1743,0.01,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-10
13,1,Recommendation Systems,Amazon-CDs,2019-06,HGN,0.0426,100.0,0.0426,1.0,0.0426,0.0,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-10
14,1,Recommendation Systems,GoodReads-Children,2019-06,HGN,0.1263,100.0,0.1263,1.0,0.1263,0.0,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-10
0,1,Recommendation Systems,MovieLens-Latest,2019-02,RATE-CSE,0.199,100.0,0.199,1.0,0.199,0.97,ito:ITO_00113,Miscellaneous process,mAP\\-at\\-10
1,1,Recommendation Systems,Netflix,2019-02,RATE-CSE,0.1039,100.0,0.1039,1.0,0.1039,0.51,ito:ITO_00113,Miscellaneous process,mAP\\-at\\-10
2,1,Recommendation Systems,Echonest,2019-02,RANK-CSE,0.0679,100.0,0.0679,1.0,0.0679,0.33,ito:ITO_00113,Miscellaneous process,mAP\\-at\\-10
3,1,Recommendation Systems,CiteULike,2019-02,RATE-CSE,0.1452,100.0,0.1452,1.0,0.1452,0.71,ito:ITO_00113,Miscellaneous process,mAP\\-at\\-10
4,1,Recommendation Systems,Epinions-Extend,2019-02,RANK-CSE,0.0921,100.0,0.0921,1.0,0.0921,0.45,ito:ITO_00113,Miscellaneous process,mAP\\-at\\-10
5,1,Recommendation Systems,Last.FM-360k,2019-02,RANK-CSE,0.097,100.0,0.097,1.0,0.097,0.47,ito:ITO_00113,Miscellaneous process,mAP\\-at\\-10
6,1,Recommendation Systems,Amazon-Book,2019-02,RANK-CSE,0.0274,100.0,0.0274,1.0,0.0274,0.13,ito:ITO_00113,Miscellaneous process,mAP\\-at\\-10
7,1,Recommendation Systems,Frappe,2019-02,RATE-CSE,0.2047,100.0,0.2047,1.0,0.2047,1.0,ito:ITO_00113,Miscellaneous process,mAP\\-at\\-10
0,1,Node Classification,YouTube,2019-03,LINE,70.09,100.0,70.09,1.0,70.09,1.0,ito:ITO_00113,Miscellaneous process,runtime\\ \\(s\\)
1,1,Human motion prediction,Human motion prediction,2019-03,LINE,70.09,100.0,70.09,1.0,70.09,1.0,ito:ITO_00113,Miscellaneous process,runtime\\ \\(s\\)
0,1,Node Classification,YouTube,2019-03,LINE,33.69,100.0,33.69,1.0,33.69,1.0,ito:ITO_00113,Miscellaneous process,Macro\\-F1\\-at\\-2%
1,1,Human motion prediction,Human motion prediction,2019-03,LINE,33.69,100.0,33.69,1.0,33.69,1.0,ito:ITO_00113,Miscellaneous process,Macro\\-F1\\-at\\-2%
0,1,Node Classification,YouTube,2019-03,LINE,40.61,100.0,40.61,1.0,40.61,1.0,ito:ITO_00113,Miscellaneous process,Micro\\-F1\\-at\\-2%
1,1,Human motion prediction,Human motion prediction,2019-03,LINE,40.61,100.0,40.61,1.0,40.61,1.0,ito:ITO_00113,Miscellaneous process,Micro\\-F1\\-at\\-2%
0,1,Unsupervised Anomaly Detection,Reuters-21578,2019-03,RSRAE,0.849,100.0,0.849,1.0,0.849,1.0,ito:ITO_00113,Miscellaneous process,AUC\\ \\(outlier\\ ratio\\ =\\ 0\\.5\\)
1,1,Unsupervised Anomaly Detection,Caltech-101,2019-03,RSRAE,0.772,100.0,0.772,1.0,0.772,0.91,ito:ITO_00113,Miscellaneous process,AUC\\ \\(outlier\\ ratio\\ =\\ 0\\.5\\)
2,1,Unsupervised Anomaly Detection,Fashion-MNIST,2019-03,RSRAE,0.833,100.0,0.833,1.0,0.833,0.98,ito:ITO_00113,Miscellaneous process,AUC\\ \\(outlier\\ ratio\\ =\\ 0\\.5\\)
3,1,Unsupervised Anomaly Detection,20NEWS,2019-03,RSRAE,0.831,100.0,0.831,1.0,0.831,0.98,ito:ITO_00113,Miscellaneous process,AUC\\ \\(outlier\\ ratio\\ =\\ 0\\.5\\)
0,1,Emotion Recognition in Conversation,EC,2019-03,HRLCE + BERT,0.7709,99.28,0.7709,0.99,0.7765,0.01,ito:ITO_00113,Miscellaneous process,Micro\\-F1
1,1,Emotion Recognition in Conversation,EC,2019-04,NELEC,0.7765,100.0,0.0,0.0,0.7765,0.01,ito:ITO_00113,Miscellaneous process,Micro\\-F1
2,1,Emotion Recognition in Conversation,DailyDialog,2019-09,KET,53.37,100.0,53.37,1.0,53.37,1.0,ito:ITO_00113,Miscellaneous process,Micro\\-F1
0,1,Human Grasp Contact Prediction,ContactDB,2019-04,DiverseNet-VoxNet,8.72,29.17,8.72,0.29,29.89,0.29,ito:ITO_00113,Miscellaneous process,Error\\ rate
1,1,Human Grasp Contact Prediction,ContactDB,2019-04,sMCL-VoxNet,17.27,57.78,8.5,0.28,29.89,0.58,ito:ITO_00113,Miscellaneous process,Error\\ rate
2,1,Human Grasp Contact Prediction,ContactDB,2019-04,DiverseNet-PointNet,21.82,73.0,4.6,0.15,29.89,0.73,ito:ITO_00113,Miscellaneous process,Error\\ rate
3,1,Human Grasp Contact Prediction,ContactDB,2019-04,sMCL-PointNet,29.89,100.0,8.1,0.27,29.89,1.0,ito:ITO_00113,Miscellaneous process,Error\\ rate
4,1,Grasp Contact Prediction,ContactDB,2019-04,sMCL-VoxNet,17.27,57.78,17.27,0.58,29.89,0.58,ito:ITO_00113,Miscellaneous process,Error\\ rate
5,1,Grasp Contact Prediction,ContactDB,2019-04,sMCL-PointNet,29.89,100.0,12.6,0.42,29.89,1.0,ito:ITO_00113,Miscellaneous process,Error\\ rate
0,1,Trajectory Prediction,Stanford Drone,2019-04,Social-Ways,0.62,100.0,0.62,1.0,0.62,1.0,ito:ITO_00113,Miscellaneous process,ADE\\ \\(in\\ world\\ coordinates\\)
0,1,Trajectory Prediction,Stanford Drone,2019-04,Social-Ways,1.16,100.0,1.16,1.0,1.16,1.0,ito:ITO_00113,Miscellaneous process,FDE\\ \\(in\\ world\\ coordinates\\)
0,1,Arabic Text Diacritization,Tashkeela,2019-04,Shakkala,0.0373,100.0,0.0373,1.0,0.0373,1.0,ito:ITO_00113,Miscellaneous process,Diacritic\\ Error\\ Rate
1,1,EEG Emotion Recognition,EEG Emotion Recognition,2019-04,Shakkala,0.0373,100.0,0.0373,1.0,0.0373,1.0,ito:ITO_00113,Miscellaneous process,Diacritic\\ Error\\ Rate
0,1,Synthetic Data Generation,UCI Epileptic Seizure Recognition,2019-05,GAN,0.87,94.57,0.87,0.95,0.92,0.01,ito:ITO_00113,Miscellaneous process,AUROC
1,1,Synthetic Data Generation,UCI Epileptic Seizure Recognition,2020-01,corGAN,0.92,100.0,0.1,0.11,0.92,0.01,ito:ITO_00113,Miscellaneous process,AUROC
2,1,Emotion-Cause Pair Extraction,Emotion-Cause Pair Extraction,2019-05,GAN,0.87,94.57,0.87,0.95,0.92,0.01,ito:ITO_00113,Miscellaneous process,AUROC
3,1,Emotion-Cause Pair Extraction,Emotion-Cause Pair Extraction,2020-01,corGAN,0.92,100.0,0.1,0.11,0.92,0.01,ito:ITO_00113,Miscellaneous process,AUROC
4,1,Anomaly Detection,One-class ImageNet-30,2019-06,RotNet,65.3,76.2,65.3,0.76,85.7,0.74,ito:ITO_00113,Miscellaneous process,AUROC
5,1,Anomaly Detection,One-class ImageNet-30,2019-06,RotNet + Translation,77.9,90.9,12.6,0.15,85.7,0.88,ito:ITO_00113,Miscellaneous process,AUROC
6,1,Anomaly Detection,One-class ImageNet-30,2019-06,RotNet + Translation + Self-Attention + Resize,85.7,100.0,7.8,0.09,85.7,0.97,ito:ITO_00113,Miscellaneous process,AUROC
7,1,Anomaly Detection,One-class CIFAR-10,2019-06,GOAD,88.2,100.0,88.2,1.0,88.2,1.0,ito:ITO_00113,Miscellaneous process,AUROC
0,1,Recommendation Systems,Book-Crossing,2019-05,KGNN-LS,0.045,100.0,0.045,1.0,0.045,0.96,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-2
1,1,Recommendation Systems,MovieLens 20M,2019-05,KGNN-LS,0.043,100.0,0.043,1.0,0.043,0.91,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-2
2,1,Recommendation Systems,Last.FM,2019-05,KGNN-LS,0.044,100.0,0.044,1.0,0.044,0.94,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-2
3,1,Recommendation Systems,Dianping-Food,2019-05,KGNN-LS,0.047,100.0,0.047,1.0,0.047,1.0,ito:ITO_00113,Miscellaneous process,Recall\\-at\\-2
0,1,Recommendation Systems,Declicious,2019-06,TransCF,0.2586,100.0,0.2586,1.0,0.2586,0.35,ito:ITO_00113,Miscellaneous process,Hits\\-at\\-10
1,1,Recommendation Systems,Book-Crossing,2019-06,TransCF,0.3329,100.0,0.3329,1.0,0.3329,0.46,ito:ITO_00113,Miscellaneous process,Hits\\-at\\-10
2,1,Recommendation Systems,Pinterest,2019-06,TransCF,0.5504,100.0,0.5504,1.0,0.5504,0.75,ito:ITO_00113,Miscellaneous process,Hits\\-at\\-10
3,1,Recommendation Systems,Ciao,2019-06,TransCF,0.2292,100.0,0.2292,1.0,0.2292,0.31,ito:ITO_00113,Miscellaneous process,Hits\\-at\\-10
4,1,Recommendation Systems,Flixster,2019-06,TransCF,0.7309,100.0,0.7309,1.0,0.7309,1.0,ito:ITO_00113,Miscellaneous process,Hits\\-at\\-10
5,1,Recommendation Systems,Amazon C&A,2019-06,TransCF,0.3436,100.0,0.3436,1.0,0.3436,0.47,ito:ITO_00113,Miscellaneous process,Hits\\-at\\-10
6,1,Recommendation Systems,Tradesy,2019-06,TransCF,0.3198,100.0,0.3198,1.0,0.3198,0.44,ito:ITO_00113,Miscellaneous process,Hits\\-at\\-10
0,1,Recommendation Systems,Ciao,2019-06,TransCF,0.374,100.0,0.374,1.0,0.374,0.45,ito:ITO_00113,Miscellaneous process,Hits\\-at\\-20
1,1,Recommendation Systems,Amazon C&A,2019-06,TransCF,0.4658,100.0,0.4658,1.0,0.4658,0.56,ito:ITO_00113,Miscellaneous process,Hits\\-at\\-20
2,1,Recommendation Systems,Declicious,2019-06,TransCF,0.3786,100.0,0.3786,1.0,0.3786,0.45,ito:ITO_00113,Miscellaneous process,Hits\\-at\\-20
3,1,Recommendation Systems,Flixster,2019-06,TransCF,0.8374,100.0,0.8374,1.0,0.8374,1.0,ito:ITO_00113,Miscellaneous process,Hits\\-at\\-20
4,1,Recommendation Systems,Tradesy,2019-06,TransCF,0.4505,100.0,0.4505,1.0,0.4505,0.54,ito:ITO_00113,Miscellaneous process,Hits\\-at\\-20
5,1,Recommendation Systems,Pinterest,2019-06,TransCF,0.8108,100.0,0.8108,1.0,0.8108,0.97,ito:ITO_00113,Miscellaneous process,Hits\\-at\\-20
6,1,Recommendation Systems,Book-Crossing,2019-06,TransCF,0.4744,100.0,0.4744,1.0,0.4744,0.57,ito:ITO_00113,Miscellaneous process,Hits\\-at\\-20
0,1,Recommendation Systems,Flixster,2019-06,TransCF,0.5257,100.0,0.5257,1.0,0.5257,1.0,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-20
1,1,Recommendation Systems,Ciao,2019-06,TransCF,0.1525,100.0,0.1525,1.0,0.1525,0.29,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-20
2,1,Recommendation Systems,Amazon C&A,2019-06,TransCF,0.2323,100.0,0.2323,1.0,0.2323,0.44,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-20
3,1,Recommendation Systems,Declicious,2019-06,TransCF,0.1781,100.0,0.1781,1.0,0.1781,0.34,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-20
4,1,Recommendation Systems,Book-Crossing,2019-06,TransCF,0.2221,100.0,0.2221,1.0,0.2221,0.42,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-20
5,1,Recommendation Systems,Tradesy,2019-06,TransCF,0.2095,100.0,0.2095,1.0,0.2095,0.4,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-20
6,1,Recommendation Systems,Pinterest,2019-06,TransCF,0.3242,100.0,0.3242,1.0,0.3242,0.62,ito:ITO_00113,Miscellaneous process,nDCG\\-at\\-20
0,1,3D Semantic Segmentation,S3DIS,2019-07,PVCNN++ (1xC) volumetric,87.12,100.0,87.12,1.0,87.12,1.0,ito:ITO_00113,Miscellaneous process,mAcc
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,1820000.0,100.0,1820000,1.0,1820000,1.0,ito:ITO_00113,Miscellaneous process,No\\.\\ parameters
0,1,Topic Models,20NEWS,2019-08,Bayesian SMM,851.0,100.0,851,1.0,851,1.0,ito:ITO_00113,Miscellaneous process,PPL
0,1,Recipe Generation,Food.com,2019-08,Prior Name,9.516,100.0,9.516,1.0,9.516,1.0,ito:ITO_00113,Miscellaneous process,BPE\\ Perplexity
0,1,Recipe Generation,Food.com,2019-08,Prior Name,24.794,100.0,24.794,1.0,24.794,1.0,ito:ITO_00113,Miscellaneous process,Rouge\\-L
0,1,Recipe Generation,Food.com,2019-08,Prior Name,28.046,100.0,28.046,1.0,28.046,1.0,ito:ITO_00113,Miscellaneous process,BLEU\\-1
0,1,Recipe Generation,Food.com,2019-08,Prior Name,3.211,100.0,3.211,1.0,3.211,1.0,ito:ITO_00113,Miscellaneous process,BLEU\\-4
0,1,Recipe Generation,Food.com,2019-08,Prior Name,0.233,100.0,0.233,1.0,0.233,1.0,ito:ITO_00113,Miscellaneous process,D\\-1
0,1,Recipe Generation,Food.com,2019-08,Prior Name,2.08,100.0,2.08,1.0,2.08,1.0,ito:ITO_00113,Miscellaneous process,D\\-2
0,1,Emotion Recognition in Conversation,EmoryNLP,2019-09,KET,34.39,100.0,34.39,1.0,34.39,1.0,ito:ITO_00113,Miscellaneous process,Weighted\\ Macro\\-F1
0,1,Multiple Object Forecasting,Citywalks,2019-09,STED,26.7,100.0,26.7,1.0,26.7,1.0,ito:ITO_00113,Miscellaneous process,ADE
1,1,Trajectory Prediction,Argoverse,2019-12,SpectralCows,0.005,100.0,0.005,1.0,0.005,0.0,ito:ITO_00113,Miscellaneous process,ADE
2,1,Trajectory Prediction,Lyft Level 5,2019-12,SpectralCows,0.008,100.0,0.008,1.0,0.008,0.0,ito:ITO_00113,Miscellaneous process,ADE
3,1,Trajectory Prediction,Apolloscape,2019-12,SpectralCows,0.005,100.0,0.005,1.0,0.005,0.0,ito:ITO_00113,Miscellaneous process,ADE
0,1,Multiple Object Forecasting,Citywalks,2019-09,STED,54.3,100.0,54.3,1.0,54.3,1.0,ito:ITO_00113,Miscellaneous process,AIOU
0,1,Fraud Detection,Kaggle-Credit Card Fraud Dataset,2019-11,DevNet,0.69,100.0,0.69,1.0,0.69,0.78,ito:ITO_00113,Miscellaneous process,Average\\ Precision
1,1,Anomaly Detection,Thyroid,2019-11,DevNet,0.274,100.0,0.274,1.0,0.274,0.31,ito:ITO_00113,Miscellaneous process,Average\\ Precision
2,1,Anomaly Detection,Census,2019-11,DevNet,0.321,100.0,0.321,1.0,0.321,0.36,ito:ITO_00113,Miscellaneous process,Average\\ Precision
3,1,Network Intrusion Detection,NB15-Backdoor,2019-11,DevNet,0.883,100.0,0.883,1.0,0.883,1.0,ito:ITO_00113,Miscellaneous process,Average\\ Precision
0,1,Neural Network Compression,CIFAR-10,2020-01,ShuffleNet – Quantised,1.9,3.48,1.9,0.03,54.6,0.03,ito:ITO_00113,Miscellaneous process,Size\\ \\(MB\\)
1,1,Neural Network Compression,CIFAR-10,2020-01,MobileNet – Quantised,2.9,5.31,1.0,0.02,54.6,0.05,ito:ITO_00113,Miscellaneous process,Size\\ \\(MB\\)
2,1,Neural Network Compression,CIFAR-10,2020-01,AlexNet – Quantised,54.6,100.0,51.7,0.95,54.6,1.0,ito:ITO_00113,Miscellaneous process,Size\\ \\(MB\\)
0,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet-tiny,0.44,11.08,0.44,0.11,3.97,0.11,ito:ITO_00113,Miscellaneous process,Parameters\\ \\(M\\)
1,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet,3.97,100.0,3.5,0.88,3.97,1.0,ito:ITO_00113,Miscellaneous process,Parameters\\ \\(M\\)
0,1,Table Detection,ICDAR2013,2020-04,cascadetabnet,1.0,100.0,1,1.0,1,1.0,ito:ITO_00113,Miscellaneous process,Avg\\ F1
0,1,Arrhythmia Detection,MIT-BIH AR,2005-01,SVM,76.3,76.66,76.3,0.77,99.53,0.77,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(Inter\\-Patient\\)
1,1,Arrhythmia Detection,MIT-BIH AR,2017-09,TVCG_PSO,92.4,92.84,16.1,0.16,99.53,0.93,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(Inter\\-Patient\\)
2,1,Arrhythmia Detection,MIT-BIH AR,2018-04,Deep residual CNN ,93.4,93.84,1.0,0.01,99.53,0.94,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(Inter\\-Patient\\)
3,1,Arrhythmia Detection,MIT-BIH AR,2018-12,BiRNN,99.53,100.0,6.1,0.06,99.53,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(Inter\\-Patient\\)
0,1,Arrhythmia Detection,MIT-BIH AR,2005-01,SVM,98.7,98.78,98.7,0.99,99.92,0.99,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(Intra\\-Patient\\)
1,1,Arrhythmia Detection,MIT-BIH AR,2018-12,BiRNN,99.92,100.0,1.2,0.01,99.92,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(Intra\\-Patient\\)
0,1,Skeleton Based Action Recognition,UWA3D,2012-07,HOJ3D,17.7,21.74,17.7,0.22,81.4,0.18,ito:ITO_00115,Fundamental AI process,Accuracy
1,1,Skeleton Based Action Recognition,UWA3D,2017-08,ESV (Synthesized + Pre-trained),73.8,90.66,56.1,0.69,81.4,0.74,ito:ITO_00115,Fundamental AI process,Accuracy
2,1,Skeleton Based Action Recognition,UWA3D,2018-04,VA-fusion (aug.),81.4,100.0,7.6,0.09,81.4,0.81,ito:ITO_00115,Fundamental AI process,Accuracy
3,1,Skeleton Based Action Recognition,CAD-120,2012-10,KGS,86.0,96.3,86.0,0.96,89.3,0.86,ito:ITO_00115,Fundamental AI process,Accuracy
4,1,Skeleton Based Action Recognition,CAD-120,2013-02,All Features (w ground truth),89.3,100.0,3.3,0.04,89.3,0.89,ito:ITO_00115,Fundamental AI process,Accuracy
5,1,Unsupervised Domain Adaptation,Office-Home,2012-12,AlexNet [cite:NIPS12CNN],54.9,71.48,54.9,0.71,76.8,0.55,ito:ITO_00115,Fundamental AI process,Accuracy
6,1,Unsupervised Domain Adaptation,Office-Home,2015-02,DAN [cite:ICML15DAN],74.3,96.74,19.4,0.25,76.8,0.74,ito:ITO_00115,Fundamental AI process,Accuracy
7,1,Unsupervised Domain Adaptation,Office-Home,2015-05,DANN [cite:JMLR16RevGrad],76.8,100.0,2.5,0.03,76.8,0.77,ito:ITO_00115,Fundamental AI process,Accuracy
8,1,Few-Shot Image Classification,ImageNet,2013-12,ConSE,1.4,93.33,1.4,0.93,1.5,0.01,ito:ITO_00115,Fundamental AI process,Accuracy
9,1,Few-Shot Image Classification,ImageNet,2016-03,Synthesised Classifier,1.5,100.0,0.1,0.07,1.5,0.02,ito:ITO_00115,Fundamental AI process,Accuracy
10,1,Domain Adaptation,UCF-to-HMDBsmall,2014-06,W. Sultani et al.,68.7,69.16,68.7,0.69,99.33,0.69,ito:ITO_00115,Fundamental AI process,Accuracy
11,1,Domain Adaptation,UCF-to-HMDBsmall,2014-09,TemPooling + RevGrad,99.33,100.0,30.6,0.31,99.33,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
12,1,Domain Adaptation,UCF-to-Olympic,2014-06,W. Sultani et al.,33.33,33.96,33.33,0.34,98.15,0.33,ito:ITO_00115,Fundamental AI process,Accuracy
13,1,Domain Adaptation,UCF-to-Olympic,2014-09,TemPooling + RevGrad,98.15,100.0,64.8,0.66,98.15,0.98,ito:ITO_00115,Fundamental AI process,Accuracy
14,1,Domain Adaptation,Olympic-to-HMDBsmall,2014-06,W. Sultani et al.,47.91,51.56,47.91,0.52,92.92,0.48,ito:ITO_00115,Fundamental AI process,Accuracy
15,1,Domain Adaptation,Olympic-to-HMDBsmall,2014-09,TemPooling + RevGrad,90.0,96.86,42.1,0.45,92.92,0.9,ito:ITO_00115,Fundamental AI process,Accuracy
16,1,Domain Adaptation,Olympic-to-HMDBsmall,2019-05,TA3N,92.92,100.0,2.9,0.03,92.92,0.93,ito:ITO_00115,Fundamental AI process,Accuracy
17,1,Domain Adaptation,HMDBsmall-to-UCF,2014-06,W. Sultani et al.,68.67,69.04,68.67,0.69,99.47,0.69,ito:ITO_00115,Fundamental AI process,Accuracy
18,1,Domain Adaptation,HMDBsmall-to-UCF,2014-09,TemPooling + RevGrad,98.41,98.93,29.7,0.3,99.47,0.98,ito:ITO_00115,Fundamental AI process,Accuracy
19,1,Domain Adaptation,HMDBsmall-to-UCF,2019-05,TA3N,99.47,100.0,1.1,0.01,99.47,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
20,1,Skeleton Based Action Recognition,Florence 3D,2014-06,Lie Group,90.9,91.73,90.9,0.92,99.1,0.91,ito:ITO_00115,Fundamental AI process,Accuracy
21,1,Skeleton Based Action Recognition,Florence 3D,2016-06,Rolling Rotations (FTP),91.4,92.23,0.5,0.01,99.1,0.91,ito:ITO_00115,Fundamental AI process,Accuracy
22,1,Skeleton Based Action Recognition,Florence 3D,2018-02,Deep STGC_K,99.1,100.0,7.7,0.08,99.1,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
23,1,Skeleton Based Action Recognition,UT-Kinect,2014-06,Lie Group,97.1,98.58,97.1,0.99,98.5,0.97,ito:ITO_00115,Fundamental AI process,Accuracy
24,1,Skeleton Based Action Recognition,UT-Kinect,2018-06,DPRL,98.5,100.0,1.4,0.01,98.5,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
25,1,Myocardial Infarction Detection,"PTB dataset, ECG lead II",2014-08,T-wave + Total Integral,94.7,98.75,94.7,0.99,95.9,0.95,ito:ITO_00115,Fundamental AI process,Accuracy
26,1,Myocardial Infarction Detection,"PTB dataset, ECG lead II",2018-04,Deep residual CNN,95.9,100.0,1.2,0.01,95.9,0.96,ito:ITO_00115,Fundamental AI process,Accuracy
27,1,Activity Recognition In Videos,DogCentric,2014-09,VGG [[Simonyan and Zisserman2015]],59.9,73.59,59.9,0.74,81.4,0.6,ito:ITO_00115,Fundamental AI process,Accuracy
28,1,Activity Recognition In Videos,DogCentric,2014-12,"PoT [[Ryoo, Rothrock, and Matthies2015]]",73.0,89.68,13.1,0.16,81.4,0.73,ito:ITO_00115,Fundamental AI process,Accuracy
29,1,Activity Recognition In Videos,DogCentric,2015-05,"TDD [[Wang, Qiao, and Tang2015]]",76.6,94.1,3.6,0.04,81.4,0.77,ito:ITO_00115,Fundamental AI process,Accuracy
30,1,Activity Recognition In Videos,DogCentric,2016-05,Sub-events (temporal filters + LSTM),81.4,100.0,4.8,0.06,81.4,0.81,ito:ITO_00115,Fundamental AI process,Accuracy
31,1,Transfer Learning,Office-Home,2014-09,DANN,57.6,80.67,57.6,0.81,71.4,0.58,ito:ITO_00115,Fundamental AI process,Accuracy
32,1,Transfer Learning,Office-Home,2015-02,DAN [cite:ICML15DAN],62.8,87.96,5.2,0.07,71.4,0.63,ito:ITO_00115,Fundamental AI process,Accuracy
33,1,Transfer Learning,Office-Home,2016-02,RTN [cite:NIPS16RTN],64.8,90.76,2.0,0.03,71.4,0.65,ito:ITO_00115,Fundamental AI process,Accuracy
34,1,Transfer Learning,Office-Home,2016-05,JAN [cite:ICML17JAN],70.0,98.04,5.2,0.07,71.4,0.7,ito:ITO_00115,Fundamental AI process,Accuracy
35,1,Transfer Learning,Office-Home,2017-04,GTA [cite:CVPR18GTA],71.4,100.0,1.4,0.02,71.4,0.71,ito:ITO_00115,Fundamental AI process,Accuracy
36,1,Domain Adaptation,UCF-to-HMDBfull,2014-09,RevGrad,74.44,95.03,74.44,0.95,78.33,0.74,ito:ITO_00115,Fundamental AI process,Accuracy
37,1,Domain Adaptation,UCF-to-HMDBfull,2016-05,JAN,74.72,95.39,0.3,0.0,78.33,0.75,ito:ITO_00115,Fundamental AI process,Accuracy
38,1,Domain Adaptation,UCF-to-HMDBfull,2019-05,TA3N,78.33,100.0,3.6,0.05,78.33,0.78,ito:ITO_00115,Fundamental AI process,Accuracy
39,1,Domain Adaptation,HMDBfull-to-UCF,2014-09,RevGrad,74.44,91.01,74.44,0.91,81.79,0.74,ito:ITO_00115,Fundamental AI process,Accuracy
40,1,Domain Adaptation,HMDBfull-to-UCF,2016-05,JAN,79.69,97.43,5.2,0.06,81.79,0.8,ito:ITO_00115,Fundamental AI process,Accuracy
41,1,Domain Adaptation,HMDBfull-to-UCF,2019-05,TA3N,81.79,100.0,2.1,0.03,81.79,0.82,ito:ITO_00115,Fundamental AI process,Accuracy
42,1,Few-Shot Image Classification,CUB-200,2014-09,SJE,50.1,88.05,50.1,0.88,56.9,0.5,ito:ITO_00115,Fundamental AI process,Accuracy
43,1,Few-Shot Image Classification,CUB-200,2019-04,TAFE-Net,56.9,100.0,6.8,0.12,56.9,0.57,ito:ITO_00115,Fundamental AI process,Accuracy
44,1,Domain Adaptation,Synth Digits-to-SVHN,2015-02,MMD [tzeng2015ddc]; [long2015learning],88.0,96.49,88.0,0.96,91.2,0.88,ito:ITO_00115,Fundamental AI process,Accuracy
45,1,Domain Adaptation,Synth Digits-to-SVHN,2015-05,DANN [ganin2016domain],90.3,99.01,2.3,0.03,91.2,0.9,ito:ITO_00115,Fundamental AI process,Accuracy
46,1,Domain Adaptation,Synth Digits-to-SVHN,2016-08,DSN (DANN),91.2,100.0,0.9,0.01,91.2,0.91,ito:ITO_00115,Fundamental AI process,Accuracy
47,1,Domain Adaptation,SYNSIG-to-GTSRB,2015-02,DAN,91.1,96.5,91.1,0.97,94.4,0.91,ito:ITO_00115,Fundamental AI process,Accuracy
48,1,Domain Adaptation,SYNSIG-to-GTSRB,2017-12,MCD,94.4,100.0,3.3,0.03,94.4,0.94,ito:ITO_00115,Fundamental AI process,Accuracy
49,1,Domain Adaptation,MNIST-to-MNIST-M,2015-02,MMD [tzeng2015ddc]; [long2015learning],76.9,92.43,76.9,0.92,83.2,0.77,ito:ITO_00115,Fundamental AI process,Accuracy
50,1,Domain Adaptation,MNIST-to-MNIST-M,2015-05,DANN [ganin2016domain],77.4,93.03,0.5,0.01,83.2,0.77,ito:ITO_00115,Fundamental AI process,Accuracy
51,1,Domain Adaptation,MNIST-to-MNIST-M,2016-08,DSN (DANN),83.2,100.0,5.8,0.07,83.2,0.83,ito:ITO_00115,Fundamental AI process,Accuracy
52,1,Domain Adaptation,Synth Signs-to-GTSRB,2015-02,MMD [tzeng2015ddc]; [long2015learning],91.1,97.85,91.1,0.98,93.1,0.91,ito:ITO_00115,Fundamental AI process,Accuracy
53,1,Domain Adaptation,Synth Signs-to-GTSRB,2016-08,DSN (DANN),93.1,100.0,2.0,0.02,93.1,0.93,ito:ITO_00115,Fundamental AI process,Accuracy
54,1,Domain Adaptation,ImageCLEF-DA,2015-02,DAN,76.9,85.16,76.9,0.85,90.3,0.77,ito:ITO_00115,Fundamental AI process,Accuracy
55,1,Domain Adaptation,ImageCLEF-DA,2018-11,IAFN+ENT,88.9,98.45,12.0,0.13,90.3,0.89,ito:ITO_00115,Fundamental AI process,Accuracy
56,1,Domain Adaptation,ImageCLEF-DA,2019-11,SPL,90.3,100.0,1.4,0.02,90.3,0.9,ito:ITO_00115,Fundamental AI process,Accuracy
57,1,Domain Adaptation,SVNH-to-MNIST,2015-02,MMD [tzeng2015ddc]; [long2015learning],71.1,71.88,71.1,0.72,98.91,0.71,ito:ITO_00115,Fundamental AI process,Accuracy
58,1,Domain Adaptation,SVNH-to-MNIST,2016-08,DSN (DANN),82.7,83.61,11.6,0.12,98.91,0.83,ito:ITO_00115,Fundamental AI process,Accuracy
59,1,Domain Adaptation,SVNH-to-MNIST,2019-03,rRevGrad+CAT,98.8,99.89,16.1,0.16,98.91,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
60,1,Domain Adaptation,SVNH-to-MNIST,2019-05,SRDA (RAN),98.91,100.0,0.1,0.0,98.91,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
61,1,One-Shot Learning,MNIST,2015-07,Siamese Neural Network,97.5,100.0,97.5,1.0,97.5,0.98,ito:ITO_00115,Fundamental AI process,Accuracy
62,1,Semanticity prediction,Semanticity prediction,2015-09,GCN-FP,50.5,67.43,50.5,0.67,74.89,0.51,ito:ITO_00115,Fundamental AI process,Accuracy
63,1,Semanticity prediction,Semanticity prediction,2015-11,DCNN,59.0,78.78,8.5,0.11,74.89,0.59,ito:ITO_00115,Fundamental AI process,Accuracy
64,1,Semanticity prediction,Semanticity prediction,2019-01,AdaLanczosNet,60.8,81.19,1.8,0.02,74.89,0.61,ito:ITO_00115,Fundamental AI process,Accuracy
65,1,Semanticity prediction,Semanticity prediction,2019-06,Truncated Krylov,74.89,100.0,14.1,0.19,74.89,0.75,ito:ITO_00115,Fundamental AI process,Accuracy
66,1,Node Classification,20NEWS,2015-10,GraRep,81.44,100.0,81.44,1.0,81.44,0.81,ito:ITO_00115,Fundamental AI process,Accuracy
67,1,Attention Score Prediction,Attention Score Prediction,2015-10,GraRep,81.44,100.0,81.44,1.0,81.44,0.81,ito:ITO_00115,Fundamental AI process,Accuracy
68,1,Unsupervised MNIST,MNIST,2015-11,Adversarial AE,95.9,96.58,95.9,0.97,99.3,0.96,ito:ITO_00115,Fundamental AI process,Accuracy
69,1,Unsupervised MNIST,MNIST,2018-03,Bidirectional InfoGAN,96.61,97.29,0.7,0.01,99.3,0.97,ito:ITO_00115,Fundamental AI process,Accuracy
70,1,Unsupervised MNIST,MNIST,2018-07,IIC,99.3,100.0,2.7,0.03,99.3,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
71,1,Few-Shot Image Classification,SUN,2016-03,Synthesised Classifier,62.7,100.0,62.7,1.0,62.7,0.63,ito:ITO_00115,Fundamental AI process,Accuracy
72,1,Few-Shot Image Classification,AWA,2016-03,Synthesised Classifier,72.9,100.0,72.9,1.0,72.9,0.73,ito:ITO_00115,Fundamental AI process,Accuracy
73,1,Few-Shot Image Classification,Flowers-102,2016-05,Word CNN-RNN (DS-SJE Embedding),65.6,100.0,65.6,1.0,65.6,0.66,ito:ITO_00115,Fundamental AI process,Accuracy
74,1,Domain Adaptation,VisDA2017,2016-05,JAN,58.3,66.86,58.3,0.67,87.2,0.58,ito:ITO_00115,Fundamental AI process,Accuracy
75,1,Domain Adaptation,VisDA2017,2017-05,CDAN,73.7,84.52,15.4,0.18,87.2,0.74,ito:ITO_00115,Fundamental AI process,Accuracy
76,1,Domain Adaptation,VisDA2017,2018-11,IAFN,76.1,87.27,2.4,0.03,87.2,0.76,ito:ITO_00115,Fundamental AI process,Accuracy
77,1,Domain Adaptation,VisDA2017,2019-01,Contrastive Adaptation Network,87.2,100.0,11.1,0.13,87.2,0.87,ito:ITO_00115,Fundamental AI process,Accuracy
78,1,Few-Shot Image Classification,OMNIGLOT,2016-06,Neural Statistician,98.1,98.13,98.1,0.98,99.97,0.98,ito:ITO_00115,Fundamental AI process,Accuracy
79,1,Few-Shot Image Classification,OMNIGLOT,2017-03,MAML,98.7,98.73,0.6,0.01,99.97,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
80,1,Few-Shot Image Classification,OMNIGLOT,2017-03,Prototypical Networks,98.8,98.83,0.1,0.0,99.97,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
81,1,Few-Shot Image Classification,OMNIGLOT,2017-11,Relation Net,99.6,99.63,0.8,0.01,99.97,1.0,ito:ITO_00115,Fundamental AI process,Accuracy
82,1,Few-Shot Image Classification,OMNIGLOT,2019-02,MC2+,99.97,100.0,0.4,0.0,99.97,1.0,ito:ITO_00115,Fundamental AI process,Accuracy
83,1,Few-Shot Image Classification,OMNIGLOT,2016-06,Neural Statistician,99.5,99.58,99.5,1.0,99.92,1.0,ito:ITO_00115,Fundamental AI process,Accuracy
84,1,Few-Shot Image Classification,OMNIGLOT,2017-03,ConvNet with Memory Module,99.6,99.68,0.1,0.0,99.92,1.0,ito:ITO_00115,Fundamental AI process,Accuracy
85,1,Few-Shot Image Classification,OMNIGLOT,2017-03,MAML,99.9,99.98,0.3,0.0,99.92,1.0,ito:ITO_00115,Fundamental AI process,Accuracy
86,1,Few-Shot Image Classification,OMNIGLOT,2019-08,DCN6-E,99.92,100.0,0.0,0.0,99.92,1.0,ito:ITO_00115,Fundamental AI process,Accuracy
87,1,Few-Shot Image Classification,OMNIGLOT,2016-06,Neural Statistician,98.1,98.44,98.1,0.98,99.65,0.98,ito:ITO_00115,Fundamental AI process,Accuracy
88,1,Few-Shot Image Classification,OMNIGLOT,2016-06,Matching Nets,98.5,98.85,0.4,0.0,99.65,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
89,1,Few-Shot Image Classification,OMNIGLOT,2017-03,ConvNet with Memory Module,98.6,98.95,0.1,0.0,99.65,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
90,1,Few-Shot Image Classification,OMNIGLOT,2017-03,Prototypical Networks,98.9,99.25,0.3,0.0,99.65,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
91,1,Few-Shot Image Classification,OMNIGLOT,2017-11,Relation Net,99.1,99.45,0.2,0.0,99.65,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
92,1,Few-Shot Image Classification,OMNIGLOT,2018-10,MAML++,99.33,99.68,0.2,0.0,99.65,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
93,1,Few-Shot Image Classification,OMNIGLOT,2019-02,MC2+,99.65,100.0,0.3,0.0,99.65,1.0,ito:ITO_00115,Fundamental AI process,Accuracy
94,1,Few-Shot Image Classification,OMNIGLOT,2016-06,Neural Statistician,93.2,93.55,93.2,0.94,99.63,0.93,ito:ITO_00115,Fundamental AI process,Accuracy
95,1,Few-Shot Image Classification,OMNIGLOT,2016-06,Matching Nets,93.8,94.15,0.6,0.01,99.63,0.94,ito:ITO_00115,Fundamental AI process,Accuracy
96,1,Few-Shot Image Classification,OMNIGLOT,2017-03,ConvNet with Memory Module,95.0,95.35,1.2,0.01,99.63,0.95,ito:ITO_00115,Fundamental AI process,Accuracy
97,1,Few-Shot Image Classification,OMNIGLOT,2017-03,Prototypical Networks,96.0,96.36,1.0,0.01,99.63,0.96,ito:ITO_00115,Fundamental AI process,Accuracy
98,1,Few-Shot Image Classification,OMNIGLOT,2017-11,Relation Net,97.6,97.96,1.6,0.02,99.63,0.98,ito:ITO_00115,Fundamental AI process,Accuracy
99,1,Few-Shot Image Classification,OMNIGLOT,2018-10,MAML++,97.65,98.01,0.1,0.0,99.63,0.98,ito:ITO_00115,Fundamental AI process,Accuracy
100,1,Few-Shot Image Classification,OMNIGLOT,2019-05,TapNet,98.07,98.43,0.4,0.0,99.63,0.98,ito:ITO_00115,Fundamental AI process,Accuracy
101,1,Few-Shot Image Classification,OMNIGLOT,2019-08,GCR,99.63,100.0,1.6,0.02,99.63,1.0,ito:ITO_00115,Fundamental AI process,Accuracy
102,1,Few-Shot Image Classification,Meta-Dataset,2016-06,Matching Networks,56.247,92.86,56.247,0.93,60.573,0.56,ito:ITO_00115,Fundamental AI process,Accuracy
103,1,Few-Shot Image Classification,Meta-Dataset,2017-03,fo-MAML,57.024,94.14,0.8,0.01,60.573,0.57,ito:ITO_00115,Fundamental AI process,Accuracy
104,1,Few-Shot Image Classification,Meta-Dataset,2017-03,Prototypical Networks,60.573,100.0,3.5,0.06,60.573,0.61,ito:ITO_00115,Fundamental AI process,Accuracy
105,1,Skeleton Based Action Recognition,SBU,2016-06,ChebyNet,96.0,96.95,96.0,0.97,99.02,0.96,ito:ITO_00115,Fundamental AI process,Accuracy
106,1,Skeleton Based Action Recognition,SBU,2017-03,Joint Line Distance,99.02,100.0,3.0,0.03,99.02,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
107,1,Outlier Detection,ECG5000,2016-07,SAE-C,0.934,94.89,0.934,0.95,0.9843,0.01,ito:ITO_00115,Fundamental AI process,Accuracy
108,1,Outlier Detection,ECG5000,2017-09,F-t ALSTM-FCN,0.9496,96.47,0.0,0.0,0.9843,0.01,ito:ITO_00115,Fundamental AI process,Accuracy
109,1,Outlier Detection,ECG5000,2019-04,VRAE+SVM,0.9843,100.0,0.0,0.0,0.9843,0.01,ito:ITO_00115,Fundamental AI process,Accuracy
110,1,Node Classification,Reddit,2016-09,GCN,95.68,98.62,95.68,0.99,97.02,0.96,ito:ITO_00115,Fundamental AI process,Accuracy
111,1,Node Classification,Reddit,2018-09,ASGCN,96.27,99.23,0.6,0.01,97.02,0.96,ito:ITO_00115,Fundamental AI process,Accuracy
112,1,Node Classification,Reddit,2019-07,GraphSAINT,97.0,99.98,0.7,0.01,97.02,0.97,ito:ITO_00115,Fundamental AI process,Accuracy
113,1,Node Classification,Reddit,2020-01,JKNet+DropEdge,97.02,100.0,0.0,0.0,97.02,0.97,ito:ITO_00115,Fundamental AI process,Accuracy
114,1,LWR Classification,LWR Classification,2016-09,GCN,95.68,98.62,95.68,0.99,97.02,0.96,ito:ITO_00115,Fundamental AI process,Accuracy
115,1,LWR Classification,LWR Classification,2018-09,ASGCN,96.27,99.23,0.6,0.01,97.02,0.96,ito:ITO_00115,Fundamental AI process,Accuracy
116,1,LWR Classification,LWR Classification,2019-07,GraphSAINT,97.0,99.98,0.7,0.01,97.02,0.97,ito:ITO_00115,Fundamental AI process,Accuracy
117,1,LWR Classification,LWR Classification,2020-01,JKNet+DropEdge,97.02,100.0,0.0,0.0,97.02,0.97,ito:ITO_00115,Fundamental AI process,Accuracy
118,1,Action Recognition,Volleyball,2016-11,GTT (VGG19),82.6,100.0,82.6,1.0,82.6,0.83,ito:ITO_00115,Fundamental AI process,Accuracy
119,1,Action Recognition In Videos,Volleyball,2016-11,SSU (GT),81.8,99.03,81.8,0.99,82.6,0.82,ito:ITO_00115,Fundamental AI process,Accuracy
120,1,Action Recognition In Videos,Volleyball,2019-04,GTT (VGG19),82.6,100.0,0.8,0.01,82.6,0.83,ito:ITO_00115,Fundamental AI process,Accuracy
121,1,Multivariate Time Series Forecasting,BPI challenge '12,2016-12,LSTM,0.76,100.0,0.76,1.0,0.76,0.01,ito:ITO_00115,Fundamental AI process,Accuracy
122,1,Multivariate Time Series Forecasting,Helpdesk,2016-12,LSTM,0.7123,100.0,0.7123,1.0,0.7123,0.01,ito:ITO_00115,Fundamental AI process,Accuracy
123,1,Skeleton Based Action Recognition,SYSU 3D,2016-12,Dynamic Skeletons,75.5,86.88,75.5,0.87,86.9,0.76,ito:ITO_00115,Fundamental AI process,Accuracy
124,1,Skeleton Based Action Recognition,SYSU 3D,2017-03,VA-LSTM,77.5,89.18,2.0,0.02,86.9,0.78,ito:ITO_00115,Fundamental AI process,Accuracy
125,1,Skeleton Based Action Recognition,SYSU 3D,2018-04,VA-fusion (aug.),86.7,99.77,9.2,0.11,86.9,0.87,ito:ITO_00115,Fundamental AI process,Accuracy
126,1,Skeleton Based Action Recognition,SYSU 3D,2019-04,SGN,86.9,100.0,0.2,0.0,86.9,0.87,ito:ITO_00115,Fundamental AI process,Accuracy
127,1,Domain Adaptation,MNIST-to-USPS,2017-02,ADDN,90.1,92.79,90.1,0.93,97.1,0.9,ito:ITO_00115,Fundamental AI process,Accuracy
128,1,Domain Adaptation,MNIST-to-USPS,2017-12,MCD,93.8,96.6,3.7,0.04,97.1,0.94,ito:ITO_00115,Fundamental AI process,Accuracy
129,1,Domain Adaptation,MNIST-to-USPS,2019-03,rRevGrad+CAT,96.0,98.87,2.2,0.02,97.1,0.96,ito:ITO_00115,Fundamental AI process,Accuracy
130,1,Domain Adaptation,MNIST-to-USPS,2019-09,3CATN,96.1,98.97,0.1,0.0,97.1,0.96,ito:ITO_00115,Fundamental AI process,Accuracy
131,1,Domain Adaptation,MNIST-to-USPS,2019-11,CyCleGAN (Light-weight Calibrator),97.1,100.0,1.0,0.01,97.1,0.97,ito:ITO_00115,Fundamental AI process,Accuracy
132,1,Domain Adaptation,SVHN-to-MNIST,2017-02,ADDN,80.1,82.15,80.1,0.82,97.5,0.8,ito:ITO_00115,Fundamental AI process,Accuracy
133,1,Domain Adaptation,SVHN-to-MNIST,2017-05,CDAN,89.2,91.49,9.1,0.09,97.5,0.89,ito:ITO_00115,Fundamental AI process,Accuracy
134,1,Domain Adaptation,SVHN-to-MNIST,2017-11,CYCADA,90.4,92.72,1.2,0.01,97.5,0.9,ito:ITO_00115,Fundamental AI process,Accuracy
135,1,Domain Adaptation,SVHN-to-MNIST,2017-12,MCD,95.8,98.26,5.4,0.06,97.5,0.96,ito:ITO_00115,Fundamental AI process,Accuracy
136,1,Domain Adaptation,SVHN-to-MNIST,2019-11,CyCleGAN (Light-weight Calibrator),97.5,100.0,1.7,0.02,97.5,0.98,ito:ITO_00115,Fundamental AI process,Accuracy
137,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2017-04,Res-TCN,20.3,52.59,20.3,0.53,38.6,0.2,ito:ITO_00115,Fundamental AI process,Accuracy
138,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2018-01,ST-GCN,30.7,79.53,10.4,0.27,38.6,0.31,ito:ITO_00115,Fundamental AI process,Accuracy
139,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2018-05,2s-AGCN,36.1,93.52,5.4,0.14,38.6,0.36,ito:ITO_00115,Fundamental AI process,Accuracy
140,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2018-11,SLnL-rFA,36.6,94.82,0.5,0.01,38.6,0.37,ito:ITO_00115,Fundamental AI process,Accuracy
141,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-06,DGNN,36.9,95.6,0.3,0.01,38.6,0.37,ito:ITO_00115,Fundamental AI process,Accuracy
142,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-11,GCN-NAS,37.1,96.11,0.2,0.01,38.6,0.37,ito:ITO_00115,Fundamental AI process,Accuracy
143,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-12,JB-AAGCN,37.4,96.89,0.3,0.01,38.6,0.37,ito:ITO_00115,Fundamental AI process,Accuracy
144,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-12,MS-AAGCN,37.8,97.93,0.4,0.01,38.6,0.38,ito:ITO_00115,Fundamental AI process,Accuracy
145,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2020-03,2s-AGCN+TEM,38.6,100.0,0.8,0.02,38.6,0.39,ito:ITO_00115,Fundamental AI process,Accuracy
146,1,Domain Adaptation,USPS-to-MNIST,2017-05,CDAN,98.0,99.69,98.0,1.0,98.3,0.98,ito:ITO_00115,Fundamental AI process,Accuracy
147,1,Domain Adaptation,USPS-to-MNIST,2019-09,3CATN,98.3,100.0,0.3,0.0,98.3,0.98,ito:ITO_00115,Fundamental AI process,Accuracy
148,1,Semantic Segmentation,S3DIS,2017-06,PointNet++,91.9,100.0,91.9,1.0,91.9,0.92,ito:ITO_00115,Fundamental AI process,Accuracy
149,1,Few-Shot Image Classification,CUB 200 5-way 1-shot,2017-11,Relation Net,50.44,57.09,50.44,0.57,88.35,0.5,ito:ITO_00115,Fundamental AI process,Accuracy
150,1,Few-Shot Image Classification,CUB 200 5-way 1-shot,2018-06,Delta-encoder,69.8,79.0,19.4,0.22,88.35,0.7,ito:ITO_00115,Fundamental AI process,Accuracy
151,1,Few-Shot Image Classification,CUB 200 5-way 1-shot,2019-05,Self-Critique and Adapt + High-End MAML++,70.46,79.75,0.7,0.01,88.35,0.7,ito:ITO_00115,Fundamental AI process,Accuracy
152,1,Few-Shot Image Classification,CUB 200 5-way 1-shot,2019-07,S2M2R,80.68,91.32,10.2,0.12,88.35,0.81,ito:ITO_00115,Fundamental AI process,Accuracy
153,1,Few-Shot Image Classification,CUB 200 5-way 1-shot,2020-01,Transfer+SGC,88.35,100.0,7.7,0.09,88.35,0.88,ito:ITO_00115,Fundamental AI process,Accuracy
154,1,Few-Shot Image Classification,CUB 200 5-way 5-shot,2017-11,Relation Net,65.32,70.89,65.32,0.71,92.14,0.65,ito:ITO_00115,Fundamental AI process,Accuracy
155,1,Few-Shot Image Classification,CUB 200 5-way 5-shot,2018-12,feat (ProtoNet),83.03,90.11,17.7,0.19,92.14,0.83,ito:ITO_00115,Fundamental AI process,Accuracy
156,1,Few-Shot Image Classification,CUB 200 5-way 5-shot,2019-05,High-End MAML++,83.8,90.95,0.8,0.01,92.14,0.84,ito:ITO_00115,Fundamental AI process,Accuracy
157,1,Few-Shot Image Classification,CUB 200 5-way 5-shot,2019-05,Self-Critique and Adapt + High-End MAML++,85.63,92.93,1.8,0.02,92.14,0.86,ito:ITO_00115,Fundamental AI process,Accuracy
158,1,Few-Shot Image Classification,CUB 200 5-way 5-shot,2019-07,S2M2R,90.85,98.6,5.2,0.06,92.14,0.91,ito:ITO_00115,Fundamental AI process,Accuracy
159,1,Few-Shot Image Classification,CUB 200 5-way 5-shot,2020-01,Transfer+SGC,92.14,100.0,1.3,0.01,92.14,0.92,ito:ITO_00115,Fundamental AI process,Accuracy
160,1,Action Recognition,IRD,2018-01,ST-GCN,74.03,92.41,74.03,0.92,80.11,0.74,ito:ITO_00115,Fundamental AI process,Accuracy
161,1,Action Recognition,IRD,2019-01,OHA-GCN (Two stream; HP + OHP-hands + informative samples),80.11,100.0,6.1,0.08,80.11,0.8,ito:ITO_00115,Fundamental AI process,Accuracy
162,1,Action Recognition,ICVL-4,2018-01,ST-GCN,80.23,87.34,80.23,0.87,91.86,0.8,ito:ITO_00115,Fundamental AI process,Accuracy
163,1,Action Recognition,ICVL-4,2019-01,OHA-GCN (Two stream; HP + OHP-hands + informative samples),91.86,100.0,11.6,0.13,91.86,0.92,ito:ITO_00115,Fundamental AI process,Accuracy
164,1,Action Recognition In Videos,ICVL-4,2018-01,ST-GCN,80.23,87.34,80.23,0.87,91.86,0.8,ito:ITO_00115,Fundamental AI process,Accuracy
165,1,Action Recognition In Videos,ICVL-4,2019-01,OHA-GCN (Two stream; HP + OHP-hands + informative samples),91.86,100.0,11.6,0.13,91.86,0.92,ito:ITO_00115,Fundamental AI process,Accuracy
166,1,Action Recognition In Videos,IRD,2018-01,ST-GCN,74.03,92.41,74.03,0.92,80.11,0.74,ito:ITO_00115,Fundamental AI process,Accuracy
167,1,Action Recognition In Videos,IRD,2019-01,OHA-GCN (Two stream; HP + OHP-hands + informative samples),80.11,100.0,6.1,0.08,80.11,0.8,ito:ITO_00115,Fundamental AI process,Accuracy
168,1,Skeleton Based Action Recognition,N-UCLA,2018-02,Glimpse Clouds,87.6,94.7,87.6,0.95,92.5,0.88,ito:ITO_00115,Fundamental AI process,Accuracy
169,1,Skeleton Based Action Recognition,N-UCLA,2018-04,VA-fusion (aug.),88.1,95.24,0.5,0.01,92.5,0.88,ito:ITO_00115,Fundamental AI process,Accuracy
170,1,Skeleton Based Action Recognition,N-UCLA,2018-12,Action Machine,92.3,99.78,4.2,0.05,92.5,0.92,ito:ITO_00115,Fundamental AI process,Accuracy
171,1,Skeleton Based Action Recognition,N-UCLA,2019-04,SGN,92.5,100.0,0.2,0.0,92.5,0.93,ito:ITO_00115,Fundamental AI process,Accuracy
172,1,Click-Through Rate Prediction,Book-Crossing,2018-03,RippleNet,0.662,100.0,0.662,1.0,0.662,0.01,ito:ITO_00115,Fundamental AI process,Accuracy
173,1,Unsupervised Domain Expansion,Unsupervised Domain Expansion,2018-03,RippleNet,0.662,100.0,0.662,1.0,0.662,0.01,ito:ITO_00115,Fundamental AI process,Accuracy
174,1,Click-Through Rate Prediction,MovieLens 1M,2018-03,RippleNet,84.4,100.0,84.4,1.0,84.4,0.84,ito:ITO_00115,Fundamental AI process,Accuracy
175,1,Weakly-Supervised Action Recognition,Weakly-Supervised Action Recognition,2018-03,RippleNet,84.4,100.0,84.4,1.0,84.4,0.84,ito:ITO_00115,Fundamental AI process,Accuracy
176,1,Few-Shot Image Classification,Mini-ImageNet,2018-06,PLATIPUS,50.13,64.02,50.13,0.64,78.3,0.5,ito:ITO_00115,Fundamental AI process,Accuracy
177,1,Few-Shot Image Classification,Mini-ImageNet,2019-03,DivCoop,63.73,81.39,13.6,0.17,78.3,0.64,ito:ITO_00115,Fundamental AI process,Accuracy
178,1,Few-Shot Image Classification,Mini-ImageNet,2019-06,Multiple-semantics,67.2,85.82,3.5,0.04,78.3,0.67,ito:ITO_00115,Fundamental AI process,Accuracy
179,1,Few-Shot Image Classification,Mini-ImageNet,2019-11,AmdimNet,76.82,98.11,9.6,0.12,78.3,0.77,ito:ITO_00115,Fundamental AI process,Accuracy
180,1,Few-Shot Image Classification,Mini-ImageNet,2020-02,DFMN+MCT,78.3,100.0,1.5,0.02,78.3,0.78,ito:ITO_00115,Fundamental AI process,Accuracy
181,1,Neural Architecture Search,ImageNet,2018-06,DARTS,73.3,94.34,73.3,0.94,77.7,0.73,ito:ITO_00115,Fundamental AI process,Accuracy
182,1,Neural Architecture Search,ImageNet,2018-12,ProxylesNAS,75.1,96.65,1.8,0.02,77.7,0.75,ito:ITO_00115,Fundamental AI process,Accuracy
183,1,Neural Architecture Search,ImageNet,2019-03,OneShot-S+,75.75,97.49,0.7,0.01,77.7,0.76,ito:ITO_00115,Fundamental AI process,Accuracy
184,1,Neural Architecture Search,ImageNet,2019-07,PC-DARTS (ImageNet),75.8,97.55,0.0,0.0,77.7,0.76,ito:ITO_00115,Fundamental AI process,Accuracy
185,1,Neural Architecture Search,ImageNet,2019-08,SCARLET-B,76.3,98.2,0.5,0.01,77.7,0.76,ito:ITO_00115,Fundamental AI process,Accuracy
186,1,Neural Architecture Search,ImageNet,2019-08,SCARLET-A,76.9,98.97,0.6,0.01,77.7,0.77,ito:ITO_00115,Fundamental AI process,Accuracy
187,1,Neural Architecture Search,ImageNet,2020-03,GreedyNAS-A,77.1,99.23,0.2,0.0,77.7,0.77,ito:ITO_00115,Fundamental AI process,Accuracy
188,1,Neural Architecture Search,ImageNet,2020-04,AutoNL-L,77.7,100.0,0.6,0.01,77.7,0.78,ito:ITO_00115,Fundamental AI process,Accuracy
189,1,Unsupervised Semantic Segmentation,Potsdam-3,2018-07,IIC,45.4,100.0,45.4,1.0,45.4,0.45,ito:ITO_00115,Fundamental AI process,Accuracy
190,1,Unsupervised Semantic Segmentation,COCO-Stuff-3,2018-07,IIC,72.3,100.0,72.3,1.0,72.3,0.72,ito:ITO_00115,Fundamental AI process,Accuracy
191,1,Unsupervised Semantic Segmentation,Potsdam,2018-07,IIC,65.1,100.0,65.1,1.0,65.1,0.65,ito:ITO_00115,Fundamental AI process,Accuracy
192,1,Unsupervised Semantic Segmentation,COCO-Stuff-15,2018-07,IIC,27.7,100.0,27.7,1.0,27.7,0.28,ito:ITO_00115,Fundamental AI process,Accuracy
193,1,Steering Control,BDD100k,2018-11,FM-Net,85.03,100.0,85.03,1.0,85.03,0.85,ito:ITO_00115,Fundamental AI process,Accuracy
194,1,Steering Control,BDD100K,2018-11,FM-Net,85.03,100.0,85.03,1.0,85.03,0.85,ito:ITO_00115,Fundamental AI process,Accuracy
195,1,Domain Adaptation,Office-Home,2018-11,IAFN (ResNet-50),71.83,98.67,71.83,0.99,72.8,0.72,ito:ITO_00115,Fundamental AI process,Accuracy
196,1,Domain Adaptation,Office-Home,2019-04,MDAIR,72.8,100.0,1.0,0.01,72.8,0.73,ito:ITO_00115,Fundamental AI process,Accuracy
197,1,Action Recognition,Diving-48,2018-12,SlowFast,77.6,100.0,77.6,1.0,77.6,0.78,ito:ITO_00115,Fundamental AI process,Accuracy
198,1,Action Recognition In Videos,UTD-MHAD,2018-12,Action Machine (RGB only),92.5,100.0,92.5,1.0,92.5,0.93,ito:ITO_00115,Fundamental AI process,Accuracy
199,1,Action Recognition,UTD-MHAD,2018-12,Action Machine (RGB only),92.5,100.0,92.5,1.0,92.5,0.93,ito:ITO_00115,Fundamental AI process,Accuracy
200,1,Representation Learning,Circle Data,2019-01,Morphological Network,97.3,100.0,97.3,1.0,97.3,0.97,ito:ITO_00115,Fundamental AI process,Accuracy
201,1,Click-Through Rate Prediction,Children's Book Test Common noun,2019-01,MKR,70.4,100.0,70.4,1.0,70.4,0.7,ito:ITO_00115,Fundamental AI process,Accuracy
202,1,Generalized Zero Shot skeletal action recognition,Generalized Zero Shot skeletal action recognition,2019-01,MKR,70.4,100.0,70.4,1.0,70.4,0.7,ito:ITO_00115,Fundamental AI process,Accuracy
203,1,Feature Selection,MNIST,2019-01,CAE,90.6,100.0,90.6,1.0,90.6,0.91,ito:ITO_00115,Fundamental AI process,Accuracy
204,1,Feature Selection,Coil-20,2019-01,CAE,58.6,100.0,58.6,1.0,58.6,0.59,ito:ITO_00115,Fundamental AI process,Accuracy
205,1,Feature Selection,Fashion-MNIST,2019-01,CAE,67.7,100.0,67.7,1.0,67.7,0.68,ito:ITO_00115,Fundamental AI process,Accuracy
206,1,Feature Selection,Activity,2019-01,CAE,42.0,100.0,42,1.0,42,0.42,ito:ITO_00115,Fundamental AI process,Accuracy
207,1,Feature Selection,Mice Protein,2019-01,CAE,13.4,100.0,13.4,1.0,13.4,0.13,ito:ITO_00115,Fundamental AI process,Accuracy
208,1,Feature Selection,ISOLET,2019-01,CAE,68.5,100.0,68.5,1.0,68.5,0.69,ito:ITO_00115,Fundamental AI process,Accuracy
209,1,Few-Shot Image Classification,OMNIGLOT,2019-02,APL,68.9,100.0,68.9,1.0,68.9,0.69,ito:ITO_00115,Fundamental AI process,Accuracy
210,1,Few-Shot Image Classification,OMNIGLOT,2019-02,APL,73.5,100.0,73.5,1.0,73.5,0.74,ito:ITO_00115,Fundamental AI process,Accuracy
211,1,Few-Shot Image Classification,OMNIGLOT,2019-02,APL,78.9,100.0,78.9,1.0,78.9,0.79,ito:ITO_00115,Fundamental AI process,Accuracy
212,1,Few-Shot Image Classification,OMNIGLOT,2019-02,APL,88.0,100.0,88,1.0,88,0.88,ito:ITO_00115,Fundamental AI process,Accuracy
213,1,Transfer Learning,ImageCLEF-DA,2019-04,EasyTL,88.2,100.0,88.2,1.0,88.2,0.88,ito:ITO_00115,Fundamental AI process,Accuracy
214,1,Transfer Learning,Amazon Review Polarity,2019-04,EasyTL,79.5,100.0,79.5,1.0,79.5,0.8,ito:ITO_00115,Fundamental AI process,Accuracy
215,1,Action Recognition In Videos,miniSports,2019-04,IF+MD+RGB-R (ResNet-18),74.9,100.0,74.9,1.0,74.9,0.75,ito:ITO_00115,Fundamental AI process,Accuracy
216,1,Action Recognition,miniSports,2019-04,IF+MD+RGB-R (ResNet-18),74.9,100.0,74.9,1.0,74.9,0.75,ito:ITO_00115,Fundamental AI process,Accuracy
217,1,Few-Shot Image Classification,AWA1,2019-04,TAFE-Net,70.8,100.0,70.8,1.0,70.8,0.71,ito:ITO_00115,Fundamental AI process,Accuracy
218,1,Few-Shot Image Classification,aPY,2019-04,TAFE-Net,42.2,100.0,42.2,1.0,42.2,0.42,ito:ITO_00115,Fundamental AI process,Accuracy
219,1,Few-Shot Image Classification,AWA2,2019-04,TAFE-Net,69.3,100.0,69.3,1.0,69.3,0.69,ito:ITO_00115,Fundamental AI process,Accuracy
220,1,Network Pruning,CIFAR-100,2019-05,TAS-pruned ResNet-110,73.16,99.51,73.16,1.0,73.52,0.73,ito:ITO_00115,Fundamental AI process,Accuracy
221,1,Network Pruning,CIFAR-100,2020-01,PreResNet-101,73.52,100.0,0.4,0.01,73.52,0.74,ito:ITO_00115,Fundamental AI process,Accuracy
222,1,Network Pruning,CIFAR-10,2019-05,TAS-pruned ResNet-110,94.33,100.0,94.33,1.0,94.33,0.94,ito:ITO_00115,Fundamental AI process,Accuracy
223,1,Network Pruning,ImageNet,2019-05,TAS-pruned ResNet-50,76.2,97.69,76.2,0.98,78.0,0.76,ito:ITO_00115,Fundamental AI process,Accuracy
224,1,Network Pruning,ImageNet,2020-01,ResNet50-3G FLOPs,77.1,98.85,0.9,0.01,78.0,0.77,ito:ITO_00115,Fundamental AI process,Accuracy
225,1,Network Pruning,ImageNet,2020-02,ResNet50 2.5 GFLOPS,78.0,100.0,0.9,0.01,78.0,0.78,ito:ITO_00115,Fundamental AI process,Accuracy
226,1,Skeleton Based Action Recognition,MSR Action3D,2019-06,HDM-BG,86.1,100.0,86.1,1.0,86.1,0.86,ito:ITO_00115,Fundamental AI process,Accuracy
227,1,Skeleton Based Action Recognition,UPenn Action,2019-06,HDM-BG,93.4,94.06,93.4,0.94,99.3,0.93,ito:ITO_00115,Fundamental AI process,Accuracy
228,1,Skeleton Based Action Recognition,UPenn Action,2020-01,UniPose-LSTM,99.3,100.0,5.9,0.06,99.3,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
229,1,QRS Complex Detection,QT,2019-07,"CNN (LOSO, Intra-Db)",97.42,100.0,97.42,1.0,97.42,0.97,ito:ITO_00115,Fundamental AI process,Accuracy
230,1,QRS Complex Detection,MIT-BIH AR,2019-07,"CNN (LOSO, Intra-Db)",99.6,100.0,99.6,1.0,99.6,1.0,ito:ITO_00115,Fundamental AI process,Accuracy
231,1,QRS Complex Detection,INCART,2019-07,"CNN (LOSO, Intra-Db)",97.85,100.0,97.85,1.0,97.85,0.98,ito:ITO_00115,Fundamental AI process,Accuracy
232,1,Congestive Heart Failure detection,CHF database,2019-07,Inclined Entropy (R-HessELM),98.49,100.0,98.49,1.0,98.49,0.99,ito:ITO_00115,Fundamental AI process,Accuracy
233,1,Stochastic Optimization,CIFAR-10 ResNet-18,2019-07,Lookahead,95.27,100.0,95.27,1.0,95.27,0.95,ito:ITO_00115,Fundamental AI process,Accuracy
234,1,Stochastic Optimization,CIFAR-100 ResNet-18,2019-07,Lookahead,78.34,100.0,78.34,1.0,78.34,0.78,ito:ITO_00115,Fundamental AI process,Accuracy
235,1,Few-Shot Image Classification,mini-ImageNet,2019-08,GCR,39.14,100.0,39.14,1.0,39.14,0.39,ito:ITO_00115,Fundamental AI process,Accuracy
236,1,Domain Generalization,PACS,2019-11,AlexNet,73.55,88.25,73.55,0.88,83.34,0.74,ito:ITO_00115,Fundamental AI process,Accuracy
237,1,Domain Generalization,PACS,2019-11,ResNet18,83.34,100.0,9.8,0.12,83.34,0.83,ito:ITO_00115,Fundamental AI process,Accuracy
238,1,Few-Shot Image Classification,Mini-ImageNet to CUB,2020-03,Neg-Margin,69.3,100.0,69.3,1.0,69.3,0.69,ito:ITO_00115,Fundamental AI process,Accuracy
0,1,Action Recognition,UCF101,2012-12,Baseline UCF101,43.9,44.7,43.9,0.45,98.2,0.45,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
1,1,Action Recognition,UCF101,2014-06,Two-Stream (ImageNet pretrained),88.0,89.61,44.1,0.45,98.2,0.9,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
2,1,Action Recognition,UCF101,2015-03,Two-stream+LSTM,88.6,90.22,0.6,0.01,98.2,0.9,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
3,1,Action Recognition,UCF101,2015-05,TDD + IDT,91.5,93.18,2.9,0.03,98.2,0.93,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
4,1,Action Recognition,UCF101,2016-04,LTC,91.7,93.38,0.2,0.0,98.2,0.93,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
5,1,Action Recognition,UCF101,2016-04,"S:VGG-16, T:VGG-16 (ImageNet pretrain)",92.5,94.2,0.8,0.01,98.2,0.94,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
6,1,Action Recognition,UCF101,2016-08,Temporal Segment Networks,94.2,95.93,1.7,0.02,98.2,0.96,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
7,1,Action Recognition,UCF101,2017-04,Hidden Two-Stream,97.1,98.88,2.9,0.03,98.2,0.99,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
8,1,Action Recognition,UCF101,2017-05,Two-Stream I3D (Imagenet+Kinetics pre-training),98.0,99.8,0.9,0.01,98.2,1.0,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
9,1,Action Recognition,UCF101,2019-06,LGD-3D Two-stream,98.2,100.0,0.2,0.0,98.2,1.0,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
10,1,Action Recognition In Videos,UCF101,2012-12,Baseline UCF101,43.9,44.7,43.9,0.45,98.2,0.45,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
11,1,Action Recognition In Videos,UCF101,2014-05,iDT+HSV,87.9,89.51,44.0,0.45,98.2,0.9,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
12,1,Action Recognition In Videos,UCF101,2014-06,Two-stream,88.0,89.61,0.1,0.0,98.2,0.9,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
13,1,Action Recognition In Videos,UCF101,2015-03,Two-stream+LSTM,88.6,90.22,0.6,0.01,98.2,0.9,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
14,1,Action Recognition In Videos,UCF101,2015-07,Very deep two-stream ConvNet,91.4,93.08,2.8,0.03,98.2,0.93,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
15,1,Action Recognition In Videos,UCF101,2016-04,LTC,91.7,93.38,0.3,0.0,98.2,0.93,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
16,1,Action Recognition In Videos,UCF101,2016-04,"S:VGG-16, T:VGG-16",92.5,94.2,0.8,0.01,98.2,0.94,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
17,1,Action Recognition In Videos,UCF101,2017-03,TS-LSTM,94.1,95.82,1.6,0.02,98.2,0.96,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
18,1,Action Recognition In Videos,UCF101,2017-04,Hidden Two-Stream,97.1,98.88,3.0,0.03,98.2,0.99,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
19,1,Action Recognition In Videos,UCF101,2017-05,Two-stream I3D (on pre-trained),98.0,99.8,0.9,0.01,98.2,1.0,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
20,1,Action Recognition In Videos,UCF101,2019-06,LGD-3D Two-stream,98.2,100.0,0.2,0.0,98.2,1.0,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
21,1,Self-Supervised Action Recognition,UCF101,2016-09,VideoGan (C3D),52.1,88.61,52.1,0.89,58.8,0.53,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
22,1,Self-Supervised Action Recognition,UCF101,2019-04,Motion & Appearance (C3D),58.8,100.0,6.7,0.11,58.8,0.6,ito:ITO_00115,Fundamental AI process,3\\-fold\\ Accuracy
0,1,Few-Shot Image Classification,CUB-200-2011,2013-06,ALE,18.0,31.69,18.0,0.32,56.8,0.19,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
1,1,Few-Shot Image Classification,CUB-200-2011,2014-09,SJE,50.1,88.2,32.1,0.57,56.8,0.53,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
2,1,Few-Shot Image Classification,CUB-200-2011,2016-03,Synthesised Classifier,54.7,96.3,4.6,0.08,56.8,0.58,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
3,1,Few-Shot Image Classification,CUB-200-2011,2016-05,Word CNN-RNN (DS-SJE Embedding),56.8,100.0,2.1,0.04,56.8,0.6,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
4,1,Action Recognition In Videos,Something-Something V2,2017-06,model3D_1 with left-right augmentation and fps jitter,51.33,77.07,51.33,0.77,66.6,0.54,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
5,1,Action Recognition In Videos,Something-Something V2,2017-11,2-Stream TRN,55.52,83.36,4.2,0.06,66.6,0.59,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
6,1,Action Recognition In Videos,Something-Something V2,2018-11,TSM (RGB + Flow),66.6,100.0,11.1,0.17,66.6,0.71,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
7,1,Action Recognition,Something-Something V2,2017-06,model3D_1 with left-right augmentation and fps jitter,51.33,77.07,51.33,0.77,66.6,0.54,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
8,1,Action Recognition,Something-Something V2,2017-11,2-Stream TRN,55.52,83.36,4.2,0.06,66.6,0.59,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
9,1,Action Recognition,Something-Something V2,2018-11,TSM (RGB + Flow),66.6,100.0,11.1,0.17,66.6,0.71,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
10,1,Action Recognition,Something-Something V1,2017-12,S3D,47.3,100.0,47.3,1.0,47.3,0.5,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
11,1,Self-Supervised Action Recognition,HMDB51,2019-04,Motion & Appearance (C3D),20.3,100.0,20.3,1.0,20.3,0.22,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
12,1,Sparse Learning,ImageNet,2019-11,Resnet-50: 80% Sparse,77.1,100.0,77.1,1.0,77.1,0.82,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
13,1,Chinese Spelling Error Correction,Chinese Spelling Error Correction,2019-11,Resnet-50: 80% Sparse,77.1,100.0,77.1,1.0,77.1,0.82,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
14,1,Action Recognition In Videos,EPIC-Kitchens,2020-04,TSM+W3,34.2,100.0,34.2,1.0,34.2,0.36,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
15,1,Action Recognition In Videos,EgoGesture,2020-04,TSM+W3,94.3,100.0,94.3,1.0,94.3,1.0,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
16,1,Action Recognition,EPIC-KITCHENS-55,2020-04,TSM+W3,34.2,100.0,34.2,1.0,34.2,0.36,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
17,1,Action Recognition,EgoGesture,2020-04,TSM+W3,94.3,100.0,94.3,1.0,94.3,1.0,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Accuracy
0,1,Latent Variable Models,200k Short Texts for Humor Detection,2014-01,meto,0.987,100.0,0.987,1.0,0.987,1.0,ito:ITO_00115,Fundamental AI process,10\\-20%\\ Mask\\ PSNR
1,1,Grasp Contact Prediction,Grasp Contact Prediction,2014-01,meto,0.987,100.0,0.987,1.0,0.987,1.0,ito:ITO_00115,Fundamental AI process,10\\-20%\\ Mask\\ PSNR
0,1,Action Recognition In Videos,HMDB-51,2014-06,Two-stream,59.4,72.02,59.4,0.72,82.48,0.72,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
1,1,Action Recognition In Videos,HMDB-51,2016-04,LTC,64.8,78.56,5.4,0.07,82.48,0.79,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
2,1,Action Recognition In Videos,HMDB-51,2016-04,"S:VGG-16, T:VGG-16",65.4,79.29,0.6,0.01,82.48,0.79,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
3,1,Action Recognition In Videos,HMDB-51,2016-05,Sub-events,68.4,82.93,3.0,0.04,82.48,0.83,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
4,1,Action Recognition In Videos,HMDB-51,2017-03,TS-LSTM,69.0,83.66,0.6,0.01,82.48,0.84,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
5,1,Action Recognition In Videos,HMDB-51,2017-04,Hidden Two-Stream,78.7,95.42,9.7,0.12,82.48,0.95,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
6,1,Action Recognition In Videos,HMDB-51,2017-05,Two-stream I3D,80.9,98.08,2.2,0.03,82.48,0.98,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
7,1,Action Recognition In Videos,HMDB-51,2018-10,RepFlow-50,81.1,98.33,0.2,0.0,82.48,0.98,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
8,1,Action Recognition In Videos,HMDB-51,2018-11,EvaNet,82.1,99.54,1.0,0.01,82.48,1.0,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
9,1,Action Recognition In Videos,HMDB-51,2019-06,HAF+BoW/FV halluc,82.48,100.0,0.4,0.0,82.48,1.0,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
10,1,Action Recognition,HMDB-51,2014-06,Two-Stream (ImageNet pretrained),59.4,72.02,59.4,0.72,82.48,0.72,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
11,1,Action Recognition,HMDB-51,2015-05,TDD + IDT,65.9,79.9,6.5,0.08,82.48,0.8,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
12,1,Action Recognition,HMDB-51,2016-08,Temporal Segment Networks,69.4,84.14,3.5,0.04,82.48,0.84,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
13,1,Action Recognition,HMDB-51,2017-04,Hidden Two-Stream,78.7,95.42,9.3,0.11,82.48,0.95,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
14,1,Action Recognition,HMDB-51,2017-05,Two-Stream I3D (Imagenet+Kinetics pre-training),80.7,97.84,2.0,0.02,82.48,0.98,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
15,1,Action Recognition,HMDB-51,2017-05,Two-stream I3D,80.9,98.08,0.2,0.0,82.48,0.98,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
16,1,Action Recognition,HMDB-51,2018-10,"RepFlow-50 ([2+1]D CNN, FcF, Non-local block)",81.1,98.33,0.2,0.0,82.48,0.98,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
17,1,Action Recognition,HMDB-51,2019-06,HAF+BoW/FV halluc,82.48,100.0,1.4,0.02,82.48,1.0,ito:ITO_00115,Fundamental AI process,Average\\ accuracy\\ of\\ 3\\ splits
0,1,Action Recognition In Videos,Sports-1M,2014-06,DeepVideo’s Slow Fusion,60.9,80.66,60.9,0.81,75.5,0.75,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-1
1,1,Action Recognition In Videos,Sports-1M,2015-03,Conv pooling,71.7,94.97,10.8,0.14,75.5,0.88,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-1
2,1,Action Recognition In Videos,Sports-1M,2017-11,R(2+1)D-Two-Stream-32frame,73.3,97.09,1.6,0.02,75.5,0.9,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-1
3,1,Action Recognition In Videos,Sports-1M,2019-04,ir-CSN-152,75.5,100.0,2.2,0.03,75.5,0.93,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-1
4,1,Action Recognition,Sports-1M,2014-06,DeepVideo’s Slow Fusion,60.9,80.66,60.9,0.81,75.5,0.75,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-1
5,1,Action Recognition,Sports-1M,2014-12,C3D,61.1,80.93,0.2,0.0,75.5,0.75,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-1
6,1,Action Recognition,Sports-1M,2015-03,Conv pooling,71.7,94.97,10.6,0.14,75.5,0.88,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-1
7,1,Action Recognition,Sports-1M,2017-11,R[2+1]D-Two-Stream-32frame,73.3,97.09,1.6,0.02,75.5,0.9,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-1
8,1,Action Recognition,Sports-1M,2019-04,ip-CSN-101 (RGB),74.9,99.21,1.6,0.02,75.5,0.92,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-1
9,1,Action Recognition,Sports-1M,2019-04,ip-CSN-152 (RGB),75.5,100.0,0.6,0.01,75.5,0.93,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-1
10,1,Action Recognition In Videos,Kinetics-400,2017-08,Inception-ResNet,73.0,89.79,73.0,0.9,81.3,0.9,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-1
11,1,Action Recognition In Videos,Kinetics-400,2018-12,SlowFast+NL,79.8,98.15,6.8,0.08,81.3,0.98,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-1
12,1,Action Recognition In Videos,Kinetics-400,2019-05,R(2+1)D-152*,81.3,100.0,1.5,0.02,81.3,1.0,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-1
13,1,Action Recognition In Videos,miniSports,2019-05,G-Blend,62.8,100.0,62.8,1.0,62.8,0.77,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-1
14,1,Action Recognition,miniSports,2019-05,G-Blend,62.8,100.0,62.8,1.0,62.8,0.77,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-1
0,1,Action Recognition In Videos,Sports-1M,2014-06,DeepVideo’s Slow Fusion,80.2,86.52,80.2,0.87,92.7,0.84,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
1,1,Action Recognition In Videos,Sports-1M,2014-12,C3D,84.4,91.05,4.2,0.05,92.7,0.89,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
2,1,Action Recognition In Videos,Sports-1M,2015-03,Conv pooling,90.4,97.52,6.0,0.06,92.7,0.95,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
3,1,Action Recognition In Videos,Sports-1M,2017-11,R(2+1)D-RGB-32frame ,91.5,98.71,1.1,0.01,92.7,0.96,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
4,1,Action Recognition In Videos,Sports-1M,2017-11,R(2+1)D-Two-Stream-32frame,91.9,99.14,0.4,0.0,92.7,0.97,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
5,1,Action Recognition In Videos,Sports-1M,2019-04,ir-CSN-152,92.7,100.0,0.8,0.01,92.7,0.97,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
6,1,Action Recognition,Sports-1M,2014-06,DeepVideo’s Slow Fusion,80.2,86.42,80.2,0.86,92.8,0.84,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
7,1,Action Recognition,Sports-1M,2014-12,C3D,85.5,92.13,5.3,0.06,92.8,0.9,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
8,1,Action Recognition,Sports-1M,2015-03,Conv pooling,90.4,97.41,4.9,0.05,92.8,0.95,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
9,1,Action Recognition,Sports-1M,2017-11,R[2+1]D-Two-Stream-32frame,91.9,99.03,1.5,0.02,92.8,0.97,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
10,1,Action Recognition,Sports-1M,2019-04,ip-CSN-101 (RGB),92.6,99.78,0.7,0.01,92.8,0.97,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
11,1,Action Recognition,Sports-1M,2019-04,ip-CSN-152 (RGB),92.8,100.0,0.2,0.0,92.8,0.98,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
12,1,Action Recognition In Videos,Kinetics-400,2017-08,Inception-ResNet,90.9,95.58,90.9,0.96,95.1,0.96,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
13,1,Action Recognition In Videos,Kinetics-400,2018-12,SlowFast+NL,93.9,98.74,3.0,0.03,95.1,0.99,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
14,1,Action Recognition In Videos,Kinetics-400,2019-05,R(2+1)D-152*,95.1,100.0,1.2,0.01,95.1,1.0,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
15,1,Action Recognition In Videos,miniSports,2019-05,G-Blend,85.5,100.0,85.5,1.0,85.5,0.9,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
16,1,Action Recognition,miniSports,2019-05,G-Blend,85.5,100.0,85.5,1.0,85.5,0.9,ito:ITO_00115,Fundamental AI process,Video\\ hit\\-at\\-5
0,1,Action Recognition In Videos,Sports-1M,2014-06,DeepVideo’s Slow Fusion,41.9,73.51,41.9,0.74,57.0,0.74,ito:ITO_00115,Fundamental AI process,Clip\\ Hit\\-at\\-1
1,1,Action Recognition In Videos,Sports-1M,2014-12,C3D,44.9,78.77,3.0,0.05,57.0,0.79,ito:ITO_00115,Fundamental AI process,Clip\\ Hit\\-at\\-1
2,1,Action Recognition In Videos,Sports-1M,2017-11,P3D,47.9,84.04,3.0,0.05,57.0,0.84,ito:ITO_00115,Fundamental AI process,Clip\\ Hit\\-at\\-1
3,1,Action Recognition In Videos,Sports-1M,2017-11,R(2+1)D-RGB-32frame ,57.0,100.0,9.1,0.16,57.0,1.0,ito:ITO_00115,Fundamental AI process,Clip\\ Hit\\-at\\-1
4,1,Action Recognition,Sports-1M,2014-06,DeepVideo’s Slow Fusion,41.9,73.51,41.9,0.74,57.0,0.74,ito:ITO_00115,Fundamental AI process,Clip\\ Hit\\-at\\-1
5,1,Action Recognition,Sports-1M,2014-12,C3D,46.1,80.88,4.2,0.07,57.0,0.81,ito:ITO_00115,Fundamental AI process,Clip\\ Hit\\-at\\-1
6,1,Action Recognition,Sports-1M,2017-11,P3D,47.9,84.04,1.8,0.03,57.0,0.84,ito:ITO_00115,Fundamental AI process,Clip\\ Hit\\-at\\-1
7,1,Action Recognition,Sports-1M,2017-11,R[2+1]D-RGB-32frame,57.0,100.0,9.1,0.16,57.0,1.0,ito:ITO_00115,Fundamental AI process,Clip\\ Hit\\-at\\-1
8,1,Action Recognition In Videos,miniSports,2019-05,G-Blend,49.7,100.0,49.7,1.0,49.7,0.87,ito:ITO_00115,Fundamental AI process,Clip\\ Hit\\-at\\-1
9,1,Action Recognition,miniSports,2019-05,G-Blend,49.7,100.0,49.7,1.0,49.7,0.87,ito:ITO_00115,Fundamental AI process,Clip\\ Hit\\-at\\-1
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,60.0,78.95,60,0.79,76,0.79,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(CS\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-04,Res-TCN,63.0,82.89,3,0.04,76,0.83,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(CS\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2018-01,ST-GCN,71.0,93.42,8,0.11,76,0.93,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(CS\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,76.0,100.0,5,0.07,76,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(CS\\)
0,1,Action Recognition In Videos,VIRAT Ground 2.0,2014-06,DHCM,66.45,100.0,66.45,1.0,66.45,0.67,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
1,1,Action Recognition,VIRAT Ground 2.0,2014-06,DHCM,66.45,100.0,66.45,1.0,66.45,0.67,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
2,1,Domain Adaptation,Office-Caltech,2014-12,DDC[[Tzeng et al.2014]],88.2,94.84,88.2,0.95,93.0,0.89,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
3,1,Domain Adaptation,Office-Caltech,2015-02,DAN[[Long et al.2015]],90.1,96.88,1.9,0.02,93.0,0.91,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
4,1,Domain Adaptation,Office-Caltech,2018-07,MEDA[[Wang et al.2018]],92.8,99.78,2.7,0.03,93.0,0.94,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
5,1,Domain Adaptation,Office-Caltech,2019-11,SPL,93.0,100.0,0.2,0.0,93.0,0.94,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
6,1,Domain Adaptation,Office-31,2015-12,ResNet-50,76.1,84.0,76.1,0.84,90.6,0.77,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
7,1,Domain Adaptation,Office-31,2017-04,GTA,86.5,95.47,10.4,0.11,90.6,0.87,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
8,1,Domain Adaptation,Office-31,2018-11,IAFN+ENT,87.1,96.14,0.6,0.01,90.6,0.88,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
9,1,Domain Adaptation,Office-31,2019-01,Contrastive Adaptation Network,90.6,100.0,3.5,0.04,90.6,0.91,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
10,1,Scene Segmentation,ScanNet,2016-12,PointNet++,60.2,80.27,60.2,0.8,75.0,0.61,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
11,1,Scene Segmentation,ScanNet,2018-03,3DMV,75.0,100.0,14.8,0.2,75.0,0.76,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
12,1,Outlier Detection,Balance scale_class 1,2018-01,ASVDD,99.03,100.0,99.03,1.0,99.03,1.0,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
13,1,Outlier Detection,Breast cancer Wisconsin_class 4,2018-01,ASVDD,65.6,100.0,65.6,1.0,65.6,0.66,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
14,1,Outlier Detection,Ionosphere_class b,2018-01,ASVDD,86.33,100.0,86.33,1.0,86.33,0.87,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
15,1,Outlier Detection,Glass identification,2018-01,ASVDD,99.05,100.0,99.05,1.0,99.05,1.0,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
16,1,Outlier Detection,Breast cancer Wisconsin_class 2,2018-01,ASVDD,37.62,100.0,37.62,1.0,37.62,0.38,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
17,1,Skeleton Based Action Recognition,UAV-Human,2018-01,ST-GCN,30.25,86.83,30.25,0.87,34.84,0.31,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
18,1,Skeleton Based Action Recognition,UAV-Human,2018-05,2S-AGCN,34.84,100.0,4.6,0.13,34.84,0.35,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
19,1,Multi-Task Learning,OMNIGLOT,2019-05,Mixture-of-Experts,92.19,98.58,92.19,0.99,93.52,0.93,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
20,1,Multi-Task Learning,OMNIGLOT,2019-10,Gumbel-Matrix Routing,93.52,100.0,1.3,0.01,93.52,0.94,ito:ITO_00115,Fundamental AI process,Average\\ Accuracy
0,1,Heartbeat Classification,MIT-BIH AR,2014-06,SVM Ensembles (II Leads),90.9,94.98,90.9,0.95,95.7,0.95,ito:ITO_00115,Fundamental AI process,PPV\\ \\(VEB\\)
1,1,Heartbeat Classification,MIT-BIH AR,2019-07,ESN Ensembles (II Leads),95.7,100.0,4.8,0.05,95.7,1.0,ito:ITO_00115,Fundamental AI process,PPV\\ \\(VEB\\)
0,1,Heartbeat Classification,MIT-BIH AR,2014-06,SVM Ensembles (II Leads),93.9,100.0,93.9,1.0,93.9,1.0,ito:ITO_00115,Fundamental AI process,Sensitivity\\ \\(VEB\\)
1,1,Unsupervised Pre-training,UCI measles,2018-05,RMDL (30 RDLs),90.69,100.0,90.69,1.0,90.69,0.97,ito:ITO_00115,Fundamental AI process,Sensitivity\\ \\(VEB\\)
0,1,Semantic Segmentation,PASCAL VOC 2012 test,2014-07,SDS,51.6,57.98,51.6,0.58,89.0,0.56,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
1,1,Semantic Segmentation,PASCAL VOC 2012 test,2014-11,FCN (VGG-16),62.2,69.89,10.6,0.12,89.0,0.68,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
2,1,Semantic Segmentation,PASCAL VOC 2012 test,2014-12,DeepLab-MSc-CRF-LargeFOV (VGG-16),71.6,80.45,9.4,0.11,89.0,0.78,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
3,1,Semantic Segmentation,PASCAL VOC 2012 test,2015-02,CRF-RNN,74.7,83.93,3.1,0.03,89.0,0.81,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
4,1,Semantic Segmentation,PASCAL VOC 2012 test,2016-03,CentraleSupelec Deep G-CRF,80.2,90.11,5.5,0.06,89.0,0.87,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
5,1,Semantic Segmentation,PASCAL VOC 2012 test,2016-11,Multipath-RefineNet,84.2,94.61,4.0,0.04,89.0,0.91,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
6,1,Semantic Segmentation,PASCAL VOC 2012 test,2016-11,ResNet-38 MS COCO,84.9,95.39,0.7,0.01,89.0,0.92,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
7,1,Semantic Segmentation,PASCAL VOC 2012 test,2016-12,PSPNet,85.4,95.96,0.5,0.01,89.0,0.93,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
8,1,Semantic Segmentation,PASCAL VOC 2012 test,2017-06,DeepLabv3-JFT,86.9,97.64,1.5,0.02,89.0,0.94,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
9,1,Semantic Segmentation,PASCAL VOC 2012 test,2018-02,DeepLabv3+ (Xception-65-JFT),89.0,100.0,2.1,0.02,89.0,0.97,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
10,1,Semantic Segmentation,SkyScapes-Lane,2014-11,FCN8s (ResNet-50),13.74,26.98,13.74,0.27,50.93,0.15,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
11,1,Semantic Segmentation,SkyScapes-Lane,2019-10,SkyScapesNet-Lane,50.93,100.0,37.2,0.73,50.93,0.55,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
12,1,Semantic Segmentation,SkyScapes-Dense,2014-11,FCN8s (ResNet-50),33.06,82.38,33.06,0.82,40.13,0.36,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
13,1,Semantic Segmentation,SkyScapes-Dense,2018-02,DeepLabv3+,38.2,95.19,5.1,0.13,40.13,0.41,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
14,1,Semantic Segmentation,SkyScapes-Dense,2019-10,SkyScapesNet-Dense,40.13,100.0,1.9,0.05,40.13,0.44,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
15,1,Semantic Segmentation,CamVid,2014-12,DeepLab-MSc-CRF-LargeFOV,61.6,75.4,61.6,0.75,81.7,0.67,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
16,1,Semantic Segmentation,CamVid,2015-11,Dilated Convolutions,65.3,79.93,3.7,0.05,81.7,0.71,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
17,1,Semantic Segmentation,CamVid,2016-11,FC-DenseNet103,66.9,81.88,1.6,0.02,81.7,0.73,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
18,1,Semantic Segmentation,CamVid,2016-12,PSPNet,69.1,84.58,2.2,0.03,81.7,0.75,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
19,1,Semantic Segmentation,CamVid,2018-12,DeepLabV3Plus + SDCNetAug,81.7,100.0,12.6,0.15,81.7,0.89,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
20,1,Scene Segmentation,SUN-RGBD,2014-12,DeepLab-LargeFOV,32.08,95.82,32.08,0.96,33.48,0.35,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
21,1,Scene Segmentation,SUN-RGBD,2019-08,Index Network,33.48,100.0,1.4,0.04,33.48,0.36,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
22,1,Semantic Segmentation,PASCAL VOC 2011,2016-11,DLDL-8s+CRF,67.6,100.0,67.6,1.0,67.6,0.73,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
23,1,Semantic Segmentation,PASCAL VOC 2012,2016-11,DLDL-8s+CRF,67.1,100.0,67.1,1.0,67.1,0.73,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
24,1,Semantic Segmentation,NYU Depth v2,2016-11,RefineNet (ResNet-101),40.6,91.44,40.6,0.91,44.4,0.44,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
25,1,Semantic Segmentation,NYU Depth v2,2019-08,Asymmetric ALNN,44.4,100.0,3.8,0.09,44.4,0.48,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
26,1,Semantic Segmentation,S3DIS,2016-12,PointNet,47.6,67.42,47.6,0.67,70.6,0.52,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
27,1,Semantic Segmentation,S3DIS,2017-11,SPG,62.1,87.96,14.5,0.21,70.6,0.67,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
28,1,Semantic Segmentation,S3DIS,2018-12,PointCNN,65.4,92.63,3.3,0.05,70.6,0.71,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
29,1,Semantic Segmentation,S3DIS,2019-04,ConvPoint,68.2,96.6,2.8,0.04,70.6,0.74,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
30,1,Semantic Segmentation,S3DIS,2019-04,KPConv,70.6,100.0,2.4,0.03,70.6,0.77,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
31,1,Semantic Segmentation,ShapeNet,2017-06,PointNet++,84.6,98.6,84.6,0.99,85.8,0.92,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
32,1,Semantic Segmentation,ShapeNet,2017-11,SGPN,85.8,100.0,1.2,0.01,85.8,0.93,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
33,1,Semantic Segmentation,PASCAL VOC 2007,2017-07,DeepLabv3 (ImageNet+300M),81.3,97.95,81.3,0.98,83.0,0.88,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
34,1,Semantic Segmentation,PASCAL VOC 2007,2019-09,GALDNet,83.0,100.0,1.7,0.02,83.0,0.9,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
35,1,Scene Segmentation,NYU Depth v2,2017-07,Dilated FCN-2s RGB,32.3,100.0,32.3,1.0,32.3,0.35,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
36,1,Semantic Segmentation,ScanNetV2,2018-08,SSMA,57.7,100.0,57.7,1.0,57.7,0.63,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
37,1,Semantic Segmentation,SYNTHIA-CVPR’16,2018-08,SSMA,92.1,100.0,92.1,1.0,92.1,1.0,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
38,1,Semantic Segmentation,SUN-RGBD,2018-08,SSMA,45.73,100.0,45.73,1.0,45.73,0.5,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
39,1,Semantic Segmentation,Freiburg Forest,2018-08,SSMA,84.18,100.0,84.18,1.0,84.18,0.91,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
40,1,Weakly-Supervised Semantic Segmentation,PASCAL VOC 2012 val,2019-04,IRNet (ResNet-50),63.5,100.0,63.5,1.0,63.5,0.69,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
41,1,Weakly-Supervised Semantic Segmentation,PASCAL VOC 2012 test,2019-04,IRNet (ResNet-50),64.8,100.0,64.8,1.0,64.8,0.7,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
42,1,Semantic Segmentation,S3DIS Area5,2019-04,KPConv,67.1,100.0,67.1,1.0,67.1,0.73,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
43,1,Few-Shot Semantic Segmentation,FSS-1000,2019-07,Adapted relation network,80.12,96.11,80.12,0.96,83.36,0.87,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
44,1,Few-Shot Semantic Segmentation,FSS-1000,2019-12,EfficientLab,82.78,99.3,2.7,0.03,83.36,0.9,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
45,1,Few-Shot Semantic Segmentation,FSS-1000,2020-03,DoG-BConvLSTM,83.36,100.0,0.6,0.01,83.36,0.91,ito:ITO_00115,Fundamental AI process,Mean\\ IoU
0,1,Dialog Generation,Persona-Chat,2014-09,Seq2Seq + Attention,16.18,81.84,16.18,0.82,19.77,0.82,ito:ITO_00115,Fundamental AI process,Avg\\ F1
1,1,Dialog Generation,Persona-Chat,2020-04,P^2 Bot,19.77,100.0,3.6,0.18,19.77,1.0,ito:ITO_00115,Fundamental AI process,Avg\\ F1
0,1,Arrhythmia Detection,The PhysioNet Computing in Cardiology Challenge 2017,2014-09,Feature-based approach (no segmentation),79.0,100.0,79,1.0,79,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(TEST\\-DB\\)
0,1,Arrhythmia Detection,The PhysioNet Computing in Cardiology Challenge 2017,2014-09,Feature-based approach (no segmentation),72.0,81.82,72.0,0.82,88.0,0.82,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(TRAIN\\-DB\\)
1,1,Arrhythmia Detection,The PhysioNet Computing in Cardiology Challenge 2017,2014-09,Feature-based approach (10 s segments),76.6,87.05,4.6,0.05,88.0,0.87,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(TRAIN\\-DB\\)
2,1,Arrhythmia Detection,The PhysioNet Computing in Cardiology Challenge 2017,2018-08,Towards Understanding ECG Rhyth,88.0,100.0,11.4,0.13,88.0,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(TRAIN\\-DB\\)
0,1,Semantic Segmentation,COCO-Stuff test,2014-11,FCN (VGG-16),22.7,56.05,22.7,0.56,40.5,0.25,ito:ITO_00115,Fundamental AI process,mIoU
1,1,Semantic Segmentation,COCO-Stuff test,2015-09,DAG-RNN (VGG-16),31.2,77.04,8.5,0.21,40.5,0.35,ito:ITO_00115,Fundamental AI process,mIoU
2,1,Semantic Segmentation,COCO-Stuff test,2016-11,RefineNet (ResNet-101),33.6,82.96,2.4,0.06,40.5,0.37,ito:ITO_00115,Fundamental AI process,mIoU
3,1,Semantic Segmentation,COCO-Stuff test,2018-06,CCL (ResNet-101),35.7,88.15,2.1,0.05,40.5,0.4,ito:ITO_00115,Fundamental AI process,mIoU
4,1,Semantic Segmentation,COCO-Stuff test,2018-09,DANet (ResNet-101),39.7,98.02,4.0,0.1,40.5,0.44,ito:ITO_00115,Fundamental AI process,mIoU
5,1,Semantic Segmentation,COCO-Stuff test,2019-09,OCR (HRNetV2-W48),40.5,100.0,0.8,0.02,40.5,0.45,ito:ITO_00115,Fundamental AI process,mIoU
6,1,Semantic Segmentation,PASCAL Context,2014-11,FCN-8s,37.8,64.18,37.8,0.64,58.9,0.42,ito:ITO_00115,Fundamental AI process,mIoU
7,1,Semantic Segmentation,PASCAL Context,2015-02,CRF-RNN,39.3,66.72,1.5,0.03,58.9,0.44,ito:ITO_00115,Fundamental AI process,mIoU
8,1,Semantic Segmentation,PASCAL Context,2015-03,BoxSup,40.5,68.76,1.2,0.02,58.9,0.45,ito:ITO_00115,Fundamental AI process,mIoU
9,1,Semantic Segmentation,PASCAL Context,2015-04,Piecewise,43.3,73.51,2.8,0.05,58.9,0.48,ito:ITO_00115,Fundamental AI process,mIoU
10,1,Semantic Segmentation,PASCAL Context,2016-05,VeryDeep,44.5,75.55,1.2,0.02,58.9,0.49,ito:ITO_00115,Fundamental AI process,mIoU
11,1,Semantic Segmentation,PASCAL Context,2016-06,DeepLabV2,45.7,77.59,1.2,0.02,58.9,0.51,ito:ITO_00115,Fundamental AI process,mIoU
12,1,Semantic Segmentation,PASCAL Context,2016-11,RefineNet,47.3,80.31,1.6,0.03,58.9,0.52,ito:ITO_00115,Fundamental AI process,mIoU
13,1,Semantic Segmentation,PASCAL Context,2016-11,ResNet-38,48.1,81.66,0.8,0.01,58.9,0.53,ito:ITO_00115,Fundamental AI process,mIoU
14,1,Semantic Segmentation,PASCAL Context,2018-03,EncNet (ResNet-101),51.7,87.78,3.6,0.06,58.9,0.57,ito:ITO_00115,Fundamental AI process,mIoU
15,1,Semantic Segmentation,PASCAL Context,2018-09,DANet (ResNet-101),52.6,89.3,0.9,0.02,58.9,0.58,ito:ITO_00115,Fundamental AI process,mIoU
16,1,Semantic Segmentation,PASCAL Context,2019-03,Joint Pyramid Upsampling + EncNet,53.1,90.15,0.5,0.01,58.9,0.59,ito:ITO_00115,Fundamental AI process,mIoU
17,1,Semantic Segmentation,PASCAL Context,2019-06,CFNet (ResNet-101),54.0,91.68,0.9,0.02,58.9,0.6,ito:ITO_00115,Fundamental AI process,mIoU
18,1,Semantic Segmentation,PASCAL Context,2019-09,OCR (HRNetV2-W48),56.2,95.42,2.2,0.04,58.9,0.62,ito:ITO_00115,Fundamental AI process,mIoU
19,1,Semantic Segmentation,PASCAL Context,2020-04,ResNeSt-269,58.9,100.0,2.7,0.05,58.9,0.65,ito:ITO_00115,Fundamental AI process,mIoU
20,1,Real-Time Semantic Segmentation,CamVid,2014-12,DeepLab,61.6,78.47,61.6,0.78,78.5,0.68,ito:ITO_00115,Fundamental AI process,mIoU
21,1,Real-Time Semantic Segmentation,CamVid,2015-11,Dilation10,65.3,83.18,3.7,0.05,78.5,0.72,ito:ITO_00115,Fundamental AI process,mIoU
22,1,Real-Time Semantic Segmentation,CamVid,2016-12,PSPNet,69.1,88.03,3.8,0.05,78.5,0.77,ito:ITO_00115,Fundamental AI process,mIoU
23,1,Real-Time Semantic Segmentation,CamVid,2020-04,TD2-PSP50,76.0,96.82,6.9,0.09,78.5,0.84,ito:ITO_00115,Fundamental AI process,mIoU
24,1,Real-Time Semantic Segmentation,CamVid,2020-04,BiSeNet V2-Large(Cityscapes-Pretrained),78.5,100.0,2.5,0.03,78.5,0.87,ito:ITO_00115,Fundamental AI process,mIoU
25,1,Real-Time Semantic Segmentation,Cityscapes test,2014-12,DeepLab,63.1,83.14,63.1,0.83,75.9,0.7,ito:ITO_00115,Fundamental AI process,mIoU
26,1,Real-Time Semantic Segmentation,Cityscapes test,2015-11,Dilation10,67.1,88.41,4.0,0.05,75.9,0.74,ito:ITO_00115,Fundamental AI process,mIoU
27,1,Real-Time Semantic Segmentation,Cityscapes test,2016-11,FRRN,71.8,94.6,4.7,0.06,75.9,0.8,ito:ITO_00115,Fundamental AI process,mIoU
28,1,Real-Time Semantic Segmentation,Cityscapes test,2018-08,BiSeNet(ResNet-18),74.7,98.42,2.9,0.04,75.9,0.83,ito:ITO_00115,Fundamental AI process,mIoU
29,1,Real-Time Semantic Segmentation,Cityscapes test,2018-11,ShelfNet18,74.8,98.55,0.1,0.0,75.9,0.83,ito:ITO_00115,Fundamental AI process,mIoU
30,1,Real-Time Semantic Segmentation,Cityscapes test,2019-03,SwiftNetRN-18,75.5,99.47,0.7,0.01,75.9,0.84,ito:ITO_00115,Fundamental AI process,mIoU
31,1,Real-Time Semantic Segmentation,Cityscapes test,2019-09,U-HarDNet-70,75.9,100.0,0.4,0.01,75.9,0.84,ito:ITO_00115,Fundamental AI process,mIoU
32,1,Semantic Segmentation,Kvasir-Instrument,2015-05,UNet,0.8578,100.0,0.8578,1.0,0.8578,0.01,ito:ITO_00115,Fundamental AI process,mIoU
33,1,Semantic Segmentation,Cityscapes val,2015-12,Dilated-ResNet (Dilated-ResNet-101),75.7,91.54,75.7,0.92,82.7,0.84,ito:ITO_00115,Fundamental AI process,mIoU
34,1,Semantic Segmentation,Cityscapes val,2016-12,PSPNet (Dilated-ResNet-101),79.7,96.37,4.0,0.05,82.7,0.88,ito:ITO_00115,Fundamental AI process,mIoU
35,1,Semantic Segmentation,Cityscapes val,2019-01,Auto-DeepLab-L,80.33,97.13,0.6,0.01,82.7,0.89,ito:ITO_00115,Fundamental AI process,mIoU
36,1,Semantic Segmentation,Cityscapes val,2019-08,HRNetV2 (HRNetV2-W48),81.1,98.07,0.8,0.01,82.7,0.9,ito:ITO_00115,Fundamental AI process,mIoU
37,1,Semantic Segmentation,Cityscapes val,2019-11,Panoptic-DeepLab,81.5,98.55,0.4,0.0,82.7,0.9,ito:ITO_00115,Fundamental AI process,mIoU
38,1,Semantic Segmentation,Cityscapes val,2020-04,ResNeSt200,82.7,100.0,1.2,0.01,82.7,0.92,ito:ITO_00115,Fundamental AI process,mIoU
39,1,Semantic Segmentation,Semantic3D,2016-03,TMLC-MSR,54.2,70.03,54.2,0.7,77.4,0.6,ito:ITO_00115,Fundamental AI process,mIoU
40,1,Semantic Segmentation,Semantic3D,2017-04,SnapNet_,59.1,76.36,4.9,0.06,77.4,0.65,ito:ITO_00115,Fundamental AI process,mIoU
41,1,Semantic Segmentation,Semantic3D,2017-10,SEGCloud,61.3,79.2,2.2,0.03,77.4,0.68,ito:ITO_00115,Fundamental AI process,mIoU
42,1,Semantic Segmentation,Semantic3D,2017-11,SPGraph,73.2,94.57,11.9,0.15,77.4,0.81,ito:ITO_00115,Fundamental AI process,mIoU
43,1,Semantic Segmentation,Semantic3D,2017-11,SPG,76.2,98.45,3.0,0.04,77.4,0.84,ito:ITO_00115,Fundamental AI process,mIoU
44,1,Semantic Segmentation,Semantic3D,2019-11,RandLA-Net,77.4,100.0,1.2,0.02,77.4,0.86,ito:ITO_00115,Fundamental AI process,mIoU
45,1,Semantic Segmentation,PASCAL VOC 2012 val,2016-06,DeepLab-CRF (ResNet-101),77.69,90.55,77.69,0.91,85.8,0.86,ito:ITO_00115,Fundamental AI process,mIoU
46,1,Semantic Segmentation,PASCAL VOC 2012 val,2017-03,ResNet-GCN,81.0,94.41,3.3,0.04,85.8,0.9,ito:ITO_00115,Fundamental AI process,mIoU
47,1,Semantic Segmentation,PASCAL VOC 2012 val,2017-06,DeepLabv3-JFT,82.7,96.39,1.7,0.02,85.8,0.92,ito:ITO_00115,Fundamental AI process,mIoU
48,1,Semantic Segmentation,PASCAL VOC 2012 val,2018-02,DeepLabv3+ (Xception-JFT),84.56,98.55,1.9,0.02,85.8,0.94,ito:ITO_00115,Fundamental AI process,mIoU
49,1,Semantic Segmentation,PASCAL VOC 2012 val,2018-04,ExFuse (ResNeXt-131),85.8,100.0,1.2,0.01,85.8,0.95,ito:ITO_00115,Fundamental AI process,mIoU
50,1,Semantic Segmentation,ADE20K val,2016-11,RefineNet (ResNet-152),40.7,84.16,40.7,0.84,48.36,0.45,ito:ITO_00115,Fundamental AI process,mIoU
51,1,Semantic Segmentation,ADE20K val,2016-12,PSPNet (ResNet-152),43.51,89.97,2.8,0.06,48.36,0.48,ito:ITO_00115,Fundamental AI process,mIoU
52,1,Semantic Segmentation,ADE20K val,2018-03,DSSPN (ResNet-101),43.68,90.32,0.2,0.0,48.36,0.48,ito:ITO_00115,Fundamental AI process,mIoU
53,1,Semantic Segmentation,ADE20K val,2018-03,EncNet (ResNet-101),44.65,92.33,1.0,0.02,48.36,0.49,ito:ITO_00115,Fundamental AI process,mIoU
54,1,Semantic Segmentation,ADE20K val,2019-06,CFNet (ResNet-101),44.89,92.82,0.2,0.0,48.36,0.5,ito:ITO_00115,Fundamental AI process,mIoU
55,1,Semantic Segmentation,ADE20K val,2019-08,Asymmetric ALNN,45.24,93.55,0.4,0.01,48.36,0.5,ito:ITO_00115,Fundamental AI process,mIoU
56,1,Semantic Segmentation,ADE20K val,2019-09,OCR (HRNetV2-W48),45.66,94.42,0.4,0.01,48.36,0.51,ito:ITO_00115,Fundamental AI process,mIoU
57,1,Semantic Segmentation,ADE20K val,2019-10,ACNet (ResNet-101),45.9,94.91,0.2,0.0,48.36,0.51,ito:ITO_00115,Fundamental AI process,mIoU
58,1,Semantic Segmentation,ADE20K val,2020-03,DCNAS,47.12,97.44,1.2,0.02,48.36,0.52,ito:ITO_00115,Fundamental AI process,mIoU
59,1,Semantic Segmentation,ADE20K val,2020-04,ResNeSt-200,48.36,100.0,1.2,0.02,48.36,0.54,ito:ITO_00115,Fundamental AI process,mIoU
60,1,Semantic Segmentation,S3DIS Area5,2016-12,PointNet,41.1,61.25,41.1,0.61,67.1,0.46,ito:ITO_00115,Fundamental AI process,mIoU
61,1,Semantic Segmentation,S3DIS Area5,2017-10,SegCloud,48.9,72.88,7.8,0.12,67.1,0.54,ito:ITO_00115,Fundamental AI process,mIoU
62,1,Semantic Segmentation,S3DIS Area5,2017-11,SPG,58.04,86.5,9.1,0.14,67.1,0.64,ito:ITO_00115,Fundamental AI process,mIoU
63,1,Semantic Segmentation,S3DIS Area5,2019-04,MinkowskiNet,65.4,97.47,7.4,0.11,67.1,0.72,ito:ITO_00115,Fundamental AI process,mIoU
64,1,Semantic Segmentation,S3DIS Area5,2019-04,KPConv,67.1,100.0,1.7,0.03,67.1,0.74,ito:ITO_00115,Fundamental AI process,mIoU
65,1,3D Semantic Segmentation,SemanticKITTI,2016-12,PointNet,14.6,24.83,14.6,0.25,58.8,0.16,ito:ITO_00115,Fundamental AI process,mIoU
66,1,3D Semantic Segmentation,SemanticKITTI,2017-06,PointNet++,20.1,34.18,5.5,0.09,58.8,0.22,ito:ITO_00115,Fundamental AI process,mIoU
67,1,3D Semantic Segmentation,SemanticKITTI,2017-10,SqueezeSeg,29.5,50.17,9.4,0.16,58.8,0.33,ito:ITO_00115,Fundamental AI process,mIoU
68,1,3D Semantic Segmentation,SemanticKITTI,2018-07,TangentConv,35.9,61.05,6.4,0.11,58.8,0.4,ito:ITO_00115,Fundamental AI process,mIoU
69,1,3D Semantic Segmentation,SemanticKITTI,2018-07,TagentConv,40.9,69.56,5.0,0.09,58.8,0.45,ito:ITO_00115,Fundamental AI process,mIoU
70,1,3D Semantic Segmentation,SemanticKITTI,2019-04,KPConv,58.8,100.0,17.9,0.3,58.8,0.65,ito:ITO_00115,Fundamental AI process,mIoU
71,1,Real-Time Semantic Segmentation,NYU Depth v2,2016-12,PSPNet101,43.2,99.31,43.2,0.99,43.5,0.48,ito:ITO_00115,Fundamental AI process,mIoU
72,1,Real-Time Semantic Segmentation,NYU Depth v2,2020-04,TD2-PSP50,43.5,100.0,0.3,0.01,43.5,0.48,ito:ITO_00115,Fundamental AI process,mIoU
73,1,Semantic Segmentation,LIP val,2017-03,Attention+SSL (ResNet-101),44.73,75.35,44.73,0.75,59.36,0.5,ito:ITO_00115,Fundamental AI process,mIoU
74,1,Semantic Segmentation,LIP val,2018-04,JPPNet (ResNet-101),51.37,86.54,6.6,0.11,59.36,0.57,ito:ITO_00115,Fundamental AI process,mIoU
75,1,Semantic Segmentation,LIP val,2018-09,CE2P (ResNet-101),53.1,89.45,1.7,0.03,59.36,0.59,ito:ITO_00115,Fundamental AI process,mIoU
76,1,Semantic Segmentation,LIP val,2019-04,HRNetV2 (HRNetV2-W48),55.9,94.17,2.8,0.05,59.36,0.62,ito:ITO_00115,Fundamental AI process,mIoU
77,1,Semantic Segmentation,LIP val,2019-09,OCR (HRNetV2-W48),56.65,95.43,0.8,0.01,59.36,0.63,ito:ITO_00115,Fundamental AI process,mIoU
78,1,Semantic Segmentation,LIP val,2019-10,SCHP (ResNet-101),59.36,100.0,2.7,0.05,59.36,0.66,ito:ITO_00115,Fundamental AI process,mIoU
79,1,Panoptic Segmentation,Cityscapes val,2018-08,Dynamically Instantiated Network (ResNet-101),79.8,88.37,79.8,0.88,90.3,0.88,ito:ITO_00115,Fundamental AI process,mIoU
80,1,Panoptic Segmentation,Cityscapes val,2019-11,Panoptic-DeepLab (X71),81.5,90.25,1.7,0.02,90.3,0.9,ito:ITO_00115,Fundamental AI process,mIoU
81,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS,82.1,90.92,0.6,0.01,90.3,0.91,ito:ITO_00115,Fundamental AI process,mIoU
82,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS (Cityscapes-fine),90.3,100.0,8.2,0.09,90.3,1.0,ito:ITO_00115,Fundamental AI process,mIoU
83,1,Multi-Task Learning,Cityscapes test,2018-10,MultiObjectiveOptimization,66.63,100.0,66.63,1.0,66.63,0.74,ito:ITO_00115,Fundamental AI process,mIoU
84,1,Domain Adaptation,SYNTHIA-to-Cityscapes,2018-11,ADVENT (ResNet-101),41.2,88.22,41.2,0.88,46.7,0.46,ito:ITO_00115,Fundamental AI process,mIoU
85,1,Domain Adaptation,SYNTHIA-to-Cityscapes,2019-08,PyCDA (ResNet-101),46.7,100.0,5.5,0.12,46.7,0.52,ito:ITO_00115,Fundamental AI process,mIoU
86,1,Semantic Segmentation,ParisLille3D,2019-04,KPConv deform,75.9,100.0,75.9,1.0,75.9,0.84,ito:ITO_00115,Fundamental AI process,mIoU
87,1,3D Semantic Segmentation,S3DIS,2019-07,PVCNN++,58.98,100.0,58.98,1.0,58.98,0.65,ito:ITO_00115,Fundamental AI process,mIoU
88,1,Panoptic Segmentation,Mapillary val,2019-09,AdaptIS (ResNeXt-101),56.8,100.0,56.8,1.0,56.8,0.63,ito:ITO_00115,Fundamental AI process,mIoU
89,1,Unsupervised Semantic Segmentation,PASCAL VOC 2012 val,2019-10,SegSort,55.86,100.0,55.86,1.0,55.86,0.62,ito:ITO_00115,Fundamental AI process,mIoU
90,1,Real-Time Semantic Segmentation,Cityscapes val,2019-12,LiteSeg-MobileNet,67.8,100.0,67.8,1.0,67.8,0.75,ito:ITO_00115,Fundamental AI process,mIoU
91,1,Semantic Segmentation,BDD,2019-12,FasterSeg,55.1,100.0,55.1,1.0,55.1,0.61,ito:ITO_00115,Fundamental AI process,mIoU
92,1,Semantic Segmentation,GTAV-to-Cityscapes Labels,2019-12,MRNet,48.3,96.02,48.3,0.96,50.3,0.53,ito:ITO_00115,Fundamental AI process,mIoU
93,1,Semantic Segmentation,GTAV-to-Cityscapes Labels,2020-03,MRNet+Rectifying Label,50.3,100.0,2.0,0.04,50.3,0.56,ito:ITO_00115,Fundamental AI process,mIoU
94,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet-tiny,46.9,84.05,46.9,0.84,55.8,0.52,ito:ITO_00115,Fundamental AI process,mIoU
95,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet,55.8,100.0,8.9,0.16,55.8,0.62,ito:ITO_00115,Fundamental AI process,mIoU
96,1,Real-Time Semantic Segmentation,COCO-Stuff,2020-04,BiSeNet V2-Large,28.7,100.0,28.7,1.0,28.7,0.32,ito:ITO_00115,Fundamental AI process,mIoU
0,1,Semantic Segmentation,ADE20K,2014-11,FCN,29.39,60.77,29.39,0.61,48.36,0.41,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
1,1,Semantic Segmentation,ADE20K,2015-11,DilatedNet,32.31,66.81,2.9,0.06,48.36,0.45,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
2,1,Semantic Segmentation,ADE20K,2016-11,RefineNet,40.7,84.16,8.4,0.17,48.36,0.57,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
3,1,Semantic Segmentation,ADE20K,2016-12,PSPNet,44.94,92.93,4.2,0.09,48.36,0.63,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
4,1,Semantic Segmentation,ADE20K,2019-11,LaU-regression-loss,45.02,93.09,0.1,0.0,48.36,0.63,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
5,1,Semantic Segmentation,ADE20K,2020-04,CPN(ResNet-101),46.27,95.68,1.2,0.02,48.36,0.65,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
6,1,Semantic Segmentation,ADE20K,2020-04,ResNeSt-200,48.36,100.0,2.1,0.04,48.36,0.68,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
7,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 12.5% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),64.3,90.06,64.3,0.9,71.4,0.9,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
8,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 12.5% labeled,2019-06,CutMix (DeepLab v2 ImageNet pre-trained),67.6,94.68,3.3,0.05,71.4,0.95,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
9,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 12.5% labeled,2019-08,s4GAN+MLMT (DeepLab v3 ImageNet pre-trained),70.4,98.6,2.8,0.04,71.4,0.99,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
10,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 12.5% labeled,2019-08,s4GAN + MLMT (DeepLab v2 MSCOCO/ImageNet pre-trained),71.4,100.0,1.0,0.01,71.4,1.0,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
11,1,Semi-Supervised Semantic Segmentation,Cityscapes 12.5% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),57.1,94.63,57.1,0.95,60.34,0.8,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
12,1,Semi-Supervised Semantic Segmentation,Cityscapes 12.5% labeled,2019-06,"CutMix (DeepLab v2, ImageNet pre-trained)",60.34,100.0,3.2,0.05,60.34,0.85,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
13,1,Semi-Supervised Semantic Segmentation,Cityscapes 25% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),60.5,94.72,60.5,0.95,63.87,0.85,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
14,1,Semi-Supervised Semantic Segmentation,Cityscapes 25% labeled,2019-06,"CutMix (DeepLab v2, ImageNet pre-trained)",63.87,100.0,3.4,0.05,63.87,0.89,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
15,1,Semi-Supervised Semantic Segmentation,Cityscapes 50% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),65.7,100.0,65.7,1.0,65.7,0.92,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
16,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 2% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),49.2,75.91,49.2,0.76,64.81,0.69,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
17,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 2% labeled,2019-06,CutMix (DeepLab v2 ImageNet pre-trained),64.81,100.0,15.6,0.24,64.81,0.91,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
18,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 5% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),59.1,87.95,59.1,0.88,67.2,0.83,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
19,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 5% labeled,2019-06,CutMix (DeepLab v2 ImageNet pre-trained),66.48,98.93,7.4,0.11,67.2,0.93,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
20,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 5% labeled,2019-08,s4GAN+MLMT (DeepLab v3 ImageNet pre-trained),66.6,99.11,0.1,0.0,67.2,0.93,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
21,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 5% labeled,2019-08,s4GAN + MLMT (DeepLab v2 MSCOCO/ImageNet pre-trained),67.2,100.0,0.6,0.01,67.2,0.94,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
22,1,Semi-Supervised Semantic Segmentation,Cityscapes 100 samples labeled,2019-06,"CutMix (DeepLab v2, ImageNet pre-trained)",51.2,100.0,51.2,1.0,51.2,0.72,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
23,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 1% labeled,2019-06,CutMix (DeepLab v2 ImageNet pre-trained),53.79,100.0,53.79,1.0,53.79,0.75,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
24,1,Semi-Supervised Semantic Segmentation,PASCAL Context 12.5% labeled,2019-08,s4GAN+MLMT (DeepLab v2 ImageNet pre-trained),35.3,100.0,35.3,1.0,35.3,0.49,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
25,1,Semi-Supervised Semantic Segmentation,PASCAL Context 25% labeled,2019-08,s4GAN+MLMT (DeepLab v2 ImageNet pre-trained),37.8,100.0,37.8,1.0,37.8,0.53,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
26,1,Semi-Supervised Semantic Segmentation,Cityscapes 5% labeled,2019-08,"S4GAN (DeepLabv2 with ResNet101, MSCOCO pre-trained)",55.61,100.0,55.61,1.0,55.61,0.78,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
27,1,Semi-Supervised Semantic Segmentation,Cityscapes 2% labeled,2019-08,"S4GAN (DeepLabv2 with ResNet101, MSCOCO pre-trained)",50.48,100.0,50.48,1.0,50.48,0.71,ito:ITO_00115,Fundamental AI process,Validation\\ mIoU
0,1,Skeleton Based Action Recognition,J-HMDB,2014-11,Action Tubes,62.5,69.14,62.5,0.69,90.4,0.69,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(RGB\\+pose\\)
1,1,Skeleton Based Action Recognition,J-HMDB,2016-09,MR Two-Sream R-CNN,71.1,78.65,8.6,0.1,90.4,0.79,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(RGB\\+pose\\)
2,1,Skeleton Based Action Recognition,J-HMDB,2017-04,Chained (RGB+Flow +Pose),76.1,84.18,5.0,0.06,90.4,0.84,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(RGB\\+pose\\)
3,1,Skeleton Based Action Recognition,J-HMDB,2017-05,I3D,84.1,93.03,8.0,0.09,90.4,0.93,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(RGB\\+pose\\)
4,1,Skeleton Based Action Recognition,J-HMDB,2018-06,I3D + Potion,85.5,94.58,1.4,0.02,90.4,0.95,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(RGB\\+pose\\)
5,1,Skeleton Based Action Recognition,J-HMDB,2018-06,Potion,90.4,100.0,4.9,0.05,90.4,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(RGB\\+pose\\)
0,1,Real-Time Semantic Segmentation,CamVid,2014-12,DeepLab,203.0,89.43,203.0,0.89,227.0,0.05,ito:ITO_00115,Fundamental AI process,Time\\ \\(ms\\)
1,1,Real-Time Semantic Segmentation,CamVid,2015-11,SegNet,217.0,95.59,14.0,0.06,227.0,0.05,ito:ITO_00115,Fundamental AI process,Time\\ \\(ms\\)
2,1,Real-Time Semantic Segmentation,CamVid,2015-11,Dilation10,227.0,100.0,10.0,0.04,227.0,0.06,ito:ITO_00115,Fundamental AI process,Time\\ \\(ms\\)
3,1,Real-Time Semantic Segmentation,Cityscapes test,2014-12,DeepLab,4000.0,100.0,4000.0,1.0,4000.0,1.0,ito:ITO_00115,Fundamental AI process,Time\\ \\(ms\\)
0,1,Semantic Segmentation,Cityscapes test,2014-12,DeepLab,63.1,74.67,63.1,0.75,84.5,0.75,ito:ITO_00115,Fundamental AI process,Mean\\ IoU\\ \\(class\\)
1,1,Semantic Segmentation,Cityscapes test,2015-04,Context,71.6,84.73,8.5,0.1,84.5,0.85,ito:ITO_00115,Fundamental AI process,Mean\\ IoU\\ \\(class\\)
2,1,Semantic Segmentation,Cityscapes test,2016-05,LRR-4x,71.8,84.97,0.2,0.0,84.5,0.85,ito:ITO_00115,Fundamental AI process,Mean\\ IoU\\ \\(class\\)
3,1,Semantic Segmentation,Cityscapes test,2016-11,RefineNet (ResNet-101),73.6,87.1,1.8,0.02,84.5,0.87,ito:ITO_00115,Fundamental AI process,Mean\\ IoU\\ \\(class\\)
4,1,Semantic Segmentation,Cityscapes test,2016-11,ResNet-38,78.4,92.78,4.8,0.06,84.5,0.93,ito:ITO_00115,Fundamental AI process,Mean\\ IoU\\ \\(class\\)
5,1,Semantic Segmentation,Cityscapes test,2016-12,"PSPNet (ResNet-101, coarse)",81.2,96.09,2.8,0.03,84.5,0.96,ito:ITO_00115,Fundamental AI process,Mean\\ IoU\\ \\(class\\)
6,1,Semantic Segmentation,Cityscapes test,2017-06,"DeepLabv3 (ResNet-101, coarse)",81.3,96.21,0.1,0.0,84.5,0.96,ito:ITO_00115,Fundamental AI process,Mean\\ IoU\\ \\(class\\)
7,1,Semantic Segmentation,Cityscapes test,2017-12,Mapillary,82.0,97.04,0.7,0.01,84.5,0.97,ito:ITO_00115,Fundamental AI process,Mean\\ IoU\\ \\(class\\)
8,1,Semantic Segmentation,Cityscapes test,2018-02,DeepLabv3+ (Xception-JFT),82.1,97.16,0.1,0.0,84.5,0.97,ito:ITO_00115,Fundamental AI process,Mean\\ IoU\\ \\(class\\)
9,1,Semantic Segmentation,Cityscapes test,2018-08,SSMA,82.3,97.4,0.2,0.0,84.5,0.97,ito:ITO_00115,Fundamental AI process,Mean\\ IoU\\ \\(class\\)
10,1,Semantic Segmentation,Cityscapes test,2018-09,Dense Prediction Cell,82.7,97.87,0.4,0.0,84.5,0.98,ito:ITO_00115,Fundamental AI process,Mean\\ IoU\\ \\(class\\)
11,1,Semantic Segmentation,Cityscapes test,2018-12,DeepLabV3Plus + SDCNetAug,83.5,98.82,0.8,0.01,84.5,0.99,ito:ITO_00115,Fundamental AI process,Mean\\ IoU\\ \\(class\\)
12,1,Semantic Segmentation,Cityscapes test,2019-09,HRNetV2 + OCR +,84.5,100.0,1.0,0.01,84.5,1.0,ito:ITO_00115,Fundamental AI process,Mean\\ IoU\\ \\(class\\)
13,1,Semantic Segmentation,KITTI Semantic Segmentation,2018-12,DeepLabV3Plus + SDCNetAug,72.8,100.0,72.8,1.0,72.8,0.86,ito:ITO_00115,Fundamental AI process,Mean\\ IoU\\ \\(class\\)
0,1,Real-Time Semantic Segmentation,Cityscapes test,2014-12,DeepLab,0.25,0.15,0.25,0.0,163.9,0.0,ito:ITO_00115,Fundamental AI process,Frame\\ \\(fps\\)
1,1,Real-Time Semantic Segmentation,Cityscapes test,2015-02,CRF-RNN,1.4,0.85,1.2,0.01,163.9,0.01,ito:ITO_00115,Fundamental AI process,Frame\\ \\(fps\\)
2,1,Real-Time Semantic Segmentation,Cityscapes test,2015-11,SegNet,16.7,10.19,15.3,0.09,163.9,0.1,ito:ITO_00115,Fundamental AI process,Frame\\ \\(fps\\)
3,1,Real-Time Semantic Segmentation,Cityscapes test,2016-06,ENet,76.9,46.92,60.2,0.37,163.9,0.47,ito:ITO_00115,Fundamental AI process,Frame\\ \\(fps\\)
4,1,Real-Time Semantic Segmentation,Cityscapes test,2018-08,BiSeNet(Xception39),105.8,64.55,28.9,0.18,163.9,0.65,ito:ITO_00115,Fundamental AI process,Frame\\ \\(fps\\)
5,1,Real-Time Semantic Segmentation,Cityscapes test,2020-01,FasterSeg,163.9,100.0,58.1,0.35,163.9,1.0,ito:ITO_00115,Fundamental AI process,Frame\\ \\(fps\\)
6,1,Real-Time Semantic Segmentation,CamVid,2014-12,DeepLab,4.9,3.94,4.9,0.04,124.5,0.03,ito:ITO_00115,Fundamental AI process,Frame\\ \\(fps\\)
7,1,Real-Time Semantic Segmentation,CamVid,2016-12,PSPNet,5.4,4.34,0.5,0.0,124.5,0.03,ito:ITO_00115,Fundamental AI process,Frame\\ \\(fps\\)
8,1,Real-Time Semantic Segmentation,CamVid,2017-04,ICNet,27.8,22.33,22.4,0.18,124.5,0.17,ito:ITO_00115,Fundamental AI process,Frame\\ \\(fps\\)
9,1,Real-Time Semantic Segmentation,CamVid,2020-04,BiSeNet V2-Large(Cityscapes-Pretrained),32.7,26.27,4.9,0.04,124.5,0.2,ito:ITO_00115,Fundamental AI process,Frame\\ \\(fps\\)
10,1,Real-Time Semantic Segmentation,CamVid,2020-04,BiSeNet V2,124.5,100.0,91.8,0.74,124.5,0.76,ito:ITO_00115,Fundamental AI process,Frame\\ \\(fps\\)
0,1,Semantic Segmentation,Kvasir-Instrument,2015-05,UNet,0.9158,100.0,0.9158,1.0,0.9158,1.0,ito:ITO_00115,Fundamental AI process,DSC
0,1,Temporal Action Localization,CrossTask,2015-06,Alayrac,13.3,39.58,13.3,0.4,33.6,0.4,ito:ITO_00115,Fundamental AI process,Recall
1,1,Temporal Action Localization,CrossTask,2019-03,Fully-supervised upper-bound,31.6,94.05,18.3,0.54,33.6,0.94,ito:ITO_00115,Fundamental AI process,Recall
2,1,Temporal Action Localization,CrossTask,2019-06,Text-Video Embedding,33.6,100.0,2.0,0.06,33.6,1.0,ito:ITO_00115,Fundamental AI process,Recall
3,1,Mortality Prediction,MIMIC-III,2018-03,Random Forest,0.97,100.0,0.97,1.0,0.97,0.03,ito:ITO_00115,Fundamental AI process,Recall
0,1,Sentence Compression,Google Dataset,2015-09,LSTM,0.82,96.36,0.82,0.96,0.851,0.01,ito:ITO_00115,Fundamental AI process,F1
1,1,Sentence Compression,Google Dataset,2018-07,BiRNN + LM Evaluator,0.851,100.0,0.0,0.0,0.851,0.01,ito:ITO_00115,Fundamental AI process,F1
2,1,Click-Through Rate Prediction,Book-Crossing,2019-03,KGCN-sum,0.688,100.0,0.688,1.0,0.688,0.01,ito:ITO_00115,Fundamental AI process,F1
3,1,Unsupervised Domain Expansion,Unsupervised Domain Expansion,2019-03,KGCN-sum,0.688,100.0,0.688,1.0,0.688,0.01,ito:ITO_00115,Fundamental AI process,F1
4,1,Multi-Label Text Classification,AAPD,2020-02,MAGNET,69.6,100.0,69.6,1.0,69.6,1.0,ito:ITO_00115,Fundamental AI process,F1
0,1,Sentence Compression,Google Dataset,2015-09,LSTM,0.38,88.37,0.38,0.88,0.43,0.88,ito:ITO_00115,Fundamental AI process,CR
1,1,Sentence Compression,Google Dataset,2017-07,BiLSTM,0.43,100.0,0.0,0.0,0.43,1.0,ito:ITO_00115,Fundamental AI process,CR
0,1,Anomaly Detection,Numenta Anomaly Benchmark,2015-10,Numenta HTM,64.7,92.3,64.7,0.92,70.1,0.92,ito:ITO_00115,Fundamental AI process,NAB\\ score
1,1,Anomaly Detection,Numenta Anomaly Benchmark,2017-06,HTM AL,70.1,100.0,5.4,0.08,70.1,1.0,ito:ITO_00115,Fundamental AI process,NAB\\ score
0,1,Semantic Segmentation,CamVid,2015-11,ReSeg,88.7,96.94,88.7,0.97,91.5,0.97,ito:ITO_00115,Fundamental AI process,Global\\ Accuracy
1,1,Semantic Segmentation,CamVid,2016-11,FC-DenseNet103,91.5,100.0,2.8,0.03,91.5,1.0,ito:ITO_00115,Fundamental AI process,Global\\ Accuracy
0,1,Action Recognition In Videos,THUMOS’14,2015-11,Yeung et. al.,17.1,45.72,17.1,0.46,37.4,0.38,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
1,1,Action Recognition In Videos,THUMOS’14,2016-01,Shou et. al.,19.0,50.8,1.9,0.05,37.4,0.42,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
2,1,Action Recognition In Videos,THUMOS’14,2017-03,TURN,24.5,65.51,5.5,0.15,37.4,0.54,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
3,1,Action Recognition In Videos,THUMOS’14,2017-03,Single-stream R-C3D  (two-way buffer),28.9,77.27,4.4,0.12,37.4,0.64,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
4,1,Action Recognition In Videos,THUMOS’14,2017-04,SSN,29.8,79.68,0.9,0.02,37.4,0.66,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
5,1,Action Recognition In Videos,THUMOS’14,2018-06,BSN,36.9,98.66,7.1,0.19,37.4,0.81,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
6,1,Action Recognition In Videos,THUMOS’14,2018-11,MGG UNet,37.4,100.0,0.5,0.01,37.4,0.83,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
7,1,Action Recognition,THUMOS’14,2015-11,Yeung et. al.,17.1,44.07,17.1,0.44,38.8,0.38,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
8,1,Action Recognition,THUMOS’14,2016-01,Shou et. al.,19.0,48.97,1.9,0.05,38.8,0.42,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
9,1,Action Recognition,THUMOS’14,2017-03,TURN,24.5,63.14,5.5,0.14,38.8,0.54,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
10,1,Action Recognition,THUMOS’14,2017-03,Single-stream R-C3D  (one-way buffer),27.0,69.59,2.5,0.06,38.8,0.6,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
11,1,Action Recognition,THUMOS’14,2017-03,Single-stream R-C3D  (two-way buffer),28.9,74.48,1.9,0.05,38.8,0.64,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
12,1,Action Recognition,THUMOS’14,2017-04,SSN,29.8,76.8,0.9,0.02,38.8,0.66,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
13,1,Action Recognition,THUMOS’14,2018-06,BSN,36.9,95.1,7.1,0.18,38.8,0.81,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
14,1,Action Recognition,THUMOS’14,2018-11,MGG UNet,37.4,96.39,0.5,0.01,38.8,0.83,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
15,1,Action Recognition,THUMOS’14,2019-07,BMN,38.8,100.0,1.4,0.04,38.8,0.86,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
16,1,Weakly Supervised Action Localization,THUMOS 2014,2017-03,UntrimmedNets,13.7,50.74,13.7,0.51,27.0,0.3,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
17,1,Weakly Supervised Action Localization,THUMOS 2014,2017-12,STPN,16.9,62.59,3.2,0.12,27.0,0.37,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
18,1,Weakly Supervised Action Localization,THUMOS 2014,2018-07,W-TALC,22.8,84.44,5.9,0.22,27.0,0.5,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
19,1,Weakly Supervised Action Localization,THUMOS 2014,2019-06,CMCS,23.1,85.56,0.3,0.01,27.0,0.51,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
20,1,Weakly Supervised Action Localization,THUMOS 2014,2019-08,3C-Net,26.6,98.52,3.5,0.13,27.0,0.59,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
21,1,Weakly Supervised Action Localization,THUMOS 2014,2019-11,BaS-Net,27.0,100.0,0.4,0.01,27.0,0.6,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
22,1,Weakly Supervised Action Localization,ActivityNet-1.3,2017-12,STPN,29.3,84.93,29.3,0.85,34.5,0.65,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
23,1,Weakly Supervised Action Localization,ActivityNet-1.3,2019-05,MAAN,33.7,97.68,4.4,0.13,34.5,0.74,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
24,1,Weakly Supervised Action Localization,ActivityNet-1.3,2019-06,CMCS,34.0,98.55,0.3,0.01,34.5,0.75,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
25,1,Weakly Supervised Action Localization,ActivityNet-1.3,2019-11,BaS-Net,34.5,100.0,0.5,0.01,34.5,0.76,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
26,1,Unsupervised Domain Adaptation,Cityscapes to Foggy Cityscapes,2018-03,DA-Faster,26.1,75.0,26.1,0.75,34.8,0.58,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
27,1,Unsupervised Domain Adaptation,Cityscapes to Foggy Cityscapes,2018-12,SWDA,34.8,100.0,8.7,0.25,34.8,0.77,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
28,1,Weakly Supervised Action Localization,ActivityNet-1.2,2018-07,W-TALC,37.0,96.1,37.0,0.96,38.5,0.82,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
29,1,Weakly Supervised Action Localization,ActivityNet-1.2,2019-08,3C-Net,37.2,96.62,0.2,0.01,38.5,0.82,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
30,1,Weakly Supervised Action Localization,ActivityNet-1.2,2019-11,BaS-Net,38.5,100.0,1.3,0.03,38.5,0.85,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
31,1,Unsupervised Domain Adaptation,SIM10K to BDD100K,2018-12,SWDA,42.9,94.7,42.9,0.95,45.3,0.95,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
32,1,Unsupervised Domain Adaptation,SIM10K to BDD100K,2020-03,CDN,45.3,100.0,2.4,0.05,45.3,1.0,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
33,1,Weakly Supervised Action Localization,THUMOS’14,2019-11,BasNet,27.0,100.0,27,1.0,27,0.6,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.5
0,1,Action Recognition In Videos,THUMOS’14,2015-11,Yeung et. al.,48.9,74.09,48.9,0.74,66.0,0.74,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.1
1,1,Action Recognition In Videos,THUMOS’14,2017-03,Single-stream R-C3D  (two-way buffer),54.5,82.58,5.6,0.08,66.0,0.83,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.1
2,1,Action Recognition In Videos,THUMOS’14,2017-04,SSN,66.0,100.0,11.5,0.17,66.0,1.0,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.1
3,1,Action Recognition,THUMOS’14,2015-11,Yeung et. al.,48.9,74.09,48.9,0.74,66.0,0.74,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.1
4,1,Action Recognition,THUMOS’14,2017-03,Single-stream R-C3D  (one-way buffer),51.6,78.18,2.7,0.04,66.0,0.78,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.1
5,1,Action Recognition,THUMOS’14,2017-03,Single-stream R-C3D  (two-way buffer),54.5,82.58,2.9,0.04,66.0,0.83,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.1
6,1,Action Recognition,THUMOS’14,2017-04,SSN,66.0,100.0,11.5,0.17,66.0,1.0,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.1
0,1,Action Recognition In Videos,THUMOS’14,2015-11,Yeung et. al.,44.0,74.07,44.0,0.74,59.4,0.74,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.2
1,1,Action Recognition In Videos,THUMOS’14,2017-03,Single-stream R-C3D  (two-way buffer),51.5,86.7,7.5,0.13,59.4,0.87,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.2
2,1,Action Recognition In Videos,THUMOS’14,2017-04,SSN,59.4,100.0,7.9,0.13,59.4,1.0,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.2
3,1,Action Recognition,THUMOS’14,2015-11,Yeung et. al.,44.0,74.07,44.0,0.74,59.4,0.74,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.2
4,1,Action Recognition,THUMOS’14,2017-03,Single-stream R-C3D  (one-way buffer),49.2,82.83,5.2,0.09,59.4,0.83,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.2
5,1,Action Recognition,THUMOS’14,2017-03,Single-stream R-C3D  (two-way buffer),51.5,86.7,2.3,0.04,59.4,0.87,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.2
6,1,Action Recognition,THUMOS’14,2017-04,SSN,59.4,100.0,7.9,0.13,59.4,1.0,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.2
0,1,Temporal Action Localization,THUMOS’14,2015-11,Yeung et al.,17.1,34.83,17.1,0.35,49.1,0.34,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.5
1,1,Temporal Action Localization,THUMOS’14,2016-01,S-CNN,19.0,38.7,1.9,0.04,49.1,0.38,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.5
2,1,Temporal Action Localization,THUMOS’14,2017-03,CDC,23.3,47.45,4.3,0.09,49.1,0.46,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.5
3,1,Temporal Action Localization,THUMOS’14,2017-03,TURN-FL-16 + S-CNN,25.6,52.14,2.3,0.05,49.1,0.51,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.5
4,1,Temporal Action Localization,THUMOS’14,2017-03,R-C3D,28.9,58.86,3.3,0.07,49.1,0.57,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.5
5,1,Temporal Action Localization,THUMOS’14,2017-05,CBR-TS,31.0,63.14,2.1,0.04,49.1,0.62,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.5
6,1,Temporal Action Localization,THUMOS’14,2018-04,TAL-Net,42.8,87.17,11.8,0.24,49.1,0.85,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.5
7,1,Temporal Action Localization,THUMOS’14,2019-04,Decouple-SSAD,44.2,90.02,1.4,0.03,49.1,0.88,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.5
8,1,Temporal Action Localization,THUMOS’14,2019-09,P-GCN,49.1,100.0,4.9,0.1,49.1,0.97,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.5
9,1,Temporal Action Localization,ActivityNet-1.3,2017-03,SSN,39.12,77.68,39.12,0.78,50.36,0.78,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.5
10,1,Temporal Action Localization,ActivityNet-1.3,2018-06,BSN,46.45,92.24,7.3,0.14,50.36,0.92,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.5
11,1,Temporal Action Localization,ActivityNet-1.3,2019-07,BMN,50.07,99.42,3.6,0.07,50.36,0.99,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.5
12,1,Temporal Action Localization,ActivityNet-1.3,2019-11,G-TAD,50.36,100.0,0.3,0.01,50.36,1.0,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.5
13,1,Temporal Action Localization,ActivityNet-1.2,2020-01,DeepMetricLearner,35.2,100.0,35.2,1.0,35.2,0.7,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.5
0,1,Temporal Action Localization,THUMOS’14,2015-11,Yeung et al.,44.0,64.9,44.0,0.65,67.8,0.65,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.2
1,1,Temporal Action Localization,THUMOS’14,2017-03,TURN-FL-16 + S-CNN,50.9,75.07,6.9,0.1,67.8,0.75,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.2
2,1,Temporal Action Localization,THUMOS’14,2017-03,R-C3D,51.5,75.96,0.6,0.01,67.8,0.76,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.2
3,1,Temporal Action Localization,THUMOS’14,2017-05,CBR-TS,56.7,83.63,5.2,0.08,67.8,0.84,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.2
4,1,Temporal Action Localization,THUMOS’14,2018-04,TAL-Net,57.1,84.22,0.4,0.01,67.8,0.84,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.2
5,1,Temporal Action Localization,THUMOS’14,2019-09,P-GCN,67.8,100.0,10.7,0.16,67.8,1.0,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.2
0,1,Temporal Action Localization,THUMOS’14,2015-11,Yeung et al.,36.0,56.6,36.0,0.57,63.6,0.57,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.3
1,1,Temporal Action Localization,THUMOS’14,2016-01,S-CNN,36.3,57.08,0.3,0.0,63.6,0.57,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.3
2,1,Temporal Action Localization,THUMOS’14,2017-03,CDC,40.1,63.05,3.8,0.06,63.6,0.63,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.3
3,1,Temporal Action Localization,THUMOS’14,2017-03,TURN-FL-16 + S-CNN,44.1,69.34,4.0,0.06,63.6,0.69,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.3
4,1,Temporal Action Localization,THUMOS’14,2017-03,R-C3D,44.8,70.44,0.7,0.01,63.6,0.7,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.3
5,1,Temporal Action Localization,THUMOS’14,2017-05,CBR-TS,50.1,78.77,5.3,0.08,63.6,0.79,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.3
6,1,Temporal Action Localization,THUMOS’14,2018-04,TAL-Net,53.2,83.65,3.1,0.05,63.6,0.84,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.3
7,1,Temporal Action Localization,THUMOS’14,2018-06,BSN UNet,53.5,84.12,0.3,0.0,63.6,0.84,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.3
8,1,Temporal Action Localization,THUMOS’14,2019-04,Decouple-SSAD,60.2,94.65,6.7,0.11,63.6,0.95,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.3
9,1,Temporal Action Localization,THUMOS’14,2019-09,P-GCN,63.6,100.0,3.4,0.05,63.6,1.0,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.3
10,1,Temporal Action Localization,ActivityNet-1.2,2020-01,DeepMetricLearner,48.4,100.0,48.4,1.0,48.4,0.76,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.3
0,1,Temporal Action Localization,THUMOS’14,2015-11,Yeung et al.,26.4,45.67,26.4,0.46,57.8,0.46,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.4
1,1,Temporal Action Localization,THUMOS’14,2016-01,S-CNN,28.7,49.65,2.3,0.04,57.8,0.5,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.4
2,1,Temporal Action Localization,THUMOS’14,2017-03,CDC,29.4,50.87,0.7,0.01,57.8,0.51,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.4
3,1,Temporal Action Localization,THUMOS’14,2017-03,TURN-FL-16 + S-CNN,34.9,60.38,5.5,0.1,57.8,0.6,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.4
4,1,Temporal Action Localization,THUMOS’14,2017-03,R-C3D,35.6,61.59,0.7,0.01,57.8,0.62,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.4
5,1,Temporal Action Localization,THUMOS’14,2017-05,CBR-TS,41.3,71.45,5.7,0.1,57.8,0.71,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.4
6,1,Temporal Action Localization,THUMOS’14,2018-04,TAL-Net,48.5,83.91,7.2,0.12,57.8,0.84,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.4
7,1,Temporal Action Localization,THUMOS’14,2019-04,Decouple-SSAD,54.1,93.6,5.6,0.1,57.8,0.94,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.4
8,1,Temporal Action Localization,THUMOS’14,2019-09,P-GCN,57.8,100.0,3.7,0.06,57.8,1.0,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.4
0,1,Action Recognition In Videos,THUMOS’14,2015-11,Yeung et. al.,26.4,56.41,26.4,0.56,46.8,0.56,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.4
1,1,Action Recognition In Videos,THUMOS’14,2016-01,Shou et. al.,28.7,61.32,2.3,0.05,46.8,0.61,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.4
2,1,Action Recognition In Videos,THUMOS’14,2017-03,TURN,35.3,75.43,6.6,0.14,46.8,0.74,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.4
3,1,Action Recognition In Videos,THUMOS’14,2017-03,Single-stream R-C3D  (two-way buffer),35.6,76.07,0.3,0.01,46.8,0.75,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.4
4,1,Action Recognition In Videos,THUMOS’14,2017-04,SSN,41.0,87.61,5.4,0.12,46.8,0.86,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.4
5,1,Action Recognition In Videos,THUMOS’14,2018-06,BSN,45.0,96.15,4.0,0.09,46.8,0.95,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.4
6,1,Action Recognition In Videos,THUMOS’14,2018-11,MGG UNet,46.8,100.0,1.8,0.04,46.8,0.99,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.4
7,1,Action Recognition,THUMOS’14,2015-11,Yeung et. al.,26.4,55.7,26.4,0.56,47.4,0.56,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.4
8,1,Action Recognition,THUMOS’14,2016-01,Shou et. al.,28.7,60.55,2.3,0.05,47.4,0.61,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.4
9,1,Action Recognition,THUMOS’14,2017-03,TURN,35.3,74.47,6.6,0.14,47.4,0.74,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.4
10,1,Action Recognition,THUMOS’14,2017-03,Single-stream R-C3D  (two-way buffer),35.6,75.11,0.3,0.01,47.4,0.75,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.4
11,1,Action Recognition,THUMOS’14,2017-04,SSN,41.0,86.5,5.4,0.11,47.4,0.86,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.4
12,1,Action Recognition,THUMOS’14,2018-06,BSN,45.0,94.94,4.0,0.08,47.4,0.95,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.4
13,1,Action Recognition,THUMOS’14,2018-11,MGG UNet,46.8,98.73,1.8,0.04,47.4,0.99,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.4
14,1,Action Recognition,THUMOS’14,2019-07,BMN,47.4,100.0,0.6,0.01,47.4,1.0,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.4
0,1,Temporal Action Localization,THUMOS’14,2015-11,Yeung et al.,48.9,70.36,48.9,0.7,69.5,0.7,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.1
1,1,Temporal Action Localization,THUMOS’14,2017-03,TURN-FL-16 + S-CNN,54.0,77.7,5.1,0.07,69.5,0.78,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.1
2,1,Temporal Action Localization,THUMOS’14,2017-03,R-C3D,54.5,78.42,0.5,0.01,69.5,0.78,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.1
3,1,Temporal Action Localization,THUMOS’14,2017-05,CBR-TS,60.1,86.47,5.6,0.08,69.5,0.86,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.1
4,1,Temporal Action Localization,THUMOS’14,2019-09,P-GCN,69.5,100.0,9.4,0.14,69.5,1.0,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.1
5,1,Temporal Action Localization,ActivityNet-1.2,2020-01,DeepMetricLearner,60.5,100.0,60.5,1.0,60.5,0.87,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.1
0,1,Action Recognition In Videos,THUMOS’14,2015-11,Yeung et. al.,36.0,66.79,36.0,0.67,53.9,0.64,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.3
1,1,Action Recognition In Videos,THUMOS’14,2016-01,Shou et. al.,36.3,67.35,0.3,0.01,53.9,0.65,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.3
2,1,Action Recognition In Videos,THUMOS’14,2017-03,TURN,46.3,85.9,10.0,0.19,53.9,0.83,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.3
3,1,Action Recognition In Videos,THUMOS’14,2017-04,SSN,51.9,96.29,5.6,0.1,53.9,0.93,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.3
4,1,Action Recognition In Videos,THUMOS’14,2018-06,BSN,53.5,99.26,1.6,0.03,53.9,0.96,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.3
5,1,Action Recognition In Videos,THUMOS’14,2018-11,MGG UNet,53.9,100.0,0.4,0.01,53.9,0.96,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.3
6,1,Action Recognition,THUMOS’14,2015-11,Yeung et. al.,36.0,64.29,36.0,0.64,56.0,0.64,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.3
7,1,Action Recognition,THUMOS’14,2016-01,Shou et. al.,36.3,64.82,0.3,0.01,56.0,0.65,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.3
8,1,Action Recognition,THUMOS’14,2017-03,TURN,46.3,82.68,10.0,0.18,56.0,0.83,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.3
9,1,Action Recognition,THUMOS’14,2017-04,SSN,51.9,92.68,5.6,0.1,56.0,0.93,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.3
10,1,Action Recognition,THUMOS’14,2018-06,BSN,53.5,95.54,1.6,0.03,56.0,0.96,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.3
11,1,Action Recognition,THUMOS’14,2018-11,MGG UNet,53.9,96.25,0.4,0.01,56.0,0.96,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.3
12,1,Action Recognition,THUMOS’14,2019-07,BMN,56.0,100.0,2.1,0.04,56.0,1.0,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.3
0,1,Domain Generalization,ImageNet-A,2015-12,ResNet-50 (300 Epochs),4.2,50.0,4.2,0.5,8.4,0.08,ito:ITO_00115,Fundamental AI process,Top\\-1\\ accuracy\\ %
1,1,Domain Generalization,ImageNet-A,2017-08,ResNet-50+Cutout,4.4,52.38,0.2,0.02,8.4,0.08,ito:ITO_00115,Fundamental AI process,Top\\-1\\ accuracy\\ %
2,1,Domain Generalization,ImageNet-A,2017-10,ResNet-50+Mixup,6.6,78.57,2.2,0.26,8.4,0.13,ito:ITO_00115,Fundamental AI process,Top\\-1\\ accuracy\\ %
3,1,Domain Generalization,ImageNet-A,2019-05,ResNet-50+CutMix,7.3,86.9,0.7,0.08,8.4,0.14,ito:ITO_00115,Fundamental AI process,Top\\-1\\ accuracy\\ %
4,1,Domain Generalization,ImageNet-A,2020-02,ResNet-50+CutMix+MoEx,8.4,100.0,1.1,0.13,8.4,0.16,ito:ITO_00115,Fundamental AI process,Top\\-1\\ accuracy\\ %
5,1,Compositional Zero-Shot Learning,UT-Zappos,2020-04,SymNet,52.1,100.0,52.1,1.0,52.1,1.0,ito:ITO_00115,Fundamental AI process,Top\\-1\\ accuracy\\ %
6,1,Compositional Zero-Shot Learning,MIT-States,2020-04,SymNet,19.9,100.0,19.9,1.0,19.9,0.38,ito:ITO_00115,Fundamental AI process,Top\\-1\\ accuracy\\ %
0,1,Domain Generalization,ImageNet-R,2015-12,ResNet-50,63.9,100.0,63.9,1.0,63.9,1.0,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Error\\ Rate
1,1,Neural Architecture Search,ImageNet,2018-06,DARTS,26.7,100.0,26.7,1.0,26.7,0.42,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Error\\ Rate
2,1,Neural Architecture Search,CIFAR-10,2019-02,Soft Parameter Sharing,2.53,74.41,2.53,0.74,3.4,0.04,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Error\\ Rate
3,1,Neural Architecture Search,CIFAR-10,2019-03,AlphaX-1 (cutout NASNet),2.82,82.94,0.3,0.09,3.4,0.04,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Error\\ Rate
4,1,Neural Architecture Search,CIFAR-10,2019-10,GDAS,3.4,100.0,0.6,0.18,3.4,0.05,ito:ITO_00115,Fundamental AI process,Top\\-1\\ Error\\ Rate
0,1,Action Recognition In Videos,ActivityNet,2015-12,VGG19 + 393K webcam images,53.8,71.16,53.8,0.71,75.6,0.58,ito:ITO_00115,Fundamental AI process,mAP
1,1,Action Recognition In Videos,ActivityNet,2016-09,LSTM + Pretrained on YT-8M,75.6,100.0,21.8,0.29,75.6,0.81,ito:ITO_00115,Fundamental AI process,mAP
2,1,Action Recognition,ActivityNet,2015-12,VGG19,52.3,97.21,52.3,0.97,53.8,0.56,ito:ITO_00115,Fundamental AI process,mAP
3,1,Action Recognition,ActivityNet,2015-12,VGG19 + 393K webcam images,53.8,100.0,1.5,0.03,53.8,0.58,ito:ITO_00115,Fundamental AI process,mAP
4,1,Temporal Action Localization,MEXaction2,2016-01,S-CNN,7.4,100.0,7.4,1.0,7.4,0.08,ito:ITO_00115,Fundamental AI process,mAP
5,1,Multi-Label Classification,PASCAL VOC 2012,2016-11,Ours PF-DLDL,92.4,100.0,92.4,1.0,92.4,0.99,ito:ITO_00115,Fundamental AI process,mAP
6,1,Multi-Label Classification,PASCAL VOC 2007,2016-11,Ours PF-DLDL,93.4,100.0,93.4,1.0,93.4,1.0,ito:ITO_00115,Fundamental AI process,mAP
7,1,Temporal Action Localization,ActivityNet-1.3,2017-03,SSN,32.26,88.58,32.26,0.89,36.42,0.35,ito:ITO_00115,Fundamental AI process,mAP
8,1,Temporal Action Localization,ActivityNet-1.3,2019-07,BMN,36.42,100.0,4.2,0.12,36.42,0.39,ito:ITO_00115,Fundamental AI process,mAP
9,1,Unsupervised Domain Adaptation,Duke to Market,2017-11,SPGAN,22.8,32.02,22.8,0.32,71.2,0.24,ito:ITO_00115,Fundamental AI process,mAP
10,1,Unsupervised Domain Adaptation,Duke to Market,2018-11,SSG,58.3,81.88,35.5,0.5,71.2,0.62,ito:ITO_00115,Fundamental AI process,mAP
11,1,Unsupervised Domain Adaptation,Duke to Market,2020-01,MMT,71.2,100.0,12.9,0.18,71.2,0.76,ito:ITO_00115,Fundamental AI process,mAP
12,1,Unsupervised Domain Adaptation,Market to Duke,2017-11,SPGAN,22.3,34.25,22.3,0.34,65.1,0.24,ito:ITO_00115,Fundamental AI process,mAP
13,1,Unsupervised Domain Adaptation,Market to Duke,2018-11,SSG,53.4,82.03,31.1,0.48,65.1,0.57,ito:ITO_00115,Fundamental AI process,mAP
14,1,Unsupervised Domain Adaptation,Market to Duke,2020-01,MMT,65.1,100.0,11.7,0.18,65.1,0.7,ito:ITO_00115,Fundamental AI process,mAP
15,1,Unsupervised Domain Adaptation,Duke to MSMT,2017-11,PTGAN,3.3,14.16,3.3,0.14,23.3,0.04,ito:ITO_00115,Fundamental AI process,mAP
16,1,Unsupervised Domain Adaptation,Duke to MSMT,2018-11,SSG,13.3,57.08,10.0,0.43,23.3,0.14,ito:ITO_00115,Fundamental AI process,mAP
17,1,Unsupervised Domain Adaptation,Duke to MSMT,2020-01,MMT,23.3,100.0,10.0,0.43,23.3,0.25,ito:ITO_00115,Fundamental AI process,mAP
18,1,Unsupervised Domain Adaptation,Market to MSMT,2017-11,PTGAN,2.9,12.66,2.9,0.13,22.9,0.03,ito:ITO_00115,Fundamental AI process,mAP
19,1,Unsupervised Domain Adaptation,Market to MSMT,2018-11,SSG,13.2,57.64,10.3,0.45,22.9,0.14,ito:ITO_00115,Fundamental AI process,mAP
20,1,Unsupervised Domain Adaptation,Market to MSMT,2020-01,MMT,22.9,100.0,9.7,0.42,22.9,0.25,ito:ITO_00115,Fundamental AI process,mAP
21,1,Action Recognition,AVA v2.2,2018-12,"SlowFast, 8x8, R101 (Kinetics-400 pretraining)",23.8,86.55,23.8,0.87,27.5,0.25,ito:ITO_00115,Fundamental AI process,mAP
22,1,Action Recognition,AVA v2.2,2018-12,"SlowFast, 8x8 R101+NL (Kinetics-600 pretraining)",27.1,98.55,3.3,0.12,27.5,0.29,ito:ITO_00115,Fundamental AI process,mAP
23,1,Action Recognition,AVA v2.2,2018-12,"SlowFast, 16x8 R101+NL (Kinetics-600 pretraining)",27.5,100.0,0.4,0.01,27.5,0.29,ito:ITO_00115,Fundamental AI process,mAP
24,1,Activity Prediction,ActEV,2019-02,Next,0.192,100.0,0.192,1.0,0.192,0.0,ito:ITO_00115,Fundamental AI process,mAP
0,1,Click-Through Rate Prediction,iPinYou,2016-01,FNN,0.7619,93.21,0.7619,0.93,0.8174,0.01,ito:ITO_00115,Fundamental AI process,AUC
1,1,Click-Through Rate Prediction,iPinYou,2016-11,OPNN,0.8174,100.0,0.1,0.12,0.8174,0.01,ito:ITO_00115,Fundamental AI process,AUC
2,1,Few-Shot Video Object Detection,Few-Shot Video Object Detection,2016-01,FNN,0.7619,93.21,0.7619,0.93,0.8174,0.01,ito:ITO_00115,Fundamental AI process,AUC
3,1,Few-Shot Video Object Detection,Few-Shot Video Object Detection,2016-11,OPNN,0.8174,100.0,0.1,0.12,0.8174,0.01,ito:ITO_00115,Fundamental AI process,AUC
4,1,Click-Through Rate Prediction,Criteo,2016-01,FNN,0.7963,98.03,0.7963,0.98,0.8123,0.01,ito:ITO_00115,Fundamental AI process,AUC
5,1,Click-Through Rate Prediction,Criteo,2016-06,Wide & Deep (LR & DNN),0.7981,98.25,0.0,0.0,0.8123,0.01,ito:ITO_00115,Fundamental AI process,AUC
6,1,Click-Through Rate Prediction,Criteo,2016-11,PNN*,0.7987,98.33,0.0,0.0,0.8123,0.01,ito:ITO_00115,Fundamental AI process,AUC
7,1,Click-Through Rate Prediction,Criteo,2017-03,DeepFM,0.8007,98.57,0.0,0.0,0.8123,0.01,ito:ITO_00115,Fundamental AI process,AUC
8,1,Click-Through Rate Prediction,Criteo,2018-03,xDeepFM,0.8052,99.13,0.0,0.0,0.8123,0.01,ito:ITO_00115,Fundamental AI process,AUC
9,1,Click-Through Rate Prediction,Criteo,2018-10,AutoInt,0.8061,99.24,0.0,0.0,0.8123,0.01,ito:ITO_00115,Fundamental AI process,AUC
10,1,Click-Through Rate Prediction,Criteo,2019-10,Fi-GNN,0.8082,99.5,0.0,0.0,0.8123,0.01,ito:ITO_00115,Fundamental AI process,AUC
11,1,Click-Through Rate Prediction,Criteo,2020-02,Sparse DeepFwFM,0.8123,100.0,0.0,0.0,0.8123,0.01,ito:ITO_00115,Fundamental AI process,AUC
12,1,Sequential skip prediction,Sequential skip prediction,2016-01,FNN,0.7963,98.03,0.7963,0.98,0.8123,0.01,ito:ITO_00115,Fundamental AI process,AUC
13,1,Sequential skip prediction,Sequential skip prediction,2016-06,Wide & Deep (LR & DNN),0.7981,98.25,0.0,0.0,0.8123,0.01,ito:ITO_00115,Fundamental AI process,AUC
14,1,Sequential skip prediction,Sequential skip prediction,2016-11,PNN*,0.7987,98.33,0.0,0.0,0.8123,0.01,ito:ITO_00115,Fundamental AI process,AUC
15,1,Sequential skip prediction,Sequential skip prediction,2017-03,DeepFM,0.8007,98.57,0.0,0.0,0.8123,0.01,ito:ITO_00115,Fundamental AI process,AUC
16,1,Sequential skip prediction,Sequential skip prediction,2018-03,xDeepFM,0.8052,99.13,0.0,0.0,0.8123,0.01,ito:ITO_00115,Fundamental AI process,AUC
17,1,Sequential skip prediction,Sequential skip prediction,2018-10,AutoInt,0.8061,99.24,0.0,0.0,0.8123,0.01,ito:ITO_00115,Fundamental AI process,AUC
18,1,Sequential skip prediction,Sequential skip prediction,2019-10,Fi-GNN,0.8082,99.5,0.0,0.0,0.8123,0.01,ito:ITO_00115,Fundamental AI process,AUC
19,1,Sequential skip prediction,Sequential skip prediction,2020-02,Sparse DeepFwFM,0.8123,100.0,0.0,0.0,0.8123,0.01,ito:ITO_00115,Fundamental AI process,AUC
20,1,Click-Through Rate Prediction,Amazon,2016-06,Wide & Deep,0.8637,97.36,0.8637,0.97,0.8871,0.01,ito:ITO_00115,Fundamental AI process,AUC
21,1,Click-Through Rate Prediction,Amazon,2016-11,PNN,0.8679,97.84,0.0,0.0,0.8871,0.01,ito:ITO_00115,Fundamental AI process,AUC
22,1,Click-Through Rate Prediction,Amazon,2017-03,DeepFM,0.8683,97.88,0.0,0.0,0.8871,0.01,ito:ITO_00115,Fundamental AI process,AUC
23,1,Click-Through Rate Prediction,Amazon,2017-06,DIN + Dice Activation,0.8871,100.0,0.0,0.0,0.8871,0.01,ito:ITO_00115,Fundamental AI process,AUC
24,1,Generalized Zero-Shot Learning,Generalized Zero-Shot Learning,2016-06,Wide & Deep,0.8637,97.36,0.8637,0.97,0.8871,0.01,ito:ITO_00115,Fundamental AI process,AUC
25,1,Generalized Zero-Shot Learning,Generalized Zero-Shot Learning,2016-11,PNN,0.8679,97.84,0.0,0.0,0.8871,0.01,ito:ITO_00115,Fundamental AI process,AUC
26,1,Generalized Zero-Shot Learning,Generalized Zero-Shot Learning,2017-03,DeepFM,0.8683,97.88,0.0,0.0,0.8871,0.01,ito:ITO_00115,Fundamental AI process,AUC
27,1,Generalized Zero-Shot Learning,Generalized Zero-Shot Learning,2017-06,DIN + Dice Activation,0.8871,100.0,0.0,0.0,0.8871,0.01,ito:ITO_00115,Fundamental AI process,AUC
28,1,Click-Through Rate Prediction,Dianping,2016-06,Wide & Deep,0.8361,96.78,0.8361,0.97,0.8639,0.01,ito:ITO_00115,Fundamental AI process,AUC
29,1,Click-Through Rate Prediction,Dianping,2016-11,PNN,0.8445,97.75,0.0,0.0,0.8639,0.01,ito:ITO_00115,Fundamental AI process,AUC
30,1,Click-Through Rate Prediction,Dianping,2017-03,DeepFM,0.8481,98.17,0.0,0.0,0.8639,0.01,ito:ITO_00115,Fundamental AI process,AUC
31,1,Click-Through Rate Prediction,Dianping,2018-03,xDeepFM,0.8639,100.0,0.0,0.0,0.8639,0.01,ito:ITO_00115,Fundamental AI process,AUC
32,1,3D Action Recognition,3D Action Recognition,2016-06,Wide & Deep,0.8361,96.78,0.8361,0.97,0.8639,0.01,ito:ITO_00115,Fundamental AI process,AUC
33,1,3D Action Recognition,3D Action Recognition,2016-11,PNN,0.8445,97.75,0.0,0.0,0.8639,0.01,ito:ITO_00115,Fundamental AI process,AUC
34,1,3D Action Recognition,3D Action Recognition,2017-03,DeepFM,0.8481,98.17,0.0,0.0,0.8639,0.01,ito:ITO_00115,Fundamental AI process,AUC
35,1,3D Action Recognition,3D Action Recognition,2018-03,xDeepFM,0.8639,100.0,0.0,0.0,0.8639,0.01,ito:ITO_00115,Fundamental AI process,AUC
36,1,Abnormal Event Detection In Video,UBI-Fights,2017-08,Adversarial Generator,0.523,100.0,0.523,1.0,0.523,0.01,ito:ITO_00115,Fundamental AI process,AUC
37,1,Abnormal Event Detection In Video,UCSD,2017-08,Adversarial Generator,97.4,100.0,97.4,1.0,97.4,1.0,ito:ITO_00115,Fundamental AI process,AUC
38,1,Semi-supervised Anomaly Detection,UBI-Fights,2017-08,Adversarial Generator,0.533,100.0,0.533,1.0,0.533,0.01,ito:ITO_00115,Fundamental AI process,AUC
39,1,Click-Through Rate Prediction,Book-Crossing,2018-03,RippleNet,0.729,98.78,0.729,0.99,0.738,0.01,ito:ITO_00115,Fundamental AI process,AUC
40,1,Click-Through Rate Prediction,Book-Crossing,2019-03,KGCN-sum,0.738,100.0,0.0,0.0,0.738,0.01,ito:ITO_00115,Fundamental AI process,AUC
41,1,Unsupervised Domain Expansion,Unsupervised Domain Expansion,2018-03,RippleNet,0.729,98.78,0.729,0.99,0.738,0.01,ito:ITO_00115,Fundamental AI process,AUC
42,1,Unsupervised Domain Expansion,Unsupervised Domain Expansion,2019-03,KGCN-sum,0.738,100.0,0.0,0.0,0.738,0.01,ito:ITO_00115,Fundamental AI process,AUC
43,1,Click-Through Rate Prediction,MovieLens 1M,2018-03,RippleNet,0.921,97.47,0.921,0.97,0.9449,0.01,ito:ITO_00115,Fundamental AI process,AUC
44,1,Click-Through Rate Prediction,MovieLens 1M,2019-08,KNI,0.9449,100.0,0.0,0.0,0.9449,0.01,ito:ITO_00115,Fundamental AI process,AUC
45,1,Weakly-Supervised Action Recognition,Weakly-Supervised Action Recognition,2018-03,RippleNet,0.921,97.47,0.921,0.97,0.9449,0.01,ito:ITO_00115,Fundamental AI process,AUC
46,1,Weakly-Supervised Action Recognition,Weakly-Supervised Action Recognition,2019-08,KNI,0.9449,100.0,0.0,0.0,0.9449,0.01,ito:ITO_00115,Fundamental AI process,AUC
47,1,Click-Through Rate Prediction,Children's Book Test Common noun,2019-01,MKR,0.734,100.0,0.734,1.0,0.734,0.01,ito:ITO_00115,Fundamental AI process,AUC
48,1,Generalized Zero Shot skeletal action recognition,Generalized Zero Shot skeletal action recognition,2019-01,MKR,0.734,100.0,0.734,1.0,0.734,0.01,ito:ITO_00115,Fundamental AI process,AUC
49,1,Unsupervised Anomaly Detection,ECG5000,2019-04,VRAE+SVM,0.9836,100.0,0.9836,1.0,0.9836,0.01,ito:ITO_00115,Fundamental AI process,AUC
50,1,Click-Through Rate Prediction,Huawei App Store,2019-04,FGCNN+IPNN,0.9407,100.0,0.9407,1.0,0.9407,0.01,ito:ITO_00115,Fundamental AI process,AUC
51,1,Multi-label zero-shot learning,Multi-label zero-shot learning,2019-04,FGCNN+IPNN,0.9407,100.0,0.9407,1.0,0.9407,0.01,ito:ITO_00115,Fundamental AI process,AUC
52,1,Anomaly Detection,Thyroid,2019-11,DevNet,0.783,100.0,0.783,1.0,0.783,0.01,ito:ITO_00115,Fundamental AI process,AUC
53,1,Anomaly Detection,Census,2019-11,DevNet,0.828,100.0,0.828,1.0,0.828,0.01,ito:ITO_00115,Fundamental AI process,AUC
0,1,Click-Through Rate Prediction,Criteo,2016-01,FNN,0.45738,84.89,0.45738,0.85,0.5388,0.85,ito:ITO_00115,Fundamental AI process,Log\\ Loss
1,1,Click-Through Rate Prediction,Criteo,2016-06,Wide & Deep (LR & DNN),0.46772,86.81,0.0,0.0,0.5388,0.87,ito:ITO_00115,Fundamental AI process,Log\\ Loss
2,1,Click-Through Rate Prediction,Criteo,2019-04,FGCNN+IPNN,0.5388,100.0,0.1,0.19,0.5388,1.0,ito:ITO_00115,Fundamental AI process,Log\\ Loss
3,1,Sequential skip prediction,Sequential skip prediction,2016-01,FNN,0.45738,84.89,0.45738,0.85,0.5388,0.85,ito:ITO_00115,Fundamental AI process,Log\\ Loss
4,1,Sequential skip prediction,Sequential skip prediction,2016-06,Wide & Deep (LR & DNN),0.46772,86.81,0.0,0.0,0.5388,0.87,ito:ITO_00115,Fundamental AI process,Log\\ Loss
5,1,Sequential skip prediction,Sequential skip prediction,2019-04,FGCNN+IPNN,0.5388,100.0,0.1,0.19,0.5388,1.0,ito:ITO_00115,Fundamental AI process,Log\\ Loss
6,1,Click-Through Rate Prediction,Dianping,2016-06,Wide & Deep,0.3364,98.25,0.3364,0.98,0.3424,0.62,ito:ITO_00115,Fundamental AI process,Log\\ Loss
7,1,Click-Through Rate Prediction,Dianping,2016-11,PNN,0.3424,100.0,0.0,0.0,0.3424,0.64,ito:ITO_00115,Fundamental AI process,Log\\ Loss
8,1,3D Action Recognition,3D Action Recognition,2016-06,Wide & Deep,0.3364,98.25,0.3364,0.98,0.3424,0.62,ito:ITO_00115,Fundamental AI process,Log\\ Loss
9,1,3D Action Recognition,3D Action Recognition,2016-11,PNN,0.3424,100.0,0.0,0.0,0.3424,0.64,ito:ITO_00115,Fundamental AI process,Log\\ Loss
10,1,Click-Through Rate Prediction,MovieLens 1M,2018-10,AutoInt,0.3784,100.0,0.3784,1.0,0.3784,0.7,ito:ITO_00115,Fundamental AI process,Log\\ Loss
11,1,Weakly-Supervised Action Recognition,Weakly-Supervised Action Recognition,2018-10,AutoInt,0.3784,100.0,0.3784,1.0,0.3784,0.7,ito:ITO_00115,Fundamental AI process,Log\\ Loss
12,1,Click-Through Rate Prediction,Huawei App Store,2019-04,FGCNN+IPNN,0.1134,100.0,0.1134,1.0,0.1134,0.21,ito:ITO_00115,Fundamental AI process,Log\\ Loss
13,1,Multi-label zero-shot learning,Multi-label zero-shot learning,2019-04,FGCNN+IPNN,0.1134,100.0,0.1134,1.0,0.1134,0.21,ito:ITO_00115,Fundamental AI process,Log\\ Loss
0,1,Dimensionality Reduction,1B Words,2016-03,fst,1000000000.0,100.0,1000000000,1.0,1000000000,1.0,ito:ITO_00115,Fundamental AI process,14\\ gestures\\ accuracy
1,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,MFA-Net,91.3,96.51,91.3,0.97,94.6,0.0,ito:ITO_00115,Fundamental AI process,14\\ gestures\\ accuracy
2,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,STA-Res-TCN,93.6,98.94,2.3,0.02,94.6,0.0,ito:ITO_00115,Fundamental AI process,14\\ gestures\\ accuracy
3,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,94.6,100.0,1.0,0.01,94.6,0.0,ito:ITO_00115,Fundamental AI process,14\\ gestures\\ accuracy
4,1,Feature Engineering,2019_test set,2019-12,CNN,0.98,100.0,0.98,1.0,0.98,0.0,ito:ITO_00115,Fundamental AI process,14\\ gestures\\ accuracy
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,13.0,44.83,13,0.45,29,0.45,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(CV\\ I\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,LSTM,16.0,55.17,3,0.1,29,0.55,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(CV\\ I\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-08,SK-CNN,26.0,89.66,10,0.34,29,0.9,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(CV\\ I\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,29.0,100.0,3,0.1,29,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(CV\\ I\\)
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,LSTM,31.0,43.66,31,0.44,71,0.44,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(CV\\ II\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,33.0,46.48,2,0.03,71,0.46,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(CV\\ II\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-11,TCN,43.0,60.56,10,0.14,71,0.61,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(CV\\ II\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-04,Res-TCN,48.0,67.61,5,0.07,71,0.68,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(CV\\ II\\)
4,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-08,SK-CNN,68.0,95.77,20,0.28,71,0.96,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(CV\\ II\\)
5,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,71.0,100.0,3,0.04,71,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(CV\\ II\\)
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,33.0,57.89,33,0.58,57,0.58,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(AV\\ I\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-11,TCN,43.0,75.44,10,0.18,57,0.75,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(AV\\ I\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-04,Res-TCN,48.0,84.21,5,0.09,57,0.84,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(AV\\ I\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2018-01,ST-GCN,53.0,92.98,5,0.09,57,0.93,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(AV\\ I\\)
4,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,57.0,100.0,4,0.07,57,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(AV\\ I\\)
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,50.0,64.94,50,0.65,77,0.65,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(AV\\ II\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,LSTM,68.0,88.31,18,0.23,77,0.88,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(AV\\ II\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-08,SK-CNN,77.0,100.0,9,0.12,77,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(AV\\ II\\)
0,1,Continuous Control,Cart-Pole Balancing,2016-04,TRPO,4869.8,100.0,4869.8,1.0,4869.8,1.0,ito:ITO_00115,Fundamental AI process,Score
1,1,Continuous Control,Double Inverted Pendulum,2016-04,TRPO,4412.4,100.0,4412.4,1.0,4412.4,0.91,ito:ITO_00115,Fundamental AI process,Score
2,1,Continuous Control,Hopper,2016-04,TRPO,1183.3,100.0,1183.3,1.0,1183.3,0.24,ito:ITO_00115,Fundamental AI process,Score
3,1,Continuous Control,Ant,2016-04,TRPO,730.2,100.0,730.2,1.0,730.2,0.15,ito:ITO_00115,Fundamental AI process,Score
4,1,Continuous Control,Full Humanoid,2016-04,TRPO,287.0,100.0,287,1.0,287,0.06,ito:ITO_00115,Fundamental AI process,Score
5,1,Continuous Control,Inverted Pendulum,2016-04,TRPO,247.2,100.0,247.2,1.0,247.2,0.05,ito:ITO_00115,Fundamental AI process,Score
6,1,Continuous Control,Swimmer,2016-04,TRPO,96.0,100.0,96,1.0,96,0.02,ito:ITO_00115,Fundamental AI process,Score
7,1,Continuous Control,2D Walker,2016-04,TRPO,1353.8,100.0,1353.8,1.0,1353.8,0.28,ito:ITO_00115,Fundamental AI process,Score
8,1,Continuous Control,Half-Cheetah,2016-04,TRPO,1914.0,100.0,1914,1.0,1914,0.39,ito:ITO_00115,Fundamental AI process,Score
9,1,Continuous Control,Simple Humanoid,2016-04,TRPO,269.7,100.0,269.7,1.0,269.7,0.06,ito:ITO_00115,Fundamental AI process,Score
0,1,Temporal Action Localization,J-HMDB-21,2016-04,Actionness,39.9,53.63,39.9,0.54,74.4,0.46,ito:ITO_00115,Fundamental AI process,Frame\\-mAP
1,1,Temporal Action Localization,J-HMDB-21,2016-09,Peng w/ MR,58.5,78.63,18.6,0.25,74.4,0.67,ito:ITO_00115,Fundamental AI process,Frame\\-mAP
2,1,Temporal Action Localization,J-HMDB-21,2017-05,ACT,65.7,88.31,7.2,0.1,74.4,0.75,ito:ITO_00115,Fundamental AI process,Frame\\-mAP
3,1,Temporal Action Localization,J-HMDB-21,2017-05,Faster-RCNN + two-stream I3D conv,73.3,98.52,7.6,0.1,74.4,0.84,ito:ITO_00115,Fundamental AI process,Frame\\-mAP
4,1,Temporal Action Localization,J-HMDB-21,2019-11,YOWO (16-frame),74.4,100.0,1.1,0.01,74.4,0.85,ito:ITO_00115,Fundamental AI process,Frame\\-mAP
5,1,Temporal Action Localization,UCF101-24,2016-09,Peng w/o MR,64.8,74.31,64.8,0.74,87.2,0.74,ito:ITO_00115,Fundamental AI process,Frame\\-mAP
6,1,Temporal Action Localization,UCF101-24,2016-09,Peng w/ MR,65.7,75.34,0.9,0.01,87.2,0.75,ito:ITO_00115,Fundamental AI process,Frame\\-mAP
7,1,Temporal Action Localization,UCF101-24,2017-05,ACT,69.5,79.7,3.8,0.04,87.2,0.8,ito:ITO_00115,Fundamental AI process,Frame\\-mAP
8,1,Temporal Action Localization,UCF101-24,2017-05,Faster-RCNN + two-stream I3D conv,76.3,87.5,6.8,0.08,87.2,0.87,ito:ITO_00115,Fundamental AI process,Frame\\-mAP
9,1,Temporal Action Localization,UCF101-24,2019-11,YOWO (16-frame),87.2,100.0,10.9,0.12,87.2,1.0,ito:ITO_00115,Fundamental AI process,Frame\\-mAP
0,1,Few-Shot Image Classification,Flowers-102,2016-05,Word CNN-RNN (DS-SJE Embedding),59.6,100.0,59.6,1.0,59.6,1.0,ito:ITO_00115,Fundamental AI process,AP50
1,1,Few-Shot Image Classification,CUB-200-2011,2016-05,Word CNN-RNN (DS-SJE Embedding),48.7,100.0,48.7,1.0,48.7,0.82,ito:ITO_00115,Fundamental AI process,AP50
0,1,Mortality Prediction,MIMIC-III,2018-03,Random Forest,0.97,100.0,0.97,1.0,0.97,0.01,ito:ITO_00115,Fundamental AI process,Precision
1,1,Congestive Heart Failure detection,CHF database,2019-07,Inclined Entropy (R-HessELM),98.05,100.0,98.05,1.0,98.05,1.0,ito:ITO_00115,Fundamental AI process,Precision
0,1,Multivariate Time Series Forecasting,MuJoCo,2016-06,RNN GRU-D,5.833,22.04,5.833,0.22,26.463,0.22,ito:ITO_00115,Fundamental AI process,"MSE\\ \\(10\\^\\-2,\\ 50%\\ missing\\)"
1,1,Multivariate Time Series Forecasting,MuJoCo,2019-07,ODE-RNN,26.463,100.0,20.6,0.78,26.463,1.0,ito:ITO_00115,Fundamental AI process,"MSE\\ \\(10\\^\\-2,\\ 50%\\ missing\\)"
0,1,Few-Shot Image Classification,Meta-Dataset Rank,2016-06,Matching Networks,10.5,88.98,10.5,0.89,11.8,0.89,ito:ITO_00115,Fundamental AI process,Mean\\ Rank
1,1,Few-Shot Image Classification,Meta-Dataset Rank,2017-11,Relation Networks,11.8,100.0,1.3,0.11,11.8,1.0,ito:ITO_00115,Fundamental AI process,Mean\\ Rank
0,1,3D Part Segmentation,ShapeNet-Part,2016-06,3D-UNet [Cicek:2016un],84.6,90.87,84.6,0.91,93.1,0.91,ito:ITO_00115,Fundamental AI process,Instance\\ Average\\ IoU
1,1,3D Part Segmentation,ShapeNet-Part,2016-12,SSCNN,84.7,90.98,0.1,0.0,93.1,0.91,ito:ITO_00115,Fundamental AI process,Instance\\ Average\\ IoU
2,1,3D Part Segmentation,ShapeNet-Part,2017-06,SSCN,86.0,92.37,1.3,0.01,93.1,0.92,ito:ITO_00115,Fundamental AI process,Instance\\ Average\\ IoU
3,1,3D Part Segmentation,ShapeNet-Part,2018-01,PointCNN,86.14,92.52,0.1,0.0,93.1,0.93,ito:ITO_00115,Fundamental AI process,Instance\\ Average\\ IoU
4,1,3D Part Segmentation,ShapeNet-Part,2019-04,ConvPoint,93.1,100.0,7.0,0.08,93.1,1.0,ito:ITO_00115,Fundamental AI process,Instance\\ Average\\ IoU
0,1,Domain Adaptation,Synth Objects-to-LINEMOD,2016-08,DSN (DANN),53.27,100.0,53.27,1.0,53.27,1.0,ito:ITO_00115,Fundamental AI process,Mean\\ Angle\\ Error
0,1,Domain Adaptation,Synth Objects-to-LINEMOD,2016-08,DSN (DANN),100.0,100.0,100,1.0,100,1.0,ito:ITO_00115,Fundamental AI process,Classification\\ Accuracy
0,1,Multivariate Time Series Forecasting,USHCN-Daily,2016-09,Sequential VAE,0.83,86.46,0.83,0.86,0.96,0.86,ito:ITO_00115,Fundamental AI process,MSE
1,1,Multivariate Time Series Forecasting,USHCN-Daily,2018-06,NeuralODE-VAE,0.96,100.0,0.1,0.1,0.96,1.0,ito:ITO_00115,Fundamental AI process,MSE
2,1,Multivariate Time Series Forecasting,MIMIC-III,2016-09,Sequential VAE,0.92,100.0,0.92,1.0,0.92,0.96,ito:ITO_00115,Fundamental AI process,MSE
3,1,ECG Denoising,UnoViS_auto2012,2019-03,L1 + RFFT,0.167,100.0,0.167,1.0,0.167,0.17,ito:ITO_00115,Fundamental AI process,MSE
0,1,Multivariate Time Series Forecasting,MIMIC-III,2016-09,Sequential VAE,1.39,100.0,1.39,1.0,1.39,1.0,ito:ITO_00115,Fundamental AI process,NegLL
0,1,Anomaly Detection,CIFAR-10 model detecting CIFAR-10,2016-10,Wide ResNet,54.1,71.0,54.1,0.71,76.2,0.71,ito:ITO_00115,Fundamental AI process,AUPR
1,1,Anomaly Detection,CIFAR-10 model detecting CIFAR-10,2018-12,Wide ResNet + Outlier Exposure,76.2,100.0,22.1,0.29,76.2,1.0,ito:ITO_00115,Fundamental AI process,AUPR
0,1,Metric Learning,CUB-200-2011,2016-10,PDDM Quadruplet,58.3,80.75,58.3,0.81,72.2,0.64,ito:ITO_00115,Fundamental AI process,R\\-at\\-1
1,1,Metric Learning,CUB-200-2011,2016-11,HDC,60.7,84.07,2.4,0.03,72.2,0.67,ito:ITO_00115,Fundamental AI process,R\\-at\\-1
2,1,Metric Learning,CUB-200-2011,2017-06,ResNet-50 + Margin,63.6,88.09,2.9,0.04,72.2,0.7,ito:ITO_00115,Fundamental AI process,R\\-at\\-1
3,1,Metric Learning,CUB-200-2011,2019-08,ABE + HORDE,66.8,92.52,3.2,0.04,72.2,0.73,ito:ITO_00115,Fundamental AI process,R\\-at\\-1
4,1,Metric Learning,CUB-200-2011,2020-03,ResNet-50 + Cross-Entropy,69.2,95.84,2.4,0.03,72.2,0.76,ito:ITO_00115,Fundamental AI process,R\\-at\\-1
5,1,Metric Learning,CUB-200-2011,2020-04,ProxyNCA++,72.2,100.0,3.0,0.04,72.2,0.79,ito:ITO_00115,Fundamental AI process,R\\-at\\-1
6,1,Metric Learning,CARS196,2017-06,ResNet-50 + Margin,79.6,88.35,79.6,0.88,90.1,0.88,ito:ITO_00115,Fundamental AI process,R\\-at\\-1
7,1,Metric Learning,CARS196,2018-04,ABE-8-512,85.2,94.56,5.6,0.06,90.1,0.94,ito:ITO_00115,Fundamental AI process,R\\-at\\-1
8,1,Metric Learning,CARS196,2019-08,ABE + HORDE,88.0,97.67,2.8,0.03,90.1,0.97,ito:ITO_00115,Fundamental AI process,R\\-at\\-1
9,1,Metric Learning,CARS196,2020-03,ResNet-50 + Cross-Entropy,89.3,99.11,1.3,0.01,90.1,0.98,ito:ITO_00115,Fundamental AI process,R\\-at\\-1
10,1,Metric Learning,CARS196,2020-04,ProxyNCA++,90.1,100.0,0.8,0.01,90.1,0.99,ito:ITO_00115,Fundamental AI process,R\\-at\\-1
11,1,Metric Learning,Stanford Online Products,2020-03,ResNet-50 + Cross-Entropy,81.1,99.63,81.1,1.0,81.4,0.89,ito:ITO_00115,Fundamental AI process,R\\-at\\-1
12,1,Metric Learning,Stanford Online Products,2020-04,ProxyNCA++,81.4,100.0,0.3,0.0,81.4,0.9,ito:ITO_00115,Fundamental AI process,R\\-at\\-1
13,1,Metric Learning,In-Shop,2020-03,ResNet-50 + Cross-Entropy,90.6,99.67,90.6,1.0,90.9,1.0,ito:ITO_00115,Fundamental AI process,R\\-at\\-1
14,1,Metric Learning,In-Shop,2020-04,ProxyNCA++,90.9,100.0,0.3,0.0,90.9,1.0,ito:ITO_00115,Fundamental AI process,R\\-at\\-1
0,1,Neural Architecture Search,CIFAR-10 Image Classification,2016-11,NASNet-A + c/o,2.4,83.04,2.4,0.83,2.89,0.83,ito:ITO_00115,Fundamental AI process,Percentage\\ error
1,1,Neural Architecture Search,CIFAR-10 Image Classification,2017-08,DARTS + c/o,2.83,97.92,0.4,0.14,2.89,0.98,ito:ITO_00115,Fundamental AI process,Percentage\\ error
2,1,Neural Architecture Search,CIFAR-10 Image Classification,2018-02,ENAS + c/o,2.89,100.0,0.1,0.03,2.89,1.0,ito:ITO_00115,Fundamental AI process,Percentage\\ error
0,1,Neural Architecture Search,CIFAR-10 Image Classification,2016-11,NASNet-A + c/o,27600000.0,19.09,27600000.0,0.19,144600000.0,0.19,ito:ITO_00115,Fundamental AI process,Params
1,1,Neural Architecture Search,CIFAR-10 Image Classification,2018-02,AmoebaNet-B + c/o,34900000.0,24.14,7300000.0,0.05,144600000.0,0.24,ito:ITO_00115,Fundamental AI process,Params
2,1,Neural Architecture Search,CIFAR-10 Image Classification,2018-08,NAONet + c/o,144600000.0,100.0,109700000.0,0.76,144600000.0,1.0,ito:ITO_00115,Fundamental AI process,Params
3,1,Neural Architecture Search,ImageNet,2018-06,DARTS,4900000.0,73.13,4900000,0.73,6700000,0.03,ito:ITO_00115,Fundamental AI process,Params
4,1,Neural Architecture Search,ImageNet,2018-12,ProxylesNAS,5100000.0,76.12,200000,0.03,6700000,0.04,ito:ITO_00115,Fundamental AI process,Params
5,1,Neural Architecture Search,ImageNet,2019-03,AlphaX-1,5400000.0,80.6,300000,0.04,6700000,0.04,ito:ITO_00115,Fundamental AI process,Params
6,1,Neural Architecture Search,ImageNet,2019-08,SCARLET-C,6000000.0,89.55,600000,0.09,6700000,0.04,ito:ITO_00115,Fundamental AI process,Params
7,1,Neural Architecture Search,ImageNet,2019-08,SCARLET-B,6500000.0,97.01,500000,0.07,6700000,0.04,ito:ITO_00115,Fundamental AI process,Params
8,1,Neural Architecture Search,ImageNet,2019-08,SCARLET-A,6700000.0,100.0,200000,0.03,6700000,0.05,ito:ITO_00115,Fundamental AI process,Params
0,1,3D Part Segmentation,ShapeNet-Part,2016-12,PointNet,80.4,94.48,80.4,0.94,85.1,0.94,ito:ITO_00115,Fundamental AI process,Class\\ Average\\ IoU
1,1,3D Part Segmentation,ShapeNet-Part,2016-12,SSCNN,82.0,96.36,1.6,0.02,85.1,0.96,ito:ITO_00115,Fundamental AI process,Class\\ Average\\ IoU
2,1,3D Part Segmentation,ShapeNet-Part,2017-11,SGPN,82.8,97.3,0.8,0.01,85.1,0.97,ito:ITO_00115,Fundamental AI process,Class\\ Average\\ IoU
3,1,3D Part Segmentation,ShapeNet-Part,2018-01,PointCNN,84.6,99.41,1.8,0.02,85.1,0.99,ito:ITO_00115,Fundamental AI process,Class\\ Average\\ IoU
4,1,3D Part Segmentation,ShapeNet-Part,2019-04,KPConv,85.1,100.0,0.5,0.01,85.1,1.0,ito:ITO_00115,Fundamental AI process,Class\\ Average\\ IoU
0,1,Semantic Segmentation,S3DIS Area5,2016-12,PointNet,49.0,67.31,49.0,0.67,72.8,0.56,ito:ITO_00115,Fundamental AI process,mAcc
1,1,Semantic Segmentation,S3DIS Area5,2017-10,SegCloud,57.4,78.85,8.4,0.12,72.8,0.66,ito:ITO_00115,Fundamental AI process,mAcc
2,1,Semantic Segmentation,S3DIS Area5,2017-11,SPG,66.5,91.35,9.1,0.12,72.8,0.76,ito:ITO_00115,Fundamental AI process,mAcc
3,1,Semantic Segmentation,S3DIS Area5,2019-04,MinkowskiNet,71.7,98.49,5.2,0.07,72.8,0.82,ito:ITO_00115,Fundamental AI process,mAcc
4,1,Semantic Segmentation,S3DIS Area5,2019-04,KPConv,72.8,100.0,1.1,0.02,72.8,0.84,ito:ITO_00115,Fundamental AI process,mAcc
5,1,Semantic Segmentation,S3DIS,2016-12,PointNet,66.2,80.73,66.2,0.81,82.0,0.76,ito:ITO_00115,Fundamental AI process,mAcc
6,1,Semantic Segmentation,S3DIS,2017-11,SPG,73.0,89.02,6.8,0.08,82.0,0.84,ito:ITO_00115,Fundamental AI process,mAcc
7,1,Semantic Segmentation,S3DIS,2018-12,PointCNN,75.6,92.2,2.6,0.03,82.0,0.87,ito:ITO_00115,Fundamental AI process,mAcc
8,1,Semantic Segmentation,S3DIS,2019-04,KPConv,79.1,96.46,3.5,0.04,82.0,0.91,ito:ITO_00115,Fundamental AI process,mAcc
9,1,Semantic Segmentation,S3DIS,2019-11,RandLA-Net,82.0,100.0,2.9,0.04,82.0,0.94,ito:ITO_00115,Fundamental AI process,mAcc
10,1,3D Semantic Segmentation,S3DIS,2019-07,PVCNN++ (1xC) volumetric,87.12,100.0,87.12,1.0,87.12,1.0,ito:ITO_00115,Fundamental AI process,mAcc
0,1,Semantic Segmentation,S3DIS,2016-12,PointNet,78.5,88.4,78.5,0.88,88.8,0.83,ito:ITO_00115,Fundamental AI process,oAcc
1,1,Semantic Segmentation,S3DIS,2017-11,SPG,85.5,96.28,7.0,0.08,88.8,0.9,ito:ITO_00115,Fundamental AI process,oAcc
2,1,Semantic Segmentation,S3DIS,2018-12,PointCNN,88.1,99.21,2.6,0.03,88.8,0.93,ito:ITO_00115,Fundamental AI process,oAcc
3,1,Semantic Segmentation,S3DIS,2019-04,ConvPoint,88.8,100.0,0.7,0.01,88.8,0.94,ito:ITO_00115,Fundamental AI process,oAcc
4,1,Semantic Segmentation,Semantic3D,2017-11,SPG,92.9,98.0,92.9,0.98,94.8,0.98,ito:ITO_00115,Fundamental AI process,oAcc
5,1,Semantic Segmentation,Semantic3D,2019-11,RandLA-Net,94.8,100.0,1.9,0.02,94.8,1.0,ito:ITO_00115,Fundamental AI process,oAcc
6,1,Semantic Segmentation,S3DIS Area5,2017-11,SPG,86.38,100.0,86.38,1.0,86.38,0.91,ito:ITO_00115,Fundamental AI process,oAcc
0,1,Semantic Segmentation,ADE20K,2016-12,PSPNet,0.5538,0.98,0.5538,0.01,56.41,0.01,ito:ITO_00115,Fundamental AI process,Test\\ Score
1,1,Semantic Segmentation,ADE20K,2016-12,PSPNet,55.38,98.17,54.8,0.97,56.41,0.98,ito:ITO_00115,Fundamental AI process,Test\\ Score
2,1,Semantic Segmentation,ADE20K,2018-03,EncNet,55.67,98.69,0.3,0.01,56.41,0.99,ito:ITO_00115,Fundamental AI process,Test\\ Score
3,1,Semantic Segmentation,ADE20K,2019-03,EncNet + JPU,55.84,98.99,0.2,0.0,56.41,0.99,ito:ITO_00115,Fundamental AI process,Test\\ Score
4,1,Semantic Segmentation,ADE20K,2019-11,LaU-regression-loss,56.32,99.84,0.5,0.01,56.41,1.0,ito:ITO_00115,Fundamental AI process,Test\\ Score
5,1,Semantic Segmentation,ADE20K,2019-11,LaU-offset-loss,56.41,100.0,0.1,0.0,56.41,1.0,ito:ITO_00115,Fundamental AI process,Test\\ Score
0,1,Real-Time Semantic Segmentation,NYU Depth v2,2016-12,PSPNet18,19.0,26.39,19,0.26,72,0.26,ito:ITO_00115,Fundamental AI process,Speed\\(ms/f\\)
1,1,Real-Time Semantic Segmentation,NYU Depth v2,2016-12,PSPNet50,47.0,65.28,28,0.39,72,0.65,ito:ITO_00115,Fundamental AI process,Speed\\(ms/f\\)
2,1,Real-Time Semantic Segmentation,NYU Depth v2,2016-12,PSPNet101,72.0,100.0,25,0.35,72,1.0,ito:ITO_00115,Fundamental AI process,Speed\\(ms/f\\)
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,85.5,92.53,85.5,0.93,92.4,0.93,ito:ITO_00115,Fundamental AI process,PCK\\-at\\-0\\.5
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,91.4,98.92,5.9,0.06,92.4,0.99,ito:ITO_00115,Fundamental AI process,PCK\\-at\\-0\\.5
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,92.4,100.0,1.0,0.01,92.4,1.0,ito:ITO_00115,Fundamental AI process,PCK\\-at\\-0\\.5
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,45.2,77.4,45.2,0.77,58.4,0.77,ito:ITO_00115,Fundamental AI process,PCK\\-at\\-0\\.1
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,58.4,100.0,13.2,0.23,58.4,1.0,ito:ITO_00115,Fundamental AI process,PCK\\-at\\-0\\.1
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,62.9,80.54,62.9,0.81,78.1,0.81,ito:ITO_00115,Fundamental AI process,PCK\\-at\\-0\\.2
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,69.6,89.12,6.7,0.09,78.1,0.89,ito:ITO_00115,Fundamental AI process,PCK\\-at\\-0\\.2
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,78.1,100.0,8.5,0.11,78.1,1.0,ito:ITO_00115,Fundamental AI process,PCK\\-at\\-0\\.2
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,73.5,85.56,73.5,0.86,85.9,0.86,ito:ITO_00115,Fundamental AI process,PCK\\-at\\-0\\.3
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,80.8,94.06,7.3,0.08,85.9,0.94,ito:ITO_00115,Fundamental AI process,PCK\\-at\\-0\\.3
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,85.9,100.0,5.1,0.06,85.9,1.0,ito:ITO_00115,Fundamental AI process,PCK\\-at\\-0\\.3
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,80.6,89.76,80.6,0.9,89.8,0.9,ito:ITO_00115,Fundamental AI process,PCK\\-at\\-0\\.4
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,87.5,97.44,6.9,0.08,89.8,0.97,ito:ITO_00115,Fundamental AI process,PCK\\-at\\-0\\.4
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,89.8,100.0,2.3,0.03,89.8,1.0,ito:ITO_00115,Fundamental AI process,PCK\\-at\\-0\\.4
0,1,Dialog Generation,Amazon-5,2017-01,mm,5.0,100.0,5,1.0,5,1.0,ito:ITO_00115,Fundamental AI process,1\\ in\\ 10\\ R\\-at\\-2
0,1,Semantic Segmentation,ScanNet,2017-02,ScanNet,0.306,41.69,0.306,0.42,0.734,0.0,ito:ITO_00115,Fundamental AI process,3DIoU
1,1,Semantic Segmentation,ScanNet,2017-06,PointNet++,0.339,46.19,0.0,0.0,0.734,0.0,ito:ITO_00115,Fundamental AI process,3DIoU
2,1,Semantic Segmentation,ScanNet,2017-11,SparseConvNet,0.725,98.77,0.4,0.54,0.734,0.01,ito:ITO_00115,Fundamental AI process,3DIoU
3,1,Semantic Segmentation,ScanNet,2019-04,MinkowskiNet,0.734,100.0,0.0,0.0,0.734,0.01,ito:ITO_00115,Fundamental AI process,3DIoU
4,1,Scene Segmentation,ScanNet,2019-04,KPConv,68.6,100.0,68.6,1.0,68.6,1.0,ito:ITO_00115,Fundamental AI process,3DIoU
0,1,Temporal Action Localization,THUMOS’14,2017-03,CDC,7.9,37.98,7.9,0.38,20.8,0.33,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.7
1,1,Temporal Action Localization,THUMOS’14,2017-05,CBR-TS,9.9,47.6,2.0,0.1,20.8,0.42,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.7
2,1,Temporal Action Localization,THUMOS’14,2018-04,TAL-Net,20.8,100.0,10.9,0.52,20.8,0.88,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.7
3,1,Temporal Action Localization,ActivityNet-1.3,2019-08,3C-Net,23.7,100.0,23.7,1.0,23.7,1.0,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.7
4,1,Temporal Action Localization,ActivityNet-1.2,2020-01,DeepMetricLearner,16.3,100.0,16.3,1.0,16.3,0.69,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.7
0,1,Temporal Action Localization,THUMOS’14,2017-03,CDC,13.1,38.76,13.1,0.39,33.8,0.39,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.6
1,1,Temporal Action Localization,THUMOS’14,2017-05,CBR-TS,19.1,56.51,6.0,0.18,33.8,0.57,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.6
2,1,Temporal Action Localization,THUMOS’14,2018-04,TAL-Net,33.8,100.0,14.7,0.43,33.8,1.0,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.6
0,1,Weakly Supervised Action Localization,THUMOS 2014,2017-03,UntrimmedNets,13.7,50.74,13.7,0.51,27.0,0.51,ito:ITO_00115,Fundamental AI process,MAP
1,1,Weakly Supervised Action Localization,THUMOS 2014,2017-12,STPN,16.9,62.59,3.2,0.12,27.0,0.63,ito:ITO_00115,Fundamental AI process,MAP
2,1,Weakly Supervised Action Localization,THUMOS 2014,2018-07,W-TALC,22.8,84.44,5.9,0.22,27.0,0.84,ito:ITO_00115,Fundamental AI process,MAP
3,1,Weakly Supervised Action Localization,THUMOS 2014,2019-06,CMCS,23.1,85.56,0.3,0.01,27.0,0.86,ito:ITO_00115,Fundamental AI process,MAP
4,1,Weakly Supervised Action Localization,THUMOS 2014,2019-10,TSM,24.5,90.74,1.4,0.05,27.0,0.91,ito:ITO_00115,Fundamental AI process,MAP
5,1,Weakly Supervised Action Localization,THUMOS 2014,2019-11,BaS-Net,27.0,100.0,2.5,0.09,27.0,1.0,ito:ITO_00115,Fundamental AI process,MAP
6,1,Quantization,CIFAR-10,2019-02,DTQ,0.792,100.0,0.792,1.0,0.792,0.03,ito:ITO_00115,Fundamental AI process,MAP
0,1,Panoptic Segmentation,Cityscapes val,2017-03,Mask R-CNN+COCO,54.0,85.44,54.0,0.85,63.2,0.85,ito:ITO_00115,Fundamental AI process,PQth
1,1,Panoptic Segmentation,Cityscapes val,2018-12,"TASCNet (ResNet-50, multi-scale)",56.1,88.77,2.1,0.03,63.2,0.89,ito:ITO_00115,Fundamental AI process,PQth
2,1,Panoptic Segmentation,Cityscapes val,2019-01,"UPSNet (ResNet-101, multiscale)",57.6,91.14,1.5,0.02,63.2,0.91,ito:ITO_00115,Fundamental AI process,PQth
3,1,Panoptic Segmentation,Cityscapes val,2019-09,AdaptIS (ResNeXt-101),58.7,92.88,1.1,0.02,63.2,0.93,ito:ITO_00115,Fundamental AI process,PQth
4,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS,63.2,100.0,4.5,0.07,63.2,1.0,ito:ITO_00115,Fundamental AI process,PQth
5,1,Panoptic Segmentation,COCO test-dev,2018-09,JSIS-Net (ResNet-50),29.6,53.05,29.6,0.53,55.8,0.47,ito:ITO_00115,Fundamental AI process,PQth
6,1,Panoptic Segmentation,COCO test-dev,2018-12,AUNet (ResNeXt-152-FPN),55.8,100.0,26.2,0.47,55.8,0.88,ito:ITO_00115,Fundamental AI process,PQth
0,1,Panoptic Segmentation,Cityscapes test,2017-04,Dynamically Instantiated Network,55.4,84.07,55.4,0.84,65.9,0.82,ito:ITO_00115,Fundamental AI process,PQ
1,1,Panoptic Segmentation,Cityscapes test,2019-10,Panoptic-Deeplab,65.5,99.39,10.1,0.15,65.9,0.97,ito:ITO_00115,Fundamental AI process,PQ
2,1,Panoptic Segmentation,Cityscapes test,2020-04,EfficientPS,65.9,100.0,0.4,0.01,65.9,0.98,ito:ITO_00115,Fundamental AI process,PQ
3,1,Panoptic Segmentation,Cityscapes val,2018-01,MRCNN + PSPNet (ResNet-101),61.2,90.94,61.2,0.91,67.3,0.91,ito:ITO_00115,Fundamental AI process,PQ
4,1,Panoptic Segmentation,Cityscapes val,2019-01,"UPSNet (ResNet-101, multiscale)",61.8,91.83,0.6,0.01,67.3,0.92,ito:ITO_00115,Fundamental AI process,PQ
5,1,Panoptic Segmentation,Cityscapes val,2019-09,AdaptIS (ResNeXt-101),62.0,92.12,0.2,0.0,67.3,0.92,ito:ITO_00115,Fundamental AI process,PQ
6,1,Panoptic Segmentation,Cityscapes val,2019-11,Panoptic-DeepLab (X71),64.1,95.25,2.1,0.03,67.3,0.95,ito:ITO_00115,Fundamental AI process,PQ
7,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS,67.3,100.0,3.2,0.05,67.3,1.0,ito:ITO_00115,Fundamental AI process,PQ
8,1,Panoptic Segmentation,COCO panoptic,2018-01,MobileNetV2,35.2,81.86,35.2,0.82,43.0,0.52,ito:ITO_00115,Fundamental AI process,PQ
9,1,Panoptic Segmentation,COCO panoptic,2019-01,Panoptic-FPN-ResNet-101,43.0,100.0,7.8,0.18,43.0,0.64,ito:ITO_00115,Fundamental AI process,PQ
10,1,Panoptic Segmentation,COCO test-dev,2018-09,JSIS-Net (ResNet-50),27.2,56.9,27.2,0.57,47.8,0.4,ito:ITO_00115,Fundamental AI process,PQ
11,1,Panoptic Segmentation,COCO test-dev,2018-12,AUNet (ResNeXt-152-FPN),46.5,97.28,19.3,0.4,47.8,0.69,ito:ITO_00115,Fundamental AI process,PQ
12,1,Panoptic Segmentation,COCO test-dev,2019-01,UPSNet (ResNet-101-FPN),46.6,97.49,0.1,0.0,47.8,0.69,ito:ITO_00115,Fundamental AI process,PQ
13,1,Panoptic Segmentation,COCO test-dev,2019-11,SOGNet (ResNet-101-FPN),47.8,100.0,1.2,0.03,47.8,0.71,ito:ITO_00115,Fundamental AI process,PQ
14,1,Panoptic Segmentation,Mapillary val,2018-09,JSIS-Net (ResNet-50),35.9,88.64,35.9,0.89,40.5,0.53,ito:ITO_00115,Fundamental AI process,PQ
15,1,Panoptic Segmentation,Mapillary val,2019-09,AdaptIS (ResNeXt-101),40.3,99.51,4.4,0.11,40.5,0.6,ito:ITO_00115,Fundamental AI process,PQ
16,1,Panoptic Segmentation,Mapillary val,2019-11,Panoptic-DeepLab (X71),40.5,100.0,0.2,0.0,40.5,0.6,ito:ITO_00115,Fundamental AI process,PQ
17,1,Panoptic Segmentation,KITTI Panoptic Segmentation,2019-01,Panoptic FPN,39.3,89.93,39.3,0.9,43.7,0.58,ito:ITO_00115,Fundamental AI process,PQ
18,1,Panoptic Segmentation,KITTI Panoptic Segmentation,2019-01,UPSNet,39.9,91.3,0.6,0.01,43.7,0.59,ito:ITO_00115,Fundamental AI process,PQ
19,1,Panoptic Segmentation,KITTI Panoptic Segmentation,2019-05,Seamless,42.2,96.57,2.3,0.05,43.7,0.63,ito:ITO_00115,Fundamental AI process,PQ
20,1,Panoptic Segmentation,KITTI Panoptic Segmentation,2020-04,EfficientPS,43.7,100.0,1.5,0.03,43.7,0.65,ito:ITO_00115,Fundamental AI process,PQ
21,1,Panoptic Segmentation,Indian Driving Dataset,2019-01,Panoptic FPN,46.7,91.39,46.7,0.91,51.1,0.69,ito:ITO_00115,Fundamental AI process,PQ
22,1,Panoptic Segmentation,Indian Driving Dataset,2019-01,UPSNet,47.1,92.17,0.4,0.01,51.1,0.7,ito:ITO_00115,Fundamental AI process,PQ
23,1,Panoptic Segmentation,Indian Driving Dataset,2019-05,Seamless,48.5,94.91,1.4,0.03,51.1,0.72,ito:ITO_00115,Fundamental AI process,PQ
24,1,Panoptic Segmentation,Indian Driving Dataset,2020-04,EfficientPS,51.1,100.0,2.6,0.05,51.1,0.76,ito:ITO_00115,Fundamental AI process,PQ
0,1,Entity Disambiguation,WNED-CWEB,2017-04,Global,77.9,98.73,77.9,0.99,78.9,0.87,ito:ITO_00115,Fundamental AI process,Micro\\-F1
1,1,Entity Disambiguation,WNED-CWEB,2019-09,confidence-order,78.9,100.0,1.0,0.01,78.9,0.88,ito:ITO_00115,Fundamental AI process,Micro\\-F1
2,1,Outlier Interpretation,Outlier Interpretation,2017-04,Global,77.9,98.73,77.9,0.99,78.9,0.87,ito:ITO_00115,Fundamental AI process,Micro\\-F1
3,1,Outlier Interpretation,Outlier Interpretation,2019-09,confidence-order,78.9,100.0,1.0,0.01,78.9,0.88,ito:ITO_00115,Fundamental AI process,Micro\\-F1
4,1,Multi-Label Text Classification,RCV1-v2,2020-02,MAGNET,88.5,100.0,88.5,1.0,88.5,0.98,ito:ITO_00115,Fundamental AI process,Micro\\-F1
5,1,Multi-Label Text Classification,Reuters-21578,2020-02,MAGNET,89.9,100.0,89.9,1.0,89.9,1.0,ito:ITO_00115,Fundamental AI process,Micro\\-F1
6,1,Multi-Label Text Classification,Slashdot,2020-02,MAGNET,56.8,100.0,56.8,1.0,56.8,0.63,ito:ITO_00115,Fundamental AI process,Micro\\-F1
0,1,Skeleton Based Action Recognition,PKU-MMD,2017-04,Li et al. [[Li et al.2017b]],90.4,97.31,90.4,0.97,92.9,0.97,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.50\\ \\(CS\\)
1,1,Skeleton Based Action Recognition,PKU-MMD,2018-04,HCN,92.6,99.68,2.2,0.02,92.9,1.0,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.50\\ \\(CS\\)
2,1,Skeleton Based Action Recognition,PKU-MMD,2019-09,RF-Action,92.9,100.0,0.3,0.0,92.9,1.0,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.50\\ \\(CS\\)
0,1,Skeleton Based Action Recognition,PKU-MMD,2017-04,Li et al. [[Li et al.2017b]],93.7,99.26,93.7,0.99,94.4,0.99,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.50\\ \\(CV\\)
1,1,Skeleton Based Action Recognition,PKU-MMD,2018-04,HCN,94.2,99.79,0.5,0.01,94.4,1.0,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.50\\ \\(CV\\)
2,1,Skeleton Based Action Recognition,PKU-MMD,2019-09,RF-Action,94.4,100.0,0.2,0.0,94.4,1.0,ito:ITO_00115,Fundamental AI process,mAP\\-at\\-0\\.50\\ \\(CV\\)
0,1,Blood pressure estimation,Multi-day Continuous BP Prediction,2017-05,Deep RNN,3.73,100.0,3.73,1.0,3.73,1.0,ito:ITO_00115,Fundamental AI process,RMSE
0,1,Blood pressure estimation,MIMIC-III,2017-05,Deep RNN,8.54,90.56,8.54,0.91,9.43,0.91,ito:ITO_00115,Fundamental AI process,MAE\\ for\\ SBP\\ \\[mmHg\\]
1,1,Blood pressure estimation,MIMIC-III,2019-08,"ResNet (raw PPG + PPG’ + PPG”, with personalization)",9.43,100.0,0.9,0.1,9.43,1.0,ito:ITO_00115,Fundamental AI process,MAE\\ for\\ SBP\\ \\[mmHg\\]
0,1,Blood pressure estimation,MIMIC-III,2017-05,Deep RNN,6.7,97.38,6.7,0.97,6.88,0.97,ito:ITO_00115,Fundamental AI process,MAE\\ for\\ DBP\\ \\[mmHg\\]
1,1,Blood pressure estimation,MIMIC-III,2019-08,"ResNet (raw PPG + PPG’ + PPG”, with personalization)",6.88,100.0,0.2,0.03,6.88,1.0,ito:ITO_00115,Fundamental AI process,MAE\\ for\\ DBP\\ \\[mmHg\\]
0,1,Density Estimation,CIFAR-10,2017-05,MAF,3049.0,100.0,3049,1.0,3049,1.0,ito:ITO_00115,Fundamental AI process,Log\\-likelihood
1,1,Density Estimation,UCI POWER,2017-05,MADE MoG,0.4,65.57,0.4,0.66,0.61,0.0,ito:ITO_00115,Fundamental AI process,Log\\-likelihood
2,1,Density Estimation,UCI POWER,2018-10,FFJORD,0.46,75.41,0.1,0.16,0.61,0.0,ito:ITO_00115,Fundamental AI process,Log\\-likelihood
3,1,Density Estimation,UCI POWER,2019-04,B-NAF,0.61,100.0,0.1,0.16,0.61,0.0,ito:ITO_00115,Fundamental AI process,Log\\-likelihood
4,1,Density Estimation,UCI GAS,2017-05,MADE MoG,8.47,70.23,8.47,0.7,12.06,0.0,ito:ITO_00115,Fundamental AI process,Log\\-likelihood
5,1,Density Estimation,UCI GAS,2018-10,FFJORD,8.59,71.23,0.1,0.01,12.06,0.0,ito:ITO_00115,Fundamental AI process,Log\\-likelihood
6,1,Density Estimation,UCI GAS,2019-04,B-NAF,12.06,100.0,3.5,0.29,12.06,0.0,ito:ITO_00115,Fundamental AI process,Log\\-likelihood
7,1,Density Estimation,BSDS300,2017-05,MADE MoG,153.71,97.68,153.71,0.98,157.36,0.05,ito:ITO_00115,Fundamental AI process,Log\\-likelihood
8,1,Density Estimation,BSDS300,2019-04,B-NAF,157.36,100.0,3.7,0.02,157.36,0.05,ito:ITO_00115,Fundamental AI process,Log\\-likelihood
0,1,Action Recognition,AVA v2.1,2017-05,S3D-G w/ ResNet RPN (Kinetics-400 pretraining(,22.0,77.74,22.0,0.78,28.3,0.78,ito:ITO_00115,Fundamental AI process,mAP\\ \\(Val\\)
1,1,Action Recognition,AVA v2.1,2018-12,I3D Tx HighRes,27.6,97.53,5.6,0.2,28.3,0.98,ito:ITO_00115,Fundamental AI process,mAP\\ \\(Val\\)
2,1,Action Recognition,AVA v2.1,2018-12,"SlowFast++ (Kinetics-600 pretraining, NL)",28.3,100.0,0.7,0.02,28.3,1.0,ito:ITO_00115,Fundamental AI process,mAP\\ \\(Val\\)
3,1,Action Recognition In Videos,AVA v2.1,2018-07,ARCN,17.4,61.7,17.4,0.62,28.2,0.61,ito:ITO_00115,Fundamental AI process,mAP\\ \\(Val\\)
4,1,Action Recognition In Videos,AVA v2.1,2018-12,I3D Tx HighRes,27.6,97.87,10.2,0.36,28.2,0.98,ito:ITO_00115,Fundamental AI process,mAP\\ \\(Val\\)
5,1,Action Recognition In Videos,AVA v2.1,2018-12,SlowFast,28.2,100.0,0.6,0.02,28.2,1.0,ito:ITO_00115,Fundamental AI process,mAP\\ \\(Val\\)
0,1,Temporal Action Localization,J-HMDB-21,2017-05,Faster-RCNN + two-stream I3D conv,78.6,91.72,78.6,0.92,85.7,0.92,ito:ITO_00115,Fundamental AI process,Video\\-mAP\\ 0\\.5
1,1,Temporal Action Localization,J-HMDB-21,2019-11,YOWO (16-frame),85.7,100.0,7.1,0.08,85.7,1.0,ito:ITO_00115,Fundamental AI process,Video\\-mAP\\ 0\\.5
2,1,Temporal Action Localization,UCF101-24,2017-05,Faster-RCNN + two-stream I3D conv,59.9,100.0,59.9,1.0,59.9,0.7,ito:ITO_00115,Fundamental AI process,Video\\-mAP\\ 0\\.5
0,1,Action Recognition In Videos,Something-Something V2,2017-06,model3D_1 with left-right augmentation and fps jitter,80.46,88.03,80.46,0.88,91.4,0.81,ito:ITO_00115,Fundamental AI process,Top\\-5\\ Accuracy
1,1,Action Recognition In Videos,Something-Something V2,2017-11,2-Stream TRN,83.06,90.88,2.6,0.03,91.4,0.84,ito:ITO_00115,Fundamental AI process,Top\\-5\\ Accuracy
2,1,Action Recognition In Videos,Something-Something V2,2018-11,TSM (RGB + Flow),91.3,99.89,8.2,0.09,91.4,0.92,ito:ITO_00115,Fundamental AI process,Top\\-5\\ Accuracy
3,1,Action Recognition In Videos,Something-Something V2,2019-08,TRG (Inception-V3),91.4,100.0,0.1,0.0,91.4,0.92,ito:ITO_00115,Fundamental AI process,Top\\-5\\ Accuracy
4,1,Action Recognition,Something-Something V2,2017-06,model3D_1 with left-right augmentation and fps jitter,80.46,88.03,80.46,0.88,91.4,0.81,ito:ITO_00115,Fundamental AI process,Top\\-5\\ Accuracy
5,1,Action Recognition,Something-Something V2,2017-11,2-Stream TRN,83.06,90.88,2.6,0.03,91.4,0.84,ito:ITO_00115,Fundamental AI process,Top\\-5\\ Accuracy
6,1,Action Recognition,Something-Something V2,2018-11,TSM (RGB + Flow),91.3,99.89,8.2,0.09,91.4,0.92,ito:ITO_00115,Fundamental AI process,Top\\-5\\ Accuracy
7,1,Action Recognition,Something-Something V2,2019-08,TRG (Inception-V3),91.4,100.0,0.1,0.0,91.4,0.92,ito:ITO_00115,Fundamental AI process,Top\\-5\\ Accuracy
8,1,Action Recognition In Videos,EgoGesture,2020-04,TSM+W3,99.2,100.0,99.2,1.0,99.2,1.0,ito:ITO_00115,Fundamental AI process,Top\\-5\\ Accuracy
9,1,Action Recognition,EgoGesture,2020-04,TSM+W3,99.2,100.0,99.2,1.0,99.2,1.0,ito:ITO_00115,Fundamental AI process,Top\\-5\\ Accuracy
0,1,Temporal Action Proposal Generation,ActivityNet-1.3,2017-07,Lin et al.,64.4,95.98,64.4,0.96,67.1,0.96,ito:ITO_00115,Fundamental AI process,AUC\\ \\(val\\)
1,1,Temporal Action Proposal Generation,ActivityNet-1.3,2018-06,BSN,66.17,98.61,1.8,0.03,67.1,0.99,ito:ITO_00115,Fundamental AI process,AUC\\ \\(val\\)
2,1,Temporal Action Proposal Generation,ActivityNet-1.3,2018-11,MGG,66.43,99.0,0.3,0.0,67.1,0.99,ito:ITO_00115,Fundamental AI process,AUC\\ \\(val\\)
3,1,Temporal Action Proposal Generation,ActivityNet-1.3,2019-07,BMN,67.1,100.0,0.7,0.01,67.1,1.0,ito:ITO_00115,Fundamental AI process,AUC\\ \\(val\\)
0,1,Temporal Action Proposal Generation,ActivityNet-1.3,2017-07,Lin et al.,64.8,97.8,64.8,0.98,66.26,0.98,ito:ITO_00115,Fundamental AI process,AUC\\ \\(test\\)
1,1,Temporal Action Proposal Generation,ActivityNet-1.3,2018-06,BSN,66.26,100.0,1.5,0.02,66.26,1.0,ito:ITO_00115,Fundamental AI process,AUC\\ \\(test\\)
0,1,Temporal Action Proposal Generation,ActivityNet-1.3,2017-07,Lin et al.,73.01,97.33,73.01,0.97,75.01,0.97,ito:ITO_00115,Fundamental AI process,AR@100
1,1,Temporal Action Proposal Generation,ActivityNet-1.3,2018-06,BSN,74.16,98.87,1.1,0.01,75.01,0.99,ito:ITO_00115,Fundamental AI process,AR@100
2,1,Temporal Action Proposal Generation,ActivityNet-1.3,2018-11,MGG,74.54,99.37,0.4,0.01,75.01,0.99,ito:ITO_00115,Fundamental AI process,AR@100
3,1,Temporal Action Proposal Generation,ActivityNet-1.3,2019-07,BMN,75.01,100.0,0.5,0.01,75.01,1.0,ito:ITO_00115,Fundamental AI process,AR@100
4,1,Temporal Action Proposal Generation,THUMOS' 14,2018-06,BSN + Soft-NMS,46.06,100.0,46.06,1.0,46.06,0.61,ito:ITO_00115,Fundamental AI process,AR@100
0,1,Long-tail Learning,EGTEA,2017-08,Focal loss (3D- ResNeXt101),59.17,100.0,59.17,1.0,59.17,1.0,ito:ITO_00115,Fundamental AI process,Average\\ Recall
0,1,Long-tail Learning,EGTEA,2017-08,Focal loss (3D- ResNeXt101),59.09,100.0,59.09,1.0,59.09,1.0,ito:ITO_00115,Fundamental AI process,Average\\ Precision
1,1,Anomaly Detection,Thyroid,2019-11,DevNet,0.274,100.0,0.274,1.0,0.274,0.0,ito:ITO_00115,Fundamental AI process,Average\\ Precision
2,1,Anomaly Detection,Census,2019-11,DevNet,0.321,100.0,0.321,1.0,0.321,0.01,ito:ITO_00115,Fundamental AI process,Average\\ Precision
0,1,Action Recognition In Videos,ActionNet-VE,2017-08,Baseline,90.27,100.0,90.27,1.0,90.27,1.0,ito:ITO_00115,Fundamental AI process,F\\-measure\\ \\(%\\)
1,1,Action Recognition,ActionNet-VE,2017-08,Baseline,90.27,100.0,90.27,1.0,90.27,1.0,ito:ITO_00115,Fundamental AI process,F\\-measure\\ \\(%\\)
0,1,Abnormal Event Detection In Video,UBI-Fights,2017-08,Adversarial Generator,0.011,100.0,0.011,1.0,0.011,0.07,ito:ITO_00115,Fundamental AI process,Decidability
1,1,Semi-supervised Anomaly Detection,UBI-Fights,2017-08,Adversarial Generator,0.147,100.0,0.147,1.0,0.147,1.0,ito:ITO_00115,Fundamental AI process,Decidability
0,1,Abnormal Event Detection In Video,UBI-Fights,2017-08,Adversarial Generator,0.504,100.0,0.504,1.0,0.504,1.0,ito:ITO_00115,Fundamental AI process,EER
1,1,Semi-supervised Anomaly Detection,UBI-Fights,2017-08,Adversarial Generator,0.484,100.0,0.484,1.0,0.484,0.96,ito:ITO_00115,Fundamental AI process,EER
0,1,Arrhythmia Detection,The PhysioNet Computing in Cardiology Challenge 2017,2017-09,ResNet + Expert Features,0.825,100.0,0.825,1.0,0.825,0.99,ito:ITO_00115,Fundamental AI process,F1\\ \\(Hidden\\ Test\\ Set\\)
1,1,Arrhythmia Detection,The China Physiological Signal Challenge 2018,2020-02,CNN+RNN,0.837,100.0,0.837,1.0,0.837,1.0,ito:ITO_00115,Fundamental AI process,F1\\ \\(Hidden\\ Test\\ Set\\)
0,1,Multi-Task Learning,wireframe dataset,2017-10,CNN,512.0,100.0,512,1.0,512,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(anywhere\\)
0,1,Skeleton Based Action Recognition,J-HMBD Early Action,2017-10,GAT,58.1,95.87,58.1,0.96,60.6,0.96,ito:ITO_00115,Fundamental AI process,10%
1,1,Skeleton Based Action Recognition,J-HMBD Early Action,2018-02,DR^2N,60.6,100.0,2.5,0.04,60.6,1.0,ito:ITO_00115,Fundamental AI process,10%
0,1,Unsupervised Domain Adaptation,Duke to Market,2017-11,SPGAN,51.5,58.72,51.5,0.59,87.7,0.59,ito:ITO_00115,Fundamental AI process,rank\\-1
1,1,Unsupervised Domain Adaptation,Duke to Market,2018-11,SSG,80.0,91.22,28.5,0.32,87.7,0.91,ito:ITO_00115,Fundamental AI process,rank\\-1
2,1,Unsupervised Domain Adaptation,Duke to Market,2020-01,MMT,87.7,100.0,7.7,0.09,87.7,1.0,ito:ITO_00115,Fundamental AI process,rank\\-1
3,1,Unsupervised Domain Adaptation,Market to Duke,2017-11,SPGAN,41.1,52.69,41.1,0.53,78.0,0.47,ito:ITO_00115,Fundamental AI process,rank\\-1
4,1,Unsupervised Domain Adaptation,Market to Duke,2018-11,SSG,73.0,93.59,31.9,0.41,78.0,0.83,ito:ITO_00115,Fundamental AI process,rank\\-1
5,1,Unsupervised Domain Adaptation,Market to Duke,2020-01,MMT,78.0,100.0,5.0,0.06,78.0,0.89,ito:ITO_00115,Fundamental AI process,rank\\-1
6,1,Unsupervised Domain Adaptation,Duke to MSMT,2017-11,PTGAN,11.8,23.55,11.8,0.24,50.1,0.13,ito:ITO_00115,Fundamental AI process,rank\\-1
7,1,Unsupervised Domain Adaptation,Duke to MSMT,2018-11,SSG,32.2,64.27,20.4,0.41,50.1,0.37,ito:ITO_00115,Fundamental AI process,rank\\-1
8,1,Unsupervised Domain Adaptation,Duke to MSMT,2020-01,MMT,50.1,100.0,17.9,0.36,50.1,0.57,ito:ITO_00115,Fundamental AI process,rank\\-1
9,1,Unsupervised Domain Adaptation,Market to MSMT,2017-11,PTGAN,10.2,20.73,10.2,0.21,49.2,0.12,ito:ITO_00115,Fundamental AI process,rank\\-1
10,1,Unsupervised Domain Adaptation,Market to MSMT,2018-11,SSG,31.6,64.23,21.4,0.43,49.2,0.36,ito:ITO_00115,Fundamental AI process,rank\\-1
11,1,Unsupervised Domain Adaptation,Market to MSMT,2020-01,MMT,49.2,100.0,17.6,0.36,49.2,0.56,ito:ITO_00115,Fundamental AI process,rank\\-1
0,1,Unsupervised Domain Adaptation,Duke to Market,2017-11,SPGAN,70.1,73.87,70.1,0.74,94.9,0.74,ito:ITO_00115,Fundamental AI process,rank\\-5
1,1,Unsupervised Domain Adaptation,Duke to Market,2018-11,SSG,90.0,94.84,19.9,0.21,94.9,0.95,ito:ITO_00115,Fundamental AI process,rank\\-5
2,1,Unsupervised Domain Adaptation,Duke to Market,2020-01,MMT,94.9,100.0,4.9,0.05,94.9,1.0,ito:ITO_00115,Fundamental AI process,rank\\-5
3,1,Unsupervised Domain Adaptation,Market to Duke,2017-11,SPGAN,56.6,63.74,56.6,0.64,88.8,0.6,ito:ITO_00115,Fundamental AI process,rank\\-5
4,1,Unsupervised Domain Adaptation,Market to Duke,2018-11,SSG,80.6,90.77,24.0,0.27,88.8,0.85,ito:ITO_00115,Fundamental AI process,rank\\-5
5,1,Unsupervised Domain Adaptation,Market to Duke,2020-01,MMT,88.8,100.0,8.2,0.09,88.8,0.94,ito:ITO_00115,Fundamental AI process,rank\\-5
6,1,Unsupervised Domain Adaptation,Duke to MSMT,2019-04,ECN,41.5,64.95,41.5,0.65,63.9,0.44,ito:ITO_00115,Fundamental AI process,rank\\-5
7,1,Unsupervised Domain Adaptation,Duke to MSMT,2020-01,MMT,63.9,100.0,22.4,0.35,63.9,0.67,ito:ITO_00115,Fundamental AI process,rank\\-5
8,1,Unsupervised Domain Adaptation,Market to MSMT,2019-04,ECN,36.3,57.53,36.3,0.58,63.1,0.38,ito:ITO_00115,Fundamental AI process,rank\\-5
9,1,Unsupervised Domain Adaptation,Market to MSMT,2020-01,MMT,63.1,100.0,26.8,0.42,63.1,0.66,ito:ITO_00115,Fundamental AI process,rank\\-5
0,1,Unsupervised Domain Adaptation,Duke to Market,2017-11,SPGAN,76.8,79.26,76.8,0.79,96.9,0.79,ito:ITO_00115,Fundamental AI process,rank\\-10
1,1,Unsupervised Domain Adaptation,Duke to Market,2018-11,SSG,92.4,95.36,15.6,0.16,96.9,0.95,ito:ITO_00115,Fundamental AI process,rank\\-10
2,1,Unsupervised Domain Adaptation,Duke to Market,2020-01,MMT,96.9,100.0,4.5,0.05,96.9,1.0,ito:ITO_00115,Fundamental AI process,rank\\-10
3,1,Unsupervised Domain Adaptation,Market to Duke,2017-11,SPGAN,63.0,68.11,63.0,0.68,92.5,0.65,ito:ITO_00115,Fundamental AI process,rank\\-10
4,1,Unsupervised Domain Adaptation,Market to Duke,2018-11,SSG,83.2,89.95,20.2,0.22,92.5,0.86,ito:ITO_00115,Fundamental AI process,rank\\-10
5,1,Unsupervised Domain Adaptation,Market to Duke,2020-01,MMT,92.5,100.0,9.3,0.1,92.5,0.95,ito:ITO_00115,Fundamental AI process,rank\\-10
6,1,Unsupervised Domain Adaptation,Duke to MSMT,2017-11,PTGAN,27.4,39.26,27.4,0.39,69.8,0.28,ito:ITO_00115,Fundamental AI process,rank\\-10
7,1,Unsupervised Domain Adaptation,Duke to MSMT,2018-11,SSG,51.2,73.35,23.8,0.34,69.8,0.53,ito:ITO_00115,Fundamental AI process,rank\\-10
8,1,Unsupervised Domain Adaptation,Duke to MSMT,2020-01,MMT,69.8,100.0,18.6,0.27,69.8,0.72,ito:ITO_00115,Fundamental AI process,rank\\-10
9,1,Unsupervised Domain Adaptation,Market to MSMT,2017-11,PTGAN,24.4,35.47,24.4,0.35,68.8,0.25,ito:ITO_00115,Fundamental AI process,rank\\-10
10,1,Unsupervised Domain Adaptation,Market to MSMT,2018-11,SSG,49.6,72.09,25.2,0.37,68.8,0.51,ito:ITO_00115,Fundamental AI process,rank\\-10
11,1,Unsupervised Domain Adaptation,Market to MSMT,2020-01,MMT,68.8,100.0,19.2,0.28,68.8,0.71,ito:ITO_00115,Fundamental AI process,rank\\-10
0,1,Action Recognition,Something-Something V1,2017-11,NL I3D,44.4,80.49,44.4,0.8,55.16,0.59,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
1,1,Action Recognition,Something-Something V1,2017-12,S3D-G (ImageNet pretrained),48.2,87.38,3.8,0.07,55.16,0.64,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
2,1,Action Recognition,Something-Something V1,2018-01,ResNet50 I3D (Moments pretrained),50.0,90.65,1.8,0.03,55.16,0.66,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
3,1,Action Recognition,Something-Something V1,2018-11,TSM (RGB + Flow),50.7,91.91,0.7,0.01,55.16,0.67,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
4,1,Action Recognition,Something-Something V1,2019-04,R(2+1)D-152 (IG-65M pretraining),51.6,93.55,0.9,0.02,55.16,0.68,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
5,1,Action Recognition,Something-Something V1,2019-04,ip-CSN-152 (IG-65M pretraining),53.3,96.63,1.7,0.03,55.16,0.71,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
6,1,Action Recognition,Something-Something V1,2019-08,"GB + DF + LB (ResNet152, ImageNet pretrained)",53.4,96.81,0.1,0.0,55.16,0.71,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
7,1,Action Recognition,Something-Something V1,2019-12,GSM Ensemble InceptionV3 (ImageNet pretrained),55.16,100.0,1.8,0.03,55.16,0.73,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
8,1,Action Recognition In Videos,Something-Something V1,2017-11,2-Stream TRN,42.01,76.16,42.01,0.76,55.16,0.56,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
9,1,Action Recognition In Videos,Something-Something V1,2017-12,S3D-G (ImageNet pretrained),48.2,87.38,6.2,0.11,55.16,0.64,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
10,1,Action Recognition In Videos,Something-Something V1,2018-01,ResNet50 I3D (Moments pretrained),50.0,90.65,1.8,0.03,55.16,0.66,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
11,1,Action Recognition In Videos,Something-Something V1,2018-11,TSM (RGB + Flow),50.7,91.91,0.7,0.01,55.16,0.67,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
12,1,Action Recognition In Videos,Something-Something V1,2019-06,"MARS+RGB+Flow (64 frames, Kinetics pretrained)",53.0,96.08,2.3,0.04,55.16,0.7,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
13,1,Action Recognition In Videos,Something-Something V1,2019-08,"GB + DF + LB (ResNet152, ImageNet pretrained)",53.4,96.81,0.4,0.01,55.16,0.71,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
14,1,Action Recognition In Videos,Something-Something V1,2019-12,GSM Ensemble InceptionV3 (ImageNet pretrained),55.16,100.0,1.8,0.03,55.16,0.73,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
15,1,Stochastic Optimization,ImageNet ResNet-50,2019-07,Lookahead,75.13,100.0,75.13,1.0,75.13,1.0,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
16,1,Stochastic Optimization,ImageNet ResNet-50,2019-07,Lookahead,75.49,100.0,75.49,1.0,75.49,1.0,ito:ITO_00115,Fundamental AI process,Top\\ 1\\ Accuracy
0,1,Action Recognition,Jester,2017-11,MultiScale TRN,95.31,98.56,95.31,0.99,96.7,0.99,ito:ITO_00115,Fundamental AI process,Val
1,1,Action Recognition,Jester,2018-07,MFNet,96.68,99.98,1.4,0.01,96.7,1.0,ito:ITO_00115,Fundamental AI process,Val
2,1,Action Recognition,Jester,2019-05,"CPNet Res34, 5 CP",96.7,100.0,0.0,0.0,96.7,1.0,ito:ITO_00115,Fundamental AI process,Val
3,1,Action Recognition In Videos,Jester,2017-11,MultiScale TRN,95.31,98.56,95.31,0.99,96.7,0.99,ito:ITO_00115,Fundamental AI process,Val
4,1,Action Recognition In Videos,Jester,2018-07,MFNet,96.68,99.98,1.4,0.01,96.7,1.0,ito:ITO_00115,Fundamental AI process,Val
5,1,Action Recognition In Videos,Jester,2019-05,"CPNet Res34, 5 CP",96.7,100.0,0.0,0.0,96.7,1.0,ito:ITO_00115,Fundamental AI process,Val
0,1,Action Recognition,Something-Something V1,2017-12,S3D-G (ImageNet pretrained),78.7,91.41,78.7,0.91,86.1,0.85,ito:ITO_00115,Fundamental AI process,Top\\ 5\\ Accuracy
1,1,Action Recognition,Something-Something V1,2019-08,TRG (ResNet-50),86.1,100.0,7.4,0.09,86.1,0.93,ito:ITO_00115,Fundamental AI process,Top\\ 5\\ Accuracy
2,1,Stochastic Optimization,ImageNet ResNet-50,2019-07,Lookahead,92.22,100.0,92.22,1.0,92.22,1.0,ito:ITO_00115,Fundamental AI process,Top\\ 5\\ Accuracy
3,1,Stochastic Optimization,ImageNet ResNet-50,2019-07,Lookahead,92.53,99.97,92.53,1.0,92.56,1.0,ito:ITO_00115,Fundamental AI process,Top\\ 5\\ Accuracy
4,1,Stochastic Optimization,ImageNet ResNet-50,2019-07,SGD,92.56,100.0,0.0,0.0,92.56,1.0,ito:ITO_00115,Fundamental AI process,Top\\ 5\\ Accuracy
5,1,Action Recognition In Videos,Something-Something V1,2019-08,TRG (ResNet-50),86.1,100.0,86.1,1.0,86.1,0.93,ito:ITO_00115,Fundamental AI process,Top\\ 5\\ Accuracy
0,1,Weakly Supervised Action Localization,THUMOS 2014,2017-12,STPN,27.0,76.49,27.0,0.76,35.3,0.76,ito:ITO_00115,Fundamental AI process,mAP@0\\.1:0\\.7
1,1,Weakly Supervised Action Localization,THUMOS 2014,2019-05,MAAN,31.6,89.52,4.6,0.13,35.3,0.9,ito:ITO_00115,Fundamental AI process,mAP@0\\.1:0\\.7
2,1,Weakly Supervised Action Localization,THUMOS 2014,2019-06,CMCS,32.4,91.78,0.8,0.02,35.3,0.92,ito:ITO_00115,Fundamental AI process,mAP@0\\.1:0\\.7
3,1,Weakly Supervised Action Localization,THUMOS 2014,2019-11,BaS-Net,35.3,100.0,2.9,0.08,35.3,1.0,ito:ITO_00115,Fundamental AI process,mAP@0\\.1:0\\.7
0,1,Panoptic Segmentation,Cityscapes val,2018-01,MRCNN + PSPNet (ResNet-101),66.4,94.45,66.4,0.94,70.3,0.94,ito:ITO_00115,Fundamental AI process,PQst
1,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS,70.3,100.0,3.9,0.06,70.3,1.0,ito:ITO_00115,Fundamental AI process,PQst
2,1,Panoptic Segmentation,COCO test-dev,2018-09,JSIS-Net (ResNet-50),23.4,53.06,23.4,0.53,44.1,0.33,ito:ITO_00115,Fundamental AI process,PQst
3,1,Panoptic Segmentation,COCO test-dev,2018-12,AUNet (ResNeXt-152-FPN),32.5,73.7,9.1,0.21,44.1,0.46,ito:ITO_00115,Fundamental AI process,PQst
4,1,Panoptic Segmentation,COCO test-dev,2019-01,UPSNet (ResNet-101-FPN),36.7,83.22,4.2,0.1,44.1,0.52,ito:ITO_00115,Fundamental AI process,PQst
5,1,Panoptic Segmentation,COCO test-dev,2020-03,EPSNet (ResNet-101-FPN),44.1,100.0,7.4,0.17,44.1,0.63,ito:ITO_00115,Fundamental AI process,PQst
0,1,Panoptic Segmentation,Cityscapes val,2018-01,MRCNN + PSPNet (ResNet-101),36.4,83.68,36.4,0.84,43.5,0.84,ito:ITO_00115,Fundamental AI process,AP
1,1,Panoptic Segmentation,Cityscapes val,2018-12,"TASCNet (ResNet-50, multi-scale)",39.0,89.66,2.6,0.06,43.5,0.9,ito:ITO_00115,Fundamental AI process,AP
2,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS,43.5,100.0,4.5,0.1,43.5,1.0,ito:ITO_00115,Fundamental AI process,AP
0,1,Neural Architecture Search,"NAS-Bench-201, ImageNet-16-120",2018-02,REA,45.54,100.0,45.54,1.0,45.54,0.49,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(Test\\)
1,1,Neural Architecture Search,"NAS-Bench-201, CIFAR-10",2019-10,GDAS,93.51,100.0,93.51,1.0,93.51,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(Test\\)
2,1,Neural Architecture Search,"NAS-Bench-201, CIFAR-100",2019-10,GDAS,70.61,100.0,70.61,1.0,70.61,0.76,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(Test\\)
0,1,Neural Architecture Search,"NAS-Bench-201, ImageNet-16-120",2018-02,REA,12000.0,40.13,12000,0.4,29902,0.4,ito:ITO_00115,Fundamental AI process,Search\\ time\\ \\(s\\)
1,1,Neural Architecture Search,"NAS-Bench-201, ImageNet-16-120",2018-06,DARTS (second order),29902.0,100.0,17902,0.6,29902,1.0,ito:ITO_00115,Fundamental AI process,Search\\ time\\ \\(s\\)
2,1,Neural Architecture Search,"NAS-Bench-201, CIFAR-10",2019-10,GDAS,28926.0,100.0,28926,1.0,28926,0.97,ito:ITO_00115,Fundamental AI process,Search\\ time\\ \\(s\\)
3,1,Neural Architecture Search,"NAS-Bench-201, CIFAR-100",2019-10,GDAS,28926.0,100.0,28926,1.0,28926,0.97,ito:ITO_00115,Fundamental AI process,Search\\ time\\ \\(s\\)
0,1,Neural Architecture Search,"NAS-Bench-201, ImageNet-16-120",2018-02,REA,45.15,100.0,45.15,1.0,45.15,0.5,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(val\\)
1,1,Neural Architecture Search,"NAS-Bench-201, CIFAR-10",2019-10,GDAS,90.0,100.0,90,1.0,90,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(val\\)
0,1,Mortality Prediction,MIMIC-III,2018-03,Random Forest,0.97,100.0,0.97,1.0,0.97,1.0,ito:ITO_00115,Fundamental AI process,F1\\ score
0,1,One-Shot Segmentation,Cluttered Omniglot,2018-03,MaskNet,43.7,100.0,43.7,1.0,43.7,1.0,ito:ITO_00115,Fundamental AI process,IoU\\ \\[256\\ distractors\\]
0,1,One-Shot Segmentation,Cluttered Omniglot,2018-03,MaskNet,65.6,100.0,65.6,1.0,65.6,1.0,ito:ITO_00115,Fundamental AI process,IoU\\ \\[32\\ distractors\\]
0,1,One-Shot Segmentation,Cluttered Omniglot,2018-03,MaskNet,95.8,98.66,95.8,0.99,97.1,0.99,ito:ITO_00115,Fundamental AI process,IoU\\ \\[4\\ distractors\\]
1,1,One-Shot Segmentation,Cluttered Omniglot,2018-03,Siamese-U-Net,97.1,100.0,1.3,0.01,97.1,1.0,ito:ITO_00115,Fundamental AI process,IoU\\ \\[4\\ distractors\\]
0,1,Temporal Action Localization,ActivityNet-1.3,2018-04,TAL-Net,18.3,52.62,18.3,0.53,34.78,0.53,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.75
1,1,Temporal Action Localization,ActivityNet-1.3,2018-06,BSN,29.96,86.14,11.7,0.34,34.78,0.86,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.75
2,1,Temporal Action Localization,ActivityNet-1.3,2019-07,BMN,34.78,100.0,4.8,0.14,34.78,1.0,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.75
0,1,Temporal Action Localization,ActivityNet-1.3,2018-04,TAL-Net,1.3,14.41,1.3,0.14,9.02,0.14,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.95
1,1,Temporal Action Localization,ActivityNet-1.3,2018-06,BSN,8.02,88.91,6.7,0.74,9.02,0.89,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.95
2,1,Temporal Action Localization,ActivityNet-1.3,2019-07,BMN,8.29,91.91,0.3,0.03,9.02,0.92,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.95
3,1,Temporal Action Localization,ActivityNet-1.3,2019-11,G-TAD,9.02,100.0,0.7,0.08,9.02,1.0,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.95
0,1,Unsupervised Pre-training,Measles,2018-05,RMDL,0.1,100.0,0.1,1.0,0.1,0.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(%\\)
1,1,Domain Adaptation,Office-Caltech-10,2018-07,MEDA,92.8,100.0,92.8,1.0,92.8,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(%\\)
2,1,Partial Domain Adaptation,Office-Home,2018-11,SAFN,71.8,100.0,71.8,1.0,71.8,0.77,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(%\\)
3,1,Multi-Task Learning,Hendrycks Test,2019-02,GPT-2,32.4,100.0,32.4,1.0,32.4,0.35,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(%\\)
0,1,Unsupervised Pre-training,UCI measles,2018-05,RMDL 3 RDLs,0.8739,100.0,0.8739,1.0,0.8739,0.01,ito:ITO_00115,Fundamental AI process,Sensitivity
1,1,Congestive Heart Failure detection,CHF database,2019-07,Inclined Entropy (R-HessELM),98.3,100.0,98.3,1.0,98.3,1.0,ito:ITO_00115,Fundamental AI process,Sensitivity
0,1,Temporal Action Proposal Generation,THUMOS' 14,2018-06,BSN + Soft-NMS,64.52,100.0,64.52,1.0,64.52,1.0,ito:ITO_00115,Fundamental AI process,AR@1000
0,1,Temporal Action Proposal Generation,THUMOS' 14,2018-06,BSN + Soft-NMS,53.21,100.0,53.21,1.0,53.21,1.0,ito:ITO_00115,Fundamental AI process,AR@200
0,1,Temporal Action Proposal Generation,THUMOS' 14,2018-06,BSN + Soft-NMS,37.46,100.0,37.46,1.0,37.46,1.0,ito:ITO_00115,Fundamental AI process,AR@50
0,1,Temporal Action Proposal Generation,THUMOS' 14,2018-06,BSN + Soft-NMS,60.64,100.0,60.64,1.0,60.64,1.0,ito:ITO_00115,Fundamental AI process,AR@500
0,1,Multivariate Time Series Forecasting,PhysioNet Challenge 2012,2018-06,Latent ODE (RNN enc.),3.162,100.0,3.162,1.0,3.162,1.0,ito:ITO_00115,Fundamental AI process,mse\\ \\(10\\^\\-3\\)
0,1,Multivariate Time Series Forecasting,PhysioNet Challenge 2012,2018-06,Latent ODE (RNN enc.),0.052,35.86,0.052,0.36,0.145,0.36,ito:ITO_00115,Fundamental AI process,MSE\\ stdev
1,1,Multivariate Time Series Forecasting,PhysioNet Challenge 2012,2018-06,RNN-VAE,0.145,100.0,0.1,0.69,0.145,1.0,ito:ITO_00115,Fundamental AI process,MSE\\ stdev
0,1,Neural Architecture Search,ImageNet,2018-06,DARTS,595000000.0,99.66,595000000,1.0,597000000,1.0,ito:ITO_00115,Fundamental AI process,MACs
1,1,Neural Architecture Search,ImageNet,2019-07,PC-DARTS (ImageNet),597000000.0,100.0,2000000,0.0,597000000,1.0,ito:ITO_00115,Fundamental AI process,MACs
0,1,Stroke Classification from CT data,CT Lesion Stroke Dataset,2018-07,"PSO+CNN (Cifar-10, 75/25, Cranium Segmented)",98.86,100.0,98.86,1.0,98.86,1.0,ito:ITO_00115,Fundamental AI process,Average\\ Class\\ Accuracy
0,1,EEG Artifact Removal,MayoClinic_iEEG,2018-08,CNN/APN,0.89,100.0,0.89,1.0,0.89,1.0,ito:ITO_00115,Fundamental AI process,F1\\-score
0,1,Density Estimation,UCI HEPMASS,2018-10,FFJORD,14.92,100.0,14.92,1.0,14.92,0.14,ito:ITO_00115,Fundamental AI process,NLL
1,1,Density Estimation,UCI MINIBOONE,2018-10,FFJORD,10.43,100.0,10.43,1.0,10.43,0.1,ito:ITO_00115,Fundamental AI process,NLL
2,1,Density Estimation,CIFAR-10,2018-10,FFJORD,3.4,100.0,3.4,1.0,3.4,0.03,ito:ITO_00115,Fundamental AI process,NLL
3,1,Density Estimation,MNIST,2018-10,FFJORD,0.99,1.18,0.99,0.01,83.59,0.01,ito:ITO_00115,Fundamental AI process,NLL
4,1,Density Estimation,MNIST,2019-04,B-NAF,83.59,100.0,82.6,0.99,83.59,0.79,ito:ITO_00115,Fundamental AI process,NLL
5,1,Density Estimation,Freyfaces,2019-04,B-NAF,4.42,100.0,4.42,1.0,4.42,0.04,ito:ITO_00115,Fundamental AI process,NLL
6,1,Density Estimation,Caltech-101,2019-04,B-NAF,105.42,100.0,105.42,1.0,105.42,1.0,ito:ITO_00115,Fundamental AI process,NLL
7,1,Density Estimation,OMNIGLOT,2019-04,B-NAF,100.08,100.0,100.08,1.0,100.08,0.95,ito:ITO_00115,Fundamental AI process,NLL
0,1,Density Estimation,OMNIGLOT,2018-10,FFJORD,98.33,100.0,98.33,1.0,98.33,0.95,ito:ITO_00115,Fundamental AI process,Negative\\ ELBO
1,1,Density Estimation,MNIST,2018-10,FFJORD,82.82,100.0,82.82,1.0,82.82,0.8,ito:ITO_00115,Fundamental AI process,Negative\\ ELBO
2,1,Density Estimation,Freyfaces,2018-10,FFJORD,4.39,100.0,4.39,1.0,4.39,0.04,ito:ITO_00115,Fundamental AI process,Negative\\ ELBO
3,1,Density Estimation,Caltech-101,2018-10,FFJORD,104.03,100.0,104.03,1.0,104.03,1.0,ito:ITO_00115,Fundamental AI process,Negative\\ ELBO
0,1,Multi-Task Learning,CelebA,2018-10,MGDA-UB,8.25,100.0,8.25,1.0,8.25,1.0,ito:ITO_00115,Fundamental AI process,Error
0,1,Steering Control,Udacity,2018-11,FM-Net,1.6236,100.0,1.6236,1.0,1.6236,1.0,ito:ITO_00115,Fundamental AI process,MAE
1,1,Steering Control,Comma.ai,2018-11,FM-Net,0.7048,100.0,0.7048,1.0,0.7048,0.43,ito:ITO_00115,Fundamental AI process,MAE
0,1,Domain Generalization,ImageNet-C,2018-11,ResNet-50+Stylized ImageNet,69.3,90.35,69.3,0.9,76.7,0.9,ito:ITO_00115,Fundamental AI process,mean\\ Corruption\\ Error\\ \\(mCE\\)
1,1,Domain Generalization,ImageNet-C,2019-03,ResNet-50,76.7,100.0,7.4,0.1,76.7,1.0,ito:ITO_00115,Fundamental AI process,mean\\ Corruption\\ Error\\ \\(mCE\\)
0,1,Action Recognition,AVA v2.1,2018-12,I3D Tx HighRes,39.6,100.0,39.6,1.0,39.6,1.0,ito:ITO_00115,Fundamental AI process,GFlops
1,1,Action Recognition In Videos,AVA v2.1,2018-12,I3D Tx HighRes,39.6,100.0,39.6,1.0,39.6,1.0,ito:ITO_00115,Fundamental AI process,GFlops
0,1,Action Recognition In Videos,AVA v2.1,2018-12,I3D Tx HighRes,19.3,100.0,19.3,1.0,19.3,1.0,ito:ITO_00115,Fundamental AI process,Params\\ \\(M\\)
1,1,Action Recognition,AVA v2.1,2018-12,I3D Tx HighRes,19.3,100.0,19.3,1.0,19.3,1.0,ito:ITO_00115,Fundamental AI process,Params\\ \\(M\\)
0,1,Arrhythmia Detection,"""Cardiologist-level"" 12-rhythm ECG dataset",2019-01,DNN,0.807,100.0,0.807,1.0,0.807,1.0,ito:ITO_00115,Fundamental AI process,F1\\ \\(Sequence\\)
0,1,Arrhythmia Detection,"""Cardiologist-level"" 12-rhythm ECG dataset",2019-01,DNN,0.837,100.0,0.837,1.0,0.837,1.0,ito:ITO_00115,Fundamental AI process,F1\\ \\(Set\\)
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,MFA-Net,361.0,100.0,361,1.0,361,1.0,ito:ITO_00115,Fundamental AI process,Speed\\ \\ \\(FPS\\)
1,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet-tiny,98.0,100.0,98,1.0,98,0.27,ito:ITO_00115,Fundamental AI process,Speed\\ \\ \\(FPS\\)
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,MFA-Net,86.6,94.23,86.6,0.94,91.9,0.94,ito:ITO_00115,Fundamental AI process,28\\ gestures\\ accuracy
1,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,STA-Res-TCN,90.7,98.69,4.1,0.04,91.9,0.99,ito:ITO_00115,Fundamental AI process,28\\ gestures\\ accuracy
2,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,91.9,100.0,1.2,0.01,91.9,1.0,ito:ITO_00115,Fundamental AI process,28\\ gestures\\ accuracy
0,1,Semantic Segmentation,ADE20K val,2019-01,Auto-DeepLab-L,81.72,100.0,81.72,1.0,81.72,1.0,ito:ITO_00115,Fundamental AI process,Pixel\\ Accuracy
0,1,Neural Network Compression,ImageNet,2019-01,ImageNet,0.1,100.0,0.1,1.0,0.1,1.0,ito:ITO_00115,Fundamental AI process,All
0,1,Semantic Segmentation,38-Cloud,2019-01,Cloud-Net,87.32,98.22,87.32,0.98,88.9,0.98,ito:ITO_00115,Fundamental AI process,Jaccard\\ \\(Mean\\)
1,1,Semantic Segmentation,38-Cloud,2020-01,Cloud-Net+,88.9,100.0,1.6,0.02,88.9,1.0,ito:ITO_00115,Fundamental AI process,Jaccard\\ \\(Mean\\)
0,1,Neural Architecture Search,CIFAR-10,2019-02,Soft Parameter Sharing,0.7,0.31,0.7,0.0,224.0,0.0,ito:ITO_00115,Fundamental AI process,Search\\ Time\\ \\(GPU\\ days\\)
1,1,Neural Architecture Search,CIFAR-10,2019-03,AlphaX-1 (cutout NASNet),224.0,100.0,223.3,1.0,224.0,1.0,ito:ITO_00115,Fundamental AI process,Search\\ Time\\ \\(GPU\\ days\\)
0,1,4D Spatio Temporal Semantic Segmentation,4,2019-03,4,7.0,100.0,7,1.0,7,1.0,ito:ITO_00115,Fundamental AI process,4
0,1,Unsupervised Anomaly Detection,Fashion-MNIST,2019-03,RSRAE,0.833,100.0,0.833,1.0,0.833,0.98,ito:ITO_00115,Fundamental AI process,AUC\\ \\(outlier\\ ratio\\ =\\ 0\\.5\\)
1,1,Unsupervised Anomaly Detection,Reuters-21578,2019-03,RSRAE,0.849,100.0,0.849,1.0,0.849,1.0,ito:ITO_00115,Fundamental AI process,AUC\\ \\(outlier\\ ratio\\ =\\ 0\\.5\\)
2,1,Unsupervised Anomaly Detection,20NEWS,2019-03,RSRAE,0.831,100.0,0.831,1.0,0.831,0.98,ito:ITO_00115,Fundamental AI process,AUC\\ \\(outlier\\ ratio\\ =\\ 0\\.5\\)
3,1,Unsupervised Anomaly Detection,Caltech-101,2019-03,RSRAE,0.772,100.0,0.772,1.0,0.772,0.91,ito:ITO_00115,Fundamental AI process,AUC\\ \\(outlier\\ ratio\\ =\\ 0\\.5\\)
0,1,Grasp Contact Prediction,ContactDB,2019-04,sMCL-VoxNet,17.27,57.78,17.27,0.58,29.89,0.58,ito:ITO_00115,Fundamental AI process,Error\\ rate
1,1,Grasp Contact Prediction,ContactDB,2019-04,sMCL-PointNet,29.89,100.0,12.6,0.42,29.89,1.0,ito:ITO_00115,Fundamental AI process,Error\\ rate
0,1,Multi-Task Learning,HVU,2019-04,HATNet (Multi-Task),60.6,100.0,60.6,1.0,60.6,1.0,ito:ITO_00115,Fundamental AI process,Action
0,1,Multi-Task Learning,HVU,2019-04,HATNet (Multi-Task),31.7,57.43,31.7,0.57,55.2,0.57,ito:ITO_00115,Fundamental AI process,"Tags\\(Object,\\ Scene,\\ etc\\)"
1,1,Multi-Task Learning,HVU,2019-04,HATNet,55.2,100.0,23.5,0.43,55.2,1.0,ito:ITO_00115,Fundamental AI process,"Tags\\(Object,\\ Scene,\\ etc\\)"
0,1,Feature Selection,Zoo,2019-05,Zoo,100.0,100.0,100,1.0,100,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\(10\\-fold\\)
1,1,Feature Selection,Glass identification,2019-05,Glass,75.0,100.0,75,1.0,75,0.75,ito:ITO_00115,Fundamental AI process,Accuracy\\(10\\-fold\\)
0,1,Unsupervised Domain Adaptation,PreSIL to KITTI,2019-05,CycleGAN,16.5,96.49,16.5,0.96,17.1,0.96,ito:ITO_00115,Fundamental AI process,AP\\-at\\-0\\.7
1,1,Unsupervised Domain Adaptation,PreSIL to KITTI,2019-11,PointDAN,17.1,100.0,0.6,0.04,17.1,1.0,ito:ITO_00115,Fundamental AI process,AP\\-at\\-0\\.7
0,1,Network Pruning,ImageNet,2019-05,TAS-pruned ResNet-50,2.3,76.67,2.3,0.77,3.0,0.77,ito:ITO_00115,Fundamental AI process,GFLOPs
1,1,Network Pruning,ImageNet,2020-01,ResNet50-3G FLOPs,3.0,100.0,0.7,0.23,3.0,1.0,ito:ITO_00115,Fundamental AI process,GFLOPs
2,1,Network Pruning,CIFAR-10,2019-05,TAS-pruned ResNet-110,0.119,100.0,0.119,1.0,0.119,0.04,ito:ITO_00115,Fundamental AI process,GFLOPs
3,1,Network Pruning,CIFAR-100,2019-05,TAS-pruned ResNet-110,0.12,48.0,0.12,0.48,0.25,0.04,ito:ITO_00115,Fundamental AI process,GFLOPs
4,1,Network Pruning,CIFAR-100,2020-01,PreResNet-101,0.25,100.0,0.1,0.4,0.25,0.08,ito:ITO_00115,Fundamental AI process,GFLOPs
0,1,Multi-Label Text Classification,AAPD,2019-05,LAHA,83.7,100.0,83.7,1.0,83.7,0.96,ito:ITO_00115,Fundamental AI process,nDCG\\-at\\-5
1,1,Multi-Label Text Classification,Amazon-12K,2019-05,LAHA,87.57,100.0,87.57,1.0,87.57,1.0,ito:ITO_00115,Fundamental AI process,nDCG\\-at\\-5
2,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,LAHA,54.65,100.0,54.65,1.0,54.65,0.62,ito:ITO_00115,Fundamental AI process,nDCG\\-at\\-5
3,1,Multi-Label Text Classification,Wiki-30K,2019-05,LAHA,67.82,100.0,67.82,1.0,67.82,0.77,ito:ITO_00115,Fundamental AI process,nDCG\\-at\\-5
4,1,Multi-Label Text Classification,EUR-Lex,2019-05,LAHA,59.28,72.03,59.28,0.72,82.3,0.68,ito:ITO_00115,Fundamental AI process,nDCG\\-at\\-5
5,1,Multi-Label Text Classification,EUR-Lex,2019-06,bert-base,82.3,100.0,23.0,0.28,82.3,0.94,ito:ITO_00115,Fundamental AI process,nDCG\\-at\\-5
0,1,Multi-Label Text Classification,AAPD,2019-05,LAHA,80.11,100.0,80.11,1.0,80.11,0.9,ito:ITO_00115,Fundamental AI process,nDCG\\-at\\-3
1,1,Multi-Label Text Classification,Amazon-12K,2019-05,LAHA,89.13,100.0,89.13,1.0,89.13,1.0,ito:ITO_00115,Fundamental AI process,nDCG\\-at\\-3
2,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,LAHA,51.7,100.0,51.7,1.0,51.7,0.58,ito:ITO_00115,Fundamental AI process,nDCG\\-at\\-3
3,1,Multi-Label Text Classification,Wiki-30K,2019-05,LAHA,75.64,100.0,75.64,1.0,75.64,0.85,ito:ITO_00115,Fundamental AI process,nDCG\\-at\\-3
4,1,Multi-Label Text Classification,EUR-Lex,2019-05,LAHA,64.89,91.25,64.89,0.91,71.11,0.73,ito:ITO_00115,Fundamental AI process,nDCG\\-at\\-3
5,1,Multi-Label Text Classification,EUR-Lex,2019-06,NLP-Cap,71.11,100.0,6.2,0.09,71.11,0.8,ito:ITO_00115,Fundamental AI process,nDCG\\-at\\-3
0,1,Multi-Label Text Classification,AAPD,2019-05,LAHA,84.48,100.0,84.48,1.0,84.48,0.89,ito:ITO_00115,Fundamental AI process,P\\-at\\-1
1,1,Multi-Label Text Classification,Amazon-12K,2019-05,LAHA,94.87,100.0,94.87,1.0,94.87,1.0,ito:ITO_00115,Fundamental AI process,P\\-at\\-1
2,1,Multi-Label Text Classification,EUR-Lex,2019-05,LAHA,74.95,93.45,74.95,0.93,80.2,0.79,ito:ITO_00115,Fundamental AI process,P\\-at\\-1
3,1,Multi-Label Text Classification,EUR-Lex,2019-06,NLP-Cap,80.2,100.0,5.2,0.06,80.2,0.85,ito:ITO_00115,Fundamental AI process,P\\-at\\-1
4,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,LAHA,54.38,100.0,54.38,1.0,54.38,0.57,ito:ITO_00115,Fundamental AI process,P\\-at\\-1
5,1,Multi-Label Text Classification,Wiki-30K,2019-05,LAHA,84.18,100.0,84.18,1.0,84.18,0.89,ito:ITO_00115,Fundamental AI process,P\\-at\\-1
0,1,Multi-Label Text Classification,Wiki-30K,2019-05,LAHA,62.87,100.0,62.87,1.0,62.87,0.92,ito:ITO_00115,Fundamental AI process,P\\-at\\-5
1,1,Multi-Label Text Classification,EUR-Lex,2019-05,LAHA,50.71,73.81,50.71,0.74,68.7,0.74,ito:ITO_00115,Fundamental AI process,P\\-at\\-5
2,1,Multi-Label Text Classification,EUR-Lex,2019-06,bert-base,68.7,100.0,18.0,0.26,68.7,1.0,ito:ITO_00115,Fundamental AI process,P\\-at\\-5
3,1,Multi-Label Text Classification,AAPD,2019-05,LAHA,41.19,100.0,41.19,1.0,41.19,0.6,ito:ITO_00115,Fundamental AI process,P\\-at\\-5
4,1,Multi-Label Text Classification,Amazon-12K,2019-05,LAHA,63.16,100.0,63.16,1.0,63.16,0.92,ito:ITO_00115,Fundamental AI process,P\\-at\\-5
5,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,LAHA,25.88,100.0,25.88,1.0,25.88,0.38,ito:ITO_00115,Fundamental AI process,P\\-at\\-5
0,1,Multi-Label Text Classification,AAPD,2019-05,LAHA,60.72,100.0,60.72,1.0,60.72,0.77,ito:ITO_00115,Fundamental AI process,P\\-at\\-3
1,1,Multi-Label Text Classification,EUR-Lex,2019-05,LAHA,61.48,93.89,61.48,0.94,65.48,0.78,ito:ITO_00115,Fundamental AI process,P\\-at\\-3
2,1,Multi-Label Text Classification,EUR-Lex,2019-06,NLP-Cap,65.48,100.0,4.0,0.06,65.48,0.83,ito:ITO_00115,Fundamental AI process,P\\-at\\-3
3,1,Multi-Label Text Classification,Amazon-12K,2019-05,LAHA,79.16,100.0,79.16,1.0,79.16,1.0,ito:ITO_00115,Fundamental AI process,P\\-at\\-3
4,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,LAHA,34.6,100.0,34.6,1.0,34.6,0.44,ito:ITO_00115,Fundamental AI process,P\\-at\\-3
5,1,Multi-Label Text Classification,Wiki-30K,2019-05,LAHA,73.14,100.0,73.14,1.0,73.14,0.92,ito:ITO_00115,Fundamental AI process,P\\-at\\-3
0,1,Multi-Label Text Classification,EUR-Lex,2019-06,bert-base,79.6,100.0,79.6,1.0,79.6,1.0,ito:ITO_00115,Fundamental AI process,RP\\-at\\-5
0,1,Multi-Label Text Classification,EUR-Lex,2019-06,bert-base,73.2,100.0,73.2,1.0,73.2,1.0,ito:ITO_00115,Fundamental AI process,Micro\\ F1
0,1,Multi-Label Text Classification,EUR-Lex,2019-06,NLP-Cap,80.2,100.0,80.2,1.0,80.2,1.0,ito:ITO_00115,Fundamental AI process,nDCG\\-at\\-1
0,1,3D Shape Modeling,Pix3D S2,2019-06,Mesh R-CNN,72.2,100.0,72.2,1.0,72.2,0.77,ito:ITO_00115,Fundamental AI process,box\\ AP
1,1,UNET Segmentation,UNET Segmentation,2019-06,Mesh R-CNN,72.2,100.0,72.2,1.0,72.2,0.77,ito:ITO_00115,Fundamental AI process,box\\ AP
2,1,3D Shape Modeling,Pix3D S1,2019-06,Mesh R-CNN,94.0,100.0,94,1.0,94,1.0,ito:ITO_00115,Fundamental AI process,box\\ AP
3,1,Road Segementation,Road Segementation,2019-06,Mesh R-CNN,94.0,100.0,94,1.0,94,1.0,ito:ITO_00115,Fundamental AI process,box\\ AP
0,1,3D Shape Modeling,Pix3D S2,2019-06,Mesh R-CNN,63.9,100.0,63.9,1.0,63.9,0.72,ito:ITO_00115,Fundamental AI process,mask\\ AP
1,1,UNET Segmentation,UNET Segmentation,2019-06,Mesh R-CNN,63.9,100.0,63.9,1.0,63.9,0.72,ito:ITO_00115,Fundamental AI process,mask\\ AP
2,1,3D Shape Modeling,Pix3D S1,2019-06,Mesh R-CNN,88.4,100.0,88.4,1.0,88.4,1.0,ito:ITO_00115,Fundamental AI process,mask\\ AP
3,1,Road Segementation,Road Segementation,2019-06,Mesh R-CNN,88.4,100.0,88.4,1.0,88.4,1.0,ito:ITO_00115,Fundamental AI process,mask\\ AP
0,1,3D Shape Modeling,Pix3D S2,2019-06,Mesh R-CNN,28.8,100.0,28.8,1.0,28.8,0.56,ito:ITO_00115,Fundamental AI process,mesh\\ AP
1,1,UNET Segmentation,UNET Segmentation,2019-06,Mesh R-CNN,28.8,100.0,28.8,1.0,28.8,0.56,ito:ITO_00115,Fundamental AI process,mesh\\ AP
2,1,3D Shape Modeling,Pix3D S1,2019-06,Mesh R-CNN,51.1,100.0,51.1,1.0,51.1,1.0,ito:ITO_00115,Fundamental AI process,mesh\\ AP
3,1,Road Segementation,Road Segementation,2019-06,Mesh R-CNN,51.1,100.0,51.1,1.0,51.1,1.0,ito:ITO_00115,Fundamental AI process,mesh\\ AP
0,1,Zero-Shot Learning,CUB-200,2019-06,zsl_ADA,70.9,100.0,70.9,1.0,70.9,1.0,ito:ITO_00115,Fundamental AI process,Average\\ Per\\-Class\\ Accuracy
0,1,Anomaly Detection,One-class CIFAR-10,2019-06,GOAD,88.2,100.0,88.2,1.0,88.2,1.0,ito:ITO_00115,Fundamental AI process,AUROC
1,1,Anomaly Detection,One-class ImageNet-30,2019-06,RotNet,65.3,76.2,65.3,0.76,85.7,0.74,ito:ITO_00115,Fundamental AI process,AUROC
2,1,Anomaly Detection,One-class ImageNet-30,2019-06,RotNet + Translation,77.9,90.9,12.6,0.15,85.7,0.88,ito:ITO_00115,Fundamental AI process,AUROC
3,1,Anomaly Detection,One-class ImageNet-30,2019-06,RotNet + Translation + Self-Attention + Resize,85.7,100.0,7.8,0.09,85.7,0.97,ito:ITO_00115,Fundamental AI process,AUROC
0,1,Heartbeat Classification,AHA,2019-07,ESN Ensembles (A Lead),99.5,100.0,99.5,1.0,99.5,1.0,ito:ITO_00115,Fundamental AI process,Specificity\\ \\(VEB\\+\\)
0,1,Heartbeat Classification,AHA,2019-07,ESN Ensembles (A Lead),98.6,100.0,98.6,1.0,98.6,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(VEB\\+\\)
0,1,Heartbeat Classification,AHA,2019-07,ESN Ensembles (A Lead),94.9,100.0,94.9,1.0,94.9,1.0,ito:ITO_00115,Fundamental AI process,PPV\\ \\(VEB\\+\\)
0,1,Heartbeat Classification,AHA,2019-07,ESN Ensembles (A Lead),90.4,100.0,90.4,1.0,90.4,1.0,ito:ITO_00115,Fundamental AI process,Sensitivity\\ \\(VEB\\+\\)
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,1820000.0,100.0,1820000,1.0,1820000,1.0,ito:ITO_00115,Fundamental AI process,No\\.\\ parameters
0,1,Temporal Action Localization,ActivityNet-1.3,2019-08,3C-Net,9.2,100.0,9.2,1.0,9.2,1.0,ito:ITO_00115,Fundamental AI process,mAP\\ IOU\\-at\\-0\\.9
0,1,Weakly Supervised Action Localization,ActivityNet-1.2,2019-08,3C-Net,21.7,100.0,21.7,1.0,21.7,1.0,ito:ITO_00115,Fundamental AI process,Mean\\ mAP
0,1,Neural Architecture Search,"NAS-Bench-201, CIFAR-100",2019-10,GDAS,71.14,100.0,71.14,1.0,71.14,1.0,ito:ITO_00115,Fundamental AI process,Accuracy\\ \\(Val\\)
0,1,Meta-Learning,MT50,2019-10,Multi-task multi-head SAC,35.85,100.0,35.85,1.0,35.85,0.41,ito:ITO_00115,Fundamental AI process,Average\\ Success\\ Rate
1,1,Meta-Learning,ML10,2019-10,Multi-task multi-head SAC,88.0,100.0,88,1.0,88,1.0,ito:ITO_00115,Fundamental AI process,Average\\ Success\\ Rate
0,1,Temporal Action Localization,J-HMDB-21,2019-11,YOWO (16-frame),87.8,100.0,87.8,1.0,87.8,1.0,ito:ITO_00115,Fundamental AI process,Video\\-mAP\\ 0\\.2
0,1,Temporal Action Localization,J-HMDB-21,2019-11,YOWO (16-frame),58.1,100.0,58.1,1.0,58.1,1.0,ito:ITO_00115,Fundamental AI process,Video\\-mAP\\ 0\\.75
0,1,Weakly Supervised Action Localization,THUMOS 2014,2019-11,BaS-Net,43.6,100.0,43.6,1.0,43.6,1.0,ito:ITO_00115,Fundamental AI process,mAP@0\\.1:0\\.5
0,1,Video Reconstruction,Tai-Chi-HD,2019-12,First Order Motion,0.063,100.0,0.063,1.0,0.063,1.0,ito:ITO_00115,Fundamental AI process,L1
1,1,Aerial Video Semantic Segmentation,Aerial Video Semantic Segmentation,2019-12,First Order Motion,0.063,100.0,0.063,1.0,0.063,1.0,ito:ITO_00115,Fundamental AI process,L1
0,1,Semantic Segmentation,Cityscapes test,2019-12,LightSeg-MobileNet,86.79,98.3,86.79,0.98,88.29,0.98,ito:ITO_00115,Fundamental AI process,Category\\ mIoU
1,1,Semantic Segmentation,Cityscapes test,2019-12,LightSeg-DarkNet19,88.29,100.0,1.5,0.02,88.29,1.0,ito:ITO_00115,Fundamental AI process,Category\\ mIoU
0,1,Network Pruning,CIFAR-10,2020-01,MobileNet – Quantised,4.74,20.48,4.74,0.2,23.15,0.2,ito:ITO_00115,Fundamental AI process,Inference\\ Time\\ \\(ms\\)
1,1,Network Pruning,CIFAR-10,2020-01,AlexNet – Quantised,5.23,22.59,0.5,0.02,23.15,0.23,ito:ITO_00115,Fundamental AI process,Inference\\ Time\\ \\(ms\\)
2,1,Network Pruning,CIFAR-10,2020-01,ShuffleNet – Quantised,23.15,100.0,17.9,0.77,23.15,1.0,ito:ITO_00115,Fundamental AI process,Inference\\ Time\\ \\(ms\\)
0,1,Neural Network Compression,CIFAR-10,2020-01,ShuffleNet – Quantised,1.9,3.48,1.9,0.03,54.6,0.03,ito:ITO_00115,Fundamental AI process,Size\\ \\(MB\\)
1,1,Neural Network Compression,CIFAR-10,2020-01,MobileNet – Quantised,2.9,5.31,1.0,0.02,54.6,0.05,ito:ITO_00115,Fundamental AI process,Size\\ \\(MB\\)
2,1,Neural Network Compression,CIFAR-10,2020-01,AlexNet – Quantised,54.6,100.0,51.7,0.95,54.6,1.0,ito:ITO_00115,Fundamental AI process,Size\\ \\(MB\\)
0,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet-tiny,0.44,11.08,0.44,0.11,3.97,0.11,ito:ITO_00115,Fundamental AI process,Parameters\\ \\(M\\)
1,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet,3.97,100.0,3.5,0.88,3.97,1.0,ito:ITO_00115,Fundamental AI process,Parameters\\ \\(M\\)
0,1,Sparse Learning,CINIC-10,2020-03,Resnet18,92.43,100.0,92.43,1.0,92.43,0.99,ito:ITO_00115,Fundamental AI process,Sparsity
1,1,Sparse Learning,ImageNet32,2020-03,Resnet18,93.63,100.0,93.63,1.0,93.63,1.0,ito:ITO_00115,Fundamental AI process,Sparsity
2,1,Inductive knowledge graph completion,Inductive knowledge graph completion,2020-03,Resnet18,92.43,100.0,92.43,1.0,92.43,0.99,ito:ITO_00115,Fundamental AI process,Sparsity
3,1,Speech Extraction,Speech Extraction,2020-03,Resnet18,93.63,100.0,93.63,1.0,93.63,1.0,ito:ITO_00115,Fundamental AI process,Sparsity
0,1,Few-Shot Semantic Segmentation,Pascal5i,2020-03,DoG-BConvLSTM,60.6,100.0,60.6,1.0,60.6,1.0,ito:ITO_00115,Fundamental AI process,meanIOU
0,1,Few-Shot Learning,Mini-ImageNet,2020-03,DPGN,67.6,100.0,67.6,1.0,67.6,1.0,ito:ITO_00115,Fundamental AI process,Acc
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,3.0,100.0,3,1.0,3,1.0,ito:ITO_00115,Fundamental AI process,Test\\ AUC\\ top\\ 1
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,7.6,100.0,7.6,1.0,7.6,1.0,ito:ITO_00115,Fundamental AI process,Test\\ AUC\\ top\\ 2
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,12.3,100.0,12.3,1.0,12.3,1.0,ito:ITO_00115,Fundamental AI process,Test\\ AUC\\ top\\ 3
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,4.3,100.0,4.3,1.0,4.3,1.0,ito:ITO_00115,Fundamental AI process,Val\\ AUC\\ top\\ 1
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,9.8,100.0,9.8,1.0,9.8,1.0,ito:ITO_00115,Fundamental AI process,Val\\ AUC\\ top\\ 2
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,14.8,100.0,14.8,1.0,14.8,1.0,ito:ITO_00115,Fundamental AI process,Val\\ AUC\\ top\\ 3
0,1,Compositional Zero-Shot Learning,UT-Zappos,2020-04,SymNet,67.8,100.0,67.8,1.0,67.8,1.0,ito:ITO_00115,Fundamental AI process,Top\\-2\\ accuracy\\ %
1,1,Compositional Zero-Shot Learning,MIT-States,2020-04,SymNet,28.2,100.0,28.2,1.0,28.2,0.42,ito:ITO_00115,Fundamental AI process,Top\\-2\\ accuracy\\ %
0,1,Compositional Zero-Shot Learning,UT-Zappos,2020-04,SymNet,76.0,100.0,76,1.0,76,1.0,ito:ITO_00115,Fundamental AI process,Top\\-3\\ accuracy\\ %
1,1,Compositional Zero-Shot Learning,MIT-States,2020-04,SymNet,33.8,100.0,33.8,1.0,33.8,0.44,ito:ITO_00115,Fundamental AI process,Top\\-3\\ accuracy\\ %
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,24.4,100.0,24.4,1.0,24.4,1.0,ito:ITO_00115,Fundamental AI process,Seen\\ accuracy
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,25.2,100.0,25.2,1.0,25.2,1.0,ito:ITO_00115,Fundamental AI process,Unseen\\ accuracy
0,1,Compositional Zero-Shot Learning,"MIT-States, generalized split",2020-04,SymNet,16.1,100.0,16.1,1.0,16.1,1.0,ito:ITO_00115,Fundamental AI process,H\\-Mean
0,1,Atrial Fibrillation Detection,MIT-BIH AF,2000-09,/spl Delta/RR intervals,94.95,95.52,94.95,0.96,99.4,0.95,ito:ITO_00126,Biomedical AI process,Accuracy
1,1,Atrial Fibrillation Detection,MIT-BIH AF,2014-02,Symbolic dynamics and Shannon entropy,97.57,98.16,2.6,0.03,99.4,0.98,ito:ITO_00126,Biomedical AI process,Accuracy
2,1,Atrial Fibrillation Detection,MIT-BIH AF,2018-08,Wavelet transform + 2D CNN,99.16,99.76,1.6,0.02,99.4,1.0,ito:ITO_00126,Biomedical AI process,Accuracy
3,1,Atrial Fibrillation Detection,MIT-BIH AF,2018-12,ECGNET,99.4,100.0,0.2,0.0,99.4,1.0,ito:ITO_00126,Biomedical AI process,Accuracy
4,1,Myocardial Infarction Detection,"PTB dataset, ECG lead II",2014-08,T-wave + Total Integral,94.7,98.75,94.7,0.99,95.9,0.95,ito:ITO_00126,Biomedical AI process,Accuracy
5,1,Myocardial Infarction Detection,"PTB dataset, ECG lead II",2018-04,Deep residual CNN,95.9,100.0,1.2,0.01,95.9,0.96,ito:ITO_00126,Biomedical AI process,Accuracy
6,1,Semanticity prediction,Semanticity prediction,2015-09,GCN-FP,50.5,67.43,50.5,0.67,74.89,0.51,ito:ITO_00126,Biomedical AI process,Accuracy
7,1,Semanticity prediction,Semanticity prediction,2015-11,DCNN,59.0,78.78,8.5,0.11,74.89,0.59,ito:ITO_00126,Biomedical AI process,Accuracy
8,1,Semanticity prediction,Semanticity prediction,2019-01,AdaLanczosNet,60.8,81.19,1.8,0.02,74.89,0.61,ito:ITO_00126,Biomedical AI process,Accuracy
9,1,Semanticity prediction,Semanticity prediction,2019-06,Truncated Krylov,74.89,100.0,14.1,0.19,74.89,0.75,ito:ITO_00126,Biomedical AI process,Accuracy
10,1,Node Classification,20NEWS,2015-10,GraRep,81.44,100.0,81.44,1.0,81.44,0.82,ito:ITO_00126,Biomedical AI process,Accuracy
11,1,Attention Score Prediction,Attention Score Prediction,2015-10,GraRep,81.44,100.0,81.44,1.0,81.44,0.82,ito:ITO_00126,Biomedical AI process,Accuracy
12,1,Surgical Skills Evaluation,JIGSAWS,2016-06,Bidir. LSTM,0.833,85.0,0.833,0.85,0.98,0.01,ito:ITO_00126,Biomedical AI process,Accuracy
13,1,Surgical Skills Evaluation,JIGSAWS,2018-06,CNN,0.98,100.0,0.1,0.1,0.98,0.01,ito:ITO_00126,Biomedical AI process,Accuracy
14,1,Zero-Shot Text-to-Image Generation,Zero-Shot Text-to-Image Generation,2016-06,Bidir. LSTM,0.833,85.0,0.833,0.85,0.98,0.01,ito:ITO_00126,Biomedical AI process,Accuracy
15,1,Zero-Shot Text-to-Image Generation,Zero-Shot Text-to-Image Generation,2018-06,CNN,0.98,100.0,0.1,0.1,0.98,0.01,ito:ITO_00126,Biomedical AI process,Accuracy
16,1,Surgical Skills Evaluation,MISTIC-SIL,2016-06,Bidir. LSTM,0.895,100.0,0.895,1.0,0.895,0.01,ito:ITO_00126,Biomedical AI process,Accuracy
17,1,Handwritten Word Generation,Handwritten Word Generation,2016-06,Bidir. LSTM,0.895,100.0,0.895,1.0,0.895,0.01,ito:ITO_00126,Biomedical AI process,Accuracy
18,1,Node Classification,Reddit,2016-09,GCN,95.68,98.62,95.68,0.99,97.02,0.96,ito:ITO_00126,Biomedical AI process,Accuracy
19,1,Node Classification,Reddit,2018-09,ASGCN,96.27,99.23,0.6,0.01,97.02,0.97,ito:ITO_00126,Biomedical AI process,Accuracy
20,1,Node Classification,Reddit,2019-07,GraphSAINT,97.0,99.98,0.7,0.01,97.02,0.97,ito:ITO_00126,Biomedical AI process,Accuracy
21,1,Node Classification,Reddit,2020-01,JKNet+DropEdge,97.02,100.0,0.0,0.0,97.02,0.97,ito:ITO_00126,Biomedical AI process,Accuracy
22,1,LWR Classification,LWR Classification,2016-09,GCN,95.68,98.62,95.68,0.99,97.02,0.96,ito:ITO_00126,Biomedical AI process,Accuracy
23,1,LWR Classification,LWR Classification,2018-09,ASGCN,96.27,99.23,0.6,0.01,97.02,0.97,ito:ITO_00126,Biomedical AI process,Accuracy
24,1,LWR Classification,LWR Classification,2019-07,GraphSAINT,97.0,99.98,0.7,0.01,97.02,0.97,ito:ITO_00126,Biomedical AI process,Accuracy
25,1,LWR Classification,LWR Classification,2020-01,JKNet+DropEdge,97.02,100.0,0.0,0.0,97.02,0.97,ito:ITO_00126,Biomedical AI process,Accuracy
26,1,Sleep Stage Detection,Sleep-EDF,2017-10,"Deep CNN with
transfer-learning",81.3,96.79,81.3,0.97,84.0,0.82,ito:ITO_00126,Biomedical AI process,Accuracy
27,1,Sleep Stage Detection,Sleep-EDF,2018-05,Multitask 1-max CNN,81.9,97.5,0.6,0.01,84.0,0.82,ito:ITO_00126,Biomedical AI process,Accuracy
28,1,Sleep Stage Detection,Sleep-EDF,2019-02,IITNet CRNN [Fpz-Cz],84.0,100.0,2.1,0.02,84.0,0.84,ito:ITO_00126,Biomedical AI process,Accuracy
29,1,Lung Nodule Classification,LIDC-IDRI,2018-01,DeepLung,90.44,97.7,90.44,0.98,92.57,0.91,ito:ITO_00126,Biomedical AI process,Accuracy
30,1,Lung Nodule Classification,LIDC-IDRI,2019-01,Gated-Dilated,92.57,100.0,2.1,0.02,92.57,0.93,ito:ITO_00126,Biomedical AI process,Accuracy
31,1,Sleep Stage Detection,MASS SS2,2018-05,"Multitask
1-max CNN",78.6,93.02,78.6,0.93,84.5,0.79,ito:ITO_00126,Biomedical AI process,Accuracy
32,1,Sleep Stage Detection,MASS SS2,2019-02,IITNet CRNN [F4-EOG (left)],84.5,100.0,5.9,0.07,84.5,0.85,ito:ITO_00126,Biomedical AI process,Accuracy
33,1,Sleep apnea detection,Dreem_NCT03657329,2018-12,DOSED,81.0,100.0,81,1.0,81,0.81,ito:ITO_00126,Biomedical AI process,Accuracy
34,1,Retinal Vessel Segmentation,DRIVE,2019-03,CE-Net,0.9545,99.84,0.9545,1.0,0.956,0.01,ito:ITO_00126,Biomedical AI process,Accuracy
35,1,Retinal Vessel Segmentation,DRIVE,2019-07,ET-Net,0.956,100.0,0.0,0.0,0.956,0.01,ito:ITO_00126,Biomedical AI process,Accuracy
36,1,Lung Nodule Segmentation,LUNA,2019-03,CE-Net,0.99,100.0,0.99,1.0,0.99,0.01,ito:ITO_00126,Biomedical AI process,Accuracy
37,1,Sleep Quality Task,100 sleep nights of 8 caregivers,2019-05,Random Forest,75.0,100.0,75,1.0,75,0.75,ito:ITO_00126,Biomedical AI process,Accuracy
38,1,QRS Complex Detection,QT,2019-07,"CNN (LOSO, Intra-Db)",97.42,100.0,97.42,1.0,97.42,0.98,ito:ITO_00126,Biomedical AI process,Accuracy
39,1,QRS Complex Detection,MIT-BIH AR,2019-07,"CNN (LOSO, Intra-Db)",99.6,100.0,99.6,1.0,99.6,1.0,ito:ITO_00126,Biomedical AI process,Accuracy
40,1,QRS Complex Detection,INCART,2019-07,"CNN (LOSO, Intra-Db)",97.85,100.0,97.85,1.0,97.85,0.98,ito:ITO_00126,Biomedical AI process,Accuracy
41,1,Congestive Heart Failure detection,CHF database,2019-07,Inclined Entropy (R-HessELM),98.49,100.0,98.49,1.0,98.49,0.99,ito:ITO_00126,Biomedical AI process,Accuracy
42,1,Lung Nodule Segmentation,Montgomery County,2019-07,ET-Net,0.9865,100.0,0.9865,1.0,0.9865,0.01,ito:ITO_00126,Biomedical AI process,Accuracy
43,1,Multimodal Sleep Stage Detection,Surrey-cEEGGrid,2019-07,Scratch SeqSleepNet+ (EEG+EOG),81.5,100.0,81.5,1.0,81.5,0.82,ito:ITO_00126,Biomedical AI process,Accuracy
44,1,Multimodal Sleep Stage Detection,Surrey-PSG,2019-07,Scratch SeqSleepNet+ (EEG+EOG),79.9,100.0,79.9,1.0,79.9,0.8,ito:ITO_00126,Biomedical AI process,Accuracy
45,1,Multimodal Sleep Stage Detection,Sleep-EDF-SC,2019-07,Scratch SeqSleepNet+ (EEG+EOG),82.2,100.0,82.2,1.0,82.2,0.83,ito:ITO_00126,Biomedical AI process,Accuracy
46,1,Multimodal Sleep Stage Detection,Sleep-EDF-ST,2019-07,Scratch SeqSleepNet+ (EEG+EOG),79.6,100.0,79.6,1.0,79.6,0.8,ito:ITO_00126,Biomedical AI process,Accuracy
47,1,Seizure Detection,CHB-MIT,2019-08,TF-Tensor-CNN,89.63,100.0,89.63,1.0,89.63,0.9,ito:ITO_00126,Biomedical AI process,Accuracy
48,1,Protein Secondary Structure Prediction,Jpred4 blind set,2019-10,Porter5,84.62,100.0,84.62,1.0,84.62,0.85,ito:ITO_00126,Biomedical AI process,Accuracy
0,1,Arrhythmia Detection,MIT-BIH AR,2005-01,SVM,76.3,76.66,76.3,0.77,99.53,0.77,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(Inter\\-Patient\\)
1,1,Arrhythmia Detection,MIT-BIH AR,2017-09,TVCG_PSO,92.4,92.84,16.1,0.16,99.53,0.93,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(Inter\\-Patient\\)
2,1,Arrhythmia Detection,MIT-BIH AR,2018-04,Deep residual CNN ,93.4,93.84,1.0,0.01,99.53,0.94,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(Inter\\-Patient\\)
3,1,Arrhythmia Detection,MIT-BIH AR,2018-12,BiRNN,99.53,100.0,6.1,0.06,99.53,1.0,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(Inter\\-Patient\\)
0,1,Arrhythmia Detection,MIT-BIH AR,2005-01,SVM,98.7,98.78,98.7,0.99,99.92,0.99,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(Intra\\-Patient\\)
1,1,Arrhythmia Detection,MIT-BIH AR,2018-12,BiRNN,99.92,100.0,1.2,0.01,99.92,1.0,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(Intra\\-Patient\\)
0,1,BIRL: Benchmark on Image Registration methods with Landmark validations,CIMA-10k,2006-05,bUnwarpJ,2.82,100.0,2.82,1.0,2.82,1.0,ito:ITO_00126,Biomedical AI process,AMrTRE
0,1,BIRL: Benchmark on Image Registration methods with Landmark validations,CIMA-10k,2006-05,bUnwarpJ,3.0,100.0,3.0,1.0,3.0,1.0,ito:ITO_00126,Biomedical AI process,MMrTRE
0,1,Diffeomorphic Medical Image Registration,CUMC12,2008-02,SyN,0.514,98.85,0.514,0.99,0.52,0.99,ito:ITO_00126,Biomedical AI process,Mean\\ target\\ overlap\\ ratio
1,1,Diffeomorphic Medical Image Registration,CUMC12,2018-09,VoxelMorph,0.517,99.42,0.0,0.0,0.52,0.99,ito:ITO_00126,Biomedical AI process,Mean\\ target\\ overlap\\ ratio
2,1,Diffeomorphic Medical Image Registration,CUMC12,2019-04,Metric Net (Local Reg),0.52,100.0,0.0,0.0,0.52,1.0,ito:ITO_00126,Biomedical AI process,Mean\\ target\\ overlap\\ ratio
0,1,Blood pressure estimation,Multi-day Continuous BP Prediction,2017-05,Deep RNN,3.73,100.0,3.73,1.0,3.73,1.0,ito:ITO_00126,Biomedical AI process,RMSE
0,1,Multi-tissue Nucleus Segmentation,Kumar,2014-11,FCN8 (e),31.2,61.3,31.2,0.61,50.9,0.16,ito:ITO_00126,Biomedical AI process,Hausdorff\\ Distance\\ \\(mm\\)
1,1,Multi-tissue Nucleus Segmentation,Kumar,2015-05,U-Net (e),47.8,93.91,16.6,0.33,50.9,0.24,ito:ITO_00126,Biomedical AI process,Hausdorff\\ Distance\\ \\(mm\\)
2,1,Multi-tissue Nucleus Segmentation,Kumar,2017-03,Mask R-CNN (e),50.9,100.0,3.1,0.06,50.9,0.26,ito:ITO_00126,Biomedical AI process,Hausdorff\\ Distance\\ \\(mm\\)
3,1,Colorectal Gland Segmentation:,CRAG,2015-05,FCN8 (e),199.5,100.0,199.5,1.0,199.5,1.0,ito:ITO_00126,Biomedical AI process,Hausdorff\\ Distance\\ \\(mm\\)
0,1,Multi-tissue Nucleus Segmentation,Kumar,2014-11,FCN8 (e),0.797,100.0,0.797,1.0,0.797,0.01,ito:ITO_00126,Biomedical AI process,Dice
1,1,Colorectal Gland Segmentation:,CRAG,2015-05,FCN8 (e),0.835,98.93,0.835,0.99,0.844,0.01,ito:ITO_00126,Biomedical AI process,Dice
2,1,Colorectal Gland Segmentation:,CRAG,2015-05,U-Net (e),0.844,100.0,0.0,0.0,0.844,0.01,ito:ITO_00126,Biomedical AI process,Dice
3,1,Medical Image Segmentation,RITE,2015-05,U-Net,55.24,100.0,55.24,1.0,55.24,0.61,ito:ITO_00126,Biomedical AI process,Dice
4,1,Nuclear Segmentation,Cell17,2016-03,FnsNet,0.6165,82.13,0.6165,0.82,0.7506,0.01,ito:ITO_00126,Biomedical AI process,Dice
5,1,Nuclear Segmentation,Cell17,2016-11,Pix2Pix,0.6351,84.61,0.0,0.0,0.7506,0.01,ito:ITO_00126,Biomedical AI process,Dice
6,1,Nuclear Segmentation,Cell17,2017-03,Mask R-CNN,0.707,94.19,0.1,0.13,0.7506,0.01,ito:ITO_00126,Biomedical AI process,Dice
7,1,Nuclear Segmentation,Cell17,2018-09,Cell R-CNN,0.7088,94.43,0.0,0.0,0.7506,0.01,ito:ITO_00126,Biomedical AI process,Dice
8,1,Nuclear Segmentation,Cell17,2019-08,Deep Panoptic Model with Semantic Feature Fusion,0.7506,100.0,0.0,0.0,0.7506,0.01,ito:ITO_00126,Biomedical AI process,Dice
9,1,Medical Image Segmentation,2018 Data Science Bowl,2018-07,Unet++,0.8974,100.0,0.8974,1.0,0.8974,0.01,ito:ITO_00126,Biomedical AI process,Dice
10,1,Lung Nodule Segmentation,LIDC-IDRI,2019-08,ModelGenesis,75.86,100.0,75.86,1.0,75.86,0.83,ito:ITO_00126,Biomedical AI process,Dice
11,1,Liver Segmentation,LiTS2017,2019-08,ModelGenesis,91.13,100.0,91.13,1.0,91.13,1.0,ito:ITO_00126,Biomedical AI process,Dice
0,1,Heartbeat Classification,MIT-BIH AR,2014-06,SVM Ensembles (II Leads),90.9,94.98,90.9,0.95,95.7,0.95,ito:ITO_00126,Biomedical AI process,PPV\\ \\(VEB\\)
1,1,Heartbeat Classification,MIT-BIH AR,2019-07,ESN Ensembles (II Leads),95.7,100.0,4.8,0.05,95.7,1.0,ito:ITO_00126,Biomedical AI process,PPV\\ \\(VEB\\)
0,1,Heartbeat Classification,MIT-BIH AR,2014-06,SVM Ensembles (II Leads),93.9,100.0,93.9,1.0,93.9,1.0,ito:ITO_00126,Biomedical AI process,Sensitivity\\ \\(VEB\\)
0,1,Arrhythmia Detection,The PhysioNet Computing in Cardiology Challenge 2017,2014-09,Feature-based approach (no segmentation),79.0,100.0,79,1.0,79,1.0,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(TEST\\-DB\\)
0,1,Arrhythmia Detection,The PhysioNet Computing in Cardiology Challenge 2017,2014-09,Feature-based approach (no segmentation),72.0,81.82,72.0,0.82,88.0,0.82,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(TRAIN\\-DB\\)
1,1,Arrhythmia Detection,The PhysioNet Computing in Cardiology Challenge 2017,2014-09,Feature-based approach (10 s segments),76.6,87.05,4.6,0.05,88.0,0.87,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(TRAIN\\-DB\\)
2,1,Arrhythmia Detection,The PhysioNet Computing in Cardiology Challenge 2017,2018-08,Towards Understanding ECG Rhyth,88.0,100.0,11.4,0.13,88.0,1.0,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(TRAIN\\-DB\\)
0,1,Brain Tumor Segmentation,BRATS-2013 leaderboard,2015-05,InputCascadeCNN,0.84,100.0,0.84,1.0,0.84,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
1,1,Brain Tumor Segmentation,BRATS-2013,2015-05,InputCascadeCNN,0.88,95.05,0.88,0.95,0.9258,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
2,1,Brain Tumor Segmentation,BRATS-2013,2019-08,ModelGenesis,0.9258,100.0,0.0,0.0,0.9258,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
3,1,Pancreas Segmentation,CT-150,2015-05,U-Net,0.814,96.9,0.814,0.97,0.84,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
4,1,Pancreas Segmentation,CT-150,2018-04,Att U-Net,0.84,100.0,0.0,0.0,0.84,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
5,1,Pancreas Segmentation,TCIA Pancreas-CT Dataset,2015-05,U-Net,0.82,93.61,0.82,0.94,0.876,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
6,1,Pancreas Segmentation,TCIA Pancreas-CT Dataset,2017-09,Recurrent Saliency Transformation Network,0.876,100.0,0.1,0.11,0.876,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
7,1,Brain Tumor Segmentation,BRATS-2015,2016-03,3D CNN + CRF,85.0,97.7,85,0.98,87,0.93,ito:ITO_00126,Biomedical AI process,Dice\\ Score
8,1,Brain Tumor Segmentation,BRATS-2015,2019-06,OM-Net + CGAp,87.0,100.0,2,0.02,87,0.95,ito:ITO_00126,Biomedical AI process,Dice\\ Score
9,1,Lesion Segmentation,ISLES-2015,2016-03,3D CNN + CRF,59.0,100.0,59,1.0,59,0.64,ito:ITO_00126,Biomedical AI process,Dice\\ Score
10,1,Volumetric Medical Image Segmentation,PROMISE 2012,2016-06,V-Net + Dice-based loss,0.869,100.0,0.869,1.0,0.869,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
11,1,3D Medical Imaging Segmentation,TCIA Pancreas-CT,2017-01,Holistic-nested CNN,81.3,100.0,81.3,1.0,81.3,0.89,ito:ITO_00126,Biomedical AI process,Dice\\ Score
12,1,Brain Tumor Segmentation,BRATS-2014,2017-09,Cascaded Anisotropic CNNs,0.8739,100.0,0.8739,1.0,0.8739,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
13,1,Brain Tumor Segmentation,BRATS-2017 val,2017-09,Wang et al.,0.905,99.77,0.905,1.0,0.9071,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
14,1,Brain Tumor Segmentation,BRATS-2017 val,2019-06,OM-Net + CGAp,0.9071,100.0,0.0,0.0,0.9071,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
15,1,Infant Brain MRI Segmentation,iSEG 2017 Challenge,2017-12,LiviaNet (SemiDenseNet),0.9243,100.0,0.9243,1.0,0.9243,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
16,1,Medical Image Segmentation,iSEG 2017 Challenge,2018-04,HyperDenseNet,0.9257,100.0,0.9257,1.0,0.9257,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
17,1,Lesion Segmentation,ISIC 2018,2018-10,Attn U-Net + Multi-Input + FTL,0.856,95.64,0.856,0.96,0.895,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
18,1,Lesion Segmentation,ISIC 2018,2020-03,MCGU-Net,0.895,100.0,0.0,0.0,0.895,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
19,1,Lesion Segmentation,BUS 2017 Dataset B,2018-10,Attn U-Net + Multi-Input + FTL,0.804,100.0,0.804,1.0,0.804,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
20,1,Brain Tumor Segmentation,BRATS 2018,2018-10,NVDLMED,0.87049,100.0,0.87049,1.0,0.87049,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
21,1,Brain Image Segmentation,T1-weighted MRI,2019-02,Learned Transformations (random augmentation),81.5,100.0,81.5,1.0,81.5,0.89,ito:ITO_00126,Biomedical AI process,Dice\\ Score
22,1,Lung Nodule Segmentation,NIH,2019-04,U-Net+R+A4,0.962,100.0,0.962,1.0,0.962,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
23,1,Brain Tumor Segmentation,BRATS 2018 val,2019-06,OM-Net + CGAp,91.59,100.0,91.59,1.0,91.59,1.0,ito:ITO_00126,Biomedical AI process,Dice\\ Score
24,1,Medical Image Segmentation,CHAOS MRI Dataset,2019-06,MS-Dual-Guided,86.75,100.0,86.75,1.0,86.75,0.95,ito:ITO_00126,Biomedical AI process,Dice\\ Score
25,1,Medical Image Segmentation,HSVM,2019-06,MS-Dual-Guided,83.2,100.0,83.2,1.0,83.2,0.91,ito:ITO_00126,Biomedical AI process,Dice\\ Score
26,1,Brain Image Segmentation,Brain MRI segmentation,2019-06,U-Net,0.82,100.0,0.82,1.0,0.82,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
27,1,Brain Segmentation,Brain MRI segmentation,2019-06,U-Net,0.82,100.0,0.82,1.0,0.82,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
28,1,Lung Nodule Segmentation,Lung Nodule ,2019-08,BCDU-net,0.994,100.0,0.994,1.0,0.994,0.01,ito:ITO_00126,Biomedical AI process,Dice\\ Score
0,1,Pancreas Segmentation,CT-150,2015-05,U-Net,0.848,99.88,0.848,1.0,0.849,0.01,ito:ITO_00126,Biomedical AI process,Precision
1,1,Pancreas Segmentation,CT-150,2018-04,Att U-Net,0.849,100.0,0.0,0.0,0.849,0.01,ito:ITO_00126,Biomedical AI process,Precision
2,1,Mortality Prediction,MIMIC-III,2018-03,Random Forest,0.97,100.0,0.97,1.0,0.97,0.01,ito:ITO_00126,Biomedical AI process,Precision
3,1,Lung Nodule Segmentation,NIH,2019-04,U-Net+R+A4,0.969,100.0,0.969,1.0,0.969,0.01,ito:ITO_00126,Biomedical AI process,Precision
4,1,Congestive Heart Failure detection,CHF database,2019-07,Inclined Entropy (R-HessELM),98.05,100.0,98.05,1.0,98.05,1.0,ito:ITO_00126,Biomedical AI process,Precision
0,1,Medical Image Segmentation,ISBI 2012 EM Segmentation,2015-05,U-Net,0.000353,100.0,0.000353,1.0,0.000353,1.0,ito:ITO_00126,Biomedical AI process,Warping\\ Error
0,1,Medical Image Segmentation,Kvasir-SEG,2015-05,U-Net,0.818,99.63,0.818,1.0,0.821,0.99,ito:ITO_00126,Biomedical AI process,mean\\ Dice
1,1,Medical Image Segmentation,Kvasir-SEG,2018-07,U-Net++,0.821,100.0,0.0,0.0,0.821,1.0,ito:ITO_00126,Biomedical AI process,mean\\ Dice
2,1,Medical Image Segmentation,CVC-ClinicDB,2015-05,U-Net,0.823,100.0,0.823,1.0,0.823,1.0,ito:ITO_00126,Biomedical AI process,mean\\ Dice
0,1,Medical Image Segmentation,RITE,2015-05,U-Net,31.11,79.48,31.11,0.79,39.14,0.79,ito:ITO_00126,Biomedical AI process,Jaccard\\ Index
1,1,Medical Image Segmentation,RITE,2015-11,SegNet,39.14,100.0,8.0,0.2,39.14,1.0,ito:ITO_00126,Biomedical AI process,Jaccard\\ Index
0,1,Medical Image Segmentation,Kvasir-SEG,2015-05,U-Net,0.055,100.0,0.055,1.0,0.055,1.0,ito:ITO_00126,Biomedical AI process,Average\\ MAE
0,1,Medical Image Segmentation,Kvasir-SEG,2015-05,U-Net,0.858,99.54,0.858,1.0,0.862,1.0,ito:ITO_00126,Biomedical AI process,S\\-Measure
1,1,Medical Image Segmentation,Kvasir-SEG,2018-07,U-Net++,0.862,100.0,0.0,0.0,0.862,1.0,ito:ITO_00126,Biomedical AI process,S\\-Measure
0,1,Medical Image Segmentation,Kvasir-SEG,2015-05,U-Net,0.893,98.13,0.893,0.98,0.91,0.98,ito:ITO_00126,Biomedical AI process,max\\ E\\-Measure
1,1,Medical Image Segmentation,Kvasir-SEG,2018-07,U-Net++,0.91,100.0,0.0,0.0,0.91,1.0,ito:ITO_00126,Biomedical AI process,max\\ E\\-Measure
0,1,Retinal Vessel Segmentation,DRIVE,2015-05,U-Net,0.9755,99.38,0.9755,0.99,0.9816,0.01,ito:ITO_00126,Biomedical AI process,AUC
1,1,Retinal Vessel Segmentation,DRIVE,2017-11,Residual U-Net,0.9779,99.62,0.0,0.0,0.9816,0.01,ito:ITO_00126,Biomedical AI process,AUC
2,1,Retinal Vessel Segmentation,DRIVE,2018-06,VGN,0.9802,99.86,0.0,0.0,0.9816,0.01,ito:ITO_00126,Biomedical AI process,AUC
3,1,Retinal Vessel Segmentation,DRIVE,2019-12,IterNet,0.9816,100.0,0.0,0.0,0.9816,0.01,ito:ITO_00126,Biomedical AI process,AUC
4,1,Retinal Vessel Segmentation,STARE,2015-05,U-Net,0.9898,99.84,0.9898,1.0,0.9914,0.01,ito:ITO_00126,Biomedical AI process,AUC
5,1,Retinal Vessel Segmentation,STARE,2018-02,R2U-Net,0.9914,100.0,0.0,0.0,0.9914,0.01,ito:ITO_00126,Biomedical AI process,AUC
6,1,Lung Nodule Segmentation,LUNA,2015-05,U-Net,0.9784,98.37,0.9784,0.98,0.9946,0.01,ito:ITO_00126,Biomedical AI process,AUC
7,1,Lung Nodule Segmentation,LUNA,2017-11,Residual U-Net,0.9849,99.02,0.0,0.0,0.9946,0.01,ito:ITO_00126,Biomedical AI process,AUC
8,1,Lung Nodule Segmentation,LUNA,2019-08,BCDU-Net (d=3),0.9946,100.0,0.0,0.0,0.9946,0.01,ito:ITO_00126,Biomedical AI process,AUC
9,1,Retinal Vessel Segmentation,CHASE_DB1,2015-05,U-Net,0.9772,99.2,0.9772,0.99,0.9851,0.01,ito:ITO_00126,Biomedical AI process,AUC
10,1,Retinal Vessel Segmentation,CHASE_DB1,2017-11,Residual U-Net,0.9779,99.27,0.0,0.0,0.9851,0.01,ito:ITO_00126,Biomedical AI process,AUC
11,1,Retinal Vessel Segmentation,CHASE_DB1,2018-02,R2U-Net,0.9815,99.63,0.0,0.0,0.9851,0.01,ito:ITO_00126,Biomedical AI process,AUC
12,1,Retinal Vessel Segmentation,CHASE_DB1,2018-06,VGN,0.983,99.79,0.0,0.0,0.9851,0.01,ito:ITO_00126,Biomedical AI process,AUC
13,1,Retinal Vessel Segmentation,CHASE_DB1,2018-10,LadderNet,0.9839,99.88,0.0,0.0,0.9851,0.01,ito:ITO_00126,Biomedical AI process,AUC
14,1,Retinal Vessel Segmentation,CHASE_DB1,2019-12,IterNet,0.9851,100.0,0.0,0.0,0.9851,0.01,ito:ITO_00126,Biomedical AI process,AUC
15,1,Skin Cancer Segmentation,Kaggle Skin Lesion Segmentation,2015-05,U-Net,0.9371,99.49,0.9371,0.99,0.9419,0.01,ito:ITO_00126,Biomedical AI process,AUC
16,1,Skin Cancer Segmentation,Kaggle Skin Lesion Segmentation,2017-11,Residual U-Net,0.9396,99.76,0.0,0.0,0.9419,0.01,ito:ITO_00126,Biomedical AI process,AUC
17,1,Skin Cancer Segmentation,Kaggle Skin Lesion Segmentation,2018-02,R2U-Net,0.9419,100.0,0.0,0.0,0.9419,0.01,ito:ITO_00126,Biomedical AI process,AUC
18,1,Electron Microscopy Image Segmentation,SNEMI3D,2015-05,U-Net,0.8676,96.91,0.8676,0.97,0.8953,0.01,ito:ITO_00126,Biomedical AI process,AUC
19,1,Electron Microscopy Image Segmentation,SNEMI3D,2019-08,DTN,0.8953,100.0,0.0,0.0,0.8953,0.01,ito:ITO_00126,Biomedical AI process,AUC
20,1,Drug Discovery,PCBA,2015-09,GraphConv,0.855,98.62,0.855,0.99,0.867,0.01,ito:ITO_00126,Biomedical AI process,AUC
21,1,Drug Discovery,PCBA,2017-09,GraphConv + dummy super node,0.867,100.0,0.0,0.0,0.867,0.01,ito:ITO_00126,Biomedical AI process,AUC
22,1,Drug Discovery,Tox21,2015-09,GraphConv,0.846,96.69,0.846,0.97,0.875,0.01,ito:ITO_00126,Biomedical AI process,AUC
23,1,Drug Discovery,Tox21,2017-09,GraphConv + dummy super node,0.854,97.6,0.0,0.0,0.875,0.01,ito:ITO_00126,Biomedical AI process,AUC
24,1,Drug Discovery,Tox21,2018-06,Ensemble predictor,0.862,98.51,0.0,0.0,0.875,0.01,ito:ITO_00126,Biomedical AI process,AUC
25,1,Drug Discovery,Tox21,2019-05,SSVAE with multiple SMILES,0.875,100.0,0.0,0.0,0.875,0.01,ito:ITO_00126,Biomedical AI process,AUC
26,1,Drug Discovery,ToxCast,2015-09,GraphConv,0.754,98.18,0.754,0.98,0.768,0.01,ito:ITO_00126,Biomedical AI process,AUC
27,1,Drug Discovery,ToxCast,2017-09,GraphConv + dummy super node,0.768,100.0,0.0,0.0,0.768,0.01,ito:ITO_00126,Biomedical AI process,AUC
28,1,Drug Discovery,HIV dataset,2015-09,GraphConv,0.822,96.59,0.822,0.97,0.851,0.01,ito:ITO_00126,Biomedical AI process,AUC
29,1,Drug Discovery,HIV dataset,2017-09,GraphConv + dummy super node + focal loss,0.851,100.0,0.0,0.0,0.851,0.01,ito:ITO_00126,Biomedical AI process,AUC
30,1,Drug Discovery,MUV,2015-09,GraphConv,0.836,98.93,0.836,0.99,0.845,0.01,ito:ITO_00126,Biomedical AI process,AUC
31,1,Drug Discovery,MUV,2017-09,GraphConv + dummy super node,0.845,100.0,0.0,0.0,0.845,0.01,ito:ITO_00126,Biomedical AI process,AUC
32,1,Breast Tumour Classification,PCam,2015-12,ResNet-34 (e),0.942,99.37,0.942,0.99,0.948,0.01,ito:ITO_00126,Biomedical AI process,AUC
33,1,Breast Tumour Classification,PCam,2015-12,ResNet-50 (e),0.948,100.0,0.0,0.0,0.948,0.01,ito:ITO_00126,Biomedical AI process,AUC
34,1,Retinal Vessel Segmentation,HRF,2018-06,VGN,0.9838,100.0,0.9838,1.0,0.9838,0.01,ito:ITO_00126,Biomedical AI process,AUC
35,1,Seizure Prediction,Melbourne University Seizure Prediction,2018-11,CNN,0.591,70.36,0.591,0.7,0.84,0.01,ito:ITO_00126,Biomedical AI process,AUC
36,1,Seizure Prediction,Melbourne University Seizure Prediction,2019-04,CNN+FCN,0.84,100.0,0.2,0.24,0.84,0.01,ito:ITO_00126,Biomedical AI process,AUC
37,1,Lung Nodule Classification,LIDC-IDRI,2019-01,Gated-Dilated,95.14,99.5,95.14,0.99,95.62,0.97,ito:ITO_00126,Biomedical AI process,AUC
38,1,Lung Nodule Classification,LIDC-IDRI,2019-04,Local-Global,95.62,100.0,0.5,0.01,95.62,0.97,ito:ITO_00126,Biomedical AI process,AUC
39,1,Drug Discovery,SIDER,2019-05,ContextPred,0.627,100.0,0.627,1.0,0.627,0.01,ito:ITO_00126,Biomedical AI process,AUC
40,1,Drug Discovery,ClinTox,2019-05,ContextPred,0.726,100.0,0.726,1.0,0.726,0.01,ito:ITO_00126,Biomedical AI process,AUC
41,1,Drug Discovery,BBBP,2019-05,ContextPred,0.687,100.0,0.687,1.0,0.687,0.01,ito:ITO_00126,Biomedical AI process,AUC
42,1,Drug Discovery,BACE,2019-05,ContextPred,0.845,100.0,0.845,1.0,0.845,0.01,ito:ITO_00126,Biomedical AI process,AUC
43,1,Drug Discovery,egfr-inh,2019-06,Multi-input Neural network with Attention,0.91,100.0,0.91,1.0,0.91,0.01,ito:ITO_00126,Biomedical AI process,AUC
44,1,Lung Nodule Detection,LUNA2016 FPRED,2019-08,ModelGenesis,98.2,100.0,98.2,1.0,98.2,1.0,ito:ITO_00126,Biomedical AI process,AUC
45,1,Pulmonary Embolism Detection,PE-CAD FPRED,2019-08,ModelGenesis,88.04,100.0,88.04,1.0,88.04,0.9,ito:ITO_00126,Biomedical AI process,AUC
46,1,Provable Adversarial Defense,Provable Adversarial Defense,2019-08,ModelGenesis,88.04,100.0,88.04,1.0,88.04,0.9,ito:ITO_00126,Biomedical AI process,AUC
0,1,Pancreas Segmentation,CT-150,2015-05,U-Net,0.806,95.84,0.806,0.96,0.841,0.83,ito:ITO_00126,Biomedical AI process,Recall
1,1,Pancreas Segmentation,CT-150,2018-04,Att U-Net,0.841,100.0,0.0,0.0,0.841,0.87,ito:ITO_00126,Biomedical AI process,Recall
2,1,Mortality Prediction,MIMIC-III,2018-03,Random Forest,0.97,100.0,0.97,1.0,0.97,1.0,ito:ITO_00126,Biomedical AI process,Recall
3,1,Lung Nodule Segmentation,NIH,2019-04,U-Net+R+A4,0.956,100.0,0.956,1.0,0.956,0.99,ito:ITO_00126,Biomedical AI process,Recall
0,1,Lung Nodule Segmentation,LIDC-IDRI,2019-08,ModelGenesis,77.62,100.0,77.62,1.0,77.62,0.83,ito:ITO_00126,Biomedical AI process,IoU
1,1,Liver Segmentation,LiTS2017,2019-08,ModelGenesis,79.52,100.0,79.52,1.0,79.52,0.85,ito:ITO_00126,Biomedical AI process,IoU
2,1,Skin Cancer Segmentation,PH2,2019-11,SegNet,93.61,100.0,93.61,1.0,93.61,1.0,ito:ITO_00126,Biomedical AI process,IoU
3,1,Medical Image Segmentation,EM,2019-12,UNet++,89.33,100.0,89.33,1.0,89.33,0.95,ito:ITO_00126,Biomedical AI process,IoU
4,1,Medical Image Segmentation,Cell,2019-12,UNet++,91.21,100.0,91.21,1.0,91.21,0.97,ito:ITO_00126,Biomedical AI process,IoU
5,1,Brain Image Segmentation,Brain Tumor,2019-12,UNet++,91.21,100.0,91.21,1.0,91.21,0.97,ito:ITO_00126,Biomedical AI process,IoU
0,1,Cell Segmentation,PhC-U373,2015-05,U-Net,0.9203,100.0,0.9203,1.0,0.9203,1.0,ito:ITO_00126,Biomedical AI process,Mean\\ IoU
1,1,Cell Segmentation,DIC-HeLa,2015-05,U-Net,0.7756,100.0,0.7756,1.0,0.7756,0.84,ito:ITO_00126,Biomedical AI process,Mean\\ IoU
2,1,Lesion Segmentation,ISIC 2017,2017-03,Automatic skin lesion segmentation with fully convolutional-deconvolutional networks,0.765,100.0,0.765,1.0,0.765,0.83,ito:ITO_00126,Biomedical AI process,Mean\\ IoU
0,1,Lung Nodule Segmentation,LUNA,2015-05,U-Net,0.9658,97.52,0.9658,0.98,0.9904,0.98,ito:ITO_00126,Biomedical AI process,F1\\ score
1,1,Lung Nodule Segmentation,LUNA,2017-11,Residual U-Net,0.969,97.84,0.0,0.0,0.9904,0.98,ito:ITO_00126,Biomedical AI process,F1\\ score
2,1,Lung Nodule Segmentation,LUNA,2019-08,BCDU-Net (d=3),0.9904,100.0,0.0,0.0,0.9904,1.0,ito:ITO_00126,Biomedical AI process,F1\\ score
3,1,Retinal Vessel Segmentation,CHASE_DB1,2015-05,U-Net,0.7783,96.41,0.7783,0.96,0.8073,0.79,ito:ITO_00126,Biomedical AI process,F1\\ score
4,1,Retinal Vessel Segmentation,CHASE_DB1,2017-11,Residual U-Net,0.78,96.62,0.0,0.0,0.8073,0.79,ito:ITO_00126,Biomedical AI process,F1\\ score
5,1,Retinal Vessel Segmentation,CHASE_DB1,2018-02,R2U-Net,0.7928,98.2,0.0,0.0,0.8073,0.8,ito:ITO_00126,Biomedical AI process,F1\\ score
6,1,Retinal Vessel Segmentation,CHASE_DB1,2018-06,VGN,0.8034,99.52,0.0,0.0,0.8073,0.81,ito:ITO_00126,Biomedical AI process,F1\\ score
7,1,Retinal Vessel Segmentation,CHASE_DB1,2019-12,IterNet,0.8073,100.0,0.0,0.0,0.8073,0.82,ito:ITO_00126,Biomedical AI process,F1\\ score
8,1,Skin Cancer Segmentation,Kaggle Skin Lesion Segmentation,2015-05,U-Net,0.8682,97.33,0.8682,0.97,0.892,0.88,ito:ITO_00126,Biomedical AI process,F1\\ score
9,1,Skin Cancer Segmentation,Kaggle Skin Lesion Segmentation,2017-11,Residual U-Net,0.8799,98.64,0.0,0.0,0.892,0.89,ito:ITO_00126,Biomedical AI process,F1\\ score
10,1,Skin Cancer Segmentation,Kaggle Skin Lesion Segmentation,2018-02,R2U-Net,0.892,100.0,0.0,0.0,0.892,0.9,ito:ITO_00126,Biomedical AI process,F1\\ score
11,1,Retinal Vessel Segmentation,STARE,2015-05,U-Net,0.8373,98.8,0.8373,0.99,0.8475,0.85,ito:ITO_00126,Biomedical AI process,F1\\ score
12,1,Retinal Vessel Segmentation,STARE,2017-11,Residual U-Net,0.8388,98.97,0.0,0.0,0.8475,0.85,ito:ITO_00126,Biomedical AI process,F1\\ score
13,1,Retinal Vessel Segmentation,STARE,2018-02,R2U-Net,0.8475,100.0,0.0,0.0,0.8475,0.86,ito:ITO_00126,Biomedical AI process,F1\\ score
14,1,Retinal Vessel Segmentation,DRIVE,2015-05,U-Net,0.8142,98.54,0.8142,0.99,0.8263,0.82,ito:ITO_00126,Biomedical AI process,F1\\ score
15,1,Retinal Vessel Segmentation,DRIVE,2017-11,Residual U-Net,0.8149,98.62,0.0,0.0,0.8263,0.82,ito:ITO_00126,Biomedical AI process,F1\\ score
16,1,Retinal Vessel Segmentation,DRIVE,2018-06,VGN,0.8263,100.0,0.0,0.0,0.8263,0.83,ito:ITO_00126,Biomedical AI process,F1\\ score
17,1,Mortality Prediction,MIMIC-III,2018-03,Random Forest,0.97,100.0,0.97,1.0,0.97,0.98,ito:ITO_00126,Biomedical AI process,F1\\ score
18,1,Retinal Vessel Segmentation,HRF,2018-06,VGN,0.8151,100.0,0.8151,1.0,0.8151,0.82,ito:ITO_00126,Biomedical AI process,F1\\ score
19,1,Medical Image Segmentation,DRIVE,2019-08,BCDU-net,0.8222,100.0,0.8222,1.0,0.8222,0.83,ito:ITO_00126,Biomedical AI process,F1\\ score
0,1,Colorectal Gland Segmentation:,CRAG,2015-05,FCN8 (e),0.796,96.25,0.796,0.96,0.827,0.89,ito:ITO_00126,Biomedical AI process,F1\\-score
1,1,Colorectal Gland Segmentation:,CRAG,2015-05,U-Net (e),0.827,100.0,0.0,0.0,0.827,0.93,ito:ITO_00126,Biomedical AI process,F1\\-score
2,1,Nuclear Segmentation,Cell17,2016-03,FnsNet,0.7413,85.75,0.7413,0.86,0.8645,0.83,ito:ITO_00126,Biomedical AI process,F1\\-score
3,1,Nuclear Segmentation,Cell17,2017-03,Mask R-CNN,0.8004,92.59,0.1,0.12,0.8645,0.9,ito:ITO_00126,Biomedical AI process,F1\\-score
4,1,Nuclear Segmentation,Cell17,2018-09,Cell R-CNN,0.8216,95.04,0.0,0.0,0.8645,0.92,ito:ITO_00126,Biomedical AI process,F1\\-score
5,1,Nuclear Segmentation,Cell17,2019-08,Deep Panoptic Model with Semantic Feature Fusion,0.8645,100.0,0.0,0.0,0.8645,0.97,ito:ITO_00126,Biomedical AI process,F1\\-score
6,1,EEG Artifact Removal,MayoClinic_iEEG,2018-08,CNN/APN,0.89,100.0,0.89,1.0,0.89,1.0,ito:ITO_00126,Biomedical AI process,F1\\-score
0,1,Drug Discovery,QM9,2015-11,Gated Graph Sequence NN,1.36,52.51,1.36,0.53,2.59,0.53,ito:ITO_00126,Biomedical AI process,Error\\ ratio
1,1,Drug Discovery,QM9,2016-03,Molecular Graph Convolutions,2.59,100.0,1.2,0.46,2.59,1.0,ito:ITO_00126,Biomedical AI process,Error\\ ratio
0,1,Retinal OCT Disease Classification,OCT2017,2015-12,InceptionV3,96.6,97.18,96.6,0.97,99.4,0.97,ito:ITO_00126,Biomedical AI process,Acc
1,1,Retinal OCT Disease Classification,OCT2017,2015-12,ResNet50-v1,99.3,99.9,2.7,0.03,99.4,1.0,ito:ITO_00126,Biomedical AI process,Acc
2,1,Retinal OCT Disease Classification,OCT2017,2018-01,MobileNet-v2,99.4,100.0,0.1,0.0,99.4,1.0,ito:ITO_00126,Biomedical AI process,Acc
3,1,Retinal OCT Disease Classification,Srinivasan2014,2015-12,ResNet50-v1,94.92,97.39,94.92,0.97,97.46,0.95,ito:ITO_00126,Biomedical AI process,Acc
4,1,Retinal OCT Disease Classification,Srinivasan2014,2018-01,MobileNet-v2,97.46,100.0,2.5,0.03,97.46,0.98,ito:ITO_00126,Biomedical AI process,Acc
5,1,Lung Nodule Classification,LIDC-IDRI,2018-01,DeepLung,90.44,100.0,90.44,1.0,90.44,0.91,ito:ITO_00126,Biomedical AI process,Acc
0,1,Retinal OCT Disease Classification,OCT2017,2015-12,InceptionV3 (limited),96.6,97.18,96.6,0.97,99.4,0.97,ito:ITO_00126,Biomedical AI process,Sensitivity
1,1,Retinal OCT Disease Classification,OCT2017,2015-12,InceptionV3,97.8,98.39,1.2,0.01,99.4,0.98,ito:ITO_00126,Biomedical AI process,Sensitivity
2,1,Retinal OCT Disease Classification,OCT2017,2015-12,ResNet50-v1,99.3,99.9,1.5,0.02,99.4,1.0,ito:ITO_00126,Biomedical AI process,Sensitivity
3,1,Retinal OCT Disease Classification,OCT2017,2018-01,MobileNet-v2,99.4,100.0,0.1,0.0,99.4,1.0,ito:ITO_00126,Biomedical AI process,Sensitivity
4,1,Congestive Heart Failure detection,CHF database,2019-07,Inclined Entropy (R-HessELM),98.3,100.0,98.3,1.0,98.3,0.99,ito:ITO_00126,Biomedical AI process,Sensitivity
0,1,Protein Secondary Structure Prediction,CB513,2015-12,LucaAngioloni-WindowCNN,0.6557,88.61,0.6557,0.89,0.74,0.01,ito:ITO_00126,Biomedical AI process,Q8
1,1,Protein Secondary Structure Prediction,CB513,2015-12,ACNN,0.697,94.19,0.0,0.0,0.74,0.01,ito:ITO_00126,Biomedical AI process,Q8
2,1,Protein Secondary Structure Prediction,CB513,2019-10,Porter5,0.74,100.0,0.0,0.0,0.74,0.01,ito:ITO_00126,Biomedical AI process,Q8
3,1,Protein Secondary Structure Prediction,CullPDB,2015-12,LucaAngioloni-WindowCNN,0.721522,100.0,0.721522,1.0,0.721522,0.01,ito:ITO_00126,Biomedical AI process,Q8
4,1,Protein Secondary Structure Prediction,2017_test set,2019-10,Porter5,73.02,100.0,73.02,1.0,73.02,1.0,ito:ITO_00126,Biomedical AI process,Q8
0,1,Nuclear Segmentation,Cell17,2016-03,FnsNet,25.9102,100.0,25.9102,1.0,25.9102,1.0,ito:ITO_00126,Biomedical AI process,Hausdorff
0,1,Surgical Skills Evaluation,JIGSAWS,2016-06,Bidir. LSTM,14.6,100.0,14.6,1.0,14.6,0.75,ito:ITO_00126,Biomedical AI process,Edit\\ Distance
1,1,Zero-Shot Text-to-Image Generation,Zero-Shot Text-to-Image Generation,2016-06,Bidir. LSTM,14.6,100.0,14.6,1.0,14.6,0.75,ito:ITO_00126,Biomedical AI process,Edit\\ Distance
2,1,Surgical Skills Evaluation,MISTIC-SIL,2016-06,Bidir. LSTM,19.5,100.0,19.5,1.0,19.5,1.0,ito:ITO_00126,Biomedical AI process,Edit\\ Distance
3,1,Handwritten Word Generation,Handwritten Word Generation,2016-06,Bidir. LSTM,19.5,100.0,19.5,1.0,19.5,1.0,ito:ITO_00126,Biomedical AI process,Edit\\ Distance
0,1,Disease Trajectory Forecasting,UK CF trust,2016-08,RETAIN,0.685,99.71,0.685,1.0,0.687,1.0,ito:ITO_00126,Biomedical AI process,AUC\\ \\(ABPA\\)
1,1,Disease Trajectory Forecasting,UK CF trust,2018-10,PASS,0.687,100.0,0.0,0.0,0.687,1.0,ito:ITO_00126,Biomedical AI process,AUC\\ \\(ABPA\\)
0,1,Disease Trajectory Forecasting,UK CF trust,2016-08,RETAIN,0.764,99.09,0.764,0.99,0.771,0.99,ito:ITO_00126,Biomedical AI process,AUC\\ \\(Diabetes\\)
1,1,Disease Trajectory Forecasting,UK CF trust,2018-10,PASS,0.771,100.0,0.0,0.0,0.771,1.0,ito:ITO_00126,Biomedical AI process,AUC\\ \\(Diabetes\\)
0,1,Disease Trajectory Forecasting,UK CF trust,2016-08,RETAIN,0.578,100.0,0.578,1.0,0.578,1.0,ito:ITO_00126,Biomedical AI process,AUC\\ \\(I\\.\\ Obstruction\\)
0,1,Disease Trajectory Forecasting,UK CF trust,2016-08,RETAIN,0.578,100.0,0.578,1.0,0.578,1.0,ito:ITO_00126,Biomedical AI process,I\\.\\ Obstruction
0,1,Disease Trajectory Forecasting,UK CF trust,2016-08,RETAIN,0.715,99.58,0.715,1.0,0.718,1.0,ito:ITO_00126,Biomedical AI process,AUC\\ \\(K\\.\\ Pneumonia\\)
1,1,Disease Trajectory Forecasting,UK CF trust,2018-10,PASS,0.718,100.0,0.0,0.0,0.718,1.0,ito:ITO_00126,Biomedical AI process,AUC\\ \\(K\\.\\ Pneumonia\\)
0,1,Disease Trajectory Forecasting,UK CF trust,2016-08,RETAIN,0.697,99.43,0.697,0.99,0.701,0.99,ito:ITO_00126,Biomedical AI process,AUC\\ \\(E\\.\\ Coli\\)
1,1,Disease Trajectory Forecasting,UK CF trust,2018-10,PASS,0.701,100.0,0.0,0.0,0.701,1.0,ito:ITO_00126,Biomedical AI process,AUC\\ \\(E\\.\\ Coli\\)
0,1,Disease Trajectory Forecasting,UK CF trust,2016-08,RETAIN,0.641,100.0,0.641,1.0,0.641,1.0,ito:ITO_00126,Biomedical AI process,AUC\\ \\(Aspergillus\\)
0,1,Pain Intensity Regression,UNBC-McMaster ShoulderPain dataset,2017-02,Regularized Deep Regressor,0.389,100.0,0.389,1.0,0.389,1.0,ito:ITO_00126,Biomedical AI process,MAE
0,1,Spindle Detection,MASS SS2,2017-03,Spinky,0.46,61.33,0.46,0.61,0.75,0.61,ito:ITO_00126,Biomedical AI process,F1\\-score\\ \\(at\\-IoU\\ =\\ 0\\.3\\)
1,1,Spindle Detection,MASS SS2,2017-08,Multichannel Low-Rank,0.5,66.67,0.0,0.0,0.75,0.67,ito:ITO_00126,Biomedical AI process,F1\\-score\\ \\(at\\-IoU\\ =\\ 0\\.3\\)
2,1,Spindle Detection,MASS SS2,2018-12,DOSED,0.75,100.0,0.2,0.27,0.75,1.0,ito:ITO_00126,Biomedical AI process,F1\\-score\\ \\(at\\-IoU\\ =\\ 0\\.3\\)
3,1,K-complex detection,MASS SS2,2017-03,Spinky,0.18,30.0,0.18,0.3,0.6,0.24,ito:ITO_00126,Biomedical AI process,F1\\-score\\ \\(at\\-IoU\\ =\\ 0\\.3\\)
4,1,K-complex detection,MASS SS2,2018-12,DOSED,0.6,100.0,0.4,0.67,0.6,0.8,ito:ITO_00126,Biomedical AI process,F1\\-score\\ \\(at\\-IoU\\ =\\ 0\\.3\\)
5,1,Sleep Arousal Detection,MESA,2018-12,DOSED (3 EEG + 2 EOG),0.71,100.0,0.71,1.0,0.71,0.95,ito:ITO_00126,Biomedical AI process,F1\\-score\\ \\(at\\-IoU\\ =\\ 0\\.3\\)
0,1,Blood pressure estimation,MIMIC-III,2017-05,Deep RNN,8.54,90.56,8.54,0.91,9.43,0.91,ito:ITO_00126,Biomedical AI process,MAE\\ for\\ SBP\\ \\[mmHg\\]
1,1,Blood pressure estimation,MIMIC-III,2019-08,"ResNet (raw PPG + PPG’ + PPG”, with personalization)",9.43,100.0,0.9,0.1,9.43,1.0,ito:ITO_00126,Biomedical AI process,MAE\\ for\\ SBP\\ \\[mmHg\\]
0,1,Blood pressure estimation,MIMIC-III,2017-05,Deep RNN,6.7,97.38,6.7,0.97,6.88,0.97,ito:ITO_00126,Biomedical AI process,MAE\\ for\\ DBP\\ \\[mmHg\\]
1,1,Blood pressure estimation,MIMIC-III,2019-08,"ResNet (raw PPG + PPG’ + PPG”, with personalization)",6.88,100.0,0.2,0.03,6.88,1.0,ito:ITO_00126,Biomedical AI process,MAE\\ for\\ DBP\\ \\[mmHg\\]
0,1,Arrhythmia Detection,The PhysioNet Computing in Cardiology Challenge 2017,2017-09,ResNet + Expert Features,0.825,100.0,0.825,1.0,0.825,0.99,ito:ITO_00126,Biomedical AI process,F1\\ \\(Hidden\\ Test\\ Set\\)
1,1,Arrhythmia Detection,The China Physiological Signal Challenge 2018,2020-02,CNN+RNN,0.837,100.0,0.837,1.0,0.837,1.0,ito:ITO_00126,Biomedical AI process,F1\\ \\(Hidden\\ Test\\ Set\\)
0,1,Pneumonia Detection,ChestX-ray14,2017-11,CheXNet,2800000000.0,100.0,2800000000,1.0,2800000000,1.0,ito:ITO_00126,Biomedical AI process,FLOPS
0,1,Pneumonia Detection,ChestX-ray14,2017-11,CheXNet,0.768,91.0,0.768,0.91,0.844,0.83,ito:ITO_00126,Biomedical AI process,AUROC
1,1,Pneumonia Detection,ChestX-ray14,2017-11,CheXNet,0.844,100.0,0.1,0.12,0.844,0.91,ito:ITO_00126,Biomedical AI process,AUROC
2,1,Synthetic Data Generation,UCI Epileptic Seizure Recognition,2019-05,GAN,0.87,94.57,0.87,0.95,0.92,0.94,ito:ITO_00126,Biomedical AI process,AUROC
3,1,Synthetic Data Generation,UCI Epileptic Seizure Recognition,2020-01,corGAN,0.92,100.0,0.1,0.11,0.92,0.99,ito:ITO_00126,Biomedical AI process,AUROC
4,1,Emotion-Cause Pair Extraction,Emotion-Cause Pair Extraction,2019-05,GAN,0.87,94.57,0.87,0.95,0.92,0.94,ito:ITO_00126,Biomedical AI process,AUROC
5,1,Emotion-Cause Pair Extraction,Emotion-Cause Pair Extraction,2020-01,corGAN,0.92,100.0,0.1,0.11,0.92,0.99,ito:ITO_00126,Biomedical AI process,AUROC
6,1,Sleep Arousal Detection,You Snooze You Win,2019-09,DeepSleep,0.927,100.0,0.927,1.0,0.927,1.0,ito:ITO_00126,Biomedical AI process,AUROC
0,1,Pneumonia Detection,ChestX-ray14,2017-11,CheXNet,7000000.0,100.0,7000000,1.0,7000000,1.0,ito:ITO_00126,Biomedical AI process,Params
0,1,Pulmonary Artery–Vein Classification,LUMC,2018-05,CNN3D,0.693,93.9,0.693,0.94,0.738,0.89,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(median\\)
1,1,Pulmonary Artery–Vein Classification,LUMC,2019-09,CNN-GCNt,0.738,100.0,0.0,0.0,0.738,0.95,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(median\\)
2,1,Pulmonary Artery–Vein Classification,SunYs,2018-05,CNN3D,0.727,93.44,0.727,0.93,0.778,0.93,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(median\\)
3,1,Pulmonary Artery–Vein Classification,SunYs,2019-09,CNN-GCNt,0.778,100.0,0.1,0.13,0.778,1.0,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(median\\)
0,1,Brain Image Segmentation,CREMI,2018-05,U-NET MALA,0.289,100.0,0.289,1.0,0.289,1.0,ito:ITO_00126,Biomedical AI process,CREMI\\ Score
0,1,Brain Image Segmentation,CREMI,2018-05,U-NET MALA,0.606,100.0,0.606,1.0,0.606,0.28,ito:ITO_00126,Biomedical AI process,VOI
1,1,Brain Image Segmentation,FIB-25 Whole Test,2018-05,U-NET MALA,1.071,100.0,1.071,1.0,1.071,0.5,ito:ITO_00126,Biomedical AI process,VOI
2,1,Brain Image Segmentation,FIB-25 Synaptic Sites,2018-05,U-NET MALA,2.151,100.0,2.151,1.0,2.151,1.0,ito:ITO_00126,Biomedical AI process,VOI
0,1,Brain Image Segmentation,SegEM,2018-05,U-NET MALA,4.839,100.0,4.839,1.0,4.839,1.0,ito:ITO_00126,Biomedical AI process,IED
0,1,Participant Intervention Comparison Outcome Extraction,EBM-NLP,2018-06,bi-LSTM,66.3,93.14,66.3,0.93,71.18,0.7,ito:ITO_00126,Biomedical AI process,F1
1,1,Participant Intervention Comparison Outcome Extraction,EBM-NLP,2019-03,SciBERT (SciVocab),71.18,100.0,4.9,0.07,71.18,0.75,ito:ITO_00126,Biomedical AI process,F1
2,1,Iris Segmentation,UBIRIS,2019-01,IrisParseNet (ASPP),91.82,100.0,91.82,1.0,91.82,0.97,ito:ITO_00126,Biomedical AI process,F1
3,1,Iris Segmentation,CASIA,2019-01,IrisParseNet (ASPP) CASIA,94.3,100.0,94.3,1.0,94.3,1.0,ito:ITO_00126,Biomedical AI process,F1
4,1,Iris Segmentation,MICHE,2019-01,IrisParseNet (PSP),91.5,100.0,91.5,1.0,91.5,0.97,ito:ITO_00126,Biomedical AI process,F1
5,1,Atrial Fibrillation Detection,PhysioNet Challenge 2017,2019-05,MINA,0.8342,100.0,0.8342,1.0,0.8342,0.01,ito:ITO_00126,Biomedical AI process,F1
0,1,Stroke Classification from CT data,CT Lesion Stroke Dataset,2018-07,"PSO+CNN (Cifar-10, 75/25, Cranium Segmented)",98.86,100.0,98.86,1.0,98.86,1.0,ito:ITO_00126,Biomedical AI process,Average\\ Class\\ Accuracy
0,1,Image Denoising,DND,2018-07,CBDNet,38.06,100.0,38.06,1.0,38.06,1.0,ito:ITO_00126,Biomedical AI process,PSNR\\ \\(sRGB\\)
1,1,Image Denoising,SIDD,2018-07,CBDNet,30.78,100.0,30.78,1.0,30.78,0.81,ito:ITO_00126,Biomedical AI process,PSNR\\ \\(sRGB\\)
0,1,Image Denoising,SIDD,2018-07,CBDNet,0.801,100.0,0.801,1.0,0.801,0.85,ito:ITO_00126,Biomedical AI process,SSIM\\ \\(sRGB\\)
1,1,Image Denoising,DND,2018-07,CBDNet,0.942,100.0,0.942,1.0,0.942,1.0,ito:ITO_00126,Biomedical AI process,SSIM\\ \\(sRGB\\)
0,1,Medical Image Segmentation,2018 Data Science Bowl,2018-07,Unet++,0.9255,100.0,0.9255,1.0,0.9255,0.01,ito:ITO_00126,Biomedical AI process,mIoU
1,1,Iris Segmentation,UBIRIS,2019-01,IrisParseNet (ASPP),85.39,100.0,85.39,1.0,85.39,0.96,ito:ITO_00126,Biomedical AI process,mIoU
2,1,Iris Segmentation,CASIA,2019-01,IrisParseNet (ASPP) CASIA,89.4,100.0,89.4,1.0,89.4,1.0,ito:ITO_00126,Biomedical AI process,mIoU
3,1,Iris Segmentation,MICHE,2019-01,IrisParseNet (PSP),85.07,100.0,85.07,1.0,85.07,0.95,ito:ITO_00126,Biomedical AI process,mIoU
4,1,Lung Nodule Segmentation,Montgomery County,2019-07,ET-Net,0.942,100.0,0.942,1.0,0.942,0.01,ito:ITO_00126,Biomedical AI process,mIoU
5,1,Lung Nodule Segmentation,LUNA,2019-07,ET-Net,0.9623,100.0,0.9623,1.0,0.9623,0.01,ito:ITO_00126,Biomedical AI process,mIoU
6,1,Retinal Vessel Segmentation,DRIVE,2019-07,ET-Net,0.7744,100.0,0.7744,1.0,0.7744,0.01,ito:ITO_00126,Biomedical AI process,mIoU
0,1,Lung Nodule Classification,LIDC-IDRI,2019-01,Gated-Dilated,92.57,100.0,92.57,1.0,92.57,1.0,ito:ITO_00126,Biomedical AI process,Accuracy\\(10\\-fold\\)
0,1,Arrhythmia Detection,"""Cardiologist-level"" 12-rhythm ECG dataset",2019-01,DNN,0.807,100.0,0.807,1.0,0.807,1.0,ito:ITO_00126,Biomedical AI process,F1\\ \\(Sequence\\)
0,1,Arrhythmia Detection,"""Cardiologist-level"" 12-rhythm ECG dataset",2019-01,DNN,0.837,100.0,0.837,1.0,0.837,1.0,ito:ITO_00126,Biomedical AI process,F1\\ \\(Set\\)
0,1,Medical Image Segmentation,ISBI 2012 EM Segmentation,2019-03,CE-Net,0.9878,100.0,0.9878,1.0,0.9878,1.0,ito:ITO_00126,Biomedical AI process,VInfo
0,1,Medical Image Segmentation,ISBI 2012 EM Segmentation,2019-03,CE-Net,0.9743,100.0,0.9743,1.0,0.9743,1.0,ito:ITO_00126,Biomedical AI process,VRand
0,1,ECG Denoising,UnoViS_auto2012,2019-03,L1 + RFFT,0.167,100.0,0.167,1.0,0.167,1.0,ito:ITO_00126,Biomedical AI process,MSE
0,1,Lung Nodule Segmentation,NIH,2019-04,U-Net+R+A4,0.262,100.0,0.262,1.0,0.262,1.0,ito:ITO_00126,Biomedical AI process,AVD
0,1,Lung Nodule Segmentation,NIH,2019-04,U-Net+R+A4,0.985,100.0,0.985,1.0,0.985,0.01,ito:ITO_00126,Biomedical AI process,VS
1,1,Medical Image Segmentation,CHAOS MRI Dataset,2019-06,MS-Dual-Guided,93.85,100.0,93.85,1.0,93.85,0.99,ito:ITO_00126,Biomedical AI process,VS
2,1,Medical Image Segmentation,HSVM,2019-06,MS-Dual-Guided,94.45,100.0,94.45,1.0,94.45,1.0,ito:ITO_00126,Biomedical AI process,VS
3,1,Brain Tumor Segmentation,BRATS 2018,2019-06,MS-Dual-Guided,93.08,100.0,93.08,1.0,93.08,0.99,ito:ITO_00126,Biomedical AI process,VS
0,1,Atrial Fibrillation Detection,PhysioNet Challenge 2017,2019-05,MINA,0.9488,100.0,0.9488,1.0,0.9488,1.0,ito:ITO_00126,Biomedical AI process,ROC\\-AUC
0,1,Atrial Fibrillation Detection,PhysioNet Challenge 2017,2019-05,MINA,0.9436,100.0,0.9436,1.0,0.9436,1.0,ito:ITO_00126,Biomedical AI process,PR\\-AUC
0,1,Electron Microscopy Image Segmentation,SNEMI3D,2019-06,Waterz (3D U-Net) + Refinement,0.647,80.17,0.647,0.8,0.807,0.8,ito:ITO_00126,Biomedical AI process,Total\\ Variation\\ of\\ Information
1,1,Electron Microscopy Image Segmentation,SNEMI3D,2019-06,Waterz (3D U-Net),0.807,100.0,0.2,0.25,0.807,1.0,ito:ITO_00126,Biomedical AI process,Total\\ Variation\\ of\\ Information
0,1,Electron Microscopy Image Segmentation,SNEMI3D,2019-06,Waterz (3D U-Net) + Refinement,0.438,76.71,0.438,0.77,0.571,0.77,ito:ITO_00126,Biomedical AI process,VI\\ Split
1,1,Electron Microscopy Image Segmentation,SNEMI3D,2019-06,Waterz (3D U-Net),0.571,100.0,0.1,0.18,0.571,1.0,ito:ITO_00126,Biomedical AI process,VI\\ Split
0,1,Electron Microscopy Image Segmentation,SNEMI3D,2019-06,Waterz (3D U-Net) + Refinement,0.209,88.56,0.209,0.89,0.236,0.89,ito:ITO_00126,Biomedical AI process,VI\\ Merge
1,1,Electron Microscopy Image Segmentation,SNEMI3D,2019-06,Waterz (3D U-Net),0.236,100.0,0.0,0.0,0.236,1.0,ito:ITO_00126,Biomedical AI process,VI\\ Merge
0,1,Medical Image Segmentation,HSVM,2019-06,MS-Dual-Guided,1.19,100.0,1.19,1.0,1.19,0.02,ito:ITO_00126,Biomedical AI process,MSD
1,1,Medical Image Segmentation,CHAOS MRI Dataset,2019-06,MS-Dual-Guided,66.0,100.0,66,1.0,66,1.0,ito:ITO_00126,Biomedical AI process,MSD
2,1,Brain Tumor Segmentation,BRATS 2018,2019-06,MS-Dual-Guided,0.9,100.0,0.9,1.0,0.9,0.01,ito:ITO_00126,Biomedical AI process,MSD
0,1,Drug Discovery,QED,2019-06,HierG2G,0.477,100.0,0.477,1.0,0.477,1.0,ito:ITO_00126,Biomedical AI process,Diversity
1,1,Drug Discovery,DRD2,2019-06,HierG2G,0.192,100.0,0.192,1.0,0.192,0.4,ito:ITO_00126,Biomedical AI process,Diversity
0,1,Drug Discovery,QED,2019-06,HierG2G,76.9,100.0,76.9,1.0,76.9,0.9,ito:ITO_00126,Biomedical AI process,Success
1,1,Drug Discovery,DRD2,2019-06,HierG2G,85.9,100.0,85.9,1.0,85.9,1.0,ito:ITO_00126,Biomedical AI process,Success
0,1,Heartbeat Classification,AHA,2019-07,ESN Ensembles (A Lead),99.5,100.0,99.5,1.0,99.5,1.0,ito:ITO_00126,Biomedical AI process,Specificity\\ \\(VEB\\+\\)
0,1,Heartbeat Classification,AHA,2019-07,ESN Ensembles (A Lead),98.6,100.0,98.6,1.0,98.6,1.0,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(VEB\\+\\)
0,1,Heartbeat Classification,AHA,2019-07,ESN Ensembles (A Lead),94.9,100.0,94.9,1.0,94.9,1.0,ito:ITO_00126,Biomedical AI process,PPV\\ \\(VEB\\+\\)
0,1,Heartbeat Classification,AHA,2019-07,ESN Ensembles (A Lead),90.4,100.0,90.4,1.0,90.4,1.0,ito:ITO_00126,Biomedical AI process,Sensitivity\\ \\(VEB\\+\\)
0,1,Length-of-Stay Prediction,MIMIC-III,2019-07,Random Forests (RF),69.5,100.0,69.5,1.0,69.5,1.0,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(LOS>3\\ Days\\)
0,1,Length-of-Stay Prediction,MIMIC-III,2019-07,Random Forests (RF),92.3,100.0,92.3,1.0,92.3,1.0,ito:ITO_00126,Biomedical AI process,Accuracy\\ \\(LOS>7\\ Days\\)
0,1,Lesion Segmentation,ISIC 2018,2019-08,BCDU-Net (d=3),0.851,100.0,0.851,1.0,0.851,1.0,ito:ITO_00126,Biomedical AI process,F1\\-Score
0,1,Sleep Arousal Detection,You Snooze You Win,2019-09,DeepSleep,0.55,100.0,0.55,1.0,0.55,1.0,ito:ITO_00126,Biomedical AI process,AUPRC
0,1,Protein Secondary Structure Prediction,2019_test set,2019-10,Porter5,81.74,100.0,81.74,1.0,81.74,0.97,ito:ITO_00126,Biomedical AI process,Q3
1,1,Protein Secondary Structure Prediction,2017_test set,2019-10,Porter5,84.19,100.0,84.19,1.0,84.19,1.0,ito:ITO_00126,Biomedical AI process,Q3
0,1,Image Denoising,"ultracold fermions Technion system, pixelfly",2020-03,absDL,0.0711,100.0,0.0711,1.0,0.0711,1.0,ito:ITO_00126,Biomedical AI process,ODRMSE
0,1,Multivariate Time Series Imputation,UCI localization data,2010-11,MICE,0.477,100.0,0.477,1.0,0.477,1.0,ito:ITO_00131,Time Series process,MAE\\ \\(10%\\ missing\\)
0,1,Multivariate Time Series Imputation,PhysioNet Challenge 2012,2010-11,MICE,0.634,100.0,0.634,1.0,0.634,1.0,ito:ITO_00131,Time Series process,MAE\\ \\(10%\\ of\\ data\\ as\\ GT\\)
0,1,Multivariate Time Series Imputation,Beijing Air Quality,2010-11,MICE,27.42,100.0,27.42,1.0,27.42,1.0,ito:ITO_00131,Time Series process,MAE\\ \\(PM2\\.5\\)
0,1,Multivariate Time Series Imputation,KDD CUP Challenge 2018,2010-11,MICE,0.468,100.0,0.468,1.0,0.468,1.0,ito:ITO_00131,Time Series process,MSE\\ \\(10%\\ missing\\)
0,1,Skeleton Based Action Recognition,UWA3D,2012-07,HOJ3D,17.7,21.74,17.7,0.22,81.4,0.18,ito:ITO_00131,Time Series process,Accuracy
1,1,Skeleton Based Action Recognition,UWA3D,2017-08,ESV (Synthesized + Pre-trained),73.8,90.66,56.1,0.69,81.4,0.74,ito:ITO_00131,Time Series process,Accuracy
2,1,Skeleton Based Action Recognition,UWA3D,2018-04,VA-fusion (aug.),81.4,100.0,7.6,0.09,81.4,0.82,ito:ITO_00131,Time Series process,Accuracy
3,1,Skeleton Based Action Recognition,CAD-120,2012-10,KGS,86.0,96.3,86.0,0.96,89.3,0.87,ito:ITO_00131,Time Series process,Accuracy
4,1,Skeleton Based Action Recognition,CAD-120,2013-02,All Features (w ground truth),89.3,100.0,3.3,0.04,89.3,0.9,ito:ITO_00131,Time Series process,Accuracy
5,1,Trajectory Prediction,GPS,2012-11,Support Vector Machines,88.0,100.0,88,1.0,88,0.89,ito:ITO_00131,Time Series process,Accuracy
6,1,Hand Gesture Recognition,Cambridge,2013-03,Sanin et al. [sanin2013spatio],93.0,94.68,93.0,0.95,98.23,0.94,ito:ITO_00131,Time Series process,Accuracy
7,1,Hand Gesture Recognition,Cambridge,2019-01,Key Frames + Feature Fusion,98.23,100.0,5.2,0.05,98.23,0.99,ito:ITO_00131,Time Series process,Accuracy
8,1,Hand Gesture Recognition,VIVA Hand Gestures Dataset,2014-06,Two Stream CNNs,68.0,79.0,68.0,0.79,86.08,0.68,ito:ITO_00131,Time Series process,Accuracy
9,1,Hand Gesture Recognition,VIVA Hand Gestures Dataset,2017-05,I3D,83.1,96.54,15.1,0.18,86.08,0.84,ito:ITO_00131,Time Series process,Accuracy
10,1,Hand Gesture Recognition,VIVA Hand Gestures Dataset,2018-12,MTUT,86.08,100.0,3.0,0.03,86.08,0.87,ito:ITO_00131,Time Series process,Accuracy
11,1,Skeleton Based Action Recognition,Florence 3D,2014-06,Lie Group,90.9,91.73,90.9,0.92,99.1,0.92,ito:ITO_00131,Time Series process,Accuracy
12,1,Skeleton Based Action Recognition,Florence 3D,2016-06,Rolling Rotations (FTP),91.4,92.23,0.5,0.01,99.1,0.92,ito:ITO_00131,Time Series process,Accuracy
13,1,Skeleton Based Action Recognition,Florence 3D,2018-02,Deep STGC_K,99.1,100.0,7.7,0.08,99.1,1.0,ito:ITO_00131,Time Series process,Accuracy
14,1,Skeleton Based Action Recognition,UT-Kinect,2014-06,Lie Group,97.1,98.58,97.1,0.99,98.5,0.98,ito:ITO_00131,Time Series process,Accuracy
15,1,Skeleton Based Action Recognition,UT-Kinect,2018-06,DPRL,98.5,100.0,1.4,0.01,98.5,0.99,ito:ITO_00131,Time Series process,Accuracy
16,1,Semanticity prediction,Semanticity prediction,2015-09,GCN-FP,50.5,67.43,50.5,0.67,74.89,0.51,ito:ITO_00131,Time Series process,Accuracy
17,1,Semanticity prediction,Semanticity prediction,2015-11,DCNN,59.0,78.78,8.5,0.11,74.89,0.59,ito:ITO_00131,Time Series process,Accuracy
18,1,Semanticity prediction,Semanticity prediction,2019-01,AdaLanczosNet,60.8,81.19,1.8,0.02,74.89,0.61,ito:ITO_00131,Time Series process,Accuracy
19,1,Semanticity prediction,Semanticity prediction,2019-06,Truncated Krylov,74.89,100.0,14.1,0.19,74.89,0.75,ito:ITO_00131,Time Series process,Accuracy
20,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2015-09,GCN-FP,61.5,82.0,61.5,0.82,75.0,0.62,ito:ITO_00131,Time Series process,Accuracy
21,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2015-11,DCNN,69.4,92.53,7.9,0.11,75.0,0.7,ito:ITO_00131,Time Series process,Accuracy
22,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2016-06,ChebyNet,70.1,93.47,0.7,0.01,75.0,0.71,ito:ITO_00131,Time Series process,Accuracy
23,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2017-10,GAT,72.5,96.67,2.4,0.03,75.0,0.73,ito:ITO_00131,Time Series process,Accuracy
24,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2019-02,H-GCN,72.8,97.07,0.3,0.0,75.0,0.73,ito:ITO_00131,Time Series process,Accuracy
25,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2019-03,LDS-GNN,75.0,100.0,2.2,0.03,75.0,0.76,ito:ITO_00131,Time Series process,Accuracy
26,1,Trajectory Forecasting,Trajectory Forecasting,2015-09,GCN-FP,61.5,82.0,61.5,0.82,75.0,0.62,ito:ITO_00131,Time Series process,Accuracy
27,1,Trajectory Forecasting,Trajectory Forecasting,2015-11,DCNN,69.4,92.53,7.9,0.11,75.0,0.7,ito:ITO_00131,Time Series process,Accuracy
28,1,Trajectory Forecasting,Trajectory Forecasting,2016-06,ChebyNet,70.1,93.47,0.7,0.01,75.0,0.71,ito:ITO_00131,Time Series process,Accuracy
29,1,Trajectory Forecasting,Trajectory Forecasting,2017-10,GAT,72.5,96.67,2.4,0.03,75.0,0.73,ito:ITO_00131,Time Series process,Accuracy
30,1,Trajectory Forecasting,Trajectory Forecasting,2019-02,H-GCN,72.8,97.07,0.3,0.0,75.0,0.73,ito:ITO_00131,Time Series process,Accuracy
31,1,Trajectory Forecasting,Trajectory Forecasting,2019-03,LDS-GNN,75.0,100.0,2.2,0.03,75.0,0.76,ito:ITO_00131,Time Series process,Accuracy
32,1,Node Classification,20NEWS,2015-10,GraRep,81.44,100.0,81.44,1.0,81.44,0.82,ito:ITO_00131,Time Series process,Accuracy
33,1,Attention Score Prediction,Attention Score Prediction,2015-10,GraRep,81.44,100.0,81.44,1.0,81.44,0.82,ito:ITO_00131,Time Series process,Accuracy
34,1,Skeleton Based Action Recognition,SBU,2016-06,ChebyNet,96.0,96.95,96.0,0.97,99.02,0.97,ito:ITO_00131,Time Series process,Accuracy
35,1,Skeleton Based Action Recognition,SBU,2017-03,Joint Line Distance,99.02,100.0,3.0,0.03,99.02,1.0,ito:ITO_00131,Time Series process,Accuracy
36,1,LWR Classification,LWR Classification,2016-09,GCN,95.68,98.62,95.68,0.99,97.02,0.96,ito:ITO_00131,Time Series process,Accuracy
37,1,LWR Classification,LWR Classification,2018-09,ASGCN,96.27,99.23,0.6,0.01,97.02,0.97,ito:ITO_00131,Time Series process,Accuracy
38,1,LWR Classification,LWR Classification,2019-07,GraphSAINT,97.0,99.98,0.7,0.01,97.02,0.98,ito:ITO_00131,Time Series process,Accuracy
39,1,LWR Classification,LWR Classification,2020-01,JKNet+DropEdge,97.02,100.0,0.0,0.0,97.02,0.98,ito:ITO_00131,Time Series process,Accuracy
40,1,Node Classification,Reddit,2016-09,GCN,95.68,98.62,95.68,0.99,97.02,0.96,ito:ITO_00131,Time Series process,Accuracy
41,1,Node Classification,Reddit,2018-09,ASGCN,96.27,99.23,0.6,0.01,97.02,0.97,ito:ITO_00131,Time Series process,Accuracy
42,1,Node Classification,Reddit,2019-07,GraphSAINT,97.0,99.98,0.7,0.01,97.02,0.98,ito:ITO_00131,Time Series process,Accuracy
43,1,Node Classification,Reddit,2020-01,JKNet+DropEdge,97.02,100.0,0.0,0.0,97.02,0.98,ito:ITO_00131,Time Series process,Accuracy
44,1,Multivariate Time Series Forecasting,Helpdesk,2016-12,LSTM,0.7123,100.0,0.7123,1.0,0.7123,0.01,ito:ITO_00131,Time Series process,Accuracy
45,1,Multivariate Time Series Forecasting,BPI challenge '12,2016-12,LSTM,0.76,100.0,0.76,1.0,0.76,0.01,ito:ITO_00131,Time Series process,Accuracy
46,1,Skeleton Based Action Recognition,SYSU 3D,2016-12,Dynamic Skeletons,75.5,86.88,75.5,0.87,86.9,0.76,ito:ITO_00131,Time Series process,Accuracy
47,1,Skeleton Based Action Recognition,SYSU 3D,2017-03,VA-LSTM,77.5,89.18,2.0,0.02,86.9,0.78,ito:ITO_00131,Time Series process,Accuracy
48,1,Skeleton Based Action Recognition,SYSU 3D,2018-04,VA-fusion (aug.),86.7,99.77,9.2,0.11,86.9,0.87,ito:ITO_00131,Time Series process,Accuracy
49,1,Skeleton Based Action Recognition,SYSU 3D,2019-04,SGN,86.9,100.0,0.2,0.0,86.9,0.88,ito:ITO_00131,Time Series process,Accuracy
50,1,Hand Gesture Recognition,ChaLearn val,2017-01,Wang et al.,39.23,68.34,39.23,0.68,57.4,0.4,ito:ITO_00131,Time Series process,Accuracy
51,1,Hand Gesture Recognition,ChaLearn val,2018-04,8-MFFs-3f1c (5 crop),57.4,100.0,18.2,0.32,57.4,0.58,ito:ITO_00131,Time Series process,Accuracy
52,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2017-04,Res-TCN,20.3,52.59,20.3,0.53,38.6,0.2,ito:ITO_00131,Time Series process,Accuracy
53,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2018-01,ST-GCN,30.7,79.53,10.4,0.27,38.6,0.31,ito:ITO_00131,Time Series process,Accuracy
54,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2018-05,2s-AGCN,36.1,93.52,5.4,0.14,38.6,0.36,ito:ITO_00131,Time Series process,Accuracy
55,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2018-11,SLnL-rFA,36.6,94.82,0.5,0.01,38.6,0.37,ito:ITO_00131,Time Series process,Accuracy
56,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-06,DGNN,36.9,95.6,0.3,0.01,38.6,0.37,ito:ITO_00131,Time Series process,Accuracy
57,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-11,GCN-NAS,37.1,96.11,0.2,0.01,38.6,0.37,ito:ITO_00131,Time Series process,Accuracy
58,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-12,MS-AAGCN,37.8,97.93,0.7,0.02,38.6,0.38,ito:ITO_00131,Time Series process,Accuracy
59,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2020-03,2s-AGCN+TEM,38.6,100.0,0.8,0.02,38.6,0.39,ito:ITO_00131,Time Series process,Accuracy
60,1,Hand Gesture Recognition,EgoGesture,2017-05,I3D,92.78,98.67,92.78,0.99,94.03,0.93,ito:ITO_00131,Time Series process,Accuracy
61,1,Hand Gesture Recognition,EgoGesture,2018-12,MTUT,93.87,99.83,1.1,0.01,94.03,0.95,ito:ITO_00131,Time Series process,Accuracy
62,1,Hand Gesture Recognition,EgoGesture,2019-01,ResNeXt-101,94.03,100.0,0.2,0.0,94.03,0.95,ito:ITO_00131,Time Series process,Accuracy
63,1,Hand Gesture Recognition,BUAA,2017-07,F-BGRU,99.25,100.0,99.25,1.0,99.25,1.0,ito:ITO_00131,Time Series process,Accuracy
64,1,Hand Gesture Recognition,SmartWatch,2017-07,F-BGRU,97.4,100.0,97.4,1.0,97.4,0.98,ito:ITO_00131,Time Series process,Accuracy
65,1,Hand Gesture Recognition,MGB,2017-07,F-BLSTM,98.04,100.0,98.04,1.0,98.04,0.99,ito:ITO_00131,Time Series process,Accuracy
66,1,Gesture Recognition,Chalearn 2014,2017-12,3D-CNN + LSTM,93.2,100.0,93.2,1.0,93.2,0.94,ito:ITO_00131,Time Series process,Accuracy
67,1,Time Series Classification,JapaneseVowels,2018-01,MALSTM-FCN,0.99,100.0,0.99,1.0,0.99,0.01,ito:ITO_00131,Time Series process,Accuracy
68,1,Time Series Classification,ArabicDigits,2018-01,MALSTM-FCN,0.99,100.0,0.99,1.0,0.99,0.01,ito:ITO_00131,Time Series process,Accuracy
69,1,Time Series Classification,LP2,2018-01,MALSTM-FCN,0.77,100.0,0.77,1.0,0.77,0.01,ito:ITO_00131,Time Series process,Accuracy
70,1,Time Series Classification,LP5,2018-01,MALSTM-FCN,0.67,100.0,0.67,1.0,0.67,0.01,ito:ITO_00131,Time Series process,Accuracy
71,1,Time Series Classification,Shapes,2018-01,MALSTM-FCN,1.0,100.0,1,1.0,1,0.01,ito:ITO_00131,Time Series process,Accuracy
72,1,Time Series Classification,AUSLAN,2018-01,MALSTM-FCN,0.96,100.0,0.96,1.0,0.96,0.01,ito:ITO_00131,Time Series process,Accuracy
73,1,Time Series Classification,CharacterTrajectories,2018-01,MALSTM-FCN,1.0,100.0,1,1.0,1,0.01,ito:ITO_00131,Time Series process,Accuracy
74,1,Time Series Classification,CMUsubject16,2018-01,MALSTM-FCN,1.0,100.0,1,1.0,1,0.01,ito:ITO_00131,Time Series process,Accuracy
75,1,Time Series Classification,ECG,2018-01,MALSTM-FCN,0.86,100.0,0.86,1.0,0.86,0.01,ito:ITO_00131,Time Series process,Accuracy
76,1,Time Series Classification,Libras,2018-01,MALSTM-FCN,0.97,100.0,0.97,1.0,0.97,0.01,ito:ITO_00131,Time Series process,Accuracy
77,1,Time Series Classification,LP4,2018-01,MALSTM-FCN,0.93,100.0,0.93,1.0,0.93,0.01,ito:ITO_00131,Time Series process,Accuracy
78,1,Time Series Classification,NetFlow,2018-01,MALSTM-FCN,0.95,100.0,0.95,1.0,0.95,0.01,ito:ITO_00131,Time Series process,Accuracy
79,1,Time Series Classification,Wafer,2018-01,MALSTM-FCN,0.99,100.0,0.99,1.0,0.99,0.01,ito:ITO_00131,Time Series process,Accuracy
80,1,Time Series Classification,WalkvsRun,2018-01,MALSTM-FCN,1.0,100.0,1,1.0,1,0.01,ito:ITO_00131,Time Series process,Accuracy
81,1,Time Series Classification,LP3,2018-01,MALSTM-FCN,0.73,100.0,0.73,1.0,0.73,0.01,ito:ITO_00131,Time Series process,Accuracy
82,1,Time Series Classification,UWave,2018-01,MALSTM-FCN,0.98,100.0,0.98,1.0,0.98,0.01,ito:ITO_00131,Time Series process,Accuracy
83,1,Time Series Classification,DigitShapes,2018-01,MALSTM-FCN,1.0,100.0,1,1.0,1,0.01,ito:ITO_00131,Time Series process,Accuracy
84,1,Time Series Classification,KickvsPunch,2018-01,MALSTM-FCN,1.0,100.0,1,1.0,1,0.01,ito:ITO_00131,Time Series process,Accuracy
85,1,Time Series Classification,LP1,2018-01,MALSTM-FCN,0.82,100.0,0.82,1.0,0.82,0.01,ito:ITO_00131,Time Series process,Accuracy
86,1,Time Series Classification,PenDigits,2018-01,MALSTM-FCN,0.97,100.0,0.97,1.0,0.97,0.01,ito:ITO_00131,Time Series process,Accuracy
87,1,Skeleton Based Action Recognition,N-UCLA,2018-02,Glimpse Clouds,87.6,94.7,87.6,0.95,92.5,0.88,ito:ITO_00131,Time Series process,Accuracy
88,1,Skeleton Based Action Recognition,N-UCLA,2018-04,VA-fusion (aug.),88.1,95.24,0.5,0.01,92.5,0.89,ito:ITO_00131,Time Series process,Accuracy
89,1,Skeleton Based Action Recognition,N-UCLA,2018-12,Action Machine,92.3,99.78,4.2,0.05,92.5,0.93,ito:ITO_00131,Time Series process,Accuracy
90,1,Skeleton Based Action Recognition,N-UCLA,2019-04,SGN,92.5,100.0,0.2,0.0,92.5,0.93,ito:ITO_00131,Time Series process,Accuracy
91,1,Hand Gesture Recognition,ChaLean test,2018-04,8-MFFs-3f1c,56.7,100.0,56.7,1.0,56.7,0.57,ito:ITO_00131,Time Series process,Accuracy
92,1,Hand Gesture Recognition,NVGesture,2018-04,8-MFFs-3f1c,84.7,97.43,84.7,0.97,86.93,0.85,ito:ITO_00131,Time Series process,Accuracy
93,1,Hand Gesture Recognition,NVGesture,2018-12,MTUT,86.93,100.0,2.2,0.03,86.93,0.88,ito:ITO_00131,Time Series process,Accuracy
94,1,Gesture Recognition,ChaLearn 2013,2018-11,3S Net TTM,92.08,100.0,92.08,1.0,92.08,0.93,ito:ITO_00131,Time Series process,Accuracy
95,1,Gesture Recognition,ChaLearn 2016,2018-11,3S Net TTM,39.95,100.0,39.95,1.0,39.95,0.4,ito:ITO_00131,Time Series process,Accuracy
96,1,Gesture Recognition,MSRC-12,2018-11,3S Net TTM,99.01,100.0,99.01,1.0,99.01,1.0,ito:ITO_00131,Time Series process,Accuracy
97,1,Time Series task,2019_test set,2018-12,neuralwarp,12.0,100.0,12,1.0,12,0.12,ito:ITO_00131,Time Series process,Accuracy
98,1,Hand Gesture Recognition,Northwestern University,2019-01,Key Frames + Feature Fusion,96.89,100.0,96.89,1.0,96.89,0.98,ito:ITO_00131,Time Series process,Accuracy
99,1,Gesture Recognition,Ninapro DB-1 8 gestures,2019-01,2SRNN,90.7,100.0,90.7,1.0,90.7,0.91,ito:ITO_00131,Time Series process,Accuracy
100,1,Gesture Recognition,Ninapro DB-1 12 gestures,2019-01,2SRNN,84.7,100.0,84.7,1.0,84.7,0.85,ito:ITO_00131,Time Series process,Accuracy
101,1,Gesture Recognition,CapgMyo DB-b,2019-01,2SRNN,97.1,100.0,97.1,1.0,97.1,0.98,ito:ITO_00131,Time Series process,Accuracy
102,1,Gesture Recognition,CapgMyo DB-a,2019-01,2SRNN,97.1,100.0,97.1,1.0,97.1,0.98,ito:ITO_00131,Time Series process,Accuracy
103,1,Gesture Recognition,CapgMyo DB-c,2019-01,2SRNN,96.8,100.0,96.8,1.0,96.8,0.97,ito:ITO_00131,Time Series process,Accuracy
104,1,Time Series process,Bitcoin-Alpha,2019-03,3D-TGCN,0.9607,100.0,0.9607,1.0,0.9607,0.01,ito:ITO_00131,Time Series process,Accuracy
105,1,Skeleton Based Action Recognition,MSR Action3D,2019-06,HDM-BG,86.1,100.0,86.1,1.0,86.1,0.87,ito:ITO_00131,Time Series process,Accuracy
106,1,Skeleton Based Action Recognition,UPenn Action,2019-06,HDM-BG,93.4,94.06,93.4,0.94,99.3,0.94,ito:ITO_00131,Time Series process,Accuracy
107,1,Skeleton Based Action Recognition,UPenn Action,2020-01,UniPose-LSTM,99.3,100.0,5.9,0.06,99.3,1.0,ito:ITO_00131,Time Series process,Accuracy
108,1,Time Series task,Bitcoin-Alpha,2019-06,gluon_ts,0.9,100.0,0.9,1.0,0.9,0.01,ito:ITO_00131,Time Series process,Accuracy
109,1,Hand Gesture Recognition,DHG-14,2019-07,DG-STA,91.9,100.0,91.9,1.0,91.9,0.93,ito:ITO_00131,Time Series process,Accuracy
110,1,Hand Gesture Recognition,DHG-28,2019-07,DG-STA,88.0,100.0,88,1.0,88,0.89,ito:ITO_00131,Time Series process,Accuracy
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,LSTM,56.0,73.68,56,0.74,76,0.74,ito:ITO_00131,Time Series process,Accuracy\\ \\(CS\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,60.0,78.95,4,0.05,76,0.79,ito:ITO_00131,Time Series process,Accuracy\\ \\(CS\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-04,Res-TCN,63.0,82.89,3,0.04,76,0.83,ito:ITO_00131,Time Series process,Accuracy\\ \\(CS\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2018-01,ST-GCN,71.0,93.42,8,0.11,76,0.93,ito:ITO_00131,Time Series process,Accuracy\\ \\(CS\\)
4,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,76.0,100.0,5,0.07,76,1.0,ito:ITO_00131,Time Series process,Accuracy\\ \\(CS\\)
0,1,Traffic Prediction,PeMS-M,2014-09,FC-LSTM,4.16,100.0,4.16,1.0,4.16,1.0,ito:ITO_00131,Time Series process,MAE\\ \\(60\\ min\\)
0,1,Skeleton Based Action Recognition,J-HMDB,2014-11,Action Tubes,62.5,69.14,62.5,0.69,90.4,0.69,ito:ITO_00131,Time Series process,Accuracy\\ \\(RGB\\+pose\\)
1,1,Skeleton Based Action Recognition,J-HMDB,2016-09,MR Two-Sream R-CNN,71.1,78.65,8.6,0.1,90.4,0.79,ito:ITO_00131,Time Series process,Accuracy\\ \\(RGB\\+pose\\)
2,1,Skeleton Based Action Recognition,J-HMDB,2017-04,Chained (RGB+Flow +Pose),76.1,84.18,5.0,0.06,90.4,0.84,ito:ITO_00131,Time Series process,Accuracy\\ \\(RGB\\+pose\\)
3,1,Skeleton Based Action Recognition,J-HMDB,2017-05,I3D,84.1,93.03,8.0,0.09,90.4,0.93,ito:ITO_00131,Time Series process,Accuracy\\ \\(RGB\\+pose\\)
4,1,Skeleton Based Action Recognition,J-HMDB,2018-06,I3D + Potion,85.5,94.58,1.4,0.02,90.4,0.95,ito:ITO_00131,Time Series process,Accuracy\\ \\(RGB\\+pose\\)
5,1,Skeleton Based Action Recognition,J-HMDB,2018-06,Potion,90.4,100.0,4.9,0.05,90.4,1.0,ito:ITO_00131,Time Series process,Accuracy\\ \\(RGB\\+pose\\)
0,1,Gesture Recognition,Montalbano,2015-06,Temp Conv + LSTM,2.77,100.0,2.77,1.0,2.77,1.0,ito:ITO_00131,Time Series process,Error\\ rate
0,1,Gesture Recognition,Montalbano,2015-06,Temp Conv + LSTM,94.49,100.0,94.49,1.0,94.49,1.0,ito:ITO_00131,Time Series process,Precision
0,1,Gesture Recognition,Montalbano,2015-06,Temp Conv + LSTM,94.57,100.0,94.57,1.0,94.57,1.0,ito:ITO_00131,Time Series process,Recall
0,1,Gesture Recognition,Montalbano,2015-06,Temp Conv + LSTM,90.6,100.0,90.6,1.0,90.6,1.0,ito:ITO_00131,Time Series process,Jaccard\\ \\(Mean\\)
0,1,Click-Through Rate Prediction,Criteo,2016-01,FNN,0.7963,98.03,0.7963,0.98,0.8123,0.01,ito:ITO_00131,Time Series process,AUC
1,1,Click-Through Rate Prediction,Criteo,2016-06,Wide & Deep (LR & DNN),0.7981,98.25,0.0,0.0,0.8123,0.01,ito:ITO_00131,Time Series process,AUC
2,1,Click-Through Rate Prediction,Criteo,2016-11,PNN*,0.7987,98.33,0.0,0.0,0.8123,0.01,ito:ITO_00131,Time Series process,AUC
3,1,Click-Through Rate Prediction,Criteo,2017-03,DeepFM,0.8007,98.57,0.0,0.0,0.8123,0.01,ito:ITO_00131,Time Series process,AUC
4,1,Click-Through Rate Prediction,Criteo,2018-03,xDeepFM,0.8052,99.13,0.0,0.0,0.8123,0.01,ito:ITO_00131,Time Series process,AUC
5,1,Click-Through Rate Prediction,Criteo,2018-10,AutoInt,0.8061,99.24,0.0,0.0,0.8123,0.01,ito:ITO_00131,Time Series process,AUC
6,1,Click-Through Rate Prediction,Criteo,2019-10,Fi-GNN,0.8082,99.5,0.0,0.0,0.8123,0.01,ito:ITO_00131,Time Series process,AUC
7,1,Click-Through Rate Prediction,Criteo,2020-02,Sparse DeepFwFM,0.8123,100.0,0.0,0.0,0.8123,0.01,ito:ITO_00131,Time Series process,AUC
8,1,Sequential skip prediction,Sequential skip prediction,2016-01,FNN,0.7963,98.03,0.7963,0.98,0.8123,0.01,ito:ITO_00131,Time Series process,AUC
9,1,Sequential skip prediction,Sequential skip prediction,2016-06,Wide & Deep (LR & DNN),0.7981,98.25,0.0,0.0,0.8123,0.01,ito:ITO_00131,Time Series process,AUC
10,1,Sequential skip prediction,Sequential skip prediction,2016-11,PNN*,0.7987,98.33,0.0,0.0,0.8123,0.01,ito:ITO_00131,Time Series process,AUC
11,1,Sequential skip prediction,Sequential skip prediction,2017-03,DeepFM,0.8007,98.57,0.0,0.0,0.8123,0.01,ito:ITO_00131,Time Series process,AUC
12,1,Sequential skip prediction,Sequential skip prediction,2018-03,xDeepFM,0.8052,99.13,0.0,0.0,0.8123,0.01,ito:ITO_00131,Time Series process,AUC
13,1,Sequential skip prediction,Sequential skip prediction,2018-10,AutoInt,0.8061,99.24,0.0,0.0,0.8123,0.01,ito:ITO_00131,Time Series process,AUC
14,1,Sequential skip prediction,Sequential skip prediction,2019-10,Fi-GNN,0.8082,99.5,0.0,0.0,0.8123,0.01,ito:ITO_00131,Time Series process,AUC
15,1,Sequential skip prediction,Sequential skip prediction,2020-02,Sparse DeepFwFM,0.8123,100.0,0.0,0.0,0.8123,0.01,ito:ITO_00131,Time Series process,AUC
16,1,Time Series Classification,PhysioNet Challenge 2012,2016-06,RNN GRU-D,81.8,94.65,81.8,0.95,86.42,0.95,ito:ITO_00131,Time Series process,AUC
17,1,Time Series Classification,PhysioNet Challenge 2012,2016-06,GRU-D,84.24,97.48,2.4,0.03,86.42,0.97,ito:ITO_00131,Time Series process,AUC
18,1,Time Series Classification,PhysioNet Challenge 2012,2019-09,IP-NETS,86.42,100.0,2.2,0.03,86.42,1.0,ito:ITO_00131,Time Series process,AUC
19,1,Time Series Classification,Physionet 2017 Atrial Fibrillation,2016-07,EncDec-AD,0.719,98.22,0.719,0.98,0.732,0.01,ito:ITO_00131,Time Series process,AUC
20,1,Time Series Classification,Physionet 2017 Atrial Fibrillation,2018-05,TKAE,0.732,100.0,0.0,0.0,0.732,0.01,ito:ITO_00131,Time Series process,AUC
0,1,Click-Through Rate Prediction,Criteo,2016-01,FNN,0.45738,84.89,0.45738,0.85,0.5388,0.85,ito:ITO_00131,Time Series process,Log\\ Loss
1,1,Click-Through Rate Prediction,Criteo,2016-06,Wide & Deep (LR & DNN),0.46772,86.81,0.0,0.0,0.5388,0.87,ito:ITO_00131,Time Series process,Log\\ Loss
2,1,Click-Through Rate Prediction,Criteo,2019-04,FGCNN+IPNN,0.5388,100.0,0.1,0.19,0.5388,1.0,ito:ITO_00131,Time Series process,Log\\ Loss
3,1,Sequential skip prediction,Sequential skip prediction,2016-01,FNN,0.45738,84.89,0.45738,0.85,0.5388,0.85,ito:ITO_00131,Time Series process,Log\\ Loss
4,1,Sequential skip prediction,Sequential skip prediction,2016-06,Wide & Deep (LR & DNN),0.46772,86.81,0.0,0.0,0.5388,0.87,ito:ITO_00131,Time Series process,Log\\ Loss
5,1,Sequential skip prediction,Sequential skip prediction,2019-04,FGCNN+IPNN,0.5388,100.0,0.1,0.19,0.5388,1.0,ito:ITO_00131,Time Series process,Log\\ Loss
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,LSTM,16.0,55.17,16,0.55,29,0.55,ito:ITO_00131,Time Series process,Accuracy\\ \\(CV\\ I\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-08,SK-CNN,26.0,89.66,10,0.34,29,0.9,ito:ITO_00131,Time Series process,Accuracy\\ \\(CV\\ I\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,29.0,100.0,3,0.1,29,1.0,ito:ITO_00131,Time Series process,Accuracy\\ \\(CV\\ I\\)
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,33.0,46.48,33,0.46,71,0.46,ito:ITO_00131,Time Series process,Accuracy\\ \\(CV\\ II\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-11,TCN,43.0,60.56,10,0.14,71,0.61,ito:ITO_00131,Time Series process,Accuracy\\ \\(CV\\ II\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-04,Res-TCN,48.0,67.61,5,0.07,71,0.68,ito:ITO_00131,Time Series process,Accuracy\\ \\(CV\\ II\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-08,SK-CNN,68.0,95.77,20,0.28,71,0.96,ito:ITO_00131,Time Series process,Accuracy\\ \\(CV\\ II\\)
4,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,71.0,100.0,3,0.04,71,1.0,ito:ITO_00131,Time Series process,Accuracy\\ \\(CV\\ II\\)
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,33.0,57.89,33,0.58,57,0.58,ito:ITO_00131,Time Series process,Accuracy\\ \\(AV\\ I\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-11,TCN,43.0,75.44,10,0.18,57,0.75,ito:ITO_00131,Time Series process,Accuracy\\ \\(AV\\ I\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-04,Res-TCN,48.0,84.21,5,0.09,57,0.84,ito:ITO_00131,Time Series process,Accuracy\\ \\(AV\\ I\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2018-01,ST-GCN,53.0,92.98,5,0.09,57,0.93,ito:ITO_00131,Time Series process,Accuracy\\ \\(AV\\ I\\)
4,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,57.0,100.0,4,0.07,57,1.0,ito:ITO_00131,Time Series process,Accuracy\\ \\(AV\\ I\\)
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,50.0,64.94,50,0.65,77,0.65,ito:ITO_00131,Time Series process,Accuracy\\ \\(AV\\ II\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,LSTM,68.0,88.31,18,0.23,77,0.88,ito:ITO_00131,Time Series process,Accuracy\\ \\(AV\\ II\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-08,SK-CNN,77.0,100.0,9,0.12,77,1.0,ito:ITO_00131,Time Series process,Accuracy\\ \\(AV\\ II\\)
0,1,Multivariate Time Series Imputation,MuJoCo,2016-06,RNN GRU-D,0.748,12.26,0.748,0.12,6.1,0.12,ito:ITO_00131,Time Series process,"MSE\\ \\(10\\^2,\\ 50%\\ missing\\)"
1,1,Multivariate Time Series Imputation,MuJoCo,2018-06,RNN-VAE,6.1,100.0,5.4,0.89,6.1,1.0,ito:ITO_00131,Time Series process,"MSE\\ \\(10\\^2,\\ 50%\\ missing\\)"
0,1,Multivariate Time Series Forecasting,MuJoCo,2016-06,RNN GRU-D,5.833,22.04,5.833,0.22,26.463,0.22,ito:ITO_00131,Time Series process,"MSE\\ \\(10\\^\\-2,\\ 50%\\ missing\\)"
1,1,Multivariate Time Series Forecasting,MuJoCo,2019-07,ODE-RNN,26.463,100.0,20.6,0.78,26.463,1.0,ito:ITO_00131,Time Series process,"MSE\\ \\(10\\^\\-2,\\ 50%\\ missing\\)"
0,1,Time Series Classification,PhysioNet Challenge 2012,2016-06,RNN GRU-D,0.8,88.89,0.8,0.89,0.9,0.89,ito:ITO_00131,Time Series process,AUC\\ Stdev
1,1,Time Series Classification,PhysioNet Challenge 2012,2019-07,ODE-RNN,0.9,100.0,0.1,0.11,0.9,1.0,ito:ITO_00131,Time Series process,AUC\\ Stdev
0,1,Multivariate Time Series Forecasting,USHCN-Daily,2016-09,Sequential VAE,0.83,86.46,0.83,0.86,0.96,0.0,ito:ITO_00131,Time Series process,MSE
1,1,Multivariate Time Series Forecasting,USHCN-Daily,2018-06,NeuralODE-VAE,0.96,100.0,0.1,0.1,0.96,0.0,ito:ITO_00131,Time Series process,MSE
2,1,Multivariate Time Series Forecasting,MIMIC-III,2016-09,Sequential VAE,0.92,100.0,0.92,1.0,0.92,0.0,ito:ITO_00131,Time Series process,MSE
3,1,Video Prediction,Human3.6M,2017-12,PredRNN,484.1,97.27,484.1,0.97,497.7,0.97,ito:ITO_00131,Time Series process,MSE
4,1,Video Prediction,Human3.6M,2017-12,FRNN,497.7,100.0,13.6,0.03,497.7,1.0,ito:ITO_00131,Time Series process,MSE
0,1,Multivariate Time Series Forecasting,MIMIC-III,2016-09,Sequential VAE,1.39,100.0,1.39,1.0,1.39,1.0,ito:ITO_00131,Time Series process,NegLL
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,85.5,92.53,85.5,0.93,92.4,0.93,ito:ITO_00131,Time Series process,PCK\\-at\\-0\\.5
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,91.4,98.92,5.9,0.06,92.4,0.99,ito:ITO_00131,Time Series process,PCK\\-at\\-0\\.5
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,92.4,100.0,1.0,0.01,92.4,1.0,ito:ITO_00131,Time Series process,PCK\\-at\\-0\\.5
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,45.2,77.4,45.2,0.77,58.4,0.77,ito:ITO_00131,Time Series process,PCK\\-at\\-0\\.1
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,58.4,100.0,13.2,0.23,58.4,1.0,ito:ITO_00131,Time Series process,PCK\\-at\\-0\\.1
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,62.9,80.54,62.9,0.81,78.1,0.81,ito:ITO_00131,Time Series process,PCK\\-at\\-0\\.2
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,69.6,89.12,6.7,0.09,78.1,0.89,ito:ITO_00131,Time Series process,PCK\\-at\\-0\\.2
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,78.1,100.0,8.5,0.11,78.1,1.0,ito:ITO_00131,Time Series process,PCK\\-at\\-0\\.2
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,73.5,85.56,73.5,0.86,85.9,0.86,ito:ITO_00131,Time Series process,PCK\\-at\\-0\\.3
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,80.8,94.06,7.3,0.08,85.9,0.94,ito:ITO_00131,Time Series process,PCK\\-at\\-0\\.3
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,85.9,100.0,5.1,0.06,85.9,1.0,ito:ITO_00131,Time Series process,PCK\\-at\\-0\\.3
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,80.6,89.76,80.6,0.9,89.8,0.9,ito:ITO_00131,Time Series process,PCK\\-at\\-0\\.4
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,87.5,97.44,6.9,0.08,89.8,0.97,ito:ITO_00131,Time Series process,PCK\\-at\\-0\\.4
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,89.8,100.0,2.3,0.03,89.8,1.0,ito:ITO_00131,Time Series process,PCK\\-at\\-0\\.4
0,1,Skeleton Based Action Recognition,PKU-MMD,2017-04,Li et al. [[Li et al.2017b]],90.4,97.31,90.4,0.97,92.9,0.97,ito:ITO_00131,Time Series process,mAP\\-at\\-0\\.50\\ \\(CS\\)
1,1,Skeleton Based Action Recognition,PKU-MMD,2018-04,HCN,92.6,99.68,2.2,0.02,92.9,1.0,ito:ITO_00131,Time Series process,mAP\\-at\\-0\\.50\\ \\(CS\\)
2,1,Skeleton Based Action Recognition,PKU-MMD,2019-09,RF-Action,92.9,100.0,0.3,0.0,92.9,1.0,ito:ITO_00131,Time Series process,mAP\\-at\\-0\\.50\\ \\(CS\\)
0,1,Skeleton Based Action Recognition,PKU-MMD,2017-04,Li et al. [[Li et al.2017b]],93.7,99.26,93.7,0.99,94.4,0.99,ito:ITO_00131,Time Series process,mAP\\-at\\-0\\.50\\ \\(CV\\)
1,1,Skeleton Based Action Recognition,PKU-MMD,2018-04,HCN,94.2,99.79,0.5,0.01,94.4,1.0,ito:ITO_00131,Time Series process,mAP\\-at\\-0\\.50\\ \\(CV\\)
2,1,Skeleton Based Action Recognition,PKU-MMD,2019-09,RF-Action,94.4,100.0,0.2,0.0,94.4,1.0,ito:ITO_00131,Time Series process,mAP\\-at\\-0\\.50\\ \\(CV\\)
0,1,Traffic Prediction,PEMS-BAY,2017-07,DCRNN,4.74,100.0,4.74,1.0,4.74,0.84,ito:ITO_00131,Time Series process,RMSE
1,1,Trajectory Prediction,TRAF,2019-06,TraPHic,0.78,100.0,0.78,1.0,0.78,0.14,ito:ITO_00131,Time Series process,RMSE
2,1,Trajectory Prediction,NGSIM,2019-06,TraPHic,5.63,100.0,5.63,1.0,5.63,1.0,ito:ITO_00131,Time Series process,RMSE
0,1,Traffic Prediction,METR-LA,2017-07,DCRNN,3.6,80.9,3.6,0.81,4.45,0.81,ito:ITO_00131,Time Series process,MAE\\ @\\ 12\\ step
1,1,Traffic Prediction,METR-LA,2017-09,STGCN,4.45,100.0,0.8,0.18,4.45,1.0,ito:ITO_00131,Time Series process,MAE\\ @\\ 12\\ step
2,1,Traffic Prediction,PEMS-BAY,2017-07,DCRNN,2.07,100.0,2.07,1.0,2.07,0.47,ito:ITO_00131,Time Series process,MAE\\ @\\ 12\\ step
0,1,Time Series Classification,Physionet 2017 Atrial Fibrillation,2017-09,ENCASE,0.825,100.0,0.825,1.0,0.825,1.0,ito:ITO_00131,Time Series process,F1\\ \\(Hidden\\ Test\\ Set\\)
0,1,Skeleton Based Action Recognition,J-HMBD Early Action,2017-10,GAT,58.1,95.87,58.1,0.96,60.6,0.96,ito:ITO_00131,Time Series process,10%
1,1,Skeleton Based Action Recognition,J-HMBD Early Action,2018-02,DR^2N,60.6,100.0,2.5,0.04,60.6,1.0,ito:ITO_00131,Time Series process,10%
0,1,Hand Gesture Recognition,Jester test,2017-11,Multiscale TRN,94.78,98.12,94.78,0.98,96.6,0.98,ito:ITO_00131,Time Series process,Top\\ 1\\ Accuracy
1,1,Hand Gesture Recognition,Jester test,2018-04,DRX3D,96.6,100.0,1.8,0.02,96.6,1.0,ito:ITO_00131,Time Series process,Top\\ 1\\ Accuracy
2,1,Hand Gesture Recognition,Jester val,2018-04,8-MFFs-3f1c (5 crop),96.33,100.0,96.33,1.0,96.33,1.0,ito:ITO_00131,Time Series process,Top\\ 1\\ Accuracy
0,1,Time Series Classification,AATLD Gesture Recognition,2017-11,MUSE,133656.0,100.0,133656,1.0,133656,1.0,ito:ITO_00131,Time Series process,Absolute\\ Time\\ \\(ms\\)
0,1,Video Prediction,Human3.6M,2017-12,PredRNN,1895.2,99.69,1895.2,1.0,1901.1,1.0,ito:ITO_00131,Time Series process,MAE
1,1,Video Prediction,Human3.6M,2017-12,FRNN,1901.1,100.0,5.9,0.0,1901.1,1.0,ito:ITO_00131,Time Series process,MAE
0,1,Video Prediction,Human3.6M,2017-12,PredRNN,0.781,98.86,0.781,0.99,0.79,0.87,ito:ITO_00131,Time Series process,SSIM
1,1,Video Prediction,Human3.6M,2018-11,MIM,0.79,100.0,0.0,0.0,0.79,0.88,ito:ITO_00131,Time Series process,SSIM
2,1,Novel View Synthesis,ShapeNet Chair,2018-10,Multi-view to Novel View,0.895,100.0,0.895,1.0,0.895,1.0,ito:ITO_00131,Time Series process,SSIM
3,1,Probabilistic Time Series Forecasting,Probabilistic Time Series Forecasting,2018-10,Multi-view to Novel View,0.895,100.0,0.895,1.0,0.895,1.0,ito:ITO_00131,Time Series process,SSIM
4,1,Novel View Synthesis,Synthia Novel View Synthesis,2018-10,Multi-view to Novel View,0.697,100.0,0.697,1.0,0.697,0.78,ito:ITO_00131,Time Series process,SSIM
5,1,COVID-19 Tracking,COVID-19 Tracking,2018-10,Multi-view to Novel View,0.697,100.0,0.697,1.0,0.697,0.78,ito:ITO_00131,Time Series process,SSIM
0,1,Multivariate Time Series Imputation,PEMS-SF,2018-01,MaskGAN,6.02,39.5,6.02,0.4,15.24,0.4,ito:ITO_00131,Time Series process,L2\\ Loss\\ \\(10\\^\\-4\\)
1,1,Multivariate Time Series Imputation,PEMS-SF,2018-12,GRUI,15.24,100.0,9.2,0.6,15.24,1.0,ito:ITO_00131,Time Series process,L2\\ Loss\\ \\(10\\^\\-4\\)
0,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-01,MaskGAN,0.793,69.5,0.793,0.7,1.141,0.7,ito:ITO_00131,Time Series process,Path\\ Length
1,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-12,GRUI,1.141,100.0,0.3,0.26,1.141,1.0,ito:ITO_00131,Time Series process,Path\\ Length
0,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-01,MaskGAN,9.622,64.36,9.622,0.64,14.95,0.64,ito:ITO_00131,Time Series process,Step\\ Change\\ \\(10\\^−3\\)
1,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-12,GRUI,14.95,100.0,5.3,0.35,14.95,1.0,ito:ITO_00131,Time Series process,Step\\ Change\\ \\(10\\^−3\\)
0,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-01,MaskGAN,0.68,98.55,0.68,0.99,0.69,0.99,ito:ITO_00131,Time Series process,Path\\ Difference
1,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-12,GRUI,0.69,100.0,0.0,0.0,0.69,1.0,ito:ITO_00131,Time Series process,Path\\ Difference
0,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-01,MaskGAN,0.427,100.0,0.427,1.0,0.427,1.0,ito:ITO_00131,Time Series process,Player\\ Distance
0,1,Skeleton Based Action Recognition,UAV-Human,2018-01,ST-GCN,30.25,86.83,30.25,0.87,34.84,0.87,ito:ITO_00131,Time Series process,Average\\ Accuracy
1,1,Skeleton Based Action Recognition,UAV-Human,2018-05,2S-AGCN,34.84,100.0,4.6,0.13,34.84,1.0,ito:ITO_00131,Time Series process,Average\\ Accuracy
0,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-01,MaskGAN,4.592,97.64,4.592,0.98,4.703,0.98,ito:ITO_00131,Time Series process,OOB\\ Rate\\ \\(10\\^−3\\)
1,1,Multivariate Time Series Imputation,Basketball Players Movement,2018-12,GRUI,4.703,100.0,0.1,0.02,4.703,1.0,ito:ITO_00131,Time Series process,OOB\\ Rate\\ \\(10\\^−3\\)
0,1,Hand Gesture Recognition,Jester val,2018-04,8-MFFs-3f1c (5 crop),99.86,100.0,99.86,1.0,99.86,1.0,ito:ITO_00131,Time Series process,Top\\ 5\\ Accuracy
0,1,Time Series Clustering,eICU Collaborative Research Database,2018-06,SOM-VAE-prob,0.0474,100.0,0.0474,1.0,0.0474,1.0,ito:ITO_00131,Time Series process,NMI\\ \\(physiology_6_hours\\)
0,1,Time Series Clustering,eICU Collaborative Research Database,2018-06,SOM-VAE-prob,0.0444,100.0,0.0444,1.0,0.0444,1.0,ito:ITO_00131,Time Series process,NMI\\ \\(physiology_12_hours\\)
0,1,Time Series Clustering,eICU Collaborative Research Database,2018-06,SOM-VAE-prob,0.0421,100.0,0.0421,1.0,0.0421,1.0,ito:ITO_00131,Time Series process,NMI\\ \\(physiology_24_hours\\)
0,1,Multivariate Time Series Imputation,PhysioNet Challenge 2012,2018-06,Latent ODE (RNN enc.),3.907,65.89,3.907,0.66,5.93,0.66,ito:ITO_00131,Time Series process,mse\\ \\(10\\^\\-3\\)
1,1,Multivariate Time Series Imputation,PhysioNet Challenge 2012,2018-06,RNN-VAE,5.93,100.0,2.0,0.34,5.93,1.0,ito:ITO_00131,Time Series process,mse\\ \\(10\\^\\-3\\)
2,1,Multivariate Time Series Forecasting,PhysioNet Challenge 2012,2018-06,RNN-VAE,3.055,96.62,3.055,0.97,3.162,0.52,ito:ITO_00131,Time Series process,mse\\ \\(10\\^\\-3\\)
3,1,Multivariate Time Series Forecasting,PhysioNet Challenge 2012,2018-06,Latent ODE (RNN enc.),3.162,100.0,0.1,0.03,3.162,0.53,ito:ITO_00131,Time Series process,mse\\ \\(10\\^\\-3\\)
0,1,Multivariate Time Series Forecasting,PhysioNet Challenge 2012,2018-06,RNN-VAE,0.145,100.0,0.145,1.0,0.145,1.0,ito:ITO_00131,Time Series process,MSE\\ stdev
0,1,EEG Artifact Removal,MayoClinic_iEEG,2018-08,CNN/APN,0.89,100.0,0.89,1.0,0.89,1.0,ito:ITO_00131,Time Series process,F1\\-score
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,MFA-Net,361.0,100.0,361,1.0,361,1.0,ito:ITO_00131,Time Series process,Speed\\ \\ \\(FPS\\)
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,MFA-Net,91.3,96.51,91.3,0.97,94.6,0.97,ito:ITO_00131,Time Series process,14\\ gestures\\ accuracy
1,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,STA-Res-TCN,93.6,98.94,2.3,0.02,94.6,0.99,ito:ITO_00131,Time Series process,14\\ gestures\\ accuracy
2,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,94.6,100.0,1.0,0.01,94.6,1.0,ito:ITO_00131,Time Series process,14\\ gestures\\ accuracy
3,1,Hand Gesture Recognition,SHREC 2017,2019-07,DG-STA,94.4,100.0,94.4,1.0,94.4,1.0,ito:ITO_00131,Time Series process,14\\ gestures\\ accuracy
4,1,Hand Gesture Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,94.6,100.0,94.6,1.0,94.6,1.0,ito:ITO_00131,Time Series process,14\\ gestures\\ accuracy
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,MFA-Net,86.6,94.23,86.6,0.94,91.9,0.94,ito:ITO_00131,Time Series process,28\\ gestures\\ accuracy
1,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,STA-Res-TCN,90.7,98.69,4.1,0.04,91.9,0.99,ito:ITO_00131,Time Series process,28\\ gestures\\ accuracy
2,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,91.9,100.0,1.2,0.01,91.9,1.0,ito:ITO_00131,Time Series process,28\\ gestures\\ accuracy
3,1,Hand Gesture Recognition,SHREC 2017,2019-07,DG-STA,90.7,100.0,90.7,1.0,90.7,0.99,ito:ITO_00131,Time Series process,28\\ gestures\\ accuracy
0,1,Trajectory Prediction,ETH/UCY,2019-02,Next,0.46,100.0,0.46,1.0,0.46,0.03,ito:ITO_00131,Time Series process,ADE\\-8/12
1,1,Trajectory Prediction,ActEV,2019-02,Next,17.99,100.0,17.99,1.0,17.99,1.0,ito:ITO_00131,Time Series process,ADE\\-8/12
2,1,Trajectory Forecasting,ActEV,2019-02,Next,17.99,100.0,17.99,1.0,17.99,1.0,ito:ITO_00131,Time Series process,ADE\\-8/12
3,1,Trajectory Prediction,ETH BIWI Walking Pedestrians dataset,2019-04,Social Ways,0.39,100.0,0.39,1.0,0.39,0.02,ito:ITO_00131,Time Series process,ADE\\-8/12
4,1,Trajectory Prediction,Hotel BIWI Walking Pedestrians dataset,2019-04,Social Ways,0.39,100.0,0.39,1.0,0.39,0.02,ito:ITO_00131,Time Series process,ADE\\-8/12
0,1,Trajectory Prediction,ActEV,2019-02,Next,37.24,100.0,37.24,1.0,37.24,1.0,ito:ITO_00131,Time Series process,FDE\\-8/12
0,1,Activity Prediction,ActEV,2019-02,Next,0.192,100.0,0.192,1.0,0.192,1.0,ito:ITO_00131,Time Series process,mAP
0,1,Node Classification,YouTube,2019-03,LINE,70.09,100.0,70.09,1.0,70.09,1.0,ito:ITO_00131,Time Series process,runtime\\ \\(s\\)
1,1,Human motion prediction,Human motion prediction,2019-03,LINE,70.09,100.0,70.09,1.0,70.09,1.0,ito:ITO_00131,Time Series process,runtime\\ \\(s\\)
0,1,Node Classification,YouTube,2019-03,LINE,33.69,100.0,33.69,1.0,33.69,1.0,ito:ITO_00131,Time Series process,Macro\\-F1\\-at\\-2%
1,1,Human motion prediction,Human motion prediction,2019-03,LINE,33.69,100.0,33.69,1.0,33.69,1.0,ito:ITO_00131,Time Series process,Macro\\-F1\\-at\\-2%
0,1,Node Classification,YouTube,2019-03,LINE,40.61,100.0,40.61,1.0,40.61,1.0,ito:ITO_00131,Time Series process,Micro\\-F1\\-at\\-2%
1,1,Human motion prediction,Human motion prediction,2019-03,LINE,40.61,100.0,40.61,1.0,40.61,1.0,ito:ITO_00131,Time Series process,Micro\\-F1\\-at\\-2%
0,1,Time Series process,Paper Field,2019-03,STGCN,2.24,100.0,2.24,1.0,2.24,1.0,ito:ITO_00131,Time Series process,MAE\\ \\(70\\ min\\)
0,1,Trajectory Prediction,Stanford Drone,2019-04,Social-Ways,0.62,100.0,0.62,1.0,0.62,1.0,ito:ITO_00131,Time Series process,ADE\\ \\(in\\ world\\ coordinates\\)
0,1,Trajectory Prediction,Stanford Drone,2019-04,Social-Ways,1.16,100.0,1.16,1.0,1.16,1.0,ito:ITO_00131,Time Series process,FDE\\ \\(in\\ world\\ coordinates\\)
0,1,Video Prediction,CMU Mocap-1,2019-05,ODE2VAE-KL,15.99,17.18,15.99,0.17,93.07,0.17,ito:ITO_00131,Time Series process,Test\\ Error
1,1,Video Prediction,CMU Mocap-1,2019-05,ODE2VAE,93.07,100.0,77.1,0.83,93.07,1.0,ito:ITO_00131,Time Series process,Test\\ Error
2,1,Video Prediction,CMU Mocap-2,2019-05,ODE2VAE-KL,8.09,80.42,8.09,0.8,10.06,0.09,ito:ITO_00131,Time Series process,Test\\ Error
3,1,Video Prediction,CMU Mocap-2,2019-05,ODE2VAE,10.06,100.0,2.0,0.2,10.06,0.11,ito:ITO_00131,Time Series process,Test\\ Error
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,1820000.0,100.0,1820000,1.0,1820000,1.0,ito:ITO_00131,Time Series process,No\\.\\ parameters
0,1,Gesture Recognition,GesturePod,2019-10,GesturePod,92.0,100.0,92,1.0,92,1.0,ito:ITO_00131,Time Series process,Real\\ World\\ Accuracy
0,1,Trajectory Prediction,Argoverse,2019-12,SpectralCows,0.005,100.0,0.005,1.0,0.005,0.62,ito:ITO_00131,Time Series process,ADE
1,1,Trajectory Prediction,Lyft Level 5,2019-12,SpectralCows,0.008,100.0,0.008,1.0,0.008,1.0,ito:ITO_00131,Time Series process,ADE
2,1,Trajectory Prediction,Apolloscape,2019-12,SpectralCows,0.005,100.0,0.005,1.0,0.005,0.62,ito:ITO_00131,Time Series process,ADE
0,1,Stock Trend Prediction,FI-2010,2019-12,BL-GAM-RHN-7,0.8202,100.0,0.8202,1.0,0.8202,1.0,ito:ITO_00131,Time Series process,Accuracy\\ \\(H50\\)
0,1,Stock Trend Prediction,FI-2010,2019-12,BL-GAM-RHN-7,0.8088,100.0,0.8088,1.0,0.8088,1.0,ito:ITO_00131,Time Series process,F1\\ \\(H50\\)
0,1,Stock Price Prediction,2019_test set,2019-12,Yygf,22.0,100.0,22,1.0,22,1.0,ito:ITO_00131,Time Series process,10\\ fold\\ Cross\\ validation
0,1,Stock Market Prediction,S&P 500,2020-04,LSTM,0.635,100.0,0.635,1.0,0.635,1.0,ito:ITO_00131,Time Series process,Average\\ daily\\ returns
0,1,Graph Classification,PROTEINS,2003-07,RW,74.22,87.41,74.22,0.87,84.91,0.74,ito:ITO_00137,Graph process,Accuracy
1,1,Graph Classification,PROTEINS,2015-08,DGK,75.68,89.13,1.5,0.02,84.91,0.76,ito:ITO_00137,Graph process,Accuracy
2,1,Graph Classification,PROTEINS,2016-03,MLG,76.34,89.91,0.7,0.01,84.91,0.76,ito:ITO_00137,Graph process,Accuracy
3,1,Graph Classification,PROTEINS,2016-06,WL-OA,76.4,89.98,0.1,0.0,84.91,0.77,ito:ITO_00137,Graph process,Accuracy
4,1,Graph Classification,PROTEINS,2018-11,GIC,77.65,91.45,1.2,0.01,84.91,0.78,ito:ITO_00137,Graph process,Accuracy
5,1,Graph Classification,PROTEINS,2018-11,DGA,77.71,91.52,0.1,0.0,84.91,0.78,ito:ITO_00137,Graph process,Accuracy
6,1,Graph Classification,PROTEINS,2019-04,QS-CNNs (Quantum Walk),78.8,92.8,1.1,0.01,84.91,0.79,ito:ITO_00137,Graph process,Accuracy
7,1,Graph Classification,PROTEINS,2019-05,sGIN,78.97,93.0,0.2,0.0,84.91,0.79,ito:ITO_00137,Graph process,Accuracy
8,1,Graph Classification,PROTEINS,2019-09,DUGNN,81.7,96.22,2.7,0.03,84.91,0.82,ito:ITO_00137,Graph process,Accuracy
9,1,Graph Classification,PROTEINS,2019-11,HGP-SL,84.91,100.0,3.2,0.04,84.91,0.85,ito:ITO_00137,Graph process,Accuracy
10,1,Graph Classification,BP-fMRI-97,2012-12,CNN,54.6,84.13,54.6,0.84,64.9,0.55,ito:ITO_00137,Graph process,Accuracy
11,1,Graph Classification,BP-fMRI-97,2016-06,SDBN,64.8,99.85,10.2,0.16,64.9,0.65,ito:ITO_00137,Graph process,Accuracy
12,1,Graph Classification,BP-fMRI-97,2019-07,IsoNN,64.9,100.0,0.1,0.0,64.9,0.65,ito:ITO_00137,Graph process,Accuracy
13,1,Graph Classification,HIV-fMRI-77 ,2012-12,CNN,59.3,80.79,59.3,0.81,73.4,0.59,ito:ITO_00137,Graph process,Accuracy
14,1,Graph Classification,HIV-fMRI-77 ,2016-06,SDBN,66.5,90.6,7.2,0.1,73.4,0.67,ito:ITO_00137,Graph process,Accuracy
15,1,Graph Classification,HIV-fMRI-77 ,2019-07,IsoNN,73.4,100.0,6.9,0.09,73.4,0.74,ito:ITO_00137,Graph process,Accuracy
16,1,Graph Classification,HIV-DTI-77,2012-12,CNN,54.3,80.44,54.3,0.8,67.5,0.54,ito:ITO_00137,Graph process,Accuracy
17,1,Graph Classification,HIV-DTI-77,2016-06,SDBN,65.9,97.63,11.6,0.17,67.5,0.66,ito:ITO_00137,Graph process,Accuracy
18,1,Graph Classification,HIV-DTI-77,2019-07,IsoNN,67.5,100.0,1.6,0.02,67.5,0.68,ito:ITO_00137,Graph process,Accuracy
19,1,Node Classification,BlogCatalog,2014-03,DeepWalk,22.5,26.5,22.5,0.27,84.9,0.23,ito:ITO_00137,Graph process,Accuracy
20,1,Node Classification,BlogCatalog,2017-04,Struc2vec,22.8,26.86,0.3,0.0,84.9,0.23,ito:ITO_00137,Graph process,Accuracy
21,1,Node Classification,BlogCatalog,2017-11,GraphGAN,23.2,27.33,0.4,0.0,84.9,0.23,ito:ITO_00137,Graph process,Accuracy
22,1,Node Classification,BlogCatalog,2019-06,DEMO-Net(weight),84.9,100.0,61.7,0.73,84.9,0.85,ito:ITO_00137,Graph process,Accuracy
23,1,Spoken language identification,Spoken language identification,2014-03,DeepWalk,22.5,26.5,22.5,0.27,84.9,0.23,ito:ITO_00137,Graph process,Accuracy
24,1,Spoken language identification,Spoken language identification,2017-04,Struc2vec,22.8,26.86,0.3,0.0,84.9,0.23,ito:ITO_00137,Graph process,Accuracy
25,1,Spoken language identification,Spoken language identification,2017-11,GraphGAN,23.2,27.33,0.4,0.0,84.9,0.23,ito:ITO_00137,Graph process,Accuracy
26,1,Spoken language identification,Spoken language identification,2019-06,DEMO-Net(weight),84.9,100.0,61.7,0.73,84.9,0.85,ito:ITO_00137,Graph process,Accuracy
27,1,Node Classification,Wikipedia,2014-03,DeepWalk,19.4,91.08,19.4,0.91,21.3,0.19,ito:ITO_00137,Graph process,Accuracy
28,1,Node Classification,Wikipedia,2017-04,Struc2vec,21.1,99.06,1.7,0.08,21.3,0.21,ito:ITO_00137,Graph process,Accuracy
29,1,Node Classification,Wikipedia,2017-11,GraphGAN,21.3,100.0,0.2,0.01,21.3,0.21,ito:ITO_00137,Graph process,Accuracy
30,1,Graph Classification,NEURON-Average,2015-07,PI-PL,64.2,82.52,64.2,0.83,77.8,0.64,ito:ITO_00137,Graph process,Accuracy
31,1,Graph Classification,NEURON-Average,2017-06,SW,71.2,91.52,7.0,0.09,77.8,0.71,ito:ITO_00137,Graph process,Accuracy
32,1,Graph Classification,NEURON-Average,2019-04,WKPI-kcenters,77.8,100.0,6.6,0.08,77.8,0.78,ito:ITO_00137,Graph process,Accuracy
33,1,Graph Classification,NEURON-MULTI,2015-07,PI-PL,44.3,64.11,44.3,0.64,69.1,0.44,ito:ITO_00137,Graph process,Accuracy
34,1,Graph Classification,NEURON-MULTI,2017-06,SW,57.3,82.92,13.0,0.19,69.1,0.57,ito:ITO_00137,Graph process,Accuracy
35,1,Graph Classification,NEURON-MULTI,2019-04,WKPI-kcenters,69.1,100.0,11.8,0.17,69.1,0.69,ito:ITO_00137,Graph process,Accuracy
36,1,Graph Classification,NEURON-BINARY,2015-07,PI-PL,84.1,93.13,84.1,0.93,90.3,0.84,ito:ITO_00137,Graph process,Accuracy
37,1,Graph Classification,NEURON-BINARY,2017-06,SW,85.1,94.24,1.0,0.01,90.3,0.85,ito:ITO_00137,Graph process,Accuracy
38,1,Graph Classification,NEURON-BINARY,2019-04,WKPI-kmeans,90.3,100.0,5.2,0.06,90.3,0.9,ito:ITO_00137,Graph process,Accuracy
39,1,Graph Classification,FRANKENSTEIN,2015-07,GWL_WL,78.9,100.0,78.9,1.0,78.9,0.79,ito:ITO_00137,Graph process,Accuracy
40,1,Graph Classification,NCI1,2015-08,DGK,80.31,92.1,80.31,0.92,87.2,0.8,ito:ITO_00137,Graph process,Accuracy
41,1,Graph Classification,NCI1,2016-06,WL-OA,86.1,98.74,5.8,0.07,87.2,0.86,ito:ITO_00137,Graph process,Accuracy
42,1,Graph Classification,NCI1,2018-05,FGW wl h=4 sp,86.42,99.11,0.3,0.0,87.2,0.87,ito:ITO_00137,Graph process,Accuracy
43,1,Graph Classification,NCI1,2019-04,WKPI-kmeans,87.2,100.0,0.8,0.01,87.2,0.87,ito:ITO_00137,Graph process,Accuracy
44,1,Graph Classification,IMDb-M,2015-08,DGK,44.55,59.56,44.55,0.6,74.8,0.45,ito:ITO_00137,Graph process,Accuracy
45,1,Graph Classification,IMDb-M,2018-04,DGCNN,47.83,63.94,3.3,0.04,74.8,0.48,ito:ITO_00137,Graph process,Accuracy
46,1,Graph Classification,IMDb-M,2018-07,G_ResNet,54.53,72.9,6.7,0.09,74.8,0.55,ito:ITO_00137,Graph process,Accuracy
47,1,Graph Classification,IMDb-M,2019-09,DUGNN,56.1,75.0,1.6,0.02,74.8,0.56,ito:ITO_00137,Graph process,Accuracy
48,1,Graph Classification,IMDb-M,2019-09,U2GNN (Unsupervised),74.8,100.0,18.7,0.25,74.8,0.75,ito:ITO_00137,Graph process,Accuracy
49,1,Graph Classification,RE-M12K,2015-08,DGK,32.22,64.76,32.22,0.65,49.75,0.32,ito:ITO_00137,Graph process,Accuracy
50,1,Graph Classification,RE-M12K,2017-07,2D CNN,48.13,96.74,15.9,0.32,49.75,0.48,ito:ITO_00137,Graph process,Accuracy
51,1,Graph Classification,RE-M12K,2019-05,GFN-light,49.75,100.0,1.6,0.03,49.75,0.5,ito:ITO_00137,Graph process,Accuracy
52,1,Graph Classification,MUTAG,2015-08,DGK,87.44,92.04,87.44,0.92,95.0,0.88,ito:ITO_00137,Graph process,Accuracy
53,1,Graph Classification,MUTAG,2016-05,PSCN,88.95,93.63,1.5,0.02,95.0,0.89,ito:ITO_00137,Graph process,Accuracy
54,1,Graph Classification,MUTAG,2016-05,PATCHY-SAN,92.63,97.51,3.7,0.04,95.0,0.93,ito:ITO_00137,Graph process,Accuracy
55,1,Graph Classification,MUTAG,2018-07,G_Inception,95.0,100.0,2.4,0.03,95.0,0.95,ito:ITO_00137,Graph process,Accuracy
56,1,Graph Classification,RE-M5K,2015-08,DGK,41.27,71.77,41.27,0.72,57.5,0.41,ito:ITO_00137,Graph process,Accuracy
57,1,Graph Classification,RE-M5K,2017-07,2D CNN,52.11,90.63,10.8,0.19,57.5,0.52,ito:ITO_00137,Graph process,Accuracy
58,1,Graph Classification,RE-M5K,2018-10,GIN-0,57.5,100.0,5.4,0.09,57.5,0.58,ito:ITO_00137,Graph process,Accuracy
59,1,Graph Classification,COLLAB,2015-08,DGK,73.09,76.44,73.09,0.76,95.62,0.73,ito:ITO_00137,Graph process,Accuracy
60,1,Graph Classification,COLLAB,2018-04,DGCNN,73.76,77.14,0.7,0.01,95.62,0.74,ito:ITO_00137,Graph process,Accuracy
61,1,Graph Classification,COLLAB,2018-06,GNN (DiffPool),75.48,78.94,1.7,0.02,95.62,0.76,ito:ITO_00137,Graph process,Accuracy
62,1,Graph Classification,COLLAB,2018-07,G_DenseNet,83.16,86.97,7.7,0.08,95.62,0.83,ito:ITO_00137,Graph process,Accuracy
63,1,Graph Classification,COLLAB,2019-09,DUGNN,84.2,88.06,1.0,0.01,95.62,0.84,ito:ITO_00137,Graph process,Accuracy
64,1,Graph Classification,COLLAB,2019-09,U2GNN (Unsupervised),95.62,100.0,11.4,0.12,95.62,0.96,ito:ITO_00137,Graph process,Accuracy
65,1,Graph Classification,IMDb-B,2015-08,DGK,66.96,71.61,66.96,0.72,93.5,0.67,ito:ITO_00137,Graph process,Accuracy
66,1,Graph Classification,IMDb-B,2016-05,PSCN,71.0,75.94,4.0,0.04,93.5,0.71,ito:ITO_00137,Graph process,Accuracy
67,1,Graph Classification,IMDb-B,2018-05,GCAPS-CNN,71.69,76.67,0.7,0.01,93.5,0.72,ito:ITO_00137,Graph process,Accuracy
68,1,Graph Classification,IMDb-B,2018-05,AWE,74.45,79.63,2.8,0.03,93.5,0.75,ito:ITO_00137,Graph process,Accuracy
69,1,Graph Classification,IMDb-B,2018-07,G_ResNet,79.9,85.45,5.5,0.06,93.5,0.8,ito:ITO_00137,Graph process,Accuracy
70,1,Graph Classification,IMDb-B,2019-09,U2GNN (Unsupervised),93.5,100.0,13.6,0.15,93.5,0.94,ito:ITO_00137,Graph process,Accuracy
71,1,Graph Classification,ENZYMES,2015-08,DGK,53.43,68.16,53.43,0.68,78.39,0.54,ito:ITO_00137,Graph process,Accuracy
72,1,Graph Classification,ENZYMES,2018-05,FGW sp,71.0,90.57,17.6,0.22,78.39,0.71,ito:ITO_00137,Graph process,Accuracy
73,1,Graph Classification,ENZYMES,2020-03,DSGCN-allfeat,78.39,100.0,7.4,0.09,78.39,0.79,ito:ITO_00137,Graph process,Accuracy
74,1,Graph Classification,D&D,2015-08,DGK,73.5,76.83,73.5,0.77,95.67,0.74,ito:ITO_00137,Graph process,Accuracy
75,1,Graph Classification,D&D,2016-05,PSCN,76.27,79.72,2.8,0.03,95.67,0.76,ito:ITO_00137,Graph process,Accuracy
76,1,Graph Classification,D&D,2017-12,DGCNN,77.21,80.7,0.9,0.01,95.67,0.77,ito:ITO_00137,Graph process,Accuracy
77,1,Graph Classification,D&D,2018-04,DGCNN,79.37,82.96,2.2,0.02,95.67,0.8,ito:ITO_00137,Graph process,Accuracy
78,1,Graph Classification,D&D,2018-06,GNN (DiffPool),80.64,84.29,1.3,0.01,95.67,0.81,ito:ITO_00137,Graph process,Accuracy
79,1,Graph Classification,D&D,2018-06,S2V (with 2 DiffPool),82.07,85.78,1.4,0.01,95.67,0.82,ito:ITO_00137,Graph process,Accuracy
80,1,Graph Classification,D&D,2019-04,DDGK,83.14,86.9,1.1,0.01,95.67,0.83,ito:ITO_00137,Graph process,Accuracy
81,1,Graph Classification,D&D,2019-09,U2GNN (Unsupervised),95.67,100.0,12.5,0.13,95.67,0.96,ito:ITO_00137,Graph process,Accuracy
82,1,Node Classification,PubMed with Public Split: fixed 20 nodes per class,2015-09,GCN-FP,76.0,92.21,76.0,0.92,82.42,0.76,ito:ITO_00137,Graph process,Accuracy
83,1,Node Classification,PubMed with Public Split: fixed 20 nodes per class,2015-11,DCNN,76.8,93.18,0.8,0.01,82.42,0.77,ito:ITO_00137,Graph process,Accuracy
84,1,Node Classification,PubMed with Public Split: fixed 20 nodes per class,2016-09,GCN,77.8,94.39,1.0,0.01,82.42,0.78,ito:ITO_00137,Graph process,Accuracy
85,1,Node Classification,PubMed with Public Split: fixed 20 nodes per class,2017-10,GAT,79.0,95.85,1.2,0.01,82.42,0.79,ito:ITO_00137,Graph process,Accuracy
86,1,Node Classification,PubMed with Public Split: fixed 20 nodes per class,2019-02,H-GCN,79.8,96.82,0.8,0.01,82.42,0.8,ito:ITO_00137,Graph process,Accuracy
87,1,Node Classification,PubMed with Public Split: fixed 20 nodes per class,2019-06,Truncated Krylov,81.7,99.13,1.9,0.02,82.42,0.82,ito:ITO_00137,Graph process,Accuracy
88,1,Node Classification,PubMed with Public Split: fixed 20 nodes per class,2019-09,GCN(predicted-targets),82.42,100.0,0.7,0.01,82.42,0.83,ito:ITO_00137,Graph process,Accuracy
89,1,Semanticity prediction,Semanticity prediction,2015-09,GCN-FP,50.5,67.43,50.5,0.67,74.89,0.51,ito:ITO_00137,Graph process,Accuracy
90,1,Semanticity prediction,Semanticity prediction,2015-11,DCNN,59.0,78.78,8.5,0.11,74.89,0.59,ito:ITO_00137,Graph process,Accuracy
91,1,Semanticity prediction,Semanticity prediction,2019-01,AdaLanczosNet,60.8,81.19,1.8,0.02,74.89,0.61,ito:ITO_00137,Graph process,Accuracy
92,1,Semanticity prediction,Semanticity prediction,2019-06,Truncated Krylov,74.89,100.0,14.1,0.19,74.89,0.75,ito:ITO_00137,Graph process,Accuracy
93,1,Speaker-Specific Lip to Speech Synthesis,Speaker-Specific Lip to Speech Synthesis,2015-09,GCN-FP,71.7,87.52,71.7,0.88,81.92,0.72,ito:ITO_00137,Graph process,Accuracy
94,1,Speaker-Specific Lip to Speech Synthesis,Speaker-Specific Lip to Speech Synthesis,2015-11,DCNN,76.7,93.63,5.0,0.06,81.92,0.77,ito:ITO_00137,Graph process,Accuracy
95,1,Speaker-Specific Lip to Speech Synthesis,Speaker-Specific Lip to Speech Synthesis,2019-01,AdaLanczosNet,77.7,94.85,1.0,0.01,81.92,0.78,ito:ITO_00137,Graph process,Accuracy
96,1,Speaker-Specific Lip to Speech Synthesis,Speaker-Specific Lip to Speech Synthesis,2019-06,Truncated Krylov,81.92,100.0,4.2,0.05,81.92,0.82,ito:ITO_00137,Graph process,Accuracy
97,1,Micro-Expression Spotting,Micro-Expression Spotting,2015-09,GCN-FP,43.9,67.91,43.9,0.68,64.64,0.44,ito:ITO_00137,Graph process,Accuracy
98,1,Micro-Expression Spotting,Micro-Expression Spotting,2015-11,DCNN,53.1,82.15,9.2,0.14,64.64,0.53,ito:ITO_00137,Graph process,Accuracy
99,1,Micro-Expression Spotting,Micro-Expression Spotting,2019-01,AdaLanczosNet,53.8,83.23,0.7,0.01,64.64,0.54,ito:ITO_00137,Graph process,Accuracy
100,1,Micro-Expression Spotting,Micro-Expression Spotting,2019-06,Snowball (linear + tanh),61.99,95.9,8.2,0.13,64.64,0.62,ito:ITO_00137,Graph process,Accuracy
101,1,Micro-Expression Spotting,Micro-Expression Spotting,2019-06,Truncated Krylov,64.64,100.0,2.6,0.04,64.64,0.65,ito:ITO_00137,Graph process,Accuracy
102,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2015-09,GCN-FP,61.5,82.0,61.5,0.82,75.0,0.62,ito:ITO_00137,Graph process,Accuracy
103,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2015-11,DCNN,69.4,92.53,7.9,0.11,75.0,0.7,ito:ITO_00137,Graph process,Accuracy
104,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2016-06,ChebyNet,70.1,93.47,0.7,0.01,75.0,0.7,ito:ITO_00137,Graph process,Accuracy
105,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2017-10,GAT,72.5,96.67,2.4,0.03,75.0,0.73,ito:ITO_00137,Graph process,Accuracy
106,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2019-02,H-GCN,72.8,97.07,0.3,0.0,75.0,0.73,ito:ITO_00137,Graph process,Accuracy
107,1,Node Classification,CiteSeer with Public Split: fixed 20 nodes per class,2019-03,LDS-GNN,75.0,100.0,2.2,0.03,75.0,0.75,ito:ITO_00137,Graph process,Accuracy
108,1,Trajectory Forecasting,Trajectory Forecasting,2015-09,GCN-FP,61.5,82.0,61.5,0.82,75.0,0.62,ito:ITO_00137,Graph process,Accuracy
109,1,Trajectory Forecasting,Trajectory Forecasting,2015-11,DCNN,69.4,92.53,7.9,0.11,75.0,0.7,ito:ITO_00137,Graph process,Accuracy
110,1,Trajectory Forecasting,Trajectory Forecasting,2016-06,ChebyNet,70.1,93.47,0.7,0.01,75.0,0.7,ito:ITO_00137,Graph process,Accuracy
111,1,Trajectory Forecasting,Trajectory Forecasting,2017-10,GAT,72.5,96.67,2.4,0.03,75.0,0.73,ito:ITO_00137,Graph process,Accuracy
112,1,Trajectory Forecasting,Trajectory Forecasting,2019-02,H-GCN,72.8,97.07,0.3,0.0,75.0,0.73,ito:ITO_00137,Graph process,Accuracy
113,1,Trajectory Forecasting,Trajectory Forecasting,2019-03,LDS-GNN,75.0,100.0,2.2,0.03,75.0,0.75,ito:ITO_00137,Graph process,Accuracy
114,1,Node Classification,Cora with Public Split: fixed 20 nodes per class,2015-09,GCN-FP,74.6,88.08,74.6,0.88,84.7,0.75,ito:ITO_00137,Graph process,Accuracy
115,1,Node Classification,Cora with Public Split: fixed 20 nodes per class,2015-11,DCNN,79.7,94.1,5.1,0.06,84.7,0.8,ito:ITO_00137,Graph process,Accuracy
116,1,Node Classification,Cora with Public Split: fixed 20 nodes per class,2016-09,GCN,80.5,95.04,0.8,0.01,84.7,0.81,ito:ITO_00137,Graph process,Accuracy
117,1,Node Classification,Cora with Public Split: fixed 20 nodes per class,2017-10,GAT,83.0,97.99,2.5,0.03,84.7,0.83,ito:ITO_00137,Graph process,Accuracy
118,1,Node Classification,Cora with Public Split: fixed 20 nodes per class,2019-02,H-GCN,84.5,99.76,1.5,0.02,84.7,0.85,ito:ITO_00137,Graph process,Accuracy
119,1,Node Classification,Cora with Public Split: fixed 20 nodes per class,2019-11,AIR-GCN,84.7,100.0,0.2,0.0,84.7,0.85,ito:ITO_00137,Graph process,Accuracy
120,1,Lip to Speech Synthesis,Lip to Speech Synthesis,2015-09,GCN-FP,54.3,78.66,54.3,0.79,69.03,0.54,ito:ITO_00137,Graph process,Accuracy
121,1,Lip to Speech Synthesis,Lip to Speech Synthesis,2015-11,DCNN,62.2,90.11,7.9,0.11,69.03,0.62,ito:ITO_00137,Graph process,Accuracy
122,1,Lip to Speech Synthesis,Lip to Speech Synthesis,2019-01,AdaLanczosNet,63.3,91.7,1.1,0.02,69.03,0.63,ito:ITO_00137,Graph process,Accuracy
123,1,Lip to Speech Synthesis,Lip to Speech Synthesis,2019-06,Snowball (linear),65.85,95.39,2.5,0.04,69.03,0.66,ito:ITO_00137,Graph process,Accuracy
124,1,Lip to Speech Synthesis,Lip to Speech Synthesis,2019-06,Truncated Krylov,69.03,100.0,3.2,0.05,69.03,0.69,ito:ITO_00137,Graph process,Accuracy
125,1,Constrained Lip-synchronization,Constrained Lip-synchronization,2015-09,GCN-FP,70.3,91.05,70.3,0.91,77.21,0.7,ito:ITO_00137,Graph process,Accuracy
126,1,Constrained Lip-synchronization,Constrained Lip-synchronization,2015-11,DCNN,73.1,94.68,2.8,0.04,77.21,0.73,ito:ITO_00137,Graph process,Accuracy
127,1,Constrained Lip-synchronization,Constrained Lip-synchronization,2019-01,LanczosNet,73.4,95.07,0.3,0.0,77.21,0.74,ito:ITO_00137,Graph process,Accuracy
128,1,Constrained Lip-synchronization,Constrained Lip-synchronization,2019-06,Truncated Krylov,77.21,100.0,3.8,0.05,77.21,0.77,ito:ITO_00137,Graph process,Accuracy
129,1,Node Classification,20NEWS,2015-10,GraRep,81.44,100.0,81.44,1.0,81.44,0.82,ito:ITO_00137,Graph process,Accuracy
130,1,Attention Score Prediction,Attention Score Prediction,2015-10,GraRep,81.44,100.0,81.44,1.0,81.44,0.82,ito:ITO_00137,Graph process,Accuracy
131,1,Graph Classification,IPC-lifted,2015-11,GG-NN,81.4,92.92,81.4,0.93,87.6,0.82,ito:ITO_00137,Graph process,Accuracy
132,1,Graph Classification,IPC-lifted,2016-09,GCN,87.6,100.0,6.2,0.07,87.6,0.88,ito:ITO_00137,Graph process,Accuracy
133,1,Graph Classification,IPC-grounded,2015-11,GG-NN,77.9,96.53,77.9,0.97,80.7,0.78,ito:ITO_00137,Graph process,Accuracy
134,1,Graph Classification,IPC-grounded,2016-09,GCN,80.7,100.0,2.8,0.03,80.7,0.81,ito:ITO_00137,Graph process,Accuracy
135,1,Graph Clustering,Cora,2016-02,DNGR,41.9,60.8,41.9,0.61,68.92,0.42,ito:ITO_00137,Graph process,Accuracy
136,1,Graph Clustering,Cora,2016-11,GAE,59.6,86.48,17.7,0.26,68.92,0.6,ito:ITO_00137,Graph process,Accuracy
137,1,Graph Clustering,Cora,2018-02,ARGE,64.0,92.86,4.4,0.06,68.92,0.64,ito:ITO_00137,Graph process,Accuracy
138,1,Graph Clustering,Cora,2019-06,AGC,68.92,100.0,4.9,0.07,68.92,0.69,ito:ITO_00137,Graph process,Accuracy
139,1,Graph Clustering,Citeseer,2016-02,DNGR,32.6,48.66,32.6,0.49,67.0,0.33,ito:ITO_00137,Graph process,Accuracy
140,1,Graph Clustering,Citeseer,2016-11,GAE,40.8,60.9,8.2,0.12,67.0,0.41,ito:ITO_00137,Graph process,Accuracy
141,1,Graph Clustering,Citeseer,2017-11,MGAE,63.56,94.87,22.8,0.34,67.0,0.64,ito:ITO_00137,Graph process,Accuracy
142,1,Graph Clustering,Citeseer,2019-06,AGC,67.0,100.0,3.4,0.05,67.0,0.67,ito:ITO_00137,Graph process,Accuracy
143,1,Graph Clustering,Pubmed,2016-02,DNGR,45.35,64.99,45.35,0.65,69.78,0.45,ito:ITO_00137,Graph process,Accuracy
144,1,Graph Clustering,Pubmed,2016-11,VGAE,65.48,93.84,20.1,0.29,69.78,0.66,ito:ITO_00137,Graph process,Accuracy
145,1,Graph Clustering,Pubmed,2019-06,AGC,69.78,100.0,4.3,0.06,69.78,0.7,ito:ITO_00137,Graph process,Accuracy
146,1,Node Classification,Pubmed,2016-03,Planetoid-I,77.2,86.86,77.2,0.87,88.88,0.77,ito:ITO_00137,Graph process,Accuracy
147,1,Node Classification,Pubmed,2016-09,GCN,79.0,88.88,1.8,0.02,88.88,0.79,ito:ITO_00137,Graph process,Accuracy
148,1,Node Classification,Pubmed,2017-11,SplineCNN,88.88,100.0,9.9,0.11,88.88,0.89,ito:ITO_00137,Graph process,Accuracy
149,1,Node Classification,Cora,2016-03,Planetoid-I,75.7,84.6,75.7,0.85,89.48,0.76,ito:ITO_00137,Graph process,Accuracy
150,1,Node Classification,Cora,2016-06,ChebNet,81.2,90.75,5.5,0.06,89.48,0.81,ito:ITO_00137,Graph process,Accuracy
151,1,Node Classification,Cora,2016-09,GCN,81.5,91.08,0.3,0.0,89.48,0.82,ito:ITO_00137,Graph process,Accuracy
152,1,Node Classification,Cora,2017-10,GAT,83.0,92.76,1.5,0.02,89.48,0.83,ito:ITO_00137,Graph process,Accuracy
153,1,Node Classification,Cora,2017-11,SplineCNN,89.48,100.0,6.5,0.07,89.48,0.9,ito:ITO_00137,Graph process,Accuracy
154,1,Node Classification,NELL,2016-03,Planetoid*,61.9,89.97,61.9,0.9,68.8,0.62,ito:ITO_00137,Graph process,Accuracy
155,1,Node Classification,NELL,2016-09,GCN,66.0,95.93,4.1,0.06,68.8,0.66,ito:ITO_00137,Graph process,Accuracy
156,1,Node Classification,NELL,2019-10,DFNet-ATT,68.8,100.0,2.8,0.04,68.8,0.69,ito:ITO_00137,Graph process,Accuracy
157,1,Node Classification,USA Air-Traffic,2016-03,Planetoid*,64.7,100.0,64.7,1.0,64.7,0.65,ito:ITO_00137,Graph process,Accuracy
158,1,Node Classification,Citeseer,2016-03,Planetoid-I,64.7,81.69,64.7,0.82,79.2,0.65,ito:ITO_00137,Graph process,Accuracy
159,1,Node Classification,Citeseer,2016-06,ChebNet,69.8,88.13,5.1,0.06,79.2,0.7,ito:ITO_00137,Graph process,Accuracy
160,1,Node Classification,Citeseer,2016-09,GCN,70.3,88.76,0.5,0.01,79.2,0.7,ito:ITO_00137,Graph process,Accuracy
161,1,Node Classification,Citeseer,2017-10,GAT,72.5,91.54,2.2,0.03,79.2,0.73,ito:ITO_00137,Graph process,Accuracy
162,1,Node Classification,Citeseer,2017-11,SplineCNN,79.2,100.0,6.7,0.08,79.2,0.79,ito:ITO_00137,Graph process,Accuracy
163,1,Graph Classification,PTC,2016-05,PATCHY-SAN,60.0,70.93,60.0,0.71,84.59,0.6,ito:ITO_00137,Graph process,Accuracy
164,1,Graph Classification,PTC,2017-07,Graph2Vec,60.17,71.13,0.2,0.0,84.59,0.6,ito:ITO_00137,Graph process,Accuracy
165,1,Graph Classification,PTC,2017-12,DGCNN,65.43,77.35,5.3,0.06,84.59,0.66,ito:ITO_00137,Graph process,Accuracy
166,1,Graph Classification,PTC,2018-07,G_DenseNet,73.24,86.58,7.8,0.09,84.59,0.73,ito:ITO_00137,Graph process,Accuracy
167,1,Graph Classification,PTC,2018-11,GIC,77.64,91.78,4.4,0.05,84.59,0.78,ito:ITO_00137,Graph process,Accuracy
168,1,Graph Classification,PTC,2019-09,U2GNN (Unsupervised),84.59,100.0,7.0,0.08,84.59,0.85,ito:ITO_00137,Graph process,Accuracy
169,1,Graph Classification,NCI109,2016-06,WL-OA,86.3,98.85,86.3,0.99,87.3,0.86,ito:ITO_00137,Graph process,Accuracy
170,1,Graph Classification,NCI109,2019-04,WKPI-kcenters,87.3,100.0,1.0,0.01,87.3,0.87,ito:ITO_00137,Graph process,Accuracy
171,1,Node Classification,Flickr,2016-09,"GCN_cheby (Kipf and Welling, 2017)",0.479,73.02,0.479,0.73,0.656,0.0,ito:ITO_00137,Graph process,Accuracy
172,1,Node Classification,Flickr,2016-09,"GCN (Kipf and Welling, 2017)",0.546,83.23,0.1,0.15,0.656,0.01,ito:ITO_00137,Graph process,Accuracy
173,1,Node Classification,Flickr,2017-06,"GraphSAGE (Hamilton et al., [2017a])",0.641,97.71,0.1,0.15,0.656,0.01,ito:ITO_00137,Graph process,Accuracy
174,1,Node Classification,Flickr,2019-06,DEMO-Net(weight),0.656,100.0,0.0,0.0,0.656,0.01,ito:ITO_00137,Graph process,Accuracy
175,1,Node Classification,Brazil Air-Traffic,2016-09,"GCN_cheby (Kipf and Welling, 2017)",0.516,95.03,0.516,0.95,0.543,0.01,ito:ITO_00137,Graph process,Accuracy
176,1,Node Classification,Brazil Air-Traffic,2019-06,DEMO-Net(weight),0.543,100.0,0.0,0.0,0.543,0.01,ito:ITO_00137,Graph process,Accuracy
177,1,Node Classification,Facebook,2016-09,"GCN_cheby (Kipf and Welling, 2017)",64.6,70.29,64.6,0.7,91.9,0.65,ito:ITO_00137,Graph process,Accuracy
178,1,Node Classification,Facebook,2019-06,DEMO-Net(weight),91.9,100.0,27.3,0.3,91.9,0.92,ito:ITO_00137,Graph process,Accuracy
179,1,Node Classification,Wiki-Vote,2016-09,"GCN_cheby (Kipf and Welling, 2017)",49.5,49.6,49.5,0.5,99.8,0.5,ito:ITO_00137,Graph process,Accuracy
180,1,Node Classification,Wiki-Vote,2017-10,"GAT (Velickovic et al., 2018)",59.4,59.52,9.9,0.1,99.8,0.6,ito:ITO_00137,Graph process,Accuracy
181,1,Node Classification,Wiki-Vote,2019-06,DEMO-Net(weight),99.8,100.0,40.4,0.4,99.8,1.0,ito:ITO_00137,Graph process,Accuracy
182,1,Transparent Object Depth Estimation,Transparent Object Depth Estimation,2016-09,"GCN (Kipf and Welling, 2017)",32.9,32.97,32.9,0.33,99.8,0.33,ito:ITO_00137,Graph process,Accuracy
183,1,Transparent Object Depth Estimation,Transparent Object Depth Estimation,2016-09,"GCN_cheby (Kipf and Welling, 2017)",49.5,49.6,16.6,0.17,99.8,0.5,ito:ITO_00137,Graph process,Accuracy
184,1,Transparent Object Depth Estimation,Transparent Object Depth Estimation,2017-10,"GAT (Velickovic et al., 2018)",59.4,59.52,9.9,0.1,99.8,0.6,ito:ITO_00137,Graph process,Accuracy
185,1,Transparent Object Depth Estimation,Transparent Object Depth Estimation,2019-06,DEMO-Net(weight),99.8,100.0,40.4,0.4,99.8,1.0,ito:ITO_00137,Graph process,Accuracy
186,1,Node Classification,Europe Air-Traffic,2016-09,"GCN_cheby (Kipf and Welling, 2017)",46.0,100.0,46.0,1.0,46.0,0.46,ito:ITO_00137,Graph process,Accuracy
187,1,Stereo-LiDAR Fusion,Stereo-LiDAR Fusion,2016-09,"GCN (Kipf and Welling, 2017)",37.1,80.65,37.1,0.81,46.0,0.37,ito:ITO_00137,Graph process,Accuracy
188,1,Stereo-LiDAR Fusion,Stereo-LiDAR Fusion,2016-09,"GCN_cheby (Kipf and Welling, 2017)",46.0,100.0,8.9,0.19,46.0,0.46,ito:ITO_00137,Graph process,Accuracy
189,1,Node Classification,Citeseer Full-supervised,2016-09,GCN,79.34,98.56,79.34,0.99,80.5,0.79,ito:ITO_00137,Graph process,Accuracy
190,1,Node Classification,Citeseer Full-supervised,2018-09,ASGCN,79.66,98.96,0.3,0.0,80.5,0.8,ito:ITO_00137,Graph process,Accuracy
191,1,Node Classification,Citeseer Full-supervised,2020-01,IncepGCN+DropEdge,80.5,100.0,0.8,0.01,80.5,0.81,ito:ITO_00137,Graph process,Accuracy
192,1,Node Classification,Cora Full-supervised,2016-09,GCN,86.64,98.23,86.64,0.98,88.2,0.87,ito:ITO_00137,Graph process,Accuracy
193,1,Node Classification,Cora Full-supervised,2018-09,ASGCN,87.44,99.14,0.8,0.01,88.2,0.88,ito:ITO_00137,Graph process,Accuracy
194,1,Node Classification,Cora Full-supervised,2020-01,IncepGCN+DropEdge,88.2,100.0,0.8,0.01,88.2,0.88,ito:ITO_00137,Graph process,Accuracy
195,1,Node Classification,Pubmed Full-supervised,2016-09,GCN,90.22,98.39,90.22,0.98,91.7,0.9,ito:ITO_00137,Graph process,Accuracy
196,1,Node Classification,Pubmed Full-supervised,2018-09,ASGCN,90.6,98.8,0.4,0.0,91.7,0.91,ito:ITO_00137,Graph process,Accuracy
197,1,Node Classification,Pubmed Full-supervised,2020-01,GraphSAGE+DropEdge,91.7,100.0,1.1,0.01,91.7,0.92,ito:ITO_00137,Graph process,Accuracy
198,1,Node Classification,Reddit,2016-09,GCN,95.68,98.62,95.68,0.99,97.02,0.96,ito:ITO_00137,Graph process,Accuracy
199,1,Node Classification,Reddit,2018-09,ASGCN,96.27,99.23,0.6,0.01,97.02,0.96,ito:ITO_00137,Graph process,Accuracy
200,1,Node Classification,Reddit,2019-07,GraphSAINT,97.0,99.98,0.7,0.01,97.02,0.97,ito:ITO_00137,Graph process,Accuracy
201,1,Node Classification,Reddit,2020-01,JKNet+DropEdge,97.02,100.0,0.0,0.0,97.02,0.97,ito:ITO_00137,Graph process,Accuracy
202,1,LWR Classification,LWR Classification,2016-09,GCN,95.68,98.62,95.68,0.99,97.02,0.96,ito:ITO_00137,Graph process,Accuracy
203,1,LWR Classification,LWR Classification,2018-09,ASGCN,96.27,99.23,0.6,0.01,97.02,0.96,ito:ITO_00137,Graph process,Accuracy
204,1,LWR Classification,LWR Classification,2019-07,GraphSAINT,97.0,99.98,0.7,0.01,97.02,0.97,ito:ITO_00137,Graph process,Accuracy
205,1,LWR Classification,LWR Classification,2020-01,JKNet+DropEdge,97.02,100.0,0.0,0.0,97.02,0.97,ito:ITO_00137,Graph process,Accuracy
206,1,Link Prediction,Citeseer,2016-11,Variational graph auto-encoders,91.4,93.55,91.4,0.94,97.7,0.92,ito:ITO_00137,Graph process,Accuracy
207,1,Link Prediction,Citeseer,2018-11,MTGAE,94.9,97.13,3.5,0.04,97.7,0.95,ito:ITO_00137,Graph process,Accuracy
208,1,Link Prediction,Citeseer,2019-06,GraphStar,97.7,100.0,2.8,0.03,97.7,0.98,ito:ITO_00137,Graph process,Accuracy
209,1,Link Prediction,Pubmed,2016-11,Variational graph auto-encoders,97.1,98.92,97.1,0.99,98.16,0.97,ito:ITO_00137,Graph process,Accuracy
210,1,Link Prediction,Pubmed,2019-06,GraphStar,98.16,100.0,1.1,0.01,98.16,0.98,ito:ITO_00137,Graph process,Accuracy
211,1,Link Prediction,Cora,2016-11,Variational graph auto-encoders,92.0,95.93,92.0,0.96,95.9,0.92,ito:ITO_00137,Graph process,Accuracy
212,1,Link Prediction,Cora,2018-11,MTGAE,94.6,98.64,2.6,0.03,95.9,0.95,ito:ITO_00137,Graph process,Accuracy
213,1,Link Prediction,Cora,2019-06,GraphStar,95.9,100.0,1.3,0.01,95.9,0.96,ito:ITO_00137,Graph process,Accuracy
214,1,Node Classification,BGS,2017-03,R-GCN,83.1,95.25,83.1,0.95,87.24,0.83,ito:ITO_00137,Graph process,Accuracy
215,1,Node Classification,BGS,2017-11,RDF2Vec+SVM,87.24,100.0,4.1,0.05,87.24,0.87,ito:ITO_00137,Graph process,Accuracy
216,1,Node Classification,AIFB,2017-03,R-GCN,95.83,100.0,95.83,1.0,95.83,0.96,ito:ITO_00137,Graph process,Accuracy
217,1,Unconstrained Lip-synchronization,Unconstrained Lip-synchronization,2017-03,R-GCN,95.83,100.0,95.83,1.0,95.83,0.96,ito:ITO_00137,Graph process,Accuracy
218,1,Node Classification,MUTAG,2017-03,R-GCN,73.23,99.2,73.23,0.99,73.82,0.73,ito:ITO_00137,Graph process,Accuracy
219,1,Node Classification,MUTAG,2019-08,Path Tree,73.82,100.0,0.6,0.01,73.82,0.74,ito:ITO_00137,Graph process,Accuracy
220,1,Node Classification,AM,2017-03,R-GCN,89.29,100.0,89.29,1.0,89.29,0.89,ito:ITO_00137,Graph process,Accuracy
221,1,Link Prediction,WordNet,2017-05,Poincare Embeddings (dim=100),77.4,100.0,77.4,1.0,77.4,0.78,ito:ITO_00137,Graph process,Accuracy
222,1,Graph Classification,AIDS,2017-12,DGCNN,65.1,100.0,65.1,1.0,65.1,0.65,ito:ITO_00137,Graph process,Accuracy
223,1,Graph Classification,REDDIT-MULTI-12K,2018-06,GNN (DiffPool),47.08,100.0,47.08,1.0,47.08,0.47,ito:ITO_00137,Graph process,Accuracy
224,1,Graph Classification,NCI33,2018-07,GAM,69.58,100.0,69.58,1.0,69.58,0.7,ito:ITO_00137,Graph process,Accuracy
225,1,Graph Classification,NCI-83,2018-07,GAM,70.42,100.0,70.42,1.0,70.42,0.71,ito:ITO_00137,Graph process,Accuracy
226,1,Graph Classification,HIV dataset,2018-07,GAM,74.79,100.0,74.79,1.0,74.79,0.75,ito:ITO_00137,Graph process,Accuracy
227,1,Graph Classification,NCI-123,2018-07,GAM,64.79,100.0,64.79,1.0,64.79,0.65,ito:ITO_00137,Graph process,Accuracy
228,1,Graph Classification,REDDIT-B,2018-10,GIN-0,92.4,100.0,92.4,1.0,92.4,0.93,ito:ITO_00137,Graph process,Accuracy
229,1,Node Classification,MS ACADEMIC,2018-10,APPNP,93.27,100.0,93.27,1.0,93.27,0.93,ito:ITO_00137,Graph process,Accuracy
230,1,Triple Classification,YAGO39K,2018-11,TransC (bern),93.8,100.0,93.8,1.0,93.8,0.94,ito:ITO_00137,Graph process,Accuracy
231,1,Node Classification,Cora: fixed 20 node per class,2019-03,LDS-GNN,84.1,99.88,84.1,1.0,84.2,0.84,ito:ITO_00137,Graph process,Accuracy
232,1,Node Classification,Cora: fixed 20 node per class,2020-03,DSGCN,84.2,100.0,0.1,0.0,84.2,0.84,ito:ITO_00137,Graph process,Accuracy
233,1,Graph Classification,Web,2019-04,UGraphEmb-F,45.03,100.0,45.03,1.0,45.03,0.45,ito:ITO_00137,Graph process,Accuracy
234,1,Graph Classification,HYDRIDES,2019-04,SPI-GCN,82.25,100.0,82.25,1.0,82.25,0.82,ito:ITO_00137,Graph process,Accuracy
235,1,Graph Classification,SYNTHIE,2019-04,SPI-GCN,71.0,100.0,71,1.0,71,0.71,ito:ITO_00137,Graph process,Accuracy
236,1,Graph Classification,COIL-RAG,2019-04,SPI-GCN,75.72,100.0,75.72,1.0,75.72,0.76,ito:ITO_00137,Graph process,Accuracy
237,1,Graph Classification,NC1,2019-04,EigenGCN-3,0.77,100.0,0.77,1.0,0.77,0.01,ito:ITO_00137,Graph process,Accuracy
238,1,Graph Classification,Citeseer,2019-05,sKNN-LDS,73.7,100.0,73.7,1.0,73.7,0.74,ito:ITO_00137,Graph process,Accuracy
239,1,Graph Classification,Wine,2019-05,sKNN-LDS,98.0,100.0,98,1.0,98,0.98,ito:ITO_00137,Graph process,Accuracy
240,1,Graph Classification,Cancer,2019-05,sKNN-LDS,95.7,100.0,95.7,1.0,95.7,0.96,ito:ITO_00137,Graph process,Accuracy
241,1,Graph Classification,Cora,2019-05,sKNN-LDS,72.3,100.0,72.3,1.0,72.3,0.72,ito:ITO_00137,Graph process,Accuracy
242,1,Graph Classification,Digits,2019-05,sKNN-LDS,92.5,100.0,92.5,1.0,92.5,0.93,ito:ITO_00137,Graph process,Accuracy
243,1,Graph Classification,20NEWS,2019-05,sKNN-LDS,47.9,100.0,47.9,1.0,47.9,0.48,ito:ITO_00137,Graph process,Accuracy
244,1,Link Sign Prediction,Epinions,2019-06,SiGAT,0.9293,100.0,0.9293,1.0,0.9293,0.01,ito:ITO_00137,Graph process,Accuracy
245,1,Link Sign Prediction,Bitcoin-Alpha,2019-06,SiGAT,0.948,100.0,0.948,1.0,0.948,0.01,ito:ITO_00137,Graph process,Accuracy
246,1,Link Sign Prediction,Slashdot,2019-06,SiGAT,0.8482,100.0,0.8482,1.0,0.8482,0.01,ito:ITO_00137,Graph process,Accuracy
247,1,Graph Classification,HIV-fMRI-77,2019-07,IsoNN,73.4,100.0,73.4,1.0,73.4,0.74,ito:ITO_00137,Graph process,Accuracy
248,1,Node Classification,Coauthor CS,2019-09,GraphMix,91.83,96.87,91.83,0.97,94.8,0.92,ito:ITO_00137,Graph process,Accuracy
249,1,Node Classification,Coauthor CS,2019-10,GCN (PPR Diffusion),93.01,98.11,1.2,0.01,94.8,0.93,ito:ITO_00137,Graph process,Accuracy
250,1,Node Classification,Coauthor CS,2020-02,GCN-LPA,94.8,100.0,1.8,0.02,94.8,0.95,ito:ITO_00137,Graph process,Accuracy
251,1,Face Age Editing,Face Age Editing,2019-09,GraphMix,91.83,96.87,91.83,0.97,94.8,0.92,ito:ITO_00137,Graph process,Accuracy
252,1,Face Age Editing,Face Age Editing,2019-10,GCN (PPR Diffusion),93.01,98.11,1.2,0.01,94.8,0.93,ito:ITO_00137,Graph process,Accuracy
253,1,Face Age Editing,Face Age Editing,2020-02,GCN-LPA,94.8,100.0,1.8,0.02,94.8,0.95,ito:ITO_00137,Graph process,Accuracy
254,1,Graph Classification,REDDIT-MULTI-5k,2019-09,U2GNN (Unsupervised),77.25,100.0,77.25,1.0,77.25,0.77,ito:ITO_00137,Graph process,Accuracy
255,1,Graph Classification,5pt. Bench-Easy,2019-10,NDP,97.9,100.0,97.9,1.0,97.9,0.98,ito:ITO_00137,Graph process,Accuracy
256,1,Graph Classification,Mutagenicity,2019-10,NDP,78.1,95.07,78.1,0.95,82.15,0.78,ito:ITO_00137,Graph process,Accuracy
257,1,Graph Classification,Mutagenicity,2019-11,HGP-SL,82.15,100.0,4.1,0.05,82.15,0.82,ito:ITO_00137,Graph process,Accuracy
258,1,Graph Classification,Bench-hard,2019-10,NDP,72.6,100.0,72.6,1.0,72.6,0.73,ito:ITO_00137,Graph process,Accuracy
259,1,Link Prediction,PPI,2019-10,HGCN,84.5,100.0,84.5,1.0,84.5,0.85,ito:ITO_00137,Graph process,Accuracy
260,1,Node Classification,AMZ Comp,2019-10,GCN (Heat Diffusion),86.77,100.0,86.77,1.0,86.77,0.87,ito:ITO_00137,Graph process,Accuracy
261,1,End-To-End Dialogue Modelling,End-To-End Dialogue Modelling,2019-10,GCN (Heat Diffusion),86.77,100.0,86.77,1.0,86.77,0.87,ito:ITO_00137,Graph process,Accuracy
262,1,Node Classification,AMZ Photo,2019-10,JK (Heat Diffusion),92.93,100.0,92.93,1.0,92.93,0.93,ito:ITO_00137,Graph process,Accuracy
263,1,Node Classification,Coauthor Phy,2020-02,GCN-LPA,96.9,100.0,96.9,1.0,96.9,0.97,ito:ITO_00137,Graph process,Accuracy
0,1,Graph Classification,HIV-DTI-77,2012-12,CNN,55.7,81.55,55.7,0.82,68.3,0.56,ito:ITO_00137,Graph process,F1
1,1,Graph Classification,HIV-DTI-77,2016-06,SDBN,65.6,96.05,9.9,0.14,68.3,0.66,ito:ITO_00137,Graph process,F1
2,1,Graph Classification,HIV-DTI-77,2019-07,IsoNN,68.3,100.0,2.7,0.04,68.3,0.69,ito:ITO_00137,Graph process,F1
3,1,Graph Classification,BP-fMRI-97,2012-12,CNN,52.8,75.75,52.8,0.76,69.7,0.53,ito:ITO_00137,Graph process,F1
4,1,Graph Classification,BP-fMRI-97,2016-06,SDBN,63.7,91.39,10.9,0.16,69.7,0.64,ito:ITO_00137,Graph process,F1
5,1,Graph Classification,BP-fMRI-97,2019-07,IsoNN,69.7,100.0,6.0,0.09,69.7,0.7,ito:ITO_00137,Graph process,F1
6,1,Graph Classification,HIV-fMRI-77 ,2012-12,CNN,66.3,91.83,66.3,0.92,72.2,0.67,ito:ITO_00137,Graph process,F1
7,1,Graph Classification,HIV-fMRI-77 ,2016-06,SDBN,66.7,92.38,0.4,0.01,72.2,0.67,ito:ITO_00137,Graph process,F1
8,1,Graph Classification,HIV-fMRI-77 ,2019-07,IsoNN,72.2,100.0,5.5,0.08,72.2,0.73,ito:ITO_00137,Graph process,F1
9,1,Node Classification,PPI,2017-06,GraphSAGE,61.2,61.51,61.2,0.62,99.5,0.62,ito:ITO_00137,Graph process,F1
10,1,Node Classification,PPI,2017-10,GAT,97.3,97.79,36.1,0.36,99.5,0.98,ito:ITO_00137,Graph process,F1
11,1,Node Classification,PPI,2018-03,GaAN,98.7,99.2,1.4,0.01,99.5,0.99,ito:ITO_00137,Graph process,F1
12,1,Node Classification,PPI,2019-05,Cluster-GCN,99.36,99.86,0.7,0.01,99.5,1.0,ito:ITO_00137,Graph process,F1
13,1,Node Classification,PPI,2019-06,GraphStar,99.4,99.9,0.0,0.0,99.5,1.0,ito:ITO_00137,Graph process,F1
14,1,Node Classification,PPI,2019-07,GraphSAINT,99.5,100.0,0.1,0.0,99.5,1.0,ito:ITO_00137,Graph process,F1
15,1,3D Facial Landmark Localization,3D Facial Landmark Localization,2017-06,GraphSAGE,61.2,61.51,61.2,0.62,99.5,0.62,ito:ITO_00137,Graph process,F1
16,1,3D Facial Landmark Localization,3D Facial Landmark Localization,2017-10,GAT,97.3,97.79,36.1,0.36,99.5,0.98,ito:ITO_00137,Graph process,F1
17,1,3D Facial Landmark Localization,3D Facial Landmark Localization,2018-03,GaAN,98.7,99.2,1.4,0.01,99.5,0.99,ito:ITO_00137,Graph process,F1
18,1,3D Facial Landmark Localization,3D Facial Landmark Localization,2019-05,Cluster-GCN,99.36,99.86,0.7,0.01,99.5,1.0,ito:ITO_00137,Graph process,F1
19,1,3D Facial Landmark Localization,3D Facial Landmark Localization,2019-06,GraphStar,99.4,99.9,0.0,0.0,99.5,1.0,ito:ITO_00137,Graph process,F1
20,1,3D Facial Landmark Localization,3D Facial Landmark Localization,2019-07,GraphSAINT,99.5,100.0,0.1,0.0,99.5,1.0,ito:ITO_00137,Graph process,F1
21,1,Graph Clustering,Cora,2018-02,ARGE,61.9,100.0,61.9,1.0,61.9,0.62,ito:ITO_00137,Graph process,F1
22,1,Graph Clustering,Citeseer,2018-02,ARGE,54.6,100.0,54.6,1.0,54.6,0.55,ito:ITO_00137,Graph process,F1
23,1,Node Classification,Amazon2M,2019-05,Cluster-GCN,90.41,100.0,90.41,1.0,90.41,0.91,ito:ITO_00137,Graph process,F1
24,1,Node Classification,Pubmed,2019-05,ClusterGCN,79.9,100.0,79.9,1.0,79.9,0.8,ito:ITO_00137,Graph process,F1
25,1,Graph Classification,HIV-fMRI-77,2019-07,IsoNN,72.2,100.0,72.2,1.0,72.2,0.73,ito:ITO_00137,Graph process,F1
0,1,Link Prediction,FB15k,2013-12,TransE,0.471,51.53,0.471,0.52,0.914,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
1,1,Link Prediction,FB15k,2015-07,TransD,0.773,84.57,0.3,0.33,0.914,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
2,1,Link Prediction,FB15k,2017-02,Complex,0.84,91.9,0.1,0.11,0.914,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
3,1,Link Prediction,FB15k,2017-11,Rule-Guided Embedding,0.865,94.64,0.0,0.0,0.914,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
4,1,Link Prediction,FB15k,2018-06,ComplEx-N3 (reciprocal),0.91,99.56,0.0,0.0,0.914,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
5,1,Link Prediction,FB15k,2019-04,AutoKGE,0.914,100.0,0.0,0.0,0.914,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
6,1,Link Prediction,WN18RR,2013-12,TransE,0.5555,91.97,0.5555,0.92,0.604,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
7,1,Link Prediction,WN18RR,2018-06,ComplEx-N3 (reciprocal),0.57,94.37,0.0,0.0,0.604,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
8,1,Link Prediction,WN18RR,2018-08,M3GM,0.5902,97.72,0.0,0.0,0.604,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
9,1,Link Prediction,WN18RR,2019-12,GAATs,0.604,100.0,0.0,0.0,0.604,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
10,1,Link Prediction,WN18,2014-12,DistMult,0.936,97.1,0.936,0.97,0.964,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
11,1,Link Prediction,WN18,2015-10,HolE,0.949,98.44,0.0,0.0,0.964,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-10
12,1,Link Prediction,WN18,2017-07,Inverse Model,0.964,100.0,0.0,0.0,0.964,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-10
13,1,Link Prediction,YAGO3-10,2017-07,ConvE,0.62,87.08,0.62,0.87,0.712,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
14,1,Link Prediction,YAGO3-10,2018-06,ComplEx-N3 (reciprocal),0.71,99.72,0.1,0.14,0.712,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
15,1,Link Prediction,YAGO3-10,2020-05,RefE,0.712,100.0,0.0,0.0,0.712,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
16,1,Link Prediction,FB15k-237,2017-07,ConvE,0.501,77.08,0.501,0.77,0.65,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
17,1,Link Prediction,FB15k-237,2018-06,ComplEx-N3 (reciprocal),0.56,86.15,0.1,0.15,0.65,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
18,1,Link Prediction,FB15k-237,2018-08,CapsE,0.593,91.23,0.0,0.0,0.65,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
19,1,Link Prediction,FB15k-237,2019-06,KBAT,0.626,96.31,0.0,0.0,0.65,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
20,1,Link Prediction,FB15k-237,2019-12,GAATs,0.65,100.0,0.0,0.0,0.65,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
21,1,Link Prediction,YAGO37,2017-11,Rule-Guided Embedding,0.603,100.0,0.603,1.0,0.603,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
22,1,Link Prediction,AKSW-bib,2018-03,KG2Vec LSTM,0.1923,100.0,0.1923,1.0,0.1923,0.0,ito:ITO_00137,Graph process,Hits\\-at\\-10
23,1,Link Prediction,YAGO39K,2018-11,TransC (bern),0.698,100.0,0.698,1.0,0.698,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
24,1,Knowledge Graph Completion,DBbook2014,2019-02,KTUP (soft),60.75,100.0,60.75,1.0,60.75,0.97,ito:ITO_00137,Graph process,Hits\\-at\\-10
25,1,Knowledge Graph Completion,MovieLens 1M,2019-02,KTUP (soft),48.9,100.0,48.9,1.0,48.9,0.78,ito:ITO_00137,Graph process,Hits\\-at\\-10
26,1,Link Prediction,LiveJournal,2019-03,PBG (1 partition),0.857,100.0,0.857,1.0,0.857,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
27,1,Knowledge Graph Completion,WN18RR,2019-05,KBAT,0.581,100.0,0.581,1.0,0.581,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
28,1,Knowledge Graph Completion,FB15k-237,2019-05,KBAT,0.626,1.0,0.626,0.01,62.6,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
29,1,Knowledge Graph Completion,FB15k-237,2019-06,KBGAT,62.6,100.0,62.0,0.99,62.6,1.0,ito:ITO_00137,Graph process,Hits\\-at\\-10
30,1,Link Prediction,NELL-995,2019-08,Meta-KGR (ConvE),0.347,100.0,0.347,1.0,0.347,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-10
0,1,Link Prediction,WN18RR,2013-12,TransE,0.4226,75.46,0.4226,0.75,0.56,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
1,1,Link Prediction,WN18RR,2018-08,CapsE,0.56,100.0,0.1,0.18,0.56,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
2,1,Link Prediction,WN18,2014-12,DistMult,0.728,76.39,0.728,0.76,0.953,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-1
3,1,Link Prediction,WN18,2015-10,HolE,0.93,97.59,0.2,0.21,0.953,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-1
4,1,Link Prediction,WN18,2016-06,ComplEx,0.936,98.22,0.0,0.0,0.953,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-1
5,1,Link Prediction,WN18,2017-05,ANALOGY,0.939,98.53,0.0,0.0,0.953,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-1
6,1,Link Prediction,WN18,2017-07,Inverse Model,0.953,100.0,0.0,0.0,0.953,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-1
7,1,Link Prediction,FB15k,2015-10,HolE,0.402,50.25,0.402,0.5,0.8,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
8,1,Link Prediction,FB15k,2017-02,Complex,0.599,74.87,0.2,0.25,0.8,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
9,1,Link Prediction,FB15k,2017-07,Inverse Model,0.658,82.25,0.1,0.12,0.8,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
10,1,Link Prediction,FB15k,2017-11,Rule-Guided Embedding,0.703,87.87,0.0,0.0,0.8,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-1
11,1,Link Prediction,FB15k,2018-08,HypER,0.734,91.75,0.0,0.0,0.8,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-1
12,1,Link Prediction,FB15k,2019-01,TuckER,0.741,92.62,0.0,0.0,0.8,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-1
13,1,Link Prediction,FB15k,2019-02,pRotatE,0.75,93.75,0.0,0.0,0.8,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-1
14,1,Link Prediction,FB15k,2019-04,QuatE,0.8,100.0,0.1,0.12,0.8,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-1
15,1,Link Prediction,FB15k-237,2017-07,ConvE,0.237,46.29,0.237,0.46,0.512,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
16,1,Link Prediction,FB15k-237,2018-08,HypER,0.252,49.22,0.0,0.0,0.512,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
17,1,Link Prediction,FB15k-237,2018-11,Structure-Aware Convolutional Networks,0.26,50.78,0.0,0.0,0.512,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
18,1,Link Prediction,FB15k-237,2019-01,TuckER,0.266,51.95,0.0,0.0,0.512,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
19,1,Link Prediction,FB15k-237,2019-06,KBAT,0.46,89.84,0.2,0.39,0.512,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
20,1,Link Prediction,FB15k-237,2019-12,GAATs,0.512,100.0,0.1,0.2,0.512,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
21,1,Link Prediction,YAGO37,2017-11,Rule-Guided Embedding,0.34,100.0,0.34,1.0,0.34,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
22,1,Link Prediction,AKSW-bib,2018-03,KG2Vec LSTM,0.0384,100.0,0.0384,1.0,0.0384,0.0,ito:ITO_00137,Graph process,Hits\\-at\\-1
23,1,Link Prediction,YAGO39K,2018-11,TransC (bern),0.298,100.0,0.298,1.0,0.298,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
24,1,Knowledge Graph Completion,WN18RR,2019-05,KBAT,0.361,100.0,0.361,1.0,0.361,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
25,1,Knowledge Graph Completion,FB15k-237,2019-05,KBAT,0.46,1.0,0.46,0.01,46.0,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
26,1,Knowledge Graph Completion,FB15k-237,2019-06,KBAT,46.0,100.0,45.5,0.99,46.0,1.0,ito:ITO_00137,Graph process,Hits\\-at\\-1
27,1,Link Prediction,YAGO3-10,2019-06,DihEdral,0.381,75.75,0.381,0.76,0.503,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
28,1,Link Prediction,YAGO3-10,2019-11,InteractE,0.462,91.85,0.1,0.2,0.503,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
29,1,Link Prediction,YAGO3-10,2020-05,RefE,0.503,100.0,0.0,0.0,0.503,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-1
30,1,Link Prediction,NELL-995,2019-08,Meta-KGR (ConvE),0.197,100.0,0.197,1.0,0.197,0.0,ito:ITO_00137,Graph process,Hits\\-at\\-1
0,1,Link Prediction,WN18RR,2013-12,TransE,0.4659,93.5,0.4659,0.93,0.4983,0.48,ito:ITO_00137,Graph process,MRR
1,1,Link Prediction,WN18RR,2018-06,ComplEx-N3 (reciprocal),0.48,96.33,0.0,0.0,0.4983,0.5,ito:ITO_00137,Graph process,MRR
2,1,Link Prediction,WN18RR,2018-08,M3GM,0.4983,100.0,0.0,0.0,0.4983,0.52,ito:ITO_00137,Graph process,MRR
3,1,Link Prediction,WN18,2014-12,DistMult,0.822,85.36,0.822,0.85,0.963,0.85,ito:ITO_00137,Graph process,MRR
4,1,Link Prediction,WN18,2016-06,ComplEx,0.941,97.72,0.1,0.1,0.963,0.98,ito:ITO_00137,Graph process,MRR
5,1,Link Prediction,WN18,2017-05,ANALOGY,0.942,97.82,0.0,0.0,0.963,0.98,ito:ITO_00137,Graph process,MRR
6,1,Link Prediction,WN18,2017-07,Inverse Model,0.963,100.0,0.0,0.0,0.963,1.0,ito:ITO_00137,Graph process,MRR
7,1,Knowledge Graphs,FB15k,2017-02,COMPLEX,0.587,100.0,0.587,1.0,0.587,0.61,ito:ITO_00137,Graph process,MRR
8,1,Link Prediction,FB15k,2017-02,Complex,0.692,80.37,0.692,0.8,0.861,0.72,ito:ITO_00137,Graph process,MRR
9,1,Link Prediction,FB15k,2017-11,Rule-Guided Embedding,0.768,89.2,0.1,0.12,0.861,0.8,ito:ITO_00137,Graph process,MRR
10,1,Link Prediction,FB15k,2018-06,ComplEx-N3 (reciprocal),0.86,99.88,0.1,0.12,0.861,0.89,ito:ITO_00137,Graph process,MRR
11,1,Link Prediction,FB15k,2019-04,AutoKGE,0.861,100.0,0.0,0.0,0.861,0.89,ito:ITO_00137,Graph process,MRR
12,1,Knowledge graph process,FB15k,2017-02,COMPLEX,0.587,100.0,0.587,1.0,0.587,0.61,ito:ITO_00137,Graph process,MRR
13,1,Link Prediction,FB15k-237,2017-07,ConvE,0.325,38.64,0.325,0.39,0.841,0.34,ito:ITO_00137,Graph process,MRR
14,1,Link Prediction,FB15k-237,2018-06,ComplEx-N3 (reciprocal),0.37,44.0,0.0,0.0,0.841,0.38,ito:ITO_00137,Graph process,MRR
15,1,Link Prediction,FB15k-237,2018-08,CapsE,0.523,62.19,0.2,0.24,0.841,0.54,ito:ITO_00137,Graph process,MRR
16,1,Link Prediction,FB15k-237,2019-07,DistMult (after variational EM),0.841,100.0,0.3,0.36,0.841,0.87,ito:ITO_00137,Graph process,MRR
17,1,Link Prediction,YAGO3-10,2017-07,ConvE,0.44,75.86,0.44,0.76,0.58,0.46,ito:ITO_00137,Graph process,MRR
18,1,Link Prediction,YAGO3-10,2018-06,ComplEx-N3 (reciprocal),0.58,100.0,0.1,0.17,0.58,0.6,ito:ITO_00137,Graph process,MRR
19,1,Link Prediction,YAGO37,2017-11,Rule-Guided Embedding,0.431,100.0,0.431,1.0,0.431,0.45,ito:ITO_00137,Graph process,MRR
20,1,Link Prediction,YAGO39K,2018-11,TransC (bern),0.42,100.0,0.42,1.0,0.42,0.44,ito:ITO_00137,Graph process,MRR
21,1,Link Prediction,LiveJournal,2019-03,PyTorch BigGraph,0.749,100.0,0.749,1.0,0.749,0.78,ito:ITO_00137,Graph process,MRR
22,1,Knowledge Graph Completion,FB15k-237,2019-05,KBAT,0.518,100.0,0.518,1.0,0.518,0.54,ito:ITO_00137,Graph process,MRR
23,1,Link Prediction,NELL-995,2019-08,Meta-KGR (ConvE),0.253,100.0,0.253,1.0,0.253,0.26,ito:ITO_00137,Graph process,MRR
24,1,Link Prediction,ICEWS05-15,2020-04,TNTComplEx (x10),0.67,100.0,0.67,1.0,0.67,0.7,ito:ITO_00137,Graph process,MRR
25,1,Link Prediction,ICEWS14,2020-04,TNTComplEx (x10),0.62,100.0,0.62,1.0,0.62,0.64,ito:ITO_00137,Graph process,MRR
26,1,Link Prediction,YAGO15k,2020-04,TNTComplEx (x10),0.37,100.0,0.37,1.0,0.37,0.38,ito:ITO_00137,Graph process,MRR
0,1,Link Prediction,FB15k,2013-12,TransE,125.0,5.0,125.0,0.05,2501.0,0.01,ito:ITO_00137,Graph process,MR
1,1,Link Prediction,FB15k,2017-07,Inverse Model,2501.0,100.0,2376.0,0.95,2501.0,0.18,ito:ITO_00137,Graph process,MR
2,1,Link Prediction,WN18,2014-12,DistMult,902.0,84.14,902,0.84,1072,0.07,ito:ITO_00137,Graph process,MR
3,1,Link Prediction,WN18,2018-12,ComplEx NSCaching,1072.0,100.0,170,0.16,1072,0.08,ito:ITO_00137,Graph process,MR
4,1,Link Prediction,FB15k-237,2017-07,Inverse Model,7030.0,100.0,7030,1.0,7030,0.52,ito:ITO_00137,Graph process,MR
5,1,Link Prediction,WN18RR,2017-07,Inverse Model,13526.0,100.0,13526,1.0,13526,1.0,ito:ITO_00137,Graph process,MR
6,1,Link Prediction,LiveJournal,2019-03,PBG (1 partition),245.9,100.0,245.9,1.0,245.9,0.02,ito:ITO_00137,Graph process,MR
7,1,Knowledge Graph Completion,FB15k-237,2019-05,KBAT,0.21,100.0,0.21,1.0,0.21,0.0,ito:ITO_00137,Graph process,MR
0,1,Link Property Prediction,ogbl-ddi,2014-03,DeepWalk,1543913.0,100.0,1543913,1.0,1543913,0.0,ito:ITO_00137,Graph process,Number\\ of\\ params
1,1,Link Property Prediction,ogbl-ppa,2014-03,DeepWalk,150138741.0,100.0,150138741,1.0,150138741,0.12,ito:ITO_00137,Graph process,Number\\ of\\ params
2,1,Link Property Prediction,ogbl-collab,2014-03,DeepWalk,61390187.0,100.0,61390187,1.0,61390187,0.05,ito:ITO_00137,Graph process,Number\\ of\\ params
3,1,Link Property Prediction,ogbl-biokg,2014-12,DistMult,187648000.0,100.0,187648000,1.0,187648000,0.15,ito:ITO_00137,Graph process,Number\\ of\\ params
4,1,Link Property Prediction,ogbl-wikikg2,2014-12,DistMult (500dim),1250569500.0,100.0,1250569500,1.0,1250569500,1.0,ito:ITO_00137,Graph process,Number\\ of\\ params
5,1,Graph Property Prediction,ogbg-molpcba,2016-06,ChebNet,1475003.0,43.71,1475003,0.44,3374533,0.0,ito:ITO_00137,Graph process,Number\\ of\\ params
6,1,Graph Property Prediction,ogbg-molpcba,2016-09,GCN+virtual node,2017028.0,59.77,542025,0.16,3374533,0.0,ito:ITO_00137,Graph process,Number\\ of\\ params
7,1,Graph Property Prediction,ogbg-molpcba,2018-10,GIN+virtual node,3374533.0,100.0,1357505,0.4,3374533,0.0,ito:ITO_00137,Graph process,Number\\ of\\ params
8,1,Link Property Prediction,ogbl-citation2,2016-07,Node2vec,374911105.0,100.0,374911105,1.0,374911105,0.3,ito:ITO_00137,Graph process,Number\\ of\\ params
9,1,Graph Property Prediction,ogbg-molhiv,2016-09,GCN+virtual node,1978801.0,43.02,1978801,0.43,4600000,0.0,ito:ITO_00137,Graph process,Number\\ of\\ params
10,1,Graph Property Prediction,ogbg-molhiv,2018-10,GIN+virtual node,3336306.0,72.53,1357505,0.3,4600000,0.0,ito:ITO_00137,Graph process,Number\\ of\\ params
11,1,Graph Property Prediction,ogbg-molhiv,2019-06,P-WL,4600000.0,100.0,1263694,0.27,4600000,0.0,ito:ITO_00137,Graph process,Number\\ of\\ params
12,1,Graph Property Prediction,ogbg-code2,2016-09,GCN+virtual node,12484310.0,90.19,12484310,0.9,13841815,0.01,ito:ITO_00137,Graph process,Number\\ of\\ params
13,1,Graph Property Prediction,ogbg-code2,2018-10,GIN+virtual node,13841815.0,100.0,1357505,0.1,13841815,0.01,ito:ITO_00137,Graph process,Number\\ of\\ params
14,1,Graph Property Prediction,ogbg-ppa,2016-09,GCN,479437.0,14.58,479437,0.15,3288042,0.0,ito:ITO_00137,Graph process,Number\\ of\\ params
15,1,Graph Property Prediction,ogbg-ppa,2016-09,GCN+virtual node,1930537.0,58.71,1451100,0.44,3288042,0.0,ito:ITO_00137,Graph process,Number\\ of\\ params
16,1,Graph Property Prediction,ogbg-ppa,2018-10,GIN+virtual node,3288042.0,100.0,1357505,0.41,3288042,0.0,ito:ITO_00137,Graph process,Number\\ of\\ params
0,1,Node Classification,Wikipedia,2014-03,DeepWalk,0.183,94.33,0.183,0.94,0.194,0.22,ito:ITO_00137,Graph process,Macro\\-F1
1,1,Node Classification,Wikipedia,2017-04,Struc2vec,0.19,97.94,0.0,0.0,0.194,0.22,ito:ITO_00137,Graph process,Macro\\-F1
2,1,Node Classification,Wikipedia,2017-11,GraphGAN,0.194,100.0,0.0,0.0,0.194,0.23,ito:ITO_00137,Graph process,Macro\\-F1
3,1,Node Classification,BlogCatalog,2014-03,DeepWalk,0.214,69.19,0.214,0.69,0.3093,0.25,ito:ITO_00137,Graph process,Macro\\-F1
4,1,Node Classification,BlogCatalog,2015-10,GraRep,0.3093,100.0,0.1,0.32,0.3093,0.37,ito:ITO_00137,Graph process,Macro\\-F1
5,1,Spoken language identification,Spoken language identification,2014-03,DeepWalk,0.214,69.19,0.214,0.69,0.3093,0.25,ito:ITO_00137,Graph process,Macro\\-F1
6,1,Spoken language identification,Spoken language identification,2015-10,GraRep,0.3093,100.0,0.1,0.32,0.3093,0.37,ito:ITO_00137,Graph process,Macro\\-F1
7,1,Link Sign Prediction,Bitcoin-Alpha,2019-06,SiGAT,0.7138,100.0,0.7138,1.0,0.7138,0.84,ito:ITO_00137,Graph process,Macro\\-F1
8,1,Link Sign Prediction,Slashdot,2019-06,SiGAT,0.766,100.0,0.766,1.0,0.766,0.91,ito:ITO_00137,Graph process,Macro\\-F1
9,1,Link Sign Prediction,Epinions,2019-06,SiGAT,0.8449,100.0,0.8449,1.0,0.8449,1.0,ito:ITO_00137,Graph process,Macro\\-F1
0,1,Link Prediction,WN18,2014-12,DistMult,0.914,94.81,0.914,0.95,0.964,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-3
1,1,Link Prediction,WN18,2015-10,HolE,0.945,98.03,0.0,0.0,0.964,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-3
2,1,Link Prediction,WN18,2017-07,Inverse Model,0.964,100.0,0.0,0.0,0.964,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-3
3,1,Link Prediction,FB15k,2015-10,HolE,0.613,71.36,0.613,0.71,0.859,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
4,1,Link Prediction,FB15k,2017-02,Complex,0.759,88.36,0.1,0.12,0.859,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
5,1,Link Prediction,FB15k,2017-11,Rule-Guided Embedding,0.815,94.88,0.1,0.12,0.859,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-3
6,1,Link Prediction,FB15k,2018-08,HypER,0.829,96.51,0.0,0.0,0.859,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-3
7,1,Link Prediction,FB15k,2019-01,TuckER,0.833,96.97,0.0,0.0,0.859,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-3
8,1,Link Prediction,FB15k,2019-04,QuatE,0.859,100.0,0.0,0.0,0.859,0.02,ito:ITO_00137,Graph process,Hits\\-at\\-3
9,1,Link Prediction,FB15k-237,2017-07,ConvE,0.356,62.24,0.356,0.62,0.572,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
10,1,Link Prediction,FB15k-237,2018-08,HypER,0.376,65.73,0.0,0.0,0.572,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
11,1,Link Prediction,FB15k-237,2018-11,Structure-Aware Convolutional Networks,0.39,68.18,0.0,0.0,0.572,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
12,1,Link Prediction,FB15k-237,2019-01,TuckER,0.394,68.88,0.0,0.0,0.572,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
13,1,Link Prediction,FB15k-237,2019-06,KBAT,0.54,94.41,0.1,0.17,0.572,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
14,1,Link Prediction,FB15k-237,2019-12,GAATs,0.572,100.0,0.0,0.0,0.572,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
15,1,Link Prediction,WN18RR,2017-07,ConvE,0.44,83.81,0.44,0.84,0.525,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
16,1,Link Prediction,WN18RR,2018-02,M-Walk,0.445,84.76,0.0,0.0,0.525,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
17,1,Link Prediction,WN18RR,2018-08,HypER,0.477,90.86,0.0,0.0,0.525,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
18,1,Link Prediction,WN18RR,2018-11,Structure-Aware Convolutional Networks,0.48,91.43,0.0,0.0,0.525,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
19,1,Link Prediction,WN18RR,2019-01,TuckER,0.482,91.81,0.0,0.0,0.525,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
20,1,Link Prediction,WN18RR,2019-02,RotatE,0.492,93.71,0.0,0.0,0.525,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
21,1,Link Prediction,WN18RR,2019-03,RotatE,0.508,96.76,0.0,0.0,0.525,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
22,1,Link Prediction,WN18RR,2019-11,GC-OTE,0.511,97.33,0.0,0.0,0.525,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
23,1,Link Prediction,WN18RR,2019-12,GAATs,0.525,100.0,0.0,0.0,0.525,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
24,1,Link Prediction,YAGO37,2017-11,Rule-Guided Embedding,0.482,100.0,0.482,1.0,0.482,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
25,1,Link Prediction,AKSW-bib,2018-03,KG2Vec LSTM,0.0979,100.0,0.0979,1.0,0.0979,0.0,ito:ITO_00137,Graph process,Hits\\-at\\-3
26,1,Link Prediction,YAGO39K,2018-11,TransC (bern),0.502,100.0,0.502,1.0,0.502,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
27,1,Knowledge Graph Completion,WN18RR,2019-05,KBAT,0.483,93.6,0.483,0.94,0.516,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
28,1,Knowledge Graph Completion,WN18RR,2019-11,HAKE,0.516,100.0,0.0,0.0,0.516,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
29,1,Knowledge Graph Completion,FB15k-237,2019-05,KBAT,0.54,1.0,0.54,0.01,54.0,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
30,1,Knowledge Graph Completion,FB15k-237,2019-06,KBGAT,54.0,100.0,53.5,0.99,54.0,1.0,ito:ITO_00137,Graph process,Hits\\-at\\-3
31,1,Link Prediction,YAGO3-10,2019-06,DihEdral,0.523,84.22,0.523,0.84,0.621,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
32,1,Link Prediction,YAGO3-10,2019-11,HAKE,0.596,95.97,0.1,0.16,0.621,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
33,1,Link Prediction,YAGO3-10,2020-05,RefE,0.621,100.0,0.0,0.0,0.621,0.01,ito:ITO_00137,Graph process,Hits\\-at\\-3
0,1,Graph Regression,Lipophilicity ,2015-09,GC,0.655,65.63,0.655,0.66,0.998,0.0,ito:ITO_00137,Graph process,RMSE
1,1,Graph Regression,Lipophilicity ,2016-03,Weave,0.715,71.64,0.1,0.1,0.998,0.0,ito:ITO_00137,Graph process,RMSE
2,1,Graph Regression,Lipophilicity ,2017-04,MPNN,0.719,72.04,0.0,0.0,0.998,0.0,ito:ITO_00137,Graph process,RMSE
3,1,Graph Regression,Lipophilicity ,2017-10,GAT,0.95,95.19,0.2,0.2,0.998,0.0,ito:ITO_00137,Graph process,RMSE
4,1,Graph Regression,Lipophilicity ,2018-03,AGNN,0.963,96.49,0.0,0.0,0.998,0.0,ito:ITO_00137,Graph process,RMSE
5,1,Graph Regression,Lipophilicity ,2019-02,SGC,0.998,100.0,0.0,0.0,0.998,0.0,ito:ITO_00137,Graph process,RMSE
6,1,Graph Regression,Lipophilicity,2019-02,SGC,0.998,100.0,0.998,1.0,0.998,0.0,ito:ITO_00137,Graph process,RMSE
7,1,Stereo-LiDAR Fusion,KITTI Depth Completion Validation,2019-08,GuideNet,777.78,100.0,777.78,1.0,777.78,1.0,ito:ITO_00137,Graph process,RMSE
0,1,Anomaly Detection in Edge Streams,Darpa,2016-05,RHSS,0.17,17.89,0.17,0.18,0.95,0.0,ito:ITO_00137,Graph process,AUC
1,1,Anomaly Detection in Edge Streams,Darpa,2018-11,SedanSpot,0.643,67.68,0.5,0.53,0.95,0.01,ito:ITO_00137,Graph process,AUC
2,1,Anomaly Detection in Edge Streams,Darpa,2019-11,MIDAS,0.95,100.0,0.3,0.32,0.95,0.01,ito:ITO_00137,Graph process,AUC
3,1,Link Prediction,Citeseer,2018-02,ARGE,91.9,93.37,91.9,0.93,98.43,0.93,ito:ITO_00137,Graph process,AUC
4,1,Link Prediction,Citeseer,2018-04,S-VGAE,94.7,96.21,2.8,0.03,98.43,0.96,ito:ITO_00137,Graph process,AUC
5,1,Link Prediction,Citeseer,2018-09,SCAT,97.27,98.82,2.6,0.03,98.43,0.98,ito:ITO_00137,Graph process,AUC
6,1,Link Prediction,Citeseer,2019-06,GraphStar,97.47,99.02,0.2,0.0,98.43,0.99,ito:ITO_00137,Graph process,AUC
7,1,Link Prediction,Citeseer,2019-12,GLACE,98.43,100.0,1.0,0.01,98.43,1.0,ito:ITO_00137,Graph process,AUC
8,1,Link Prediction,Cora,2018-02,ARGE,92.4,93.71,92.4,0.94,98.6,0.93,ito:ITO_00137,Graph process,AUC
9,1,Link Prediction,Cora,2018-04,S-VGAE,94.1,95.44,1.7,0.02,98.6,0.95,ito:ITO_00137,Graph process,AUC
10,1,Link Prediction,Cora,2018-09,SCAT,94.48,95.82,0.4,0.0,98.6,0.96,ito:ITO_00137,Graph process,AUC
11,1,Link Prediction,Cora,2019-06,GraphStar,95.65,97.01,1.2,0.01,98.6,0.97,ito:ITO_00137,Graph process,AUC
12,1,Link Prediction,Cora,2019-12,GLACE,98.6,100.0,2.9,0.03,98.6,1.0,ito:ITO_00137,Graph process,AUC
13,1,Link Prediction,Pubmed,2018-02,ARGE,96.8,98.96,96.8,0.99,97.82,0.98,ito:ITO_00137,Graph process,AUC
14,1,Link Prediction,Pubmed,2018-09,SCAT,97.52,99.69,0.7,0.01,97.82,0.99,ito:ITO_00137,Graph process,AUC
15,1,Link Prediction,Pubmed,2019-06,GraphStar,97.67,99.85,0.2,0.0,97.82,0.99,ito:ITO_00137,Graph process,AUC
16,1,Link Prediction,Pubmed,2019-12,GLACE,97.82,100.0,0.1,0.0,97.82,0.99,ito:ITO_00137,Graph process,AUC
17,1,Link Sign Prediction,Epinions,2018-08,SGCN-2,0.864,92.57,0.864,0.93,0.9333,0.01,ito:ITO_00137,Graph process,AUC
18,1,Link Sign Prediction,Epinions,2019-06,SiGAT,0.9333,100.0,0.1,0.11,0.9333,0.01,ito:ITO_00137,Graph process,AUC
19,1,Link Sign Prediction,Bitcoin-OTC,2018-08,SGCN-2,0.823,100.0,0.823,1.0,0.823,0.01,ito:ITO_00137,Graph process,AUC
20,1,Link Sign Prediction,Slashdot,2018-08,SGCN-2,0.804,90.7,0.804,0.91,0.8864,0.01,ito:ITO_00137,Graph process,AUC
21,1,Link Sign Prediction,Slashdot,2019-06,SiGAT,0.8864,100.0,0.1,0.11,0.8864,0.01,ito:ITO_00137,Graph process,AUC
22,1,Link Sign Prediction,Bitcoin-Alpha,2018-08,SGCN-2,0.796,89.02,0.796,0.89,0.8942,0.01,ito:ITO_00137,Graph process,AUC
23,1,Link Sign Prediction,Bitcoin-Alpha,2019-06,SiGAT,0.8942,100.0,0.1,0.11,0.8942,0.01,ito:ITO_00137,Graph process,AUC
24,1,Link Prediction,Wiki,2018-10,BANE,90.9,100.0,90.9,1.0,90.9,0.92,ito:ITO_00137,Graph process,AUC
25,1,Node Classification,Wiki,2018-10,DANMF,41.12,100.0,41.12,1.0,41.12,0.42,ito:ITO_00137,Graph process,AUC
26,1,Micro-Expression Recognition,Micro-Expression Recognition,2018-10,DANMF,41.12,100.0,41.12,1.0,41.12,0.42,ito:ITO_00137,Graph process,AUC
27,1,Link Prediction,Cit-HepPH,2018-11,Asymmetric Transitivity Preservation,89.16,100.0,89.16,1.0,89.16,0.9,ito:ITO_00137,Graph process,AUC
28,1,Link Prediction,Wiki-Vote,2018-11,Asymmetric Transitivity Preservation,94.81,100.0,94.81,1.0,94.81,0.96,ito:ITO_00137,Graph process,AUC
29,1,Link Prediction,Gnutella,2018-11,Asymmetric Transitivity Preservation,93.14,100.0,93.14,1.0,93.14,0.94,ito:ITO_00137,Graph process,AUC
30,1,Link Prediction,DBLP,2019-01,Event2vec,90.1,91.43,90.1,0.91,98.55,0.91,ito:ITO_00137,Graph process,AUC
31,1,Link Prediction,DBLP,2019-12,GLACE,98.55,100.0,8.5,0.09,98.55,1.0,ito:ITO_00137,Graph process,AUC
32,1,Link Prediction,Douban,2019-01,Event2vec,82.3,97.74,82.3,0.98,84.2,0.83,ito:ITO_00137,Graph process,AUC
33,1,Link Prediction,Douban,2019-02,HSRL (DW),84.2,100.0,1.9,0.02,84.2,0.85,ito:ITO_00137,Graph process,AUC
34,1,Link Prediction,IMDb,2019-01,Event2vec,89.4,100.0,89.4,1.0,89.4,0.9,ito:ITO_00137,Graph process,AUC
35,1,Link Prediction,Yelp,2019-01,Event2vec,86.2,95.67,86.2,0.96,90.1,0.87,ito:ITO_00137,Graph process,AUC
36,1,Link Prediction,Yelp,2019-02,HSRL (DW),90.1,100.0,3.9,0.04,90.1,0.91,ito:ITO_00137,Graph process,AUC
37,1,Link Prediction,MIT,2019-02,HSRL (DW),92.6,100.0,92.6,1.0,92.6,0.94,ito:ITO_00137,Graph process,AUC
38,1,Band Gap,OQMD v1.2,2019-05,CGNN Ensemble,0.9713,100.0,0.9713,1.0,0.9713,0.01,ito:ITO_00137,Graph process,AUC
39,1,Total Magnetization,OQMD v1.2,2019-05,CGNN Ensemble,0.9569,100.0,0.9569,1.0,0.9569,0.01,ito:ITO_00137,Graph process,AUC
40,1,Link Prediction,ACM,2019-12,GLACE,98.34,100.0,98.34,1.0,98.34,0.99,ito:ITO_00137,Graph process,AUC
41,1,Link Prediction,Last.FM,2020-02,MAGNN,98.91,100.0,98.91,1.0,98.91,1.0,ito:ITO_00137,Graph process,AUC
0,1,Node Classification,PATTERN 100k,2016-09,GCN,65.88,76.97,65.88,0.77,85.59,0.77,ito:ITO_00137,Graph process,Accuracy\\ \\(%\\)
1,1,Node Classification,PATTERN 100k,2016-11,MoNet,85.482,99.87,19.6,0.23,85.59,1.0,ito:ITO_00137,Graph process,Accuracy\\ \\(%\\)
2,1,Node Classification,PATTERN 100k,2018-10,GIN,85.59,100.0,0.1,0.0,85.59,1.0,ito:ITO_00137,Graph process,Accuracy\\ \\(%\\)
3,1,Graph Classification,CIFAR10 100k,2016-09,GCN,54.46,82.42,54.46,0.82,66.08,0.64,ito:ITO_00137,Graph process,Accuracy\\ \\(%\\)
4,1,Graph Classification,CIFAR10 100k,2017-06,GraphSage,66.08,100.0,11.6,0.18,66.08,0.77,ito:ITO_00137,Graph process,Accuracy\\ \\(%\\)
0,1,Graph Regression,ZINC 100k,2016-09,GCN,0.469,100.0,0.469,1.0,0.469,0.01,ito:ITO_00137,Graph process,MAE
1,1,Graph Regression,ZINC-500k,2016-09,GCN,0.367,69.77,0.367,0.7,0.526,0.01,ito:ITO_00137,Graph process,MAE
2,1,Graph Regression,ZINC-500k,2017-06,GraphSage,0.398,75.67,0.0,0.0,0.526,0.01,ito:ITO_00137,Graph process,MAE
3,1,Graph Regression,ZINC-500k,2018-10,GIN,0.526,100.0,0.1,0.19,0.526,0.01,ito:ITO_00137,Graph process,MAE
4,1,Formation Energy,QM9,2017-02,HDAD+KRR,0.58,100.0,0.58,1.0,0.58,0.01,ito:ITO_00137,Graph process,MAE
5,1,Formation Energy,Materials Project,2017-10,CGCNN,39.0,95.12,39.0,0.95,41.0,0.95,ito:ITO_00137,Graph process,MAE
6,1,Formation Energy,Materials Project,2018-11,MT-CGCNN,41.0,100.0,2.0,0.05,41.0,1.0,ito:ITO_00137,Graph process,MAE
7,1,Band Gap,Materials Project,2017-10,CGCNN,0.388,100.0,0.388,1.0,0.388,0.01,ito:ITO_00137,Graph process,MAE
8,1,Formation Energy,OQMD v1.2,2019-05,CGNN Ensemble,30.5,85.43,30.5,0.85,35.7,0.74,ito:ITO_00137,Graph process,MAE
9,1,Formation Energy,OQMD v1.2,2019-05,CGNN-192,34.6,96.92,4.1,0.11,35.7,0.84,ito:ITO_00137,Graph process,MAE
10,1,Formation Energy,OQMD v1.2,2019-05,CGNN-160,35.1,98.32,0.5,0.01,35.7,0.86,ito:ITO_00137,Graph process,MAE
11,1,Formation Energy,OQMD v1.2,2019-05,CGNN-128,35.7,100.0,0.6,0.02,35.7,0.87,ito:ITO_00137,Graph process,MAE
12,1,Band Gap,OQMD v1.2,2019-05,CGNN Ensemble,0.0461,100.0,0.0461,1.0,0.0461,0.0,ito:ITO_00137,Graph process,MAE
13,1,Total Magnetization,OQMD v1.2,2019-05,CGNN Ensemble,0.0691,100.0,0.0691,1.0,0.0691,0.0,ito:ITO_00137,Graph process,MAE
0,1,Graph Regression,Lipophilicity ,2016-09,GCN,1.05,90.52,1.05,0.91,1.16,0.91,ito:ITO_00137,Graph process,RMSE\\-at\\-80%Train
1,1,Graph Regression,Lipophilicity ,2019-08,Random Forests,1.16,100.0,0.1,0.09,1.16,1.0,ito:ITO_00137,Graph process,RMSE\\-at\\-80%Train
0,1,Graph Regression,Tox21 ,2016-09,GCN,0.75,96.15,0.75,0.96,0.78,0.96,ito:ITO_00137,Graph process,AUC\\-at\\-80%Train
1,1,Graph Regression,Tox21 ,2019-08,CensNet,0.78,100.0,0.0,0.0,0.78,1.0,ito:ITO_00137,Graph process,AUC\\-at\\-80%Train
0,1,Rotated MNIST,Rotated MNIST,2016-12,H-net,1.69,100.0,1.69,1.0,1.69,1.0,ito:ITO_00137,Graph process,Test\\ error
1,1,Grasp Generation,Grasp Generation,2016-12,H-net,1.69,100.0,1.69,1.0,1.69,1.0,ito:ITO_00137,Graph process,Test\\ error
0,1,Hand Pose Estimation,NYU Hands,2017-02,REN,12.7,12.09,12.7,0.12,105.06,0.12,ito:ITO_00137,Graph process,Average\\ 3D\\ Error
1,1,Hand Pose Estimation,NYU Hands,2017-07,REN,15.6,14.85,2.9,0.03,105.06,0.15,ito:ITO_00137,Graph process,Average\\ 3D\\ Error
2,1,Hand Pose Estimation,NYU Hands,2019-08,A2J (Ours),105.06,100.0,89.5,0.85,105.06,1.0,ito:ITO_00137,Graph process,Average\\ 3D\\ Error
3,1,Hand Pose Estimation,MSRA Hands,2017-02,REN,9.8,100.0,9.8,1.0,9.8,0.09,ito:ITO_00137,Graph process,Average\\ 3D\\ Error
4,1,Hand Pose Estimation,ICVL Hands,2017-02,REN,7.5,7.14,7.5,0.07,105.06,0.07,ito:ITO_00137,Graph process,Average\\ 3D\\ Error
5,1,Hand Pose Estimation,ICVL Hands,2017-08,DeepPrior++,8.1,7.71,0.6,0.01,105.06,0.08,ito:ITO_00137,Graph process,Average\\ 3D\\ Error
6,1,Hand Pose Estimation,ICVL Hands,2019-08,A2J (Ours),105.06,100.0,97.0,0.92,105.06,1.0,ito:ITO_00137,Graph process,Average\\ 3D\\ Error
7,1,Hand Pose Estimation,HANDS 2017,2017-08,THU VCLab,11.7,98.24,11.7,0.98,11.91,0.11,ito:ITO_00137,Graph process,Average\\ 3D\\ Error
8,1,Hand Pose Estimation,HANDS 2017,2017-12,Vanora,11.91,100.0,0.2,0.02,11.91,0.11,ito:ITO_00137,Graph process,Average\\ 3D\\ Error
9,1,Hand Pose Estimation,HANDS 2019,2020-01,HandAugment,13.66,100.0,13.66,1.0,13.66,0.13,ito:ITO_00137,Graph process,Average\\ 3D\\ Error
0,1,Community Detection,Amazon,2017-05,GNN,2.0,100.0,2,1.0,2,1.0,ito:ITO_00137,Graph process,Accuracy\\-NE
0,1,Link Prediction,NELL-995,2017-07,RL,79.6,100.0,79.6,1.0,79.6,1.0,ito:ITO_00137,Graph process,Mean\\ AP
0,1,Community Detection,Amazon,2017-08,Ego-Splitting,0.089,100.0,0.089,1.0,0.089,0.2,ito:ITO_00137,Graph process,NMI
1,1,Graph Clustering,Cora,2018-02,ARGE,0.449,100.0,0.449,1.0,0.449,1.0,ito:ITO_00137,Graph process,NMI
2,1,Graph Clustering,Citeseer,2018-02,ARGE,0.35,100.0,0.35,1.0,0.35,0.78,ito:ITO_00137,Graph process,NMI
3,1,Community Detection,Cora,2019-08,EdMot,0.4226,100.0,0.4226,1.0,0.4226,0.94,ito:ITO_00137,Graph process,NMI
0,1,Community Detection,Amazon,2017-08,Ego-Splitting,0.0374,41.1,0.0374,0.41,0.091,0.41,ito:ITO_00137,Graph process,F1\\-score
1,1,Community Detection,Amazon,2019-01,CommunityGAN,0.091,100.0,0.1,1.1,0.091,1.0,ito:ITO_00137,Graph process,F1\\-score
0,1,Community Detection,2010 i2b2/VA,2017-11,brian,10.0,100.0,10,1.0,10,1.0,ito:ITO_00137,Graph process,14\\ gestures\\ accuracy
0,1,Link Prediction,YAGO37,2017-11,Rule-Guided Embedding,0.541,100.0,0.541,1.0,0.541,0.65,ito:ITO_00137,Graph process,Hits\\-at\\-5
1,1,Link Prediction,FB15k,2017-11,Rule-Guided Embedding,0.836,100.0,0.836,1.0,0.836,1.0,ito:ITO_00137,Graph process,Hits\\-at\\-5
0,1,Graph Clustering,Cora,2018-02,ARGE,64.6,100.0,64.6,1.0,64.6,0.68,ito:ITO_00137,Graph process,Precision
1,1,Graph Clustering,Citeseer,2018-02,ARGE,57.3,100.0,57.3,1.0,57.3,0.6,ito:ITO_00137,Graph process,Precision
2,1,Triple Classification,YAGO39K,2018-11,TransC (bern),94.8,100.0,94.8,1.0,94.8,1.0,ito:ITO_00137,Graph process,Precision
0,1,Graph Clustering,Cora,2018-02,ARGE,35.2,100.0,35.2,1.0,35.2,1.0,ito:ITO_00137,Graph process,ARI
1,1,Graph Clustering,Citeseer,2018-02,ARGE,34.1,100.0,34.1,1.0,34.1,0.97,ito:ITO_00137,Graph process,ARI
0,1,Link Prediction,Pubmed,2018-02,ARGE,97.1,98.44,97.1,0.98,98.64,0.98,ito:ITO_00137,Graph process,AP
1,1,Link Prediction,Pubmed,2018-09,SCAT,97.19,98.53,0.1,0.0,98.64,0.98,ito:ITO_00137,Graph process,AP
2,1,Link Prediction,Pubmed,2019-06,GraphStar,98.64,100.0,1.5,0.02,98.64,1.0,ito:ITO_00137,Graph process,AP
3,1,Link Prediction,Citeseer,2018-02,ARGE,93.0,94.54,93.0,0.95,98.37,0.94,ito:ITO_00137,Graph process,AP
4,1,Link Prediction,Citeseer,2018-04,S-VGAE,95.2,96.78,2.2,0.02,98.37,0.96,ito:ITO_00137,Graph process,AP
5,1,Link Prediction,Citeseer,2018-09,SCAT,97.57,99.19,2.4,0.02,98.37,0.99,ito:ITO_00137,Graph process,AP
6,1,Link Prediction,Citeseer,2019-06,GraphStar,97.93,99.55,0.4,0.0,98.37,0.99,ito:ITO_00137,Graph process,AP
7,1,Link Prediction,Citeseer,2019-12,GLACE,98.37,100.0,0.4,0.0,98.37,0.99,ito:ITO_00137,Graph process,AP
8,1,Link Prediction,Cora,2018-02,ARGE,93.2,94.6,93.2,0.95,98.52,0.94,ito:ITO_00137,Graph process,AP
9,1,Link Prediction,Cora,2018-04,S-VGAE,94.1,95.51,0.9,0.01,98.52,0.95,ito:ITO_00137,Graph process,AP
10,1,Link Prediction,Cora,2018-09,SCAT,94.63,96.05,0.5,0.01,98.52,0.96,ito:ITO_00137,Graph process,AP
11,1,Link Prediction,Cora,2019-06,GraphStar,96.15,97.59,1.5,0.02,98.52,0.97,ito:ITO_00137,Graph process,AP
12,1,Link Prediction,Cora,2019-12,GLACE,98.52,100.0,2.4,0.02,98.52,1.0,ito:ITO_00137,Graph process,AP
13,1,Link Prediction,DBLP,2019-12,GLACE,98.4,100.0,98.4,1.0,98.4,0.99,ito:ITO_00137,Graph process,AP
14,1,Link Prediction,ACM,2019-12,GLACE,98.24,100.0,98.24,1.0,98.24,0.99,ito:ITO_00137,Graph process,AP
15,1,Link Prediction,Last.FM,2020-02,MAGNN,98.93,100.0,98.93,1.0,98.93,1.0,ito:ITO_00137,Graph process,AP
0,1,Triple Classification,YAGO39K,2018-11,TransC (bern),92.7,100.0,92.7,1.0,92.7,1.0,ito:ITO_00137,Graph process,Recall
0,1,Triple Classification,YAGO39K,2018-11,TransC (bern),93.7,100.0,93.7,1.0,93.7,1.0,ito:ITO_00137,Graph process,F1\\-Score
1,1,Community Detection,DBLP,2019-01,CommunityGAN,0.153,100.0,0.153,1.0,0.153,0.0,ito:ITO_00137,Graph process,F1\\-Score
2,1,Link Prediction,YouTube,2019-05,GATNE-T,76.83,100.0,76.83,1.0,76.83,0.82,ito:ITO_00137,Graph process,F1\\-Score
3,1,Link Prediction,Alibaba-S,2019-05,GATNE-T,62.48,100.0,62.48,1.0,62.48,0.67,ito:ITO_00137,Graph process,F1\\-Score
4,1,Link Prediction,Twitter,2019-05,GATNE-T,84.96,100.0,84.96,1.0,84.96,0.91,ito:ITO_00137,Graph process,F1\\-Score
5,1,Link Prediction,Amazon,2019-05,GATNE-T,92.87,100.0,92.87,1.0,92.87,0.99,ito:ITO_00137,Graph process,F1\\-Score
6,1,Link Prediction,Alibaba,2019-05,GATNE-I,89.94,100.0,89.94,1.0,89.94,0.96,ito:ITO_00137,Graph process,F1\\-Score
0,1,Open Knowledge Graph Canonicalization,Noun Phrase Canonicalization,2019-02,CESI,99.9,100.0,99.9,1.0,99.9,1.0,ito:ITO_00137,Graph process,ReVerb45k
0,1,Open Knowledge Graph Canonicalization,Noun Phrase Canonicalization,2019-02,CESI,99.8,100.0,99.8,1.0,99.8,1.0,ito:ITO_00137,Graph process,Ambiguous\\ dataset
0,1,Open Knowledge Graph Canonicalization,Noun Phrase Canonicalization,2019-02,CESI,98.2,100.0,98.2,1.0,98.2,1.0,ito:ITO_00137,Graph process,Base\\ Dataset
0,1,Graph Similarity,IMDb,2019-02,SimGNN,1.264,100.0,1.264,1.0,1.264,1.0,ito:ITO_00137,Graph process,mse\\ \\(10\\^\\-3\\)
0,1,Trajectory Forecasting,ActEV,2019-02,Next,17.99,100.0,17.99,1.0,17.99,1.0,ito:ITO_00137,Graph process,ADE\\-8/12
0,1,Knowledge Graph Completion,MovieLens 1M,2019-02,KTUP (soft),527.0,100.0,527,1.0,527,1.0,ito:ITO_00137,Graph process,Mean\\ Rank
1,1,Knowledge Graph Completion,DBbook2014,2019-02,KTUP (soft),499.0,100.0,499,1.0,499,0.95,ito:ITO_00137,Graph process,Mean\\ Rank
0,1,Link Prediction,FB15k,2019-03,SimplE,2105.0,100.0,2105,1.0,2105,1.0,ito:ITO_00137,Graph process,training\\ time\\ \\(s\\)
1,1,Link Prediction,WN18RR,2019-03,RotatE,828.0,100.0,828,1.0,828,0.39,ito:ITO_00137,Graph process,training\\ time\\ \\(s\\)
2,1,Link Prediction,FB15k-237,2019-03,RotatE,857.0,100.0,857,1.0,857,0.41,ito:ITO_00137,Graph process,training\\ time\\ \\(s\\)
3,1,Link Prediction,WN18,2019-03,SimplE,1042.0,100.0,1042,1.0,1042,0.5,ito:ITO_00137,Graph process,training\\ time\\ \\(s\\)
0,1,Node Classification,YouTube,2019-03,LINE,70.09,100.0,70.09,1.0,70.09,1.0,ito:ITO_00137,Graph process,runtime\\ \\(s\\)
1,1,Human motion prediction,Human motion prediction,2019-03,LINE,70.09,100.0,70.09,1.0,70.09,1.0,ito:ITO_00137,Graph process,runtime\\ \\(s\\)
0,1,Node Classification,YouTube,2019-03,LINE,33.69,100.0,33.69,1.0,33.69,1.0,ito:ITO_00137,Graph process,Macro\\-F1\\-at\\-2%
1,1,Human motion prediction,Human motion prediction,2019-03,LINE,33.69,100.0,33.69,1.0,33.69,1.0,ito:ITO_00137,Graph process,Macro\\-F1\\-at\\-2%
0,1,Node Classification,YouTube,2019-03,LINE,40.61,100.0,40.61,1.0,40.61,1.0,ito:ITO_00137,Graph process,Micro\\-F1\\-at\\-2%
1,1,Human motion prediction,Human motion prediction,2019-03,LINE,40.61,100.0,40.61,1.0,40.61,1.0,ito:ITO_00137,Graph process,Micro\\-F1\\-at\\-2%
0,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,HAN,93.11,100.0,93.11,1.0,93.11,1.0,ito:ITO_00137,Graph process,Micro\\-F1\\ \\(20%\\ training\\ data\\)
0,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,HAN,93.99,100.0,93.99,1.0,93.99,1.0,ito:ITO_00137,Graph process,Micro\\-F1\\ \\(80%\\ training\\ data\\)
0,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,HAN,92.24,100.0,92.24,1.0,92.24,1.0,ito:ITO_00137,Graph process,Macro\\-F1\\ \\(20%\\ training\\ data\\)
0,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,HAN,93.7,97.12,93.7,0.97,96.48,0.97,ito:ITO_00137,Graph process,Macro\\-F1\\ \\(60%\\ training\\ data\\)
1,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-12,NLAH (2ndprox),96.48,100.0,2.8,0.03,96.48,1.0,ito:ITO_00137,Graph process,Macro\\-F1\\ \\(60%\\ training\\ data\\)
0,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,HAN,93.08,99.61,93.08,1.0,93.44,1.0,ito:ITO_00137,Graph process,Macro\\-F1\\ \\(80%\\ training\\ data\\)
1,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,ESim,93.44,100.0,0.4,0.0,93.44,1.0,ito:ITO_00137,Graph process,Macro\\-F1\\ \\(80%\\ training\\ data\\)
0,1,Link Prediction,FB15k,2019-03,PyTorch BigGraph (ComplEx),0.79,100.0,0.79,1.0,0.79,1.0,ito:ITO_00137,Graph process,MRR\\ filtered
0,1,Link Prediction,FB15k,2019-03,PyTorch BigGraph (ComplEx),0.242,100.0,0.242,1.0,0.242,1.0,ito:ITO_00137,Graph process,MRR\\ raw
0,1,Link Prediction,YouTube,2019-03,PyTorch BigGraph,40.9,100.0,40.9,1.0,40.9,0.47,ito:ITO_00137,Graph process,Macro\\ F1
1,1,Node Classification,BlogCatalog,2019-12,DAOR,17.25,100.0,17.25,1.0,17.25,0.2,ito:ITO_00137,Graph process,Macro\\ F1
2,1,Spoken language identification,Spoken language identification,2019-12,DAOR,17.25,100.0,17.25,1.0,17.25,0.2,ito:ITO_00137,Graph process,Macro\\ F1
3,1,Node Classification,DBLP,2019-12,DAOR,87.64,100.0,87.64,1.0,87.64,1.0,ito:ITO_00137,Graph process,Macro\\ F1
4,1,Node Classification,Wiki,2019-12,DAOR,15.97,100.0,15.97,1.0,15.97,0.18,ito:ITO_00137,Graph process,Macro\\ F1
5,1,Micro-Expression Recognition,Micro-Expression Recognition,2019-12,DAOR,15.97,100.0,15.97,1.0,15.97,0.18,ito:ITO_00137,Graph process,Macro\\ F1
0,1,Link Prediction,YouTube,2019-03,PyTorch BigGraph,48.0,100.0,48,1.0,48,0.55,ito:ITO_00137,Graph process,Micro\\ F1
1,1,Node Classification,DBLP,2019-12,DAOR,87.86,100.0,87.86,1.0,87.86,1.0,ito:ITO_00137,Graph process,Micro\\ F1
2,1,Node Classification,BlogCatalog,2019-12,DAOR,33.05,100.0,33.05,1.0,33.05,0.38,ito:ITO_00137,Graph process,Micro\\ F1
3,1,Node Classification,Wiki,2019-12,DAOR,53.24,100.0,53.24,1.0,53.24,0.61,ito:ITO_00137,Graph process,Micro\\ F1
4,1,Micro-Expression Recognition,Micro-Expression Recognition,2019-12,DAOR,53.24,100.0,53.24,1.0,53.24,0.61,ito:ITO_00137,Graph process,Micro\\ F1
5,1,Spoken language identification,Spoken language identification,2019-12,DAOR,33.05,100.0,33.05,1.0,33.05,0.38,ito:ITO_00137,Graph process,Micro\\ F1
0,1,Link Prediction,YouTube,2019-05,GATNE-T,84.61,100.0,84.61,1.0,84.61,0.87,ito:ITO_00137,Graph process,ROC\\ AUC
1,1,Link Prediction,Alibaba-S,2019-05,GATNE-T,66.71,100.0,66.71,1.0,66.71,0.68,ito:ITO_00137,Graph process,ROC\\ AUC
2,1,Link Prediction,Twitter,2019-05,GATNE-T,92.3,100.0,92.3,1.0,92.3,0.95,ito:ITO_00137,Graph process,ROC\\ AUC
3,1,Link Prediction,Amazon,2019-05,GATNE-T,97.44,100.0,97.44,1.0,97.44,1.0,ito:ITO_00137,Graph process,ROC\\ AUC
4,1,Link Prediction,Alibaba,2019-05,GATNE-I,84.2,100.0,84.2,1.0,84.2,0.86,ito:ITO_00137,Graph process,ROC\\ AUC
0,1,Link Prediction,YouTube,2019-05,GATNE-T,81.93,100.0,81.93,1.0,81.93,0.84,ito:ITO_00137,Graph process,PR\\ AUC
1,1,Link Prediction,Alibaba-S,2019-05,GATNE-T,67.55,100.0,67.55,1.0,67.55,0.7,ito:ITO_00137,Graph process,PR\\ AUC
2,1,Link Prediction,Twitter,2019-05,GATNE-T,91.77,100.0,91.77,1.0,91.77,0.95,ito:ITO_00137,Graph process,PR\\ AUC
3,1,Link Prediction,Amazon,2019-05,GATNE-T,97.05,100.0,97.05,1.0,97.05,1.0,ito:ITO_00137,Graph process,PR\\ AUC
4,1,Link Prediction,Alibaba,2019-05,GATNE-I,95.04,100.0,95.04,1.0,95.04,0.98,ito:ITO_00137,Graph process,PR\\ AUC
0,1,Materials Screening,OQMD v1.2,2019-05,CGNN Ensemble,96.0,100.0,96,1.0,96,1.0,ito:ITO_00137,Graph process,EaH\\-at\\-95
0,1,Materials Screening,OQMD v1.2,2019-05,CGNN Ensemble,215.0,100.0,215,1.0,215,1.0,ito:ITO_00137,Graph process,EaH\\-at\\-99
0,1,Graph Classification,MUTAG,2019-06,P-WL-C,90.51,100.0,90.51,1.0,90.51,1.0,ito:ITO_00137,Graph process,Mean\\ Accuracy
0,1,Community Detection,Facebook Companies,2019-08,Smooth GEMSEC 2,0.684,100.0,0.684,1.0,0.684,0.8,ito:ITO_00137,Graph process,Modularity
1,1,Community Detection,Facebook Media,2019-08,Smooth GEMSEC 2,0.571,100.0,0.571,1.0,0.571,0.66,ito:ITO_00137,Graph process,Modularity
2,1,Community Detection,Facebook TV Show,2019-08,Smooth GEMSEC 2,0.847,100.0,0.847,1.0,0.847,0.99,ito:ITO_00137,Graph process,Modularity
3,1,Community Detection,Facebook Athletes,2019-08,Smooth GEMSEC 2,0.692,100.0,0.692,1.0,0.692,0.81,ito:ITO_00137,Graph process,Modularity
4,1,Community Detection,Facebook Artists,2019-08,Smooth GEMSEC 2,0.562,100.0,0.562,1.0,0.562,0.65,ito:ITO_00137,Graph process,Modularity
5,1,Community Detection,Facebook Government,2019-08,Smooth GEMSEC 2,0.712,100.0,0.712,1.0,0.712,0.83,ito:ITO_00137,Graph process,Modularity
6,1,Community Detection,Facebook Celebrities,2019-08,Smooth GEMSEC 2,0.649,100.0,0.649,1.0,0.649,0.76,ito:ITO_00137,Graph process,Modularity
7,1,Community Detection,Facebook Politicians,2019-08,Smooth GEMSEC 2,0.859,100.0,0.859,1.0,0.859,1.0,ito:ITO_00137,Graph process,Modularity
0,1,Hand Pose Estimation,K2HPD,2019-08,A2J,76.3,100.0,76.3,1.0,76.3,1.0,ito:ITO_00137,Graph process,PDJ@5mm
0,1,Hand Pose Estimation,NYU Hands,2019-08,A2J,105.06,100.0,105.06,1.0,105.06,1.0,ito:ITO_00137,Graph process,FPS
1,1,Hand Pose Estimation,ICVL Hands,2019-08,A2J,105.06,100.0,105.06,1.0,105.06,1.0,ito:ITO_00137,Graph process,FPS
0,1,Node Classification,Deezer Romania,2019-08,GEMSEC 2,0.378,100.0,0.378,1.0,0.378,0.92,ito:ITO_00137,Graph process,Micro\\-F1
1,1,Node Classification,Deezer Hungary,2019-08,Smooth GEMSEC 2,0.409,100.0,0.409,1.0,0.409,1.0,ito:ITO_00137,Graph process,Micro\\-F1
2,1,Face Quality Assessement,Face Quality Assessement,2019-08,Smooth GEMSEC 2,0.409,100.0,0.409,1.0,0.409,1.0,ito:ITO_00137,Graph process,Micro\\-F1
3,1,Node Classification,Deezer Croatia,2019-08,GEMSEC 2,0.381,100.0,0.381,1.0,0.381,0.93,ito:ITO_00137,Graph process,Micro\\-F1
0,1,Sparse Learning,CINIC-10,2020-03,Resnet18,92.43,100.0,92.43,1.0,92.43,1.0,ito:ITO_00137,Graph process,Sparsity
1,1,Inductive knowledge graph completion,Inductive knowledge graph completion,2020-03,Resnet18,92.43,100.0,92.43,1.0,92.43,1.0,ito:ITO_00137,Graph process,Sparsity
0,1,Sentiment Analysis,1B Words,2012-06,BilSTM,93.0,100.0,93,1.0,93,1.0,ito:ITO_00141,Natural Language Processing,1\\ in\\ 10\\ R\\-at\\-1
0,1,Citation Intent Classification,ACL-ARC,2013-06,SVM,41.0,60.38,41.0,0.6,67.9,0.42,ito:ITO_00141,Natural Language Processing,F1
1,1,Citation Intent Classification,ACL-ARC,2016-06,BiLSTM-Attention,51.8,76.29,10.8,0.16,67.9,0.53,ito:ITO_00141,Natural Language Processing,F1
2,1,Citation Intent Classification,ACL-ARC,2018-01,Feature-rich Random Forest,53.0,78.06,1.2,0.02,67.9,0.54,ito:ITO_00141,Natural Language Processing,F1
3,1,Citation Intent Classification,ACL-ARC,2018-02,BiLSTM-Attention + ELMo,54.6,80.41,1.6,0.02,67.9,0.55,ito:ITO_00141,Natural Language Processing,F1
4,1,Citation Intent Classification,ACL-ARC,2019-03,SciBERT,65.8,96.91,11.2,0.16,67.9,0.67,ito:ITO_00141,Natural Language Processing,F1
5,1,Citation Intent Classification,ACL-ARC,2019-04,Structural-scaffolds,67.9,100.0,2.1,0.03,67.9,0.69,ito:ITO_00141,Natural Language Processing,F1
6,1,Semantic Textual Similarity,MRPC,2013-10,TF-KLD,85.9,92.86,85.9,0.93,92.5,0.87,ito:ITO_00141,Natural Language Processing,F1
7,1,Semantic Textual Similarity,MRPC,2019-10,T5-Large,92.4,99.89,6.5,0.07,92.5,0.94,ito:ITO_00141,Natural Language Processing,F1
8,1,Semantic Textual Similarity,MRPC,2019-10,T5-3B,92.5,100.0,0.1,0.0,92.5,0.94,ito:ITO_00141,Natural Language Processing,F1
9,1,Paraphrase Identification,MSRP,2013-10,NMF factorization-unigrams-TFKLD,81.48,94.79,81.48,0.95,85.96,0.83,ito:ITO_00141,Natural Language Processing,F1
10,1,Paraphrase Identification,MSRP,2013-10,"FEAT2, TFKLD, SVM, Fine-grained features",85.96,100.0,4.5,0.05,85.96,0.87,ito:ITO_00141,Natural Language Processing,F1
11,1,Question Answering,WebQuestions,2014-04,Weakly Supervised Embeddings,29.7,70.38,29.7,0.7,42.2,0.3,ito:ITO_00141,Natural Language Processing,F1
12,1,Question Answering,WebQuestions,2014-06,Subgraph embeddings,39.2,92.89,9.5,0.23,42.2,0.4,ito:ITO_00141,Natural Language Processing,F1
13,1,Question Answering,WebQuestions,2015-06,Memory Networks (ensemble),42.2,100.0,3.0,0.07,42.2,0.43,ito:ITO_00141,Natural Language Processing,F1
14,1,Named Entity Recognition,SciERC,2014-09,SciBERT (Base Vocab),65.12,92.59,65.12,0.93,70.33,0.66,ito:ITO_00141,Natural Language Processing,F1
15,1,Named Entity Recognition,SciERC,2018-10,BERT Base,65.24,92.76,0.1,0.0,70.33,0.66,ito:ITO_00141,Natural Language Processing,F1
16,1,Named Entity Recognition,SciERC,2019-03,SciBERT (SciVocab),65.5,93.13,0.3,0.0,70.33,0.67,ito:ITO_00141,Natural Language Processing,F1
17,1,Named Entity Recognition,SciERC,2019-09,SpERT,70.33,100.0,4.8,0.07,70.33,0.71,ito:ITO_00141,Natural Language Processing,F1
18,1,Word Sense Disambiguation,SensEval 3 Lexical Sample,2015-05,IMS + adapted CW,73.4,91.61,73.4,0.92,80.12,0.75,ito:ITO_00141,Natural Language Processing,F1
19,1,Word Sense Disambiguation,SensEval 3 Lexical Sample,2019-09,kNN-BERT,80.12,100.0,6.7,0.08,80.12,0.81,ito:ITO_00141,Natural Language Processing,F1
20,1,Word Sense Disambiguation,SensEval 2 Lexical Sample,2015-05,IMS + adapted CW,66.2,86.51,66.2,0.87,76.52,0.67,ito:ITO_00141,Natural Language Processing,F1
21,1,Word Sense Disambiguation,SensEval 2 Lexical Sample,2016-06,BiLSTM with GloVe,66.9,87.43,0.7,0.01,76.52,0.68,ito:ITO_00141,Natural Language Processing,F1
22,1,Word Sense Disambiguation,SensEval 2 Lexical Sample,2019-09,kNN-BERT,76.52,100.0,9.6,0.13,76.52,0.78,ito:ITO_00141,Natural Language Processing,F1
23,1,Question Answering,SimpleQuestions,2015-06,Memory Networks (ensemble),63.9,100.0,63.9,1.0,63.9,0.65,ito:ITO_00141,Natural Language Processing,F1
24,1,Acoustic Novelty Detection,A3Lab PASCAL CHiME,2015-08,BLSTM-DAE,93.4,98.94,93.4,0.99,94.4,0.95,ito:ITO_00141,Natural Language Processing,F1
25,1,Acoustic Novelty Detection,A3Lab PASCAL CHiME,2015-10,NP-BLSTM-DAE,94.4,100.0,1.0,0.01,94.4,0.96,ito:ITO_00141,Natural Language Processing,F1
26,1,Attribute Value Extraction,Attribute Value Extraction,2015-08,BLSTM-DAE,93.4,98.94,93.4,0.99,94.4,0.95,ito:ITO_00141,Natural Language Processing,F1
27,1,Attribute Value Extraction,Attribute Value Extraction,2015-10,NP-BLSTM-DAE,94.4,100.0,1.0,0.01,94.4,0.96,ito:ITO_00141,Natural Language Processing,F1
28,1,Sentence Compression,Google Dataset,2015-09,LSTM,0.82,96.36,0.82,0.96,0.851,0.01,ito:ITO_00141,Natural Language Processing,F1
29,1,Sentence Compression,Google Dataset,2018-07,BiRNN + LM Evaluator,0.851,100.0,0.0,0.0,0.851,0.01,ito:ITO_00141,Natural Language Processing,F1
30,1,Chinese Word Segmentation,MSRA,2015-09,Pre-trained+bigram+ LSTM+CRF,97.4,100.0,97.4,1.0,97.4,0.99,ito:ITO_00141,Natural Language Processing,F1
31,1,Word Sense Disambiguation,SemEval 2007 Task 17,2016-03,LSTM (T:SemCor),64.2,87.47,64.2,0.87,73.4,0.65,ito:ITO_00141,Natural Language Processing,F1
32,1,Word Sense Disambiguation,SemEval 2007 Task 17,2018-11,"SemCor+WNGT, vocabulary reduced, ensemble",66.81,91.02,2.6,0.04,73.4,0.68,ito:ITO_00141,Natural Language Processing,F1
33,1,Word Sense Disambiguation,SemEval 2007 Task 17,2019-05,"SemCor+WNGC, hypernyms",73.4,100.0,6.6,0.09,73.4,0.75,ito:ITO_00141,Natural Language Processing,F1
34,1,Word Sense Disambiguation,SensEval 2,2016-03,"LSTMLP (T:OMSTI, U:1K)",74.4,93.35,74.4,0.93,79.7,0.76,ito:ITO_00141,Natural Language Processing,F1
35,1,Word Sense Disambiguation,SensEval 2,2018-11,"SemCor+WNGT, vocabulary reduced, ensemble",75.15,94.29,0.8,0.01,79.7,0.76,ito:ITO_00141,Natural Language Processing,F1
36,1,Word Sense Disambiguation,SensEval 2,2019-05,"SemCor+WNGC, hypernyms",79.7,100.0,4.5,0.06,79.7,0.81,ito:ITO_00141,Natural Language Processing,F1
37,1,Word Sense Disambiguation,SemEval 2007 Task 7,2016-03,"LSTMLP (T:SemCor, U:OMSTI)",84.3,93.25,84.3,0.93,90.4,0.86,ito:ITO_00141,Natural Language Processing,F1
38,1,Word Sense Disambiguation,SemEval 2007 Task 7,2018-11,"SemCor+WNGT, vocabulary reduced, ensemble",86.02,95.15,1.7,0.02,90.4,0.87,ito:ITO_00141,Natural Language Processing,F1
39,1,Word Sense Disambiguation,SemEval 2007 Task 7,2019-05,"SemCor+WNGC, hypernyms",90.4,100.0,4.4,0.05,90.4,0.92,ito:ITO_00141,Natural Language Processing,F1
40,1,Word Sense Disambiguation,SensEval 3 Task 1,2016-03,LSTM (T:SemCor),69.2,88.95,69.2,0.89,77.8,0.7,ito:ITO_00141,Natural Language Processing,F1
41,1,Word Sense Disambiguation,SensEval 3 Task 1,2016-03,"LSTMLP (T:SemCor, U:1K)",71.8,92.29,2.6,0.03,77.8,0.73,ito:ITO_00141,Natural Language Processing,F1
42,1,Word Sense Disambiguation,SensEval 3 Task 1,2019-05,"SemCor+WNGC, hypernyms",77.8,100.0,6.0,0.08,77.8,0.79,ito:ITO_00141,Natural Language Processing,F1
43,1,Word Sense Disambiguation,SemEval 2013 Task 12,2016-03,LSTM (T:SemCor),67.0,85.13,67.0,0.85,78.7,0.68,ito:ITO_00141,Natural Language Processing,F1
44,1,Word Sense Disambiguation,SemEval 2013 Task 12,2016-03,"LSTMLP (T:SemCor, U:1K)",69.5,88.31,2.5,0.03,78.7,0.71,ito:ITO_00141,Natural Language Processing,F1
45,1,Word Sense Disambiguation,SemEval 2013 Task 12,2018-11,"SemCor+WNGT, vocabulary reduced, ensemble",72.63,92.29,3.1,0.04,78.7,0.74,ito:ITO_00141,Natural Language Processing,F1
46,1,Word Sense Disambiguation,SemEval 2013 Task 12,2019-05,"SemCor+WNGC, hypernyms",78.7,100.0,6.1,0.08,78.7,0.8,ito:ITO_00141,Natural Language Processing,F1
47,1,Coreference Resolution,OntoNotes,2016-04,Global,64.21,80.67,64.21,0.81,79.6,0.65,ito:ITO_00141,Natural Language Processing,F1
48,1,Coreference Resolution,OntoNotes,2016-06,NN Cluster Ranker,65.29,82.02,1.1,0.01,79.6,0.66,ito:ITO_00141,Natural Language Processing,F1
49,1,Coreference Resolution,OntoNotes,2016-09,Reward Rescaling,65.73,82.58,0.4,0.01,79.6,0.67,ito:ITO_00141,Natural Language Processing,F1
50,1,Coreference Resolution,OntoNotes,2017-07,e2e-coref,67.2,84.42,1.5,0.02,79.6,0.68,ito:ITO_00141,Natural Language Processing,F1
51,1,Coreference Resolution,OntoNotes,2018-02,e2e-coref + ELMo,70.4,88.44,3.2,0.04,79.6,0.72,ito:ITO_00141,Natural Language Processing,F1
52,1,Coreference Resolution,OntoNotes,2018-04,e2e-coref + ELMo + hyperparameter tuning,72.3,90.83,1.9,0.02,79.6,0.73,ito:ITO_00141,Natural Language Processing,F1
53,1,Coreference Resolution,OntoNotes,2018-04,c2f-coref,73.0,91.71,0.7,0.01,79.6,0.74,ito:ITO_00141,Natural Language Processing,F1
54,1,Coreference Resolution,OntoNotes,2019-07,BERT + EE,76.61,96.24,3.6,0.05,79.6,0.78,ito:ITO_00141,Natural Language Processing,F1
55,1,Coreference Resolution,OntoNotes,2019-07,SpanBERT,79.6,100.0,3.0,0.04,79.6,0.81,ito:ITO_00141,Natural Language Processing,F1
56,1,Relation Extraction,SemEval-2010 Task 8,2016-08,Att-Pooling-CNN,88.0,96.7,88.0,0.97,91.0,0.89,ito:ITO_00141,Natural Language Processing,F1
57,1,Relation Extraction,SemEval-2010 Task 8,2019-02,Entity-Aware BERT,89.0,97.8,1.0,0.01,91.0,0.9,ito:ITO_00141,Natural Language Processing,F1
58,1,Relation Extraction,SemEval-2010 Task 8,2019-05,R-BERT,89.25,98.08,0.2,0.0,91.0,0.91,ito:ITO_00141,Natural Language Processing,F1
59,1,Relation Extraction,SemEval-2010 Task 8,2019-06,BERTEM+MTB,89.5,98.35,0.2,0.0,91.0,0.91,ito:ITO_00141,Natural Language Processing,F1
60,1,Relation Extraction,SemEval-2010 Task 8,2019-11,EPGNN,90.2,99.12,0.7,0.01,91.0,0.92,ito:ITO_00141,Natural Language Processing,F1
61,1,Relation Extraction,SemEval-2010 Task 8,2020-04,REDN,91.0,100.0,0.8,0.01,91.0,0.92,ito:ITO_00141,Natural Language Processing,F1
62,1,Question Answering,SQuAD1.1,2016-08,Match-LSTM with Ans-Ptr (Boundary) (ensemble),77.022,81.01,77.022,0.81,95.08,0.78,ito:ITO_00141,Natural Language Processing,F1
63,1,Question Answering,SQuAD1.1,2016-09,ReasoNet (single model),79.364,83.47,2.3,0.02,95.08,0.81,ito:ITO_00141,Natural Language Processing,F1
64,1,Question Answering,SQuAD1.1,2016-09,ReasoNet (ensemble),82.552,86.82,3.2,0.03,95.08,0.84,ito:ITO_00141,Natural Language Processing,F1
65,1,Question Answering,SQuAD1.1,2017-05,Reinforced Mnemonic Reader (ensemble model),88.533,93.11,6.0,0.06,95.08,0.9,ito:ITO_00141,Natural Language Processing,F1
66,1,Question Answering,SQuAD1.1,2018-10,BERT (single model),91.835,96.59,3.3,0.03,95.08,0.93,ito:ITO_00141,Natural Language Processing,F1
67,1,Question Answering,SQuAD1.1,2018-10,BERT (ensemble),93.16,97.98,1.3,0.01,95.08,0.95,ito:ITO_00141,Natural Language Processing,F1
68,1,Question Answering,SQuAD1.1,2019-06,XLNet (single model),95.08,100.0,1.9,0.02,95.08,0.97,ito:ITO_00141,Natural Language Processing,F1
69,1,Question Answering,SQuAD1.1 dev,2016-08,Match-LSTM with Bi-Ans-Ptr (Boundary+Search+b) ,64.7,67.56,64.7,0.68,95.77,0.66,ito:ITO_00141,Natural Language Processing,F1
70,1,Question Answering,SQuAD1.1 dev,2016-10,DCR,71.2,74.34,6.5,0.07,95.77,0.72,ito:ITO_00141,Natural Language Processing,F1
71,1,Question Answering,SQuAD1.1 dev,2016-11,RASOR,74.9,78.21,3.7,0.04,95.77,0.76,ito:ITO_00141,Natural Language Processing,F1
72,1,Question Answering,SQuAD1.1 dev,2016-11,BIDAF (single),77.3,80.71,2.4,0.03,95.77,0.79,ito:ITO_00141,Natural Language Processing,F1
73,1,Question Answering,SQuAD1.1 dev,2017-03,SEDT-LSTM,77.42,80.84,0.1,0.0,95.77,0.79,ito:ITO_00141,Natural Language Processing,F1
74,1,Question Answering,SQuAD1.1 dev,2017-03,FastQAExt (beam-size 5),78.5,81.97,1.1,0.01,95.77,0.8,ito:ITO_00141,Natural Language Processing,F1
75,1,Question Answering,SQuAD1.1 dev,2017-03,DrQA (Document Reader only),78.8,82.28,0.3,0.0,95.77,0.8,ito:ITO_00141,Natural Language Processing,F1
76,1,Question Answering,SQuAD1.1 dev,2017-04,Ruminating Reader,79.5,83.01,0.7,0.01,95.77,0.81,ito:ITO_00141,Natural Language Processing,F1
77,1,Question Answering,SQuAD1.1 dev,2017-05,R.M-Reader (single),86.3,90.11,6.8,0.07,95.77,0.88,ito:ITO_00141,Natural Language Processing,F1
78,1,Question Answering,SQuAD1.1 dev,2018-10,BERT large (+TriviaQA),91.1,95.12,4.8,0.05,95.77,0.93,ito:ITO_00141,Natural Language Processing,F1
79,1,Question Answering,SQuAD1.1 dev,2019-06,XLNet (single model),95.1,99.3,4.0,0.04,95.77,0.97,ito:ITO_00141,Natural Language Processing,F1
80,1,Question Answering,SQuAD1.1 dev,2019-10,T5-11B,95.64,99.86,0.5,0.01,95.77,0.97,ito:ITO_00141,Natural Language Processing,F1
81,1,Question Answering,SQuAD1.1 dev,2019-11,XLNet+DSC,95.77,100.0,0.1,0.0,95.77,0.97,ito:ITO_00141,Natural Language Processing,F1
82,1,Question Answering,NewsQA,2017-03,FastQAExt,56.1,76.22,56.1,0.76,73.6,0.57,ito:ITO_00141,Natural Language Processing,F1
83,1,Question Answering,NewsQA,2018-01,AMANDA,63.7,86.55,7.6,0.1,73.6,0.65,ito:ITO_00141,Natural Language Processing,F1
84,1,Question Answering,NewsQA,2018-11,DecaProp,66.3,90.08,2.6,0.04,73.6,0.67,ito:ITO_00141,Natural Language Processing,F1
85,1,Question Answering,NewsQA,2019-07,SpanBERT,73.6,100.0,7.3,0.1,73.6,0.75,ito:ITO_00141,Natural Language Processing,F1
86,1,Question Answering,TriviaQA,2017-05,Mnemonic Reader,52.85,63.22,52.85,0.63,83.6,0.54,ito:ITO_00141,Natural Language Processing,F1
87,1,Question Answering,TriviaQA,2017-06,Reading Twice for NLU,56.73,67.86,3.9,0.05,83.6,0.58,ito:ITO_00141,Natural Language Processing,F1
88,1,Question Answering,TriviaQA,2017-10,S-Norm,71.32,85.31,14.6,0.17,83.6,0.72,ito:ITO_00141,Natural Language Processing,F1
89,1,Question Answering,TriviaQA,2018-10,MemoReader,73.26,87.63,1.9,0.02,83.6,0.74,ito:ITO_00141,Natural Language Processing,F1
90,1,Question Answering,TriviaQA,2019-07,SpanBERT,83.6,100.0,10.3,0.12,83.6,0.85,ito:ITO_00141,Natural Language Processing,F1
91,1,Relation Extraction,WebNLG,2017-06,NovelTagging,28.3,29.39,28.3,0.29,96.3,0.29,ito:ITO_00141,Natural Language Processing,F1
92,1,Relation Extraction,WebNLG,2018-07,CopyRE MultiDecoder,37.1,38.53,8.8,0.09,96.3,0.38,ito:ITO_00141,Natural Language Processing,F1
93,1,Relation Extraction,WebNLG,2019-07,GraphRel2p,42.9,44.55,5.8,0.06,96.3,0.44,ito:ITO_00141,Natural Language Processing,F1
94,1,Relation Extraction,WebNLG,2019-09,CASREL,91.8,95.33,48.9,0.51,96.3,0.93,ito:ITO_00141,Natural Language Processing,F1
95,1,Relation Extraction,WebNLG,2020-04,REDN,96.3,100.0,4.5,0.05,96.3,0.98,ito:ITO_00141,Natural Language Processing,F1
96,1,Relation Extraction,NYT,2017-06,NovelTagging,42.0,46.77,42.0,0.47,89.8,0.43,ito:ITO_00141,Natural Language Processing,F1
97,1,Relation Extraction,NYT,2018-07,CopyRE MultiDecoder,58.7,65.37,16.7,0.19,89.8,0.6,ito:ITO_00141,Natural Language Processing,F1
98,1,Relation Extraction,NYT,2019-07,GraphRel2p,61.9,68.93,3.2,0.04,89.8,0.63,ito:ITO_00141,Natural Language Processing,F1
99,1,Relation Extraction,NYT,2019-09,CASREL,89.6,99.78,27.7,0.31,89.8,0.91,ito:ITO_00141,Natural Language Processing,F1
100,1,Relation Extraction,NYT,2020-04,REDN,89.8,100.0,0.2,0.0,89.8,0.91,ito:ITO_00141,Natural Language Processing,F1
101,1,Relation Extraction,NYT-single,2017-06,NovelTagging,49.5,83.33,49.5,0.83,59.4,0.5,ito:ITO_00141,Natural Language Processing,F1
102,1,Relation Extraction,NYT-single,2019-07,PA-LSTM,53.8,90.57,4.3,0.07,59.4,0.55,ito:ITO_00141,Natural Language Processing,F1
103,1,Relation Extraction,NYT-single,2019-09,ETL-Span,59.4,100.0,5.6,0.09,59.4,0.6,ito:ITO_00141,Natural Language Processing,F1
104,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,bc-LSTM+Att,56.19,87.55,56.19,0.88,64.18,0.57,ito:ITO_00141,Natural Language Processing,F1
105,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,ICON,58.54,91.21,2.4,0.04,64.18,0.59,ito:ITO_00141,Natural Language Processing,F1
106,1,Emotion Recognition in Conversation,IEMOCAP,2019-05,DialogueRNN,62.75,97.77,4.2,0.07,64.18,0.64,ito:ITO_00141,Natural Language Processing,F1
107,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,DialogueGCN,64.18,100.0,1.4,0.02,64.18,0.65,ito:ITO_00141,Natural Language Processing,F1
108,1,Semantic Role Labeling,OntoNotes,2017-07,He et al.,81.7,93.91,81.7,0.94,87.0,0.83,ito:ITO_00141,Natural Language Processing,F1
109,1,Semantic Role Labeling,OntoNotes,2017-12,Tan et al.,82.7,95.06,1.0,0.01,87.0,0.84,ito:ITO_00141,Natural Language Processing,F1
110,1,Semantic Role Labeling,OntoNotes,2018-02,"He et al., 2017 + ELMo",84.6,97.24,1.9,0.02,87.0,0.86,ito:ITO_00141,Natural Language Processing,F1
111,1,Semantic Role Labeling,OntoNotes,2018-05,"He et al.,",85.5,98.28,0.9,0.01,87.0,0.87,ito:ITO_00141,Natural Language Processing,F1
112,1,Semantic Role Labeling,OntoNotes,2018-10,BiLSTM-Span (Ensemble),87.0,100.0,1.5,0.02,87.0,0.88,ito:ITO_00141,Natural Language Processing,F1
113,1,Predicate Detection,CoNLL 2005,2017-07,DeepSRL,96.4,97.97,96.4,0.98,98.4,0.98,ito:ITO_00141,Natural Language Processing,F1
114,1,Predicate Detection,CoNLL 2005,2018-04,LISA,98.4,100.0,2.0,0.02,98.4,1.0,ito:ITO_00141,Natural Language Processing,F1
115,1,Question Answering,COMPLEXQUESTIONS,2017-07,WebQA,53.6,100.0,53.6,1.0,53.6,0.54,ito:ITO_00141,Natural Language Processing,F1
116,1,Sarcasm Detection,SCv1,2017-08,DeepMoji,0.69,100.0,0.69,1.0,0.69,0.01,ito:ITO_00141,Natural Language Processing,F1
117,1,Relation Extraction,Re-TACRED,2017-09,PA-LSTM,79.4,93.08,79.4,0.93,85.3,0.81,ito:ITO_00141,Natural Language Processing,F1
118,1,Relation Extraction,Re-TACRED,2018-09,C-GCN,80.3,94.14,0.9,0.01,85.3,0.82,ito:ITO_00141,Natural Language Processing,F1
119,1,Relation Extraction,Re-TACRED,2019-07,SpanBERT,85.3,100.0,5.0,0.06,85.3,0.87,ito:ITO_00141,Natural Language Processing,F1
120,1,Relation Extraction,TACRED,2017-09,PA-LSTM,65.1,91.05,65.1,0.91,71.5,0.66,ito:ITO_00141,Natural Language Processing,F1
121,1,Relation Extraction,TACRED,2018-09,GCN + PA-LSTM,67.1,93.85,2.0,0.03,71.5,0.68,ito:ITO_00141,Natural Language Processing,F1
122,1,Relation Extraction,TACRED,2018-09,C-GCN + PA-LSTM,68.2,95.38,1.1,0.02,71.5,0.69,ito:ITO_00141,Natural Language Processing,F1
123,1,Relation Extraction,TACRED,2019-05,R-BERT,69.4,97.06,1.2,0.02,71.5,0.71,ito:ITO_00141,Natural Language Processing,F1
124,1,Relation Extraction,TACRED,2019-06,BERTEM+MTB,71.5,100.0,2.1,0.03,71.5,0.73,ito:ITO_00141,Natural Language Processing,F1
125,1,Named Entity Recognition,Long-tail emerging entities,2017-09,SpinningBytes,40.78,81.24,40.78,0.81,50.2,0.41,ito:ITO_00141,Natural Language Processing,F1
126,1,Named Entity Recognition,Long-tail emerging entities,2018-06,Aguilar et al.,45.55,90.74,4.8,0.1,50.2,0.46,ito:ITO_00141,Natural Language Processing,F1
127,1,Named Entity Recognition,Long-tail emerging entities,2018-08,Flair embeddings,50.2,100.0,4.7,0.09,50.2,0.51,ito:ITO_00141,Natural Language Processing,F1
128,1,Question Answering,SQuAD2.0,2017-11,FusionNet++ (ensemble),72.484,77.96,72.484,0.78,92.978,0.74,ito:ITO_00141,Natural Language Processing,F1
129,1,Question Answering,SQuAD2.0,2017-12,SAN (ensemble model),73.704,79.27,1.2,0.01,92.978,0.75,ito:ITO_00141,Natural Language Processing,F1
130,1,Question Answering,SQuAD2.0,2018-08,Reinforced Mnemonic Reader + Answer Verifier (single model),74.295,79.91,0.6,0.01,92.978,0.76,ito:ITO_00141,Natural Language Processing,F1
131,1,Question Answering,SQuAD2.0,2018-10,BERT (single model),83.061,89.33,8.8,0.09,92.978,0.84,ito:ITO_00141,Natural Language Processing,F1
132,1,Question Answering,SQuAD2.0,2019-06,XLNet (single model),90.689,97.54,7.6,0.08,92.978,0.92,ito:ITO_00141,Natural Language Processing,F1
133,1,Question Answering,SQuAD2.0,2019-08,XLNet + SG-Net Verifier (ensemble),90.702,97.55,0.0,0.0,92.978,0.92,ito:ITO_00141,Natural Language Processing,F1
134,1,Question Answering,SQuAD2.0,2019-09,ALBERT (ensemble model),92.215,99.18,1.5,0.02,92.978,0.94,ito:ITO_00141,Natural Language Processing,F1
135,1,Question Answering,SQuAD2.0,2020-01,Retro-Reader (ensemble),92.978,100.0,0.8,0.01,92.978,0.94,ito:ITO_00141,Natural Language Processing,F1
136,1,Citation Intent Classification,SciCite,2018-01,Feature-Rich Random Forest,79.6,93.66,79.6,0.94,84.99,0.81,ito:ITO_00141,Natural Language Processing,F1
137,1,Citation Intent Classification,SciCite,2019-03,SciBERT,84.99,100.0,5.4,0.06,84.99,0.86,ito:ITO_00141,Natural Language Processing,F1
138,1,Sentence Classification,ACL-ARC,2018-01,Random Forest,53.0,74.67,53.0,0.75,70.98,0.54,ito:ITO_00141,Natural Language Processing,F1
139,1,Sentence Classification,ACL-ARC,2019-03,SciBERT (Base Vocab),65.79,92.69,12.8,0.18,70.98,0.67,ito:ITO_00141,Natural Language Processing,F1
140,1,Sentence Classification,ACL-ARC,2019-03,SciBERT,70.98,100.0,5.2,0.07,70.98,0.72,ito:ITO_00141,Natural Language Processing,F1
141,1,Sentence Classification,SciCite,2018-01,Feature-Rich Random Forest,79.6,93.76,79.6,0.94,84.9,0.81,ito:ITO_00141,Natural Language Processing,F1
142,1,Sentence Classification,SciCite,2018-10,BERT,84.4,99.41,4.8,0.06,84.9,0.86,ito:ITO_00141,Natural Language Processing,F1
143,1,Sentence Classification,SciCite,2019-03,SciBERT,84.9,100.0,0.5,0.01,84.9,0.86,ito:ITO_00141,Natural Language Processing,F1
144,1,Semantic Role Labeling,CoNLL 2005,2018-04,LISA,86.04,97.22,86.04,0.97,88.5,0.87,ito:ITO_00141,Natural Language Processing,F1
145,1,Semantic Role Labeling,CoNLL 2005,2018-10,BiLSTM-Span (Ensemble),88.5,100.0,2.5,0.03,88.5,0.9,ito:ITO_00141,Natural Language Processing,F1
146,1,Entity Linking,WebQSP-WD,2018-04,VCG,0.73,100.0,0.73,1.0,0.73,0.01,ito:ITO_00141,Natural Language Processing,F1
147,1,Predicate Detection,CoNLL 2012,2018-04,LISA,97.2,100.0,97.2,1.0,97.2,0.99,ito:ITO_00141,Natural Language Processing,F1
148,1,Chinese Named Entity Recognition,MSRA,2018-05,Lattice,93.18,96.34,93.18,0.96,96.72,0.95,ito:ITO_00141,Natural Language Processing,F1
149,1,Chinese Named Entity Recognition,MSRA,2019-01,Glyce + BERT,95.54,98.78,2.4,0.02,96.72,0.97,ito:ITO_00141,Natural Language Processing,F1
150,1,Chinese Named Entity Recognition,MSRA,2019-10,BERT-MRC,95.75,99.0,0.2,0.0,96.72,0.97,ito:ITO_00141,Natural Language Processing,F1
151,1,Chinese Named Entity Recognition,MSRA,2019-11,BERT-MRC+DSC,96.72,100.0,1.0,0.01,96.72,0.98,ito:ITO_00141,Natural Language Processing,F1
152,1,Chinese Named Entity Recognition,OntoNotes 4,2018-05,Lattice,73.88,87.46,73.88,0.87,84.47,0.75,ito:ITO_00141,Natural Language Processing,F1
153,1,Chinese Named Entity Recognition,OntoNotes 4,2019-10,BERT-MRC,82.11,97.21,8.2,0.1,84.47,0.83,ito:ITO_00141,Natural Language Processing,F1
154,1,Chinese Named Entity Recognition,OntoNotes 4,2019-11,BERT-MRC+DSC,84.47,100.0,2.4,0.03,84.47,0.86,ito:ITO_00141,Natural Language Processing,F1
155,1,Chinese Named Entity Recognition,Weibo NER,2018-05,Lattice,58.79,86.97,58.79,0.87,67.6,0.6,ito:ITO_00141,Natural Language Processing,F1
156,1,Chinese Named Entity Recognition,Weibo NER,2019-01,Glyce + BERT,67.6,100.0,8.8,0.13,67.6,0.69,ito:ITO_00141,Natural Language Processing,F1
157,1,Chinese Named Entity Recognition,Resume NER,2018-05,Lattice,94.46,97.85,94.46,0.98,96.54,0.96,ito:ITO_00141,Natural Language Processing,F1
158,1,Chinese Named Entity Recognition,Resume NER,2019-01,Glyce + BERT,96.54,100.0,2.1,0.02,96.54,0.98,ito:ITO_00141,Natural Language Processing,F1
159,1,Word Sense Disambiguation,SemEval 2015 Task 13,2018-05,GASext (Concatenation),72.6,87.89,72.6,0.88,82.6,0.74,ito:ITO_00141,Natural Language Processing,F1
160,1,Word Sense Disambiguation,SemEval 2015 Task 13,2018-11,"SemCor+WNGT, vocabulary reduced, ensemble",74.46,90.15,1.9,0.02,82.6,0.76,ito:ITO_00141,Natural Language Processing,F1
161,1,Word Sense Disambiguation,SemEval 2015 Task 13,2019-05,"SemCor+WNGC, hypernyms",82.6,100.0,8.1,0.1,82.6,0.84,ito:ITO_00141,Natural Language Processing,F1
162,1,Named Entity Recognition,CoNLL 2000,2018-05,SWEM-CRF,90.34,100.0,90.34,1.0,90.34,0.92,ito:ITO_00141,Natural Language Processing,F1
163,1,Named Entity Recognition,GENIA,2018-06,Neural layered model,74.7,89.19,74.7,0.89,83.75,0.76,ito:ITO_00141,Natural Language Processing,F1
164,1,Named Entity Recognition,GENIA,2018-10,Neural segmental hypergraphs,75.1,89.67,0.4,0.0,83.75,0.76,ito:ITO_00141,Natural Language Processing,F1
165,1,Named Entity Recognition,GENIA,2019-07,seq2seq+BERT+Flair,78.31,93.5,3.2,0.04,83.75,0.8,ito:ITO_00141,Natural Language Processing,F1
166,1,Named Entity Recognition,GENIA,2019-10,BERT-MRC,83.75,100.0,5.4,0.06,83.75,0.85,ito:ITO_00141,Natural Language Processing,F1
167,1,Nested Named Entity Recognition,GENIA,2018-06,Neural layered model,74.7,89.19,74.7,0.89,83.75,0.76,ito:ITO_00141,Natural Language Processing,F1
168,1,Nested Named Entity Recognition,GENIA,2018-10,Neural segmental hypergraphs,75.1,89.67,0.4,0.0,83.75,0.76,ito:ITO_00141,Natural Language Processing,F1
169,1,Nested Named Entity Recognition,GENIA,2019-08,seq2seq+BERT+Flair,78.31,93.5,3.2,0.04,83.75,0.8,ito:ITO_00141,Natural Language Processing,F1
170,1,Nested Named Entity Recognition,GENIA,2019-10,BERT-MRC,83.75,100.0,5.4,0.06,83.75,0.85,ito:ITO_00141,Natural Language Processing,F1
171,1,Question Answering,CliCR,2018-06,Gated-Attention Reader,33.9,100.0,33.9,1.0,33.9,0.34,ito:ITO_00141,Natural Language Processing,F1
172,1,Named Entity Recognition,ACE 2005,2018-06,Neural layered model,72.2,83.1,72.2,0.83,86.88,0.73,ito:ITO_00141,Natural Language Processing,F1
173,1,Named Entity Recognition,ACE 2005,2018-10,Neural segmental hypergraphs,74.5,85.75,2.3,0.03,86.88,0.76,ito:ITO_00141,Natural Language Processing,F1
174,1,Named Entity Recognition,ACE 2005,2019-06,Anchor-Region Networks,74.9,86.21,0.4,0.0,86.88,0.76,ito:ITO_00141,Natural Language Processing,F1
175,1,Named Entity Recognition,ACE 2005,2019-06,MGNER,78.2,90.01,3.3,0.04,86.88,0.79,ito:ITO_00141,Natural Language Processing,F1
176,1,Named Entity Recognition,ACE 2005,2019-06,Merge and Label,82.4,94.84,4.2,0.05,86.88,0.84,ito:ITO_00141,Natural Language Processing,F1
177,1,Named Entity Recognition,ACE 2005,2019-07,seq2seq+BERT+Flair,84.33,97.06,1.9,0.02,86.88,0.86,ito:ITO_00141,Natural Language Processing,F1
178,1,Named Entity Recognition,ACE 2005,2019-10,BERT-MRC,86.88,100.0,2.5,0.03,86.88,0.88,ito:ITO_00141,Natural Language Processing,F1
179,1,Nested Mention Recognition,ACE 2005,2018-06,Neural layered model,72.2,83.1,72.2,0.83,86.88,0.73,ito:ITO_00141,Natural Language Processing,F1
180,1,Nested Mention Recognition,ACE 2005,2018-10,Neural segmental hypergraphs,74.5,85.75,2.3,0.03,86.88,0.76,ito:ITO_00141,Natural Language Processing,F1
181,1,Nested Mention Recognition,ACE 2005,2019-06,Anchor-Region Networks,74.9,86.21,0.4,0.0,86.88,0.76,ito:ITO_00141,Natural Language Processing,F1
182,1,Nested Mention Recognition,ACE 2005,2019-06,MGNER,78.2,90.01,3.3,0.04,86.88,0.79,ito:ITO_00141,Natural Language Processing,F1
183,1,Nested Mention Recognition,ACE 2005,2019-06,Merge and Label,82.4,94.84,4.2,0.05,86.88,0.84,ito:ITO_00141,Natural Language Processing,F1
184,1,Nested Mention Recognition,ACE 2005,2019-08,seq2seq+BERT+Flair,84.33,97.06,1.9,0.02,86.88,0.86,ito:ITO_00141,Natural Language Processing,F1
185,1,Nested Mention Recognition,ACE 2005,2019-10,BERT-MRC,86.88,100.0,2.5,0.03,86.88,0.88,ito:ITO_00141,Natural Language Processing,F1
186,1,Multimodal Emotion Recognition,IEMOCAP,2018-06,CHFusion (A+T+V),0.768,100.0,0.768,1.0,0.768,0.01,ito:ITO_00141,Natural Language Processing,F1
187,1,Open-Domain Question Answering,SearchQA,2018-07,Denoising QA,64.5,76.06,64.5,0.76,84.8,0.66,ito:ITO_00141,Natural Language Processing,F1
188,1,Open-Domain Question Answering,SearchQA,2019-07,SpanBERT,84.8,100.0,20.3,0.24,84.8,0.86,ito:ITO_00141,Natural Language Processing,F1
189,1,Fact-based Text Editing,Fact-based Text Editing,2018-07,Choi et al. (2018) w augmentation,32.0,79.6,32.0,0.8,40.2,0.33,ito:ITO_00141,Natural Language Processing,F1
190,1,Fact-based Text Editing,Fact-based Text Editing,2019-03,LabelGCN Xiong et al. (2019),36.9,91.79,4.9,0.12,40.2,0.37,ito:ITO_00141,Natural Language Processing,F1
191,1,Fact-based Text Editing,Fact-based Text Editing,2019-05,ELMo (distant denoising data),40.2,100.0,3.3,0.08,40.2,0.41,ito:ITO_00141,Natural Language Processing,F1
192,1,Dependency Parsing,GENIA,2018-08,BiLSTM-CRF,91.92,100.0,91.92,1.0,91.92,0.93,ito:ITO_00141,Natural Language Processing,F1
193,1,Dependency Parsing,GENIA,2018-08,BiLSTM-CRF,92.84,100.0,92.84,1.0,92.84,0.94,ito:ITO_00141,Natural Language Processing,F1
194,1,Question Answering,SQuAD2.0 dev,2018-08,RMR + ELMo (Model-III),74.8,82.56,74.8,0.83,90.6,0.76,ito:ITO_00141,Natural Language Processing,F1
195,1,Question Answering,SQuAD2.0 dev,2018-10,BERT large,81.9,90.4,7.1,0.08,90.6,0.83,ito:ITO_00141,Natural Language Processing,F1
196,1,Question Answering,SQuAD2.0 dev,2019-06,XLNet (single model),90.6,100.0,8.7,0.1,90.6,0.92,ito:ITO_00141,Natural Language Processing,F1
197,1,Sentence Classification,PubMed 20k RCT,2018-08,Hierarchical Neural Networks,92.6,100.0,92.6,1.0,92.6,0.94,ito:ITO_00141,Natural Language Processing,F1
198,1,Named Entity Recognition,BC5CDR,2018-09,CollaboNet,87.12,96.88,87.12,0.97,89.93,0.89,ito:ITO_00141,Natural Language Processing,F1
199,1,Named Entity Recognition,BC5CDR,2019-03,SciBERT (SciVocab),88.94,98.9,1.8,0.02,89.93,0.9,ito:ITO_00141,Natural Language Processing,F1
200,1,Named Entity Recognition,BC5CDR,2019-08,BioFLAIR,89.42,99.43,0.5,0.01,89.93,0.91,ito:ITO_00141,Natural Language Processing,F1
201,1,Named Entity Recognition,BC5CDR,2019-11,NER+PA+RL (PubMed),89.93,100.0,0.5,0.01,89.93,0.91,ito:ITO_00141,Natural Language Processing,F1
202,1,Named Entity Recognition,JNLPBA,2018-09,CollaboNet,78.58,100.0,78.58,1.0,78.58,0.8,ito:ITO_00141,Natural Language Processing,F1
203,1,Chinese Named Entity Recognition,SighanNER,2018-10,BiLSTM+CRF+adversarial+self-attention,90.64,100.0,90.64,1.0,90.64,0.92,ito:ITO_00141,Natural Language Processing,F1
204,1,Nested Named Entity Recognition,ACE 2004,2018-10,Neural segmental hypergraphs,75.1,87.35,75.1,0.87,85.98,0.76,ito:ITO_00141,Natural Language Processing,F1
205,1,Nested Named Entity Recognition,ACE 2004,2019-06,MGNER,79.5,92.46,4.4,0.05,85.98,0.81,ito:ITO_00141,Natural Language Processing,F1
206,1,Nested Named Entity Recognition,ACE 2004,2019-08,seq2seq+BERT+Flair,84.4,98.16,4.9,0.06,85.98,0.86,ito:ITO_00141,Natural Language Processing,F1
207,1,Nested Named Entity Recognition,ACE 2004,2019-09,Second-best learning and decoding,84.97,98.83,0.6,0.01,85.98,0.86,ito:ITO_00141,Natural Language Processing,F1
208,1,Nested Named Entity Recognition,ACE 2004,2019-10,BERT-MRC,85.98,100.0,1.0,0.01,85.98,0.87,ito:ITO_00141,Natural Language Processing,F1
209,1,Nested Named Entity Recognition,ACE 2005,2018-10,neural transition-based model,73.0,96.18,73.0,0.96,75.9,0.74,ito:ITO_00141,Natural Language Processing,F1
210,1,Nested Named Entity Recognition,ACE 2005,2019-06,Anchor-Region Networks,75.9,100.0,2.9,0.04,75.9,0.77,ito:ITO_00141,Natural Language Processing,F1
211,1,Named Entity Recognition,ACE 2004,2018-10,Neural segmental hypergraphs,75.1,87.35,75.1,0.87,85.98,0.76,ito:ITO_00141,Natural Language Processing,F1
212,1,Named Entity Recognition,ACE 2004,2019-06,MGNER,79.5,92.46,4.4,0.05,85.98,0.81,ito:ITO_00141,Natural Language Processing,F1
213,1,Named Entity Recognition,ACE 2004,2019-07,seq2seq+BERT+Flair,84.4,98.16,4.9,0.06,85.98,0.86,ito:ITO_00141,Natural Language Processing,F1
214,1,Named Entity Recognition,ACE 2004,2019-09,Second-best learning and decoding,84.97,98.83,0.6,0.01,85.98,0.86,ito:ITO_00141,Natural Language Processing,F1
215,1,Named Entity Recognition,ACE 2004,2019-10,BERT-MRC,85.98,100.0,1.0,0.01,85.98,0.87,ito:ITO_00141,Natural Language Processing,F1
216,1,Nested Mention Recognition,ACE 2004,2018-10,Neural segmental hypergraphs,75.1,87.35,75.1,0.87,85.98,0.76,ito:ITO_00141,Natural Language Processing,F1
217,1,Nested Mention Recognition,ACE 2004,2019-06,MGNER,79.5,92.46,4.4,0.05,85.98,0.81,ito:ITO_00141,Natural Language Processing,F1
218,1,Nested Mention Recognition,ACE 2004,2019-08,seq2seq+BERT+Flair,84.4,98.16,4.9,0.06,85.98,0.86,ito:ITO_00141,Natural Language Processing,F1
219,1,Nested Mention Recognition,ACE 2004,2019-09,Second-best learning and decoding,84.97,98.83,0.6,0.01,85.98,0.86,ito:ITO_00141,Natural Language Processing,F1
220,1,Nested Mention Recognition,ACE 2004,2019-10,BERT-MRC,85.98,100.0,1.0,0.01,85.98,0.87,ito:ITO_00141,Natural Language Processing,F1
221,1,Question Answering,QuAC,2018-10,FlowQA (single model),64.1,100.0,64.1,1.0,64.1,0.65,ito:ITO_00141,Natural Language Processing,F1
222,1,Named Entity Recognition,NCBI-disease,2018-10,BERT Base,86.37,96.28,86.37,0.96,89.71,0.88,ito:ITO_00141,Natural Language Processing,F1
223,1,Named Entity Recognition,NCBI-disease,2019-01,BioBERT,89.71,100.0,3.3,0.04,89.71,0.91,ito:ITO_00141,Natural Language Processing,F1
224,1,Slot Filling,SNIPS,2018-12,Capsule-NLU,0.918,99.53,0.918,1.0,0.9223,0.01,ito:ITO_00141,Natural Language Processing,F1
225,1,Slot Filling,SNIPS,2019-06,SF-ID,0.9223,100.0,0.0,0.0,0.9223,0.01,ito:ITO_00141,Natural Language Processing,F1
226,1,Slot Filling,ATIS,2018-12,Capsule-NLU,0.952,99.37,0.952,0.99,0.958,0.01,ito:ITO_00141,Natural Language Processing,F1
227,1,Slot Filling,ATIS,2019-06,SF-ID,0.958,100.0,0.0,0.0,0.958,0.01,ito:ITO_00141,Natural Language Processing,F1
228,1,Relation Extraction,ChemProt,2019-01,BioBERT,76.46,91.42,76.46,0.91,83.64,0.78,ito:ITO_00141,Natural Language Processing,F1
229,1,Relation Extraction,ChemProt,2019-03,SciBert (Finetune),83.64,100.0,7.2,0.09,83.64,0.85,ito:ITO_00141,Natural Language Processing,F1
230,1,Chinese Word Segmentation,MSR,2019-01,Glyce + BERT,98.3,99.95,98.3,1.0,98.35,1.0,ito:ITO_00141,Natural Language Processing,F1
231,1,Chinese Word Segmentation,MSR,2019-11,ZEN (Init with Chinese BERT),98.35,100.0,0.0,0.0,98.35,1.0,ito:ITO_00141,Natural Language Processing,F1
232,1,Chinese Word Segmentation,AS,2019-01,Glyce + BERT,96.7,100.0,96.7,1.0,96.7,0.98,ito:ITO_00141,Natural Language Processing,F1
233,1,Chinese Word Segmentation,PKU,2019-01,Glyce + BERT,96.7,100.0,96.7,1.0,96.7,0.98,ito:ITO_00141,Natural Language Processing,F1
234,1,Chinese Word Segmentation,CITYU,2019-01,Glyce + BERT,97.9,100.0,97.9,1.0,97.9,0.99,ito:ITO_00141,Natural Language Processing,F1
235,1,Chinese Named Entity Recognition,OntoNotes,2019-01,Glyce + BERT,80.62,100.0,80.62,1.0,80.62,0.82,ito:ITO_00141,Natural Language Processing,F1
236,1,Paraphrase Identification,Quora Question Pairs,2019-01,MT-DNN,72.4,97.57,72.4,0.98,74.2,0.74,ito:ITO_00141,Natural Language Processing,F1
237,1,Paraphrase Identification,Quora Question Pairs,2019-06,XLNet-Large (ensemble),74.2,100.0,1.8,0.02,74.2,0.75,ito:ITO_00141,Natural Language Processing,F1
238,1,Document Classification,Reuters-21578,2019-02,VLAWE,89.3,99.33,89.3,0.99,89.9,0.91,ito:ITO_00141,Natural Language Processing,F1
239,1,Document Classification,Reuters-21578,2020-02,MAGNET,89.9,100.0,0.6,0.01,89.9,0.91,ito:ITO_00141,Natural Language Processing,F1
240,1,Sentence Classification,Paper Field,2019-03,SciBERT (SciVocab),64.07,97.5,64.07,0.98,65.71,0.65,ito:ITO_00141,Natural Language Processing,F1
241,1,Sentence Classification,Paper Field,2019-03,SciBERT (SciVocab),65.71,100.0,1.6,0.02,65.71,0.67,ito:ITO_00141,Natural Language Processing,F1
242,1,Sentence Classification,ScienceCite,2019-03,SciBERT (SciVocab),84.99,100.0,84.99,1.0,84.99,0.86,ito:ITO_00141,Natural Language Processing,F1
243,1,Relation Extraction,JNLPBA,2019-03,SciBERT (SciVocab),76.09,100.0,76.09,1.0,76.09,0.77,ito:ITO_00141,Natural Language Processing,F1
244,1,Relation Extraction,SciERC,2019-03,SciBERT (SciVocab),74.64,100.0,74.64,1.0,74.64,0.76,ito:ITO_00141,Natural Language Processing,F1
245,1,Named Entity Recognition,WetLab,2019-04,BiLSTM-CRF with ELMo,79.62,100.0,79.62,1.0,79.62,0.81,ito:ITO_00141,Natural Language Processing,F1
246,1,Relation Extraction,WLPC,2019-04,DyGIE,64.1,100.0,64.1,1.0,64.1,0.65,ito:ITO_00141,Natural Language Processing,F1
247,1,Named Entity Recognition,WLPC,2019-04,DyGIE,79.5,100.0,79.5,1.0,79.5,0.81,ito:ITO_00141,Natural Language Processing,F1
248,1,Speech Emotion Recognition,IEMOCAP,2019-04,Ensemble (Random Forests + Gradient Boosted Trees + Multi Layer Perceptron + Multinomial Naive Bayes + Logistic Regression) / (A+T),0.718,100.0,0.718,1.0,0.718,0.01,ito:ITO_00141,Natural Language Processing,F1
249,1,Document Classification,AAPD,2019-04,KD-LSTMreg,72.9,100.0,72.9,1.0,72.9,0.74,ito:ITO_00141,Natural Language Processing,F1
250,1,Chinese Named Entity Recognition,MSRA Dev,2019-04,ERNIE,95.0,98.65,95.0,0.99,96.3,0.97,ito:ITO_00141,Natural Language Processing,F1
251,1,Chinese Named Entity Recognition,MSRA Dev,2019-07,ERNIE 2.0 Large,96.3,100.0,1.3,0.01,96.3,0.98,ito:ITO_00141,Natural Language Processing,F1
252,1,Relation Extraction,FewRel,2019-05,ERNIE,88.32,100.0,88.32,1.0,88.32,0.9,ito:ITO_00141,Natural Language Processing,F1
253,1,Entity Typing,Open Entity,2019-05,ERNIE,75.56,100.0,75.56,1.0,75.56,0.77,ito:ITO_00141,Natural Language Processing,F1
254,1,Distractor Generation,Distractor Generation,2019-05,ERNIE,75.56,100.0,75.56,1.0,75.56,0.77,ito:ITO_00141,Natural Language Processing,F1
255,1,Relation Extraction,DocRED,2019-06,Context-Aware,50.7,84.63,50.7,0.85,59.91,0.52,ito:ITO_00141,Natural Language Processing,F1
256,1,Relation Extraction,DocRED,2019-06,BiLSTM,51.06,85.23,0.4,0.01,59.91,0.52,ito:ITO_00141,Natural Language Processing,F1
257,1,Relation Extraction,DocRED,2019-09,BERT-Two-Step,53.92,90.0,2.9,0.05,59.91,0.55,ito:ITO_00141,Natural Language Processing,F1
258,1,Relation Extraction,DocRED,2020-03,HIN-BERT,55.6,92.81,1.7,0.03,59.91,0.57,ito:ITO_00141,Natural Language Processing,F1
259,1,Relation Extraction,DocRED,2020-04,CorefRoBERTaLarge,59.91,100.0,4.3,0.07,59.91,0.61,ito:ITO_00141,Natural Language Processing,F1
260,1,Sentiment Analysis,ChnSentiCorp Dev,2019-06,RoBERTa-wwm-ext-large,95.8,100.0,95.8,1.0,95.8,0.97,ito:ITO_00141,Natural Language Processing,F1
261,1,Sentiment Analysis,ChnSentiCorp,2019-06,RoBERTa-wwm-ext-large,95.8,100.0,95.8,1.0,95.8,0.97,ito:ITO_00141,Natural Language Processing,F1
262,1,Intent Detection,ATIS,2019-06,SF-ID (BLSTM) network,95.8,100.0,95.8,1.0,95.8,0.97,ito:ITO_00141,Natural Language Processing,F1
263,1,Question Answering,NaturalQA,2019-07,SpanBERT,82.5,100.0,82.5,1.0,82.5,0.84,ito:ITO_00141,Natural Language Processing,F1
264,1,Named Entity Recognition,LINNAEUS,2019-08,BioFLAIR,87.02,100.0,87.02,1.0,87.02,0.88,ito:ITO_00141,Natural Language Processing,F1
265,1,Named Entity Recognition,Species-800,2019-08,BioFLAIR,82.44,100.0,82.44,1.0,82.44,0.84,ito:ITO_00141,Natural Language Processing,F1
266,1,Named Entity Recognition,Code-Switching English-Spanish NER,2019-09,HME (word + BPE + char),69.17,100.0,69.17,1.0,69.17,0.7,ito:ITO_00141,Natural Language Processing,F1
267,1,Named Entity Recognition,ontontoes chinese v5,2019-09,DGLSTM-CRF,79.92,100.0,79.92,1.0,79.92,0.81,ito:ITO_00141,Natural Language Processing,F1
268,1,Question Answering,ReCoRD,2019-10,T5-11B,93.3,100.0,93.3,1.0,93.3,0.95,ito:ITO_00141,Natural Language Processing,F1
269,1,Natural Language Inference,CommitmentBank,2019-10,T5-11B,93.0,100.0,93,1.0,93,0.95,ito:ITO_00141,Natural Language Processing,F1
270,1,Named Entity Recognition,French Treebank,2019-11,CamemBERT (subword masking),87.93,100.0,87.93,1.0,87.93,0.89,ito:ITO_00141,Natural Language Processing,F1
271,1,Negation Scope Resolution,SFU Review Corpus,2019-11,NegBERT,90.95,99.67,90.95,1.0,91.25,0.92,ito:ITO_00141,Natural Language Processing,F1
272,1,Negation Scope Resolution,SFU Review Corpus,2020-01,XLNet,91.25,100.0,0.3,0.0,91.25,0.93,ito:ITO_00141,Natural Language Processing,F1
273,1,Negation Scope Resolution,_sem 2012 Shared Task: Sherlock Dataset,2019-11,NegBERT,92.36,100.0,92.36,1.0,92.36,0.94,ito:ITO_00141,Natural Language Processing,F1
274,1,Negation Scope Resolution,BioScope : Abstracts,2019-11,NegBERT,95.68,99.94,95.68,1.0,95.74,0.97,ito:ITO_00141,Natural Language Processing,F1
275,1,Negation Scope Resolution,BioScope : Abstracts,2020-01,XLNet,95.74,100.0,0.1,0.0,95.74,0.97,ito:ITO_00141,Natural Language Processing,F1
276,1,Negation Scope Resolution,BioScope : Full Papers,2019-11,NegBERT,91.24,96.65,91.24,0.97,94.4,0.93,ito:ITO_00141,Natural Language Processing,F1
277,1,Negation Scope Resolution,BioScope : Full Papers,2020-01,XLNet,94.4,100.0,3.2,0.03,94.4,0.96,ito:ITO_00141,Natural Language Processing,F1
278,1,Relation Extraction,NYT29,2019-11,WDec,71.6,100.0,71.6,1.0,71.6,0.73,ito:ITO_00141,Natural Language Processing,F1
279,1,Relation Extraction,NYT24,2019-11,WDec,84.4,100.0,84.4,1.0,84.4,0.86,ito:ITO_00141,Natural Language Processing,F1
280,1,Intent Detection,ASOS.com user intent,2019-12,plain-LSTM,0.887,100.0,0.887,1.0,0.887,0.01,ito:ITO_00141,Natural Language Processing,F1
281,1,Speculation Scope Resolution,SFU Review Corpus,2020-01,XLNet,91.0,100.0,91,1.0,91,0.92,ito:ITO_00141,Natural Language Processing,F1
282,1,Speculation Scope Resolution,BioScope : Abstracts,2020-01,XLNet,97.87,100.0,97.87,1.0,97.87,0.99,ito:ITO_00141,Natural Language Processing,F1
283,1,Extractive Summarization,Extractive Summarization,2020-01,XLNet,97.87,100.0,97.87,1.0,97.87,0.99,ito:ITO_00141,Natural Language Processing,F1
284,1,Speculation Scope Resolution,BioScope : Full Papers,2020-01,XLNet,96.91,100.0,96.91,1.0,96.91,0.98,ito:ITO_00141,Natural Language Processing,F1
285,1,NER,NER,2020-01,XLNet,91.0,100.0,91,1.0,91,0.92,ito:ITO_00141,Natural Language Processing,F1
286,1,Event Extraction,Event Extraction,2020-01,XLNet,96.91,100.0,96.91,1.0,96.91,0.98,ito:ITO_00141,Natural Language Processing,F1
287,1,Sentiment Analysis,DBRD,2020-01,RobBERT,94.422,100.0,94.422,1.0,94.422,0.96,ito:ITO_00141,Natural Language Processing,F1
288,1,Question Answering,FQuAD,2020-02,CamemBERTQA,88.0,100.0,88,1.0,88,0.89,ito:ITO_00141,Natural Language Processing,F1
289,1,Multi-Label Text Classification,AAPD,2020-02,MAGNET,69.6,100.0,69.6,1.0,69.6,0.71,ito:ITO_00141,Natural Language Processing,F1
290,1,Named Entity Recognition,SoSciSoCi,2020-03,Bi-LSTM-CRF (SSC->GSC),0.82,100.0,0.82,1.0,0.82,0.01,ito:ITO_00141,Natural Language Processing,F1
0,1,Paraphrase Identification,MSRP,2013-10,NMF factorization-unigrams-TFKLD,72.75,90.47,72.75,0.9,80.41,0.73,ito:ITO_00141,Natural Language Processing,Accuracy
1,1,Paraphrase Identification,MSRP,2013-10,"FEAT2, TFKLD, SVM, Fine-grained features",80.41,100.0,7.7,0.1,80.41,0.81,ito:ITO_00141,Natural Language Processing,Accuracy
2,1,Sentiment Analysis,SST-2 Binary classification,2013-10,RNTN,85.4,87.68,85.4,0.88,97.4,0.86,ito:ITO_00141,Natural Language Processing,Accuracy
3,1,Sentiment Analysis,SST-2 Binary classification,2014-08,CNN-MC [kim:13],88.1,90.45,2.7,0.03,97.4,0.88,ito:ITO_00141,Natural Language Processing,Accuracy
4,1,Sentiment Analysis,SST-2 Binary classification,2015-06,DMN [ankit16],88.6,90.97,0.5,0.01,97.4,0.89,ito:ITO_00141,Natural Language Processing,Accuracy
5,1,Sentiment Analysis,SST-2 Binary classification,2016-03,CNN + Logic rules,89.3,91.68,0.7,0.01,97.4,0.9,ito:ITO_00141,Natural Language Processing,Accuracy
6,1,Sentiment Analysis,SST-2 Binary classification,2016-07,Neural Semantic Encoder,89.7,92.09,0.4,0.0,97.4,0.9,ito:ITO_00141,Natural Language Processing,Accuracy
7,1,Sentiment Analysis,SST-2 Binary classification,2017-04,bmLSTM,91.8,94.25,2.1,0.02,97.4,0.92,ito:ITO_00141,Natural Language Processing,Accuracy
8,1,Sentiment Analysis,SST-2 Binary classification,2017-12,Block-sparse LSTM,93.2,95.69,1.4,0.01,97.4,0.94,ito:ITO_00141,Natural Language Processing,Accuracy
9,1,Sentiment Analysis,SST-2 Binary classification,2018-10,Bidirectional Encoder Representations from Transformers ,94.9,97.43,1.7,0.02,97.4,0.95,ito:ITO_00141,Natural Language Processing,Accuracy
10,1,Sentiment Analysis,SST-2 Binary classification,2019-01,MT-DNN,95.6,98.15,0.7,0.01,97.4,0.96,ito:ITO_00141,Natural Language Processing,Accuracy
11,1,Sentiment Analysis,SST-2 Binary classification,2019-06,XLNet-Large (ensemble),96.8,99.38,1.2,0.01,97.4,0.97,ito:ITO_00141,Natural Language Processing,Accuracy
12,1,Sentiment Analysis,SST-2 Binary classification,2019-06,XLNet (single model),97.0,99.59,0.2,0.0,97.4,0.97,ito:ITO_00141,Natural Language Processing,Accuracy
13,1,Sentiment Analysis,SST-2 Binary classification,2019-09,ALBERT,97.1,99.69,0.1,0.0,97.4,0.97,ito:ITO_00141,Natural Language Processing,Accuracy
14,1,Sentiment Analysis,SST-2 Binary classification,2019-10,T5-3B,97.4,100.0,0.3,0.0,97.4,0.98,ito:ITO_00141,Natural Language Processing,Accuracy
15,1,Semantic Textual Similarity,MRPC,2013-10,TF-KLD,80.4,86.08,80.4,0.86,93.4,0.81,ito:ITO_00141,Natural Language Processing,Accuracy
16,1,Semantic Textual Similarity,MRPC,2019-05,ERNIE,88.2,94.43,7.8,0.08,93.4,0.89,ito:ITO_00141,Natural Language Processing,Accuracy
17,1,Semantic Textual Similarity,MRPC,2019-06,XLNet (single model),90.8,97.22,2.6,0.03,93.4,0.91,ito:ITO_00141,Natural Language Processing,Accuracy
18,1,Semantic Textual Similarity,MRPC,2019-07,SpanBERT,90.9,97.32,0.1,0.0,93.4,0.91,ito:ITO_00141,Natural Language Processing,Accuracy
19,1,Semantic Textual Similarity,MRPC,2019-07,RoBERTa,92.3,98.82,1.4,0.01,93.4,0.93,ito:ITO_00141,Natural Language Processing,Accuracy
20,1,Semantic Textual Similarity,MRPC,2019-09,ALBERT,93.4,100.0,1.1,0.01,93.4,0.94,ito:ITO_00141,Natural Language Processing,Accuracy
21,1,Sentiment Analysis,SST-5 Fine-grained classification,2013-10,MV-RNN,44.4,79.0,44.4,0.79,56.2,0.45,ito:ITO_00141,Natural Language Processing,Accuracy
22,1,Sentiment Analysis,SST-5 Fine-grained classification,2013-10,RNTN,45.7,81.32,1.3,0.02,56.2,0.46,ito:ITO_00141,Natural Language Processing,Accuracy
23,1,Sentiment Analysis,SST-5 Fine-grained classification,2014-06,Epic,49.6,88.26,3.9,0.07,56.2,0.5,ito:ITO_00141,Natural Language Processing,Accuracy
24,1,Sentiment Analysis,SST-5 Fine-grained classification,2015-02,Constituency Tree-LSTM,51.0,90.75,1.4,0.02,56.2,0.51,ito:ITO_00141,Natural Language Processing,Accuracy
25,1,Sentiment Analysis,SST-5 Fine-grained classification,2017-08,BCN+Char+CoVe,53.7,95.55,2.7,0.05,56.2,0.54,ito:ITO_00141,Natural Language Processing,Accuracy
26,1,Sentiment Analysis,SST-5 Fine-grained classification,2018-02,BCN+ELMo,54.7,97.33,1.0,0.02,56.2,0.55,ito:ITO_00141,Natural Language Processing,Accuracy
27,1,Sentiment Analysis,SST-5 Fine-grained classification,2018-05,BCN+Suffix BiLSTM-Tied+CoVe,56.2,100.0,1.5,0.03,56.2,0.56,ito:ITO_00141,Natural Language Processing,Accuracy
28,1,Cross-Lingual Document Classification,Reuters RCV1/RCV2 English-to-German,2013-12,biCVM+,86.2,92.99,86.2,0.93,92.7,0.87,ito:ITO_00141,Natural Language Processing,Accuracy
29,1,Cross-Lingual Document Classification,Reuters RCV1/RCV2 English-to-German,2014-04,Bi+,88.1,95.04,1.9,0.02,92.7,0.88,ito:ITO_00141,Natural Language Processing,Accuracy
30,1,Cross-Lingual Document Classification,Reuters RCV1/RCV2 English-to-German,2014-12,Biinclusion (Euro500kReuters),92.7,100.0,4.6,0.05,92.7,0.93,ito:ITO_00141,Natural Language Processing,Accuracy
31,1,Cross-Lingual Document Classification,Reuters RCV1/RCV2 German-to-English,2013-12,biCVM+,76.9,91.11,76.9,0.91,84.4,0.77,ito:ITO_00141,Natural Language Processing,Accuracy
32,1,Cross-Lingual Document Classification,Reuters RCV1/RCV2 German-to-English,2014-04,Bi+,79.2,93.84,2.3,0.03,84.4,0.8,ito:ITO_00141,Natural Language Processing,Accuracy
33,1,Cross-Lingual Document Classification,Reuters RCV1/RCV2 German-to-English,2014-12,Biinclusion (Euro500kReuters),84.4,100.0,5.2,0.06,84.4,0.85,ito:ITO_00141,Natural Language Processing,Accuracy
34,1,Node Classification,BlogCatalog,2014-03,DeepWalk,22.5,26.5,22.5,0.27,84.9,0.23,ito:ITO_00141,Natural Language Processing,Accuracy
35,1,Node Classification,BlogCatalog,2017-04,Struc2vec,22.8,26.86,0.3,0.0,84.9,0.23,ito:ITO_00141,Natural Language Processing,Accuracy
36,1,Node Classification,BlogCatalog,2017-11,GraphGAN,23.2,27.33,0.4,0.0,84.9,0.23,ito:ITO_00141,Natural Language Processing,Accuracy
37,1,Node Classification,BlogCatalog,2019-06,DEMO-Net(weight),84.9,100.0,61.7,0.73,84.9,0.85,ito:ITO_00141,Natural Language Processing,Accuracy
38,1,Spoken language identification,Spoken language identification,2014-03,DeepWalk,22.5,26.5,22.5,0.27,84.9,0.23,ito:ITO_00141,Natural Language Processing,Accuracy
39,1,Spoken language identification,Spoken language identification,2017-04,Struc2vec,22.8,26.86,0.3,0.0,84.9,0.23,ito:ITO_00141,Natural Language Processing,Accuracy
40,1,Spoken language identification,Spoken language identification,2017-11,GraphGAN,23.2,27.33,0.4,0.0,84.9,0.23,ito:ITO_00141,Natural Language Processing,Accuracy
41,1,Spoken language identification,Spoken language identification,2019-06,DEMO-Net(weight),84.9,100.0,61.7,0.73,84.9,0.85,ito:ITO_00141,Natural Language Processing,Accuracy
42,1,Document Classification,Cora,2014-03,DeepWalk,67.2,80.48,67.2,0.8,83.5,0.67,ito:ITO_00141,Natural Language Processing,Accuracy
43,1,Document Classification,Cora,2016-03,Planetoid*,75.7,90.66,8.5,0.1,83.5,0.76,ito:ITO_00141,Natural Language Processing,Accuracy
44,1,Document Classification,Cora,2016-09,Graph-CNN,81.5,97.6,5.8,0.07,83.5,0.82,ito:ITO_00141,Natural Language Processing,Accuracy
45,1,Document Classification,Cora,2016-11,MoNet,81.7,97.84,0.2,0.0,83.5,0.82,ito:ITO_00141,Natural Language Processing,Accuracy
46,1,Document Classification,Cora,2017-10,GAT,83.0,99.4,1.3,0.02,83.5,0.83,ito:ITO_00141,Natural Language Processing,Accuracy
47,1,Document Classification,Cora,2018-08,LGCN,83.3,99.76,0.3,0.0,83.5,0.84,ito:ITO_00141,Natural Language Processing,Accuracy
48,1,Document Classification,Cora,2019-04,ACNet,83.5,100.0,0.2,0.0,83.5,0.84,ito:ITO_00141,Natural Language Processing,Accuracy
49,1,Question Answering,Reverb,2014-04,Weakly Supervised Embeddings,73.0,100.0,73,1.0,73,0.73,ito:ITO_00141,Natural Language Processing,Accuracy
50,1,Text Classification,IMDb,2014-05,Paragraph Vectors Le & Mikolov (2014),92.58,95.64,92.58,0.96,96.8,0.93,ito:ITO_00141,Natural Language Processing,Accuracy
51,1,Text Classification,IMDb,2019-01,HAHNN (CNN),95.17,98.32,2.6,0.03,96.8,0.96,ito:ITO_00141,Natural Language Processing,Accuracy
52,1,Text Classification,IMDb,2019-04,BERT Finetune + UDA,95.8,98.97,0.6,0.01,96.8,0.96,ito:ITO_00141,Natural Language Processing,Accuracy
53,1,Text Classification,IMDb,2019-06,XLNet,96.8,100.0,1.0,0.01,96.8,0.97,ito:ITO_00141,Natural Language Processing,Accuracy
54,1,Document Classification,Reuters En-De,2014-10,BilBOWA,86.5,100.0,86.5,1.0,86.5,0.87,ito:ITO_00141,Natural Language Processing,Accuracy
55,1,Document Classification,Reuters De-En,2014-10,BilBOWA,75.0,100.0,75,1.0,75,0.75,ito:ITO_00141,Natural Language Processing,Accuracy
56,1,Semantic Parsing,ATIS,2014-11,"ZH15 (Zhao and Huang, 2015)",84.2,97.68,84.2,0.98,86.2,0.85,ito:ITO_00141,Natural Language Processing,Accuracy
57,1,Semantic Parsing,ATIS,2017-04,"ASN (Rabinovich et al., 2017)",85.3,98.96,1.1,0.01,86.2,0.86,ito:ITO_00141,Natural Language Processing,Accuracy
58,1,Semantic Parsing,ATIS,2018-10,Tranx,86.2,100.0,0.9,0.01,86.2,0.87,ito:ITO_00141,Natural Language Processing,Accuracy
59,1,Sentiment Analysis,IMDb,2014-12,seq2-bown-CNN,92.33,94.79,92.33,0.95,97.4,0.93,ito:ITO_00141,Natural Language Processing,Accuracy
60,1,Sentiment Analysis,IMDb,2016-02,oh-LSTM,94.1,96.61,1.8,0.02,97.4,0.94,ito:ITO_00141,Natural Language Processing,Accuracy
61,1,Sentiment Analysis,IMDb,2017-12,Block-sparse LSTM,94.99,97.53,0.9,0.01,97.4,0.95,ito:ITO_00141,Natural Language Processing,Accuracy
62,1,Sentiment Analysis,IMDb,2018-01,ULMFiT,95.4,97.95,0.4,0.0,97.4,0.96,ito:ITO_00141,Natural Language Processing,Accuracy
63,1,Sentiment Analysis,IMDb,2019-02,L MIXED,95.68,98.23,0.3,0.0,97.4,0.96,ito:ITO_00141,Natural Language Processing,Accuracy
64,1,Sentiment Analysis,IMDb,2019-04,BERT large finetune UDA,95.8,98.36,0.1,0.0,97.4,0.96,ito:ITO_00141,Natural Language Processing,Accuracy
65,1,Sentiment Analysis,IMDb,2019-06,XLNet,96.21,98.78,0.4,0.0,97.4,0.97,ito:ITO_00141,Natural Language Processing,Accuracy
66,1,Sentiment Analysis,IMDb,2019-07,NB-weighted-BON + dv-cosine,97.4,100.0,1.2,0.01,97.4,0.98,ito:ITO_00141,Natural Language Processing,Accuracy
67,1,Subjectivity Analysis,SUBJ,2015-04,AdaSent,95.5,100.0,95.5,1.0,95.5,0.96,ito:ITO_00141,Natural Language Processing,Accuracy
68,1,Part-Of-Speech Tagging,Penn Treebank,2015-08,Bi-LSTM,97.36,99.39,97.36,0.99,97.96,0.98,ito:ITO_00141,Natural Language Processing,Accuracy
69,1,Part-Of-Speech Tagging,Penn Treebank,2015-08,Char Bi-LSTM,97.78,99.82,0.4,0.0,97.96,0.98,ito:ITO_00141,Natural Language Processing,Accuracy
70,1,Part-Of-Speech Tagging,Penn Treebank,2018-05,Meta BiLSTM,97.96,100.0,0.2,0.0,97.96,0.98,ito:ITO_00141,Natural Language Processing,Accuracy
71,1,Machine Translation,20NEWS,2015-08,12,1.0,100.0,1,1.0,1,0.01,ito:ITO_00141,Natural Language Processing,Accuracy
72,1,Visual Question Answering,VQA v1 test-std,2015-11,SAN (VGG),58.9,91.18,58.9,0.91,64.6,0.59,ito:ITO_00141,Natural Language Processing,Accuracy
73,1,Visual Question Answering,VQA v1 test-std,2016-03,DMN+,60.4,93.5,1.5,0.02,64.6,0.61,ito:ITO_00141,Natural Language Processing,Accuracy
74,1,Visual Question Answering,VQA v1 test-std,2016-05,HieCoAtt (ResNet),62.1,96.13,1.7,0.03,64.6,0.62,ito:ITO_00141,Natural Language Processing,Accuracy
75,1,Visual Question Answering,VQA v1 test-std,2016-06,RAU (ResNet),63.2,97.83,1.1,0.02,64.6,0.63,ito:ITO_00141,Natural Language Processing,Accuracy
76,1,Visual Question Answering,VQA v1 test-std,2017-04,SAAA (ResNet),64.6,100.0,1.4,0.02,64.6,0.65,ito:ITO_00141,Natural Language Processing,Accuracy
77,1,Visual Question Answering,VQA v1 test-dev,2015-11,NMN+LSTM+FT,58.6,90.85,58.6,0.91,64.5,0.59,ito:ITO_00141,Natural Language Processing,Accuracy
78,1,Visual Question Answering,VQA v1 test-dev,2016-03,DMN+,60.3,93.49,1.7,0.03,64.5,0.61,ito:ITO_00141,Natural Language Processing,Accuracy
79,1,Visual Question Answering,VQA v1 test-dev,2016-05,HieCoAtt (ResNet),61.8,95.81,1.5,0.02,64.5,0.62,ito:ITO_00141,Natural Language Processing,Accuracy
80,1,Visual Question Answering,VQA v1 test-dev,2016-06,MCB (ResNet),64.2,99.53,2.4,0.04,64.5,0.64,ito:ITO_00141,Natural Language Processing,Accuracy
81,1,Visual Question Answering,VQA v1 test-dev,2016-11,DAN (ResNet),64.3,99.69,0.1,0.0,64.5,0.65,ito:ITO_00141,Natural Language Processing,Accuracy
82,1,Visual Question Answering,VQA v1 test-dev,2017-04,SAAA (ResNet),64.5,100.0,0.2,0.0,64.5,0.65,ito:ITO_00141,Natural Language Processing,Accuracy
83,1,Entity Linking,AIDA-CoNLL,2016-01,Wikipedia2Vec-GBRT,93.1,98.31,93.1,0.98,94.7,0.93,ito:ITO_00141,Natural Language Processing,Accuracy
84,1,Entity Linking,AIDA-CoNLL,2017-05,NTEE,94.7,100.0,1.6,0.02,94.7,0.95,ito:ITO_00141,Natural Language Processing,Accuracy
85,1,Text Classification,RCV1,2016-02,One-hot CNN+ Johnson & Zhang ([2016b]),94.13,100.0,94.13,1.0,94.13,0.95,ito:ITO_00141,Natural Language Processing,Accuracy
86,1,Dialog Act Classification,Switchboard corpus,2016-03,CNN[[Lee and Dernoncourt2016]],73.1,89.91,73.1,0.9,81.3,0.73,ito:ITO_00141,Natural Language Processing,Accuracy
87,1,Dialog Act Classification,Switchboard corpus,2017-09,Bi-LSTM-CRF,79.2,97.42,6.1,0.08,81.3,0.8,ito:ITO_00141,Natural Language Processing,Accuracy
88,1,Dialog Act Classification,Switchboard corpus,2017-11,CRF-ASN,81.3,100.0,2.1,0.03,81.3,0.82,ito:ITO_00141,Natural Language Processing,Accuracy
89,1,Code Generation,Django,2016-03,"lpn (Ling et al., 2016)",62.3,84.53,62.3,0.85,73.7,0.63,ito:ITO_00141,Natural Language Processing,Accuracy
90,1,Code Generation,Django,2018-10,Tranx,73.7,100.0,11.4,0.15,73.7,0.74,ito:ITO_00141,Natural Language Processing,Accuracy
91,1,Question Answering,MCTest-160,2016-03,"syntax, frame, coreference, and word embedding features",75.27,100.0,75.27,1.0,75.27,0.76,ito:ITO_00141,Natural Language Processing,Accuracy
92,1,Question Answering,MCTest-500,2016-03,Parallel-Hierarchical,71.0,100.0,71.0,1.0,71.0,0.71,ito:ITO_00141,Natural Language Processing,Accuracy
93,1,Question Answering,Story Cloze Test,2016-06,Memory chains and semantic supervision,78.7,100.0,78.7,1.0,78.7,0.79,ito:ITO_00141,Natural Language Processing,Accuracy
94,1,Visual Question Answering,VQA v2 test-dev,2016-06,MCB,64.7,88.34,64.7,0.88,73.24,0.65,ito:ITO_00141,Natural Language Processing,Accuracy
95,1,Visual Question Answering,VQA v2 test-dev,2017-04,"N2NMN (ResNet-152, policy search)",64.9,88.61,0.2,0.0,73.24,0.65,ito:ITO_00141,Natural Language Processing,Accuracy
96,1,Visual Question Answering,VQA v2 test-dev,2017-05,MUTAN,67.42,92.05,2.5,0.03,73.24,0.68,ito:ITO_00141,Natural Language Processing,Accuracy
97,1,Visual Question Answering,VQA v2 test-dev,2017-08,"Image features from bottom-up attention (adaptive K, ensemble)",69.87,95.4,2.5,0.03,73.24,0.7,ito:ITO_00141,Natural Language Processing,Accuracy
98,1,Visual Question Answering,VQA v2 test-dev,2018-05,BAN+Glove+Counter,70.04,95.63,0.2,0.0,73.24,0.7,ito:ITO_00141,Natural Language Processing,Accuracy
99,1,Visual Question Answering,VQA v2 test-dev,2019-06,MCANed-6,70.63,96.44,0.6,0.01,73.24,0.71,ito:ITO_00141,Natural Language Processing,Accuracy
100,1,Visual Question Answering,VQA v2 test-dev,2019-08,VisualBERT,70.8,96.67,0.2,0.0,73.24,0.71,ito:ITO_00141,Natural Language Processing,Accuracy
101,1,Visual Question Answering,VQA v2 test-dev,2019-08,VL-BERTLARGE,71.79,98.02,1.0,0.01,73.24,0.72,ito:ITO_00141,Natural Language Processing,Accuracy
102,1,Visual Question Answering,VQA v2 test-dev,2019-09,UNITER (Large),73.24,100.0,1.4,0.02,73.24,0.74,ito:ITO_00141,Natural Language Processing,Accuracy
103,1,Phrase Grounding,Flickr30k Entities Test,2016-06,MCB,48.69,100.0,48.69,1.0,48.69,0.49,ito:ITO_00141,Natural Language Processing,Accuracy
104,1,Phrase Grounding,ReferIt,2016-06,MCB,28.91,100.0,28.91,1.0,28.91,0.29,ito:ITO_00141,Natural Language Processing,Accuracy
105,1,Surgical Skills Evaluation,JIGSAWS,2016-06,Bidir. LSTM,0.833,85.0,0.833,0.85,0.98,0.01,ito:ITO_00141,Natural Language Processing,Accuracy
106,1,Surgical Skills Evaluation,JIGSAWS,2018-06,CNN,0.98,100.0,0.1,0.1,0.98,0.01,ito:ITO_00141,Natural Language Processing,Accuracy
107,1,Zero-Shot Text-to-Image Generation,Zero-Shot Text-to-Image Generation,2016-06,Bidir. LSTM,0.833,85.0,0.833,0.85,0.98,0.01,ito:ITO_00141,Natural Language Processing,Accuracy
108,1,Zero-Shot Text-to-Image Generation,Zero-Shot Text-to-Image Generation,2018-06,CNN,0.98,100.0,0.1,0.1,0.98,0.01,ito:ITO_00141,Natural Language Processing,Accuracy
109,1,Text Classification,Yahoo! Answers,2016-07,FastText,72.3,93.15,72.3,0.93,77.62,0.73,ito:ITO_00141,Natural Language Processing,Accuracy
110,1,Text Classification,Yahoo! Answers,2018-05,SWEM-concat,73.53,94.73,1.2,0.02,77.62,0.74,ito:ITO_00141,Natural Language Processing,Accuracy
111,1,Text Classification,Yahoo! Answers,2018-07,DRNN,76.26,98.25,2.7,0.03,77.62,0.77,ito:ITO_00141,Natural Language Processing,Accuracy
112,1,Text Classification,Yahoo! Answers,2019-05,BERT-ITPT-FiT,77.62,100.0,1.4,0.02,77.62,0.78,ito:ITO_00141,Natural Language Processing,Accuracy
113,1,Sentiment Analysis,Amazon Review Full,2016-07,FastText,60.2,91.45,60.2,0.91,65.83,0.6,ito:ITO_00141,Natural Language Processing,Accuracy
114,1,Sentiment Analysis,Amazon Review Full,2017-07,DPCNN,65.19,99.03,5.0,0.08,65.83,0.65,ito:ITO_00141,Natural Language Processing,Accuracy
115,1,Sentiment Analysis,Amazon Review Full,2019-04,BERT large,65.83,100.0,0.6,0.01,65.83,0.66,ito:ITO_00141,Natural Language Processing,Accuracy
116,1,Sentiment Analysis,Amazon Review Polarity,2016-07,FastText,94.6,97.16,94.6,0.97,97.37,0.95,ito:ITO_00141,Natural Language Processing,Accuracy
117,1,Sentiment Analysis,Amazon Review Polarity,2017-07,DPCNN,96.68,99.29,2.1,0.02,97.37,0.97,ito:ITO_00141,Natural Language Processing,Accuracy
118,1,Sentiment Analysis,Amazon Review Polarity,2019-04,BERT large,97.37,100.0,0.7,0.01,97.37,0.98,ito:ITO_00141,Natural Language Processing,Accuracy
119,1,Sentiment Analysis,Sogou News,2016-07,"fastText, h=10, bigram",96.8,100.0,96.8,1.0,96.8,0.97,ito:ITO_00141,Natural Language Processing,Accuracy
120,1,Visual Question Answering,VQA v2,2016-12,MCB,62.27,84.35,62.27,0.84,73.82,0.63,ito:ITO_00141,Natural Language Processing,Accuracy
121,1,Visual Question Answering,VQA v2,2018-07,Pythia v0.1,70.24,95.15,8.0,0.11,73.82,0.71,ito:ITO_00141,Natural Language Processing,Accuracy
122,1,Visual Question Answering,VQA v2,2019-06,DFAF,70.34,95.29,0.1,0.0,73.82,0.71,ito:ITO_00141,Natural Language Processing,Accuracy
123,1,Visual Question Answering,VQA v2,2020-04,Oscar,73.82,100.0,3.5,0.05,73.82,0.74,ito:ITO_00141,Natural Language Processing,Accuracy
124,1,Visual Question Answering,VQA v2 test-std,2016-12,"MCB [11, 12]",62.27,84.84,62.27,0.85,73.4,0.63,ito:ITO_00141,Natural Language Processing,Accuracy
125,1,Visual Question Answering,VQA v2 test-std,2017-05,MUTAN,67.4,91.83,5.1,0.07,73.4,0.68,ito:ITO_00141,Natural Language Processing,Accuracy
126,1,Visual Question Answering,VQA v2 test-std,2017-07,Up-Down,70.34,95.83,2.9,0.04,73.4,0.71,ito:ITO_00141,Natural Language Processing,Accuracy
127,1,Visual Question Answering,VQA v2 test-std,2018-05,BAN+Glove+Counter,70.4,95.91,0.1,0.0,73.4,0.71,ito:ITO_00141,Natural Language Processing,Accuracy
128,1,Visual Question Answering,VQA v2 test-std,2019-06,MCANed-6,70.9,96.59,0.5,0.01,73.4,0.71,ito:ITO_00141,Natural Language Processing,Accuracy
129,1,Visual Question Answering,VQA v2 test-std,2019-08,VisualBERT,71.0,96.73,0.1,0.0,73.4,0.71,ito:ITO_00141,Natural Language Processing,Accuracy
130,1,Visual Question Answering,VQA v2 test-std,2019-08,LXMERT,72.5,98.77,1.5,0.02,73.4,0.73,ito:ITO_00141,Natural Language Processing,Accuracy
131,1,Visual Question Answering,VQA v2 test-std,2019-09,UNITER (Large),73.4,100.0,0.9,0.01,73.4,0.74,ito:ITO_00141,Natural Language Processing,Accuracy
132,1,Sentiment Analysis,MR,2017-02,GRU-RNN-WORD2VEC,78.26,90.16,78.26,0.9,86.8,0.79,ito:ITO_00141,Natural Language Processing,Accuracy
133,1,Sentiment Analysis,MR,2018-02,RNN-Capsule,83.8,96.54,5.5,0.06,86.8,0.84,ito:ITO_00141,Natural Language Processing,Accuracy
134,1,Sentiment Analysis,MR,2018-05,byte mLSTM7,86.8,100.0,3.0,0.03,86.8,0.87,ito:ITO_00141,Natural Language Processing,Accuracy
135,1,Paraphrase Identification,Quora Question Pairs,2017-02,BiMPM,88.17,97.64,88.17,0.98,90.3,0.89,ito:ITO_00141,Natural Language Processing,Accuracy
136,1,Paraphrase Identification,Quora Question Pairs,2017-04,pt-DecAtt,88.4,97.9,0.2,0.0,90.3,0.89,ito:ITO_00141,Natural Language Processing,Accuracy
137,1,Paraphrase Identification,Quora Question Pairs,2017-09,DIIN,89.06,98.63,0.7,0.01,90.3,0.89,ito:ITO_00141,Natural Language Processing,Accuracy
138,1,Paraphrase Identification,Quora Question Pairs,2018-07,MwAN ,89.12,98.69,0.1,0.0,90.3,0.89,ito:ITO_00141,Natural Language Processing,Accuracy
139,1,Paraphrase Identification,Quora Question Pairs,2019-01,MT-DNN,89.6,99.22,0.5,0.01,90.3,0.9,ito:ITO_00141,Natural Language Processing,Accuracy
140,1,Paraphrase Identification,Quora Question Pairs,2019-06,XLNet-Large (ensemble),90.3,100.0,0.7,0.01,90.3,0.91,ito:ITO_00141,Natural Language Processing,Accuracy
141,1,Visual Question Answering,MSVD-QA,2017-04,ST-VQA,0.313,86.7,0.313,0.87,0.361,0.0,ito:ITO_00141,Natural Language Processing,Accuracy
142,1,Visual Question Answering,MSVD-QA,2018-03,Co-Mem,0.317,87.81,0.0,0.0,0.361,0.0,ito:ITO_00141,Natural Language Processing,Accuracy
143,1,Visual Question Answering,MSVD-QA,2019-04,HMEMA,0.337,93.35,0.0,0.0,0.361,0.0,ito:ITO_00141,Natural Language Processing,Accuracy
144,1,Visual Question Answering,MSVD-QA,2020-02,HCRN,0.361,100.0,0.0,0.0,0.361,0.0,ito:ITO_00141,Natural Language Processing,Accuracy
145,1,Visual Question Answering,MSRVTT-QA,2017-04,ST-VQA,0.309,86.8,0.309,0.87,0.356,0.0,ito:ITO_00141,Natural Language Processing,Accuracy
146,1,Visual Question Answering,MSRVTT-QA,2018-03,Co-Mem,0.32,89.89,0.0,0.0,0.356,0.0,ito:ITO_00141,Natural Language Processing,Accuracy
147,1,Visual Question Answering,MSRVTT-QA,2019-04,HMEMA,0.33,92.7,0.0,0.0,0.356,0.0,ito:ITO_00141,Natural Language Processing,Accuracy
148,1,Visual Question Answering,MSRVTT-QA,2020-02,HCRN,0.356,100.0,0.0,0.0,0.356,0.0,ito:ITO_00141,Natural Language Processing,Accuracy
149,1,Stance Detection,RumourEval,2017-04,Kochkina et al. 2017,0.784,100.0,0.784,1.0,0.784,0.01,ito:ITO_00141,Natural Language Processing,Accuracy
150,1,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-Spanish,2017-05,X-CBOW,60.7,81.7,60.7,0.82,74.3,0.61,ito:ITO_00141,Natural Language Processing,Accuracy
151,1,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-Spanish,2017-05,X-BiLSTM,68.7,92.46,8.0,0.11,74.3,0.69,ito:ITO_00141,Natural Language Processing,Accuracy
152,1,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-Spanish,2018-10,BERT,74.3,100.0,5.6,0.08,74.3,0.75,ito:ITO_00141,Natural Language Processing,Accuracy
153,1,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-German,2017-05,X-CBOW,61.0,86.52,61.0,0.87,70.5,0.61,ito:ITO_00141,Natural Language Processing,Accuracy
154,1,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-German,2017-05,X-BiLSTM,67.7,96.03,6.7,0.1,70.5,0.68,ito:ITO_00141,Natural Language Processing,Accuracy
155,1,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-German,2018-10,BERT,70.5,100.0,2.8,0.04,70.5,0.71,ito:ITO_00141,Natural Language Processing,Accuracy
156,1,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-French,2017-05,X-BiLSTM,67.7,100.0,67.7,1.0,67.7,0.68,ito:ITO_00141,Natural Language Processing,Accuracy
157,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,bc-LSTM+Att,56.32,86.31,56.32,0.86,65.25,0.57,ito:ITO_00141,Natural Language Processing,Accuracy
158,1,Emotion Recognition in Conversation,IEMOCAP,2018-06,CMN,56.56,86.68,0.2,0.0,65.25,0.57,ito:ITO_00141,Natural Language Processing,Accuracy
159,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,ICON,59.09,90.56,2.5,0.04,65.25,0.59,ito:ITO_00141,Natural Language Processing,Accuracy
160,1,Emotion Recognition in Conversation,IEMOCAP,2018-11,DialogueRNN,63.4,97.16,4.3,0.07,65.25,0.64,ito:ITO_00141,Natural Language Processing,Accuracy
161,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,DialogueGCN,65.25,100.0,1.9,0.03,65.25,0.66,ito:ITO_00141,Natural Language Processing,Accuracy
162,1,Emotion Recognition in Conversation,MELD,2017-07,bc-LSTM+Att,57.5,96.57,57.5,0.97,59.54,0.58,ito:ITO_00141,Natural Language Processing,Accuracy
163,1,Emotion Recognition in Conversation,MELD,2018-11,DialogueRNN,59.54,100.0,2.0,0.03,59.54,0.6,ito:ITO_00141,Natural Language Processing,Accuracy
164,1,Multimodal Emotion Recognition,Monologue,2017-07,bc-LSTM,74.1,100.0,74.1,1.0,74.1,0.74,ito:ITO_00141,Natural Language Processing,Accuracy
165,1,Multimodal Sentiment Analysis,MOSI,2017-07,bc-LSTM,80.3,97.56,80.3,0.98,82.31,0.81,ito:ITO_00141,Natural Language Processing,Accuracy
166,1,Multimodal Sentiment Analysis,MOSI,2018-10,MMMU-BA,82.31,100.0,2.0,0.02,82.31,0.83,ito:ITO_00141,Natural Language Processing,Accuracy
167,1,Text Classification,Ohsumed,2017-07,CNN+Lowercased,36.2,52.85,36.2,0.53,68.5,0.36,ito:ITO_00141,Natural Language Processing,Accuracy
168,1,Text Classification,Ohsumed,2018-09,Text GCN,68.36,99.8,32.2,0.47,68.5,0.69,ito:ITO_00141,Natural Language Processing,Accuracy
169,1,Text Classification,Ohsumed,2019-02,SGCN,68.5,100.0,0.1,0.0,68.5,0.69,ito:ITO_00141,Natural Language Processing,Accuracy
170,1,Visual Question Answering,GQA Test2019,2017-07,BottomUp,49.74,79.32,49.74,0.79,62.71,0.5,ito:ITO_00141,Natural Language Processing,Accuracy
171,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Single Model",60.33,96.2,10.6,0.17,62.71,0.61,ito:ITO_00141,Natural Language Processing,Accuracy
172,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Ensemble",62.71,100.0,2.4,0.04,62.71,0.63,ito:ITO_00141,Natural Language Processing,Accuracy
173,1,Visual Question Answering,VizWiz,2017-08,Pythia v0.3,54.72,98.77,54.72,0.99,55.4,0.55,ito:ITO_00141,Natural Language Processing,Accuracy
174,1,Visual Question Answering,VizWiz,2019-08,LXMERT,55.4,100.0,0.7,0.01,55.4,0.56,ito:ITO_00141,Natural Language Processing,Accuracy
175,1,Document Classification,WOS-5736,2017-09,HDLTex,90.93,97.18,90.93,0.97,93.57,0.91,ito:ITO_00141,Natural Language Processing,Accuracy
176,1,Document Classification,WOS-5736,2018-05,RMDL (30 RDLs),93.57,100.0,2.6,0.03,93.57,0.94,ito:ITO_00141,Natural Language Processing,Accuracy
177,1,Document Classification,WOS-46985,2017-09,HDLTex,76.58,92.91,76.58,0.93,82.42,0.77,ito:ITO_00141,Natural Language Processing,Accuracy
178,1,Document Classification,WOS-46985,2018-05,RMDL (30 RDLs),82.42,100.0,5.8,0.07,82.42,0.83,ito:ITO_00141,Natural Language Processing,Accuracy
179,1,Document Classification,WOS-11967,2017-09,HDLTex,86.07,93.97,86.07,0.94,91.59,0.86,ito:ITO_00141,Natural Language Processing,Accuracy
180,1,Document Classification,WOS-11967,2018-05,RMDL (30 RDLs),91.59,100.0,5.5,0.06,91.59,0.92,ito:ITO_00141,Natural Language Processing,Accuracy
181,1,Lexical Normalization,LexNorm,2017-10,MoNoise,87.63,100.0,87.63,1.0,87.63,0.88,ito:ITO_00141,Natural Language Processing,Accuracy
182,1,Sentiment Analysis,CR,2017-12,Block-sparse LSTM,92.2,100.0,92.2,1.0,92.2,0.93,ito:ITO_00141,Natural Language Processing,Accuracy
183,1,Natural Language Inference,SciTail,2017-12,CAFE,83.3,88.52,83.3,0.89,94.1,0.84,ito:ITO_00141,Natural Language Processing,Accuracy
184,1,Natural Language Inference,SciTail,2018-06,Finetuned Transformer LM,88.3,93.84,5.0,0.05,94.1,0.89,ito:ITO_00141,Natural Language Processing,Accuracy
185,1,Natural Language Inference,SciTail,2018-10,BERT,92.0,97.77,3.7,0.04,94.1,0.92,ito:ITO_00141,Natural Language Processing,Accuracy
186,1,Natural Language Inference,SciTail,2019-01,MT-DNN,94.1,100.0,2.1,0.02,94.1,0.94,ito:ITO_00141,Natural Language Processing,Accuracy
187,1,Sentiment Analysis,MPQA,2018-03,USE_T+DAN (w2v w.e.) ,88.14,98.12,88.14,0.98,89.83,0.89,ito:ITO_00141,Natural Language Processing,Accuracy
188,1,Sentiment Analysis,MPQA,2018-05,byte mLSTM7,88.8,98.85,0.7,0.01,89.83,0.89,ito:ITO_00141,Natural Language Processing,Accuracy
189,1,Sentiment Analysis,MPQA,2019-05,STM+TSED+PT+2L,89.83,100.0,1.0,0.01,89.83,0.9,ito:ITO_00141,Natural Language Processing,Accuracy
190,1,Document Classification,Reuters-21578,2018-05,RMDL (30 RDLs),90.69,93.07,90.69,0.93,97.44,0.91,ito:ITO_00141,Natural Language Processing,Accuracy
191,1,Document Classification,Reuters-21578,2019-04,ApproxRepSet,97.17,99.72,6.5,0.07,97.44,0.98,ito:ITO_00141,Natural Language Processing,Accuracy
192,1,Document Classification,Reuters-21578,2019-08,MPAD-path,97.44,100.0,0.3,0.0,97.44,0.98,ito:ITO_00141,Natural Language Processing,Accuracy
193,1,Text Classification,20NEWS,2018-05,RMDL (15 RDLs),87.91,99.33,87.91,0.99,88.5,0.88,ito:ITO_00141,Natural Language Processing,Accuracy
194,1,Text Classification,20NEWS,2019-02,SGC,88.5,100.0,0.6,0.01,88.5,0.89,ito:ITO_00141,Natural Language Processing,Accuracy
195,1,Semantic Parsing,Geo,2018-05,coarse2fine,88.2,100.0,88.2,1.0,88.2,0.89,ito:ITO_00141,Natural Language Processing,Accuracy
196,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-French,2018-05,BiLSTM (UN),74.52,77.58,74.52,0.78,96.05,0.75,ito:ITO_00141,Natural Language Processing,Accuracy
197,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-French,2018-12,Massively Multilingual Sentence Embeddings,77.95,81.16,3.4,0.04,96.05,0.78,ito:ITO_00141,Natural Language Processing,Accuracy
198,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-French,2019-09,"MultiFiT, pseudo",89.42,93.1,11.5,0.12,96.05,0.9,ito:ITO_00141,Natural Language Processing,Accuracy
199,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-French,2019-09,XLMft UDA,96.05,100.0,6.6,0.07,96.05,0.96,ito:ITO_00141,Natural Language Processing,Accuracy
200,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Russian,2018-05,BiLSTM (UN),61.42,68.47,61.42,0.68,89.7,0.62,ito:ITO_00141,Natural Language Processing,Accuracy
201,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Russian,2018-12,Massively Multilingual Sentence Embeddings,67.78,75.56,6.4,0.07,89.7,0.68,ito:ITO_00141,Natural Language Processing,Accuracy
202,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Russian,2019-09,"MultiFiT, pseudo",67.83,75.62,0.0,0.0,89.7,0.68,ito:ITO_00141,Natural Language Processing,Accuracy
203,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Russian,2019-09,XLMft UDA,89.7,100.0,21.9,0.24,89.7,0.9,ito:ITO_00141,Natural Language Processing,Accuracy
204,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Spanish,2018-05,MultiCCA + CNN,72.5,74.9,72.5,0.75,96.8,0.73,ito:ITO_00141,Natural Language Processing,Accuracy
205,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Spanish,2018-12,Massively Multilingual Sentence Embeddings,77.33,79.89,4.8,0.05,96.8,0.78,ito:ITO_00141,Natural Language Processing,Accuracy
206,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Spanish,2019-09,"MultiFiT, pseudo",79.1,81.71,1.8,0.02,96.8,0.79,ito:ITO_00141,Natural Language Processing,Accuracy
207,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Spanish,2019-09,XLMft UDA,96.8,100.0,17.7,0.18,96.8,0.97,ito:ITO_00141,Natural Language Processing,Accuracy
208,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Japanese,2018-05,MultiCCA + CNN,67.63,97.21,67.63,0.97,69.57,0.68,ito:ITO_00141,Natural Language Processing,Accuracy
209,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Japanese,2019-09,"MultiFiT, pseudo",69.57,100.0,1.9,0.03,69.57,0.7,ito:ITO_00141,Natural Language Processing,Accuracy
210,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-German,2018-05,MultiCCA + CNN,81.2,83.75,81.2,0.84,96.95,0.82,ito:ITO_00141,Natural Language Processing,Accuracy
211,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-German,2018-12,Massively Multilingual Sentence Embeddings,84.78,87.45,3.6,0.04,96.95,0.85,ito:ITO_00141,Natural Language Processing,Accuracy
212,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-German,2019-09,"MultiFiT, pseudo",91.62,94.5,6.8,0.07,96.95,0.92,ito:ITO_00141,Natural Language Processing,Accuracy
213,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-German,2019-09,XLMft UDA,96.95,100.0,5.3,0.05,96.95,0.97,ito:ITO_00141,Natural Language Processing,Accuracy
214,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Italian,2018-05,BiLSTM (Europarl),60.73,79.89,60.73,0.8,76.02,0.61,ito:ITO_00141,Natural Language Processing,Accuracy
215,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Italian,2018-05,MultiCCA + CNN,69.38,91.27,8.6,0.11,76.02,0.7,ito:ITO_00141,Natural Language Processing,Accuracy
216,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Italian,2018-12,Massively Multilingual Sentence Embeddings,69.43,91.33,0.1,0.0,76.02,0.7,ito:ITO_00141,Natural Language Processing,Accuracy
217,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Italian,2019-09,"MultiFiT, pseudo",76.02,100.0,6.6,0.09,76.02,0.76,ito:ITO_00141,Natural Language Processing,Accuracy
218,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Chinese,2018-05,MultiCCA + CNN,74.73,80.08,74.73,0.8,93.32,0.75,ito:ITO_00141,Natural Language Processing,Accuracy
219,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Chinese,2019-09,"MultiFiT, pseudo",82.48,88.38,7.8,0.08,93.32,0.83,ito:ITO_00141,Natural Language Processing,Accuracy
220,1,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Chinese,2019-09,XLMft UDA,93.32,100.0,10.8,0.12,93.32,0.94,ito:ITO_00141,Natural Language Processing,Accuracy
221,1,Cross-Lingual Document Classification,MLDoc Zero-Shot German-to-French,2018-05,BiLSTM (Europarl),75.45,100.0,75.45,1.0,75.45,0.76,ito:ITO_00141,Natural Language Processing,Accuracy
222,1,Question Answering,Quora Question Pairs,2018-05,SWEM-concat,83.03,89.96,83.03,0.9,92.3,0.83,ito:ITO_00141,Natural Language Processing,Accuracy
223,1,Question Answering,Quora Question Pairs,2019-06,XLNet (single model),92.3,100.0,9.3,0.1,92.3,0.93,ito:ITO_00141,Natural Language Processing,Accuracy
224,1,Memex Question Answering,MemexQA,2018-06,FVTA,0.357,100.0,0.357,1.0,0.357,0.0,ito:ITO_00141,Natural Language Processing,Accuracy
225,1,Entity Typing,Freebase FIGER,2018-06,TextEnt-full,37.4,100.0,37.4,1.0,37.4,0.38,ito:ITO_00141,Natural Language Processing,Accuracy
226,1,Question-Answer-Generation,Question-Answer-Generation,2018-06,TextEnt-full,37.4,100.0,37.4,1.0,37.4,0.38,ito:ITO_00141,Natural Language Processing,Accuracy
227,1,Text Classification,R8,2018-06,TextEnt-full,96.7,98.77,96.7,0.99,97.9,0.97,ito:ITO_00141,Natural Language Processing,Accuracy
228,1,Text Classification,R8,2018-09,Text GCN,97.07,99.15,0.4,0.0,97.9,0.97,ito:ITO_00141,Natural Language Processing,Accuracy
229,1,Text Classification,R8,2019-02,SGC,97.2,99.28,0.1,0.0,97.9,0.98,ito:ITO_00141,Natural Language Processing,Accuracy
230,1,Text Classification,R8,2019-06,GraphStar,97.4,99.49,0.2,0.0,97.9,0.98,ito:ITO_00141,Natural Language Processing,Accuracy
231,1,Text Classification,R8,2019-09,NABoE-full,97.9,100.0,0.5,0.01,97.9,0.98,ito:ITO_00141,Natural Language Processing,Accuracy
232,1,Text-To-Speech Synthesis,LJSpeech,2018-06,tacotron,12.0,100.0,12,1.0,12,0.12,ito:ITO_00141,Natural Language Processing,Accuracy
233,1,Natural Language Inference,V-SNLI,2018-06,V-BiMPM,86.99,100.0,86.99,1.0,86.99,0.87,ito:ITO_00141,Natural Language Processing,Accuracy
234,1,Natural Language Inference,MultiNLI,2018-06,MQAN,72.8,100.0,72.8,1.0,72.8,0.73,ito:ITO_00141,Natural Language Processing,Accuracy
235,1,Multimodal Sentiment Analysis,CMU-MOSEI,2018-07,Graph-MFN,76.9,93.67,76.9,0.94,82.1,0.77,ito:ITO_00141,Natural Language Processing,Accuracy
236,1,Multimodal Sentiment Analysis,CMU-MOSEI,2020-02,Multilogue-Net,82.1,100.0,5.2,0.06,82.1,0.82,ito:ITO_00141,Natural Language Processing,Accuracy
237,1,Language Modelling,LAMBADA,2018-07,Universal Transformer (w/ dynamic halting),56.25,100.0,56.25,1.0,56.25,0.56,ito:ITO_00141,Natural Language Processing,Accuracy
238,1,Visual Question Answering,CLEVR,2018-08,CNN + LSTM + RN + HAN,98.8,100.0,98.8,1.0,98.8,0.99,ito:ITO_00141,Natural Language Processing,Accuracy
239,1,Question Answering,SWAG,2018-08,BERT Large,86.3,100.0,86.3,1.0,86.3,0.87,ito:ITO_00141,Natural Language Processing,Accuracy
240,1,Query Wellformedness,Query Wellformedness,2018-08,"word-1, 2 POS-1, 2, 3",70.7,100.0,70.7,1.0,70.7,0.71,ito:ITO_00141,Natural Language Processing,Accuracy
241,1,Natural Language Inference,XNLI French,2018-09,BiLSTM-max,68.3,84.11,68.3,0.84,81.2,0.69,ito:ITO_00141,Natural Language Processing,Accuracy
242,1,Natural Language Inference,XNLI French,2019-01,XLM (MLM+TLM),80.2,98.77,11.9,0.15,81.2,0.81,ito:ITO_00141,Natural Language Processing,Accuracy
243,1,Natural Language Inference,XNLI French,2019-11,CamemBERT,81.2,100.0,1.0,0.01,81.2,0.82,ito:ITO_00141,Natural Language Processing,Accuracy
244,1,Text Classification,R52,2018-09,Text GCN,93.56,98.48,93.56,0.98,95.0,0.94,ito:ITO_00141,Natural Language Processing,Accuracy
245,1,Text Classification,R52,2019-02,SGC,94.0,98.95,0.4,0.0,95.0,0.94,ito:ITO_00141,Natural Language Processing,Accuracy
246,1,Text Classification,R52,2019-06,GraphStar,95.0,100.0,1.0,0.01,95.0,0.95,ito:ITO_00141,Natural Language Processing,Accuracy
247,1,Semantic Parsing,spider,2018-09,Exact Set Matching,19.7,100.0,19.7,1.0,19.7,0.2,ito:ITO_00141,Natural Language Processing,Accuracy
248,1,Natural Language Understanding,WNLI,2018-10,BERTLARGE,65.1,100.0,65.1,1.0,65.1,0.65,ito:ITO_00141,Natural Language Processing,Accuracy
249,1,Natural Language Understanding,PDP60,2018-10,BERTLARGE,78.3,100.0,78.3,1.0,78.3,0.79,ito:ITO_00141,Natural Language Processing,Accuracy
250,1,Text Classification,Sogou News,2018-10,CCCapsNet,97.25,99.16,97.25,0.99,98.07,0.98,ito:ITO_00141,Natural Language Processing,Accuracy
251,1,Text Classification,Sogou News,2019-05,BERT-ITPT-FiT,98.07,100.0,0.8,0.01,98.07,0.98,ito:ITO_00141,Natural Language Processing,Accuracy
252,1,Visual Question Answering,TallyQA,2018-10,RCN (Ours),71.8,100.0,71.8,1.0,71.8,0.72,ito:ITO_00141,Natural Language Processing,Accuracy
253,1,Visual Question Answering,HowmanyQA,2018-10,RCN (Ours),60.3,100.0,60.3,1.0,60.3,0.61,ito:ITO_00141,Natural Language Processing,Accuracy
254,1,Natural Language Inference,Quora Question Pairs,2018-12,aESIM,88.01,100.0,88.01,1.0,88.01,0.88,ito:ITO_00141,Natural Language Processing,Accuracy
255,1,Hate Speech Detection,Automatic Misogynistic Identification,2018-12,Logistic Regression,0.704,100.0,0.704,1.0,0.704,0.01,ito:ITO_00141,Natural Language Processing,Accuracy
256,1,Intent Detection,SNIPS,2018-12,Capsule-NLU,0.977,100.0,0.977,1.0,0.977,0.01,ito:ITO_00141,Natural Language Processing,Accuracy
257,1,Intent Detection,ATIS,2018-12,Capsule-NLU,0.95,0.97,0.95,0.01,97.76,0.01,ito:ITO_00141,Natural Language Processing,Accuracy
258,1,Intent Detection,ATIS,2018-12,Capsule-NLU,95.0,97.18,94.0,0.96,97.76,0.95,ito:ITO_00141,Natural Language Processing,Accuracy
259,1,Intent Detection,ATIS,2019-06,SF-ID (BLSTM) network,97.76,100.0,2.8,0.03,97.76,0.98,ito:ITO_00141,Natural Language Processing,Accuracy
260,1,Text Classification,Yelp-5,2019-01,HAHNN (CNN),73.28,100.0,73.28,1.0,73.28,0.74,ito:ITO_00141,Natural Language Processing,Accuracy
261,1,Linguistic Acceptability Assessment,CoLA,2019-01,MT-DNN,68.4,98.99,68.4,0.99,69.1,0.69,ito:ITO_00141,Natural Language Processing,Accuracy
262,1,Linguistic Acceptability Assessment,CoLA,2019-06,XLNet (single model),69.0,99.86,0.6,0.01,69.1,0.69,ito:ITO_00141,Natural Language Processing,Accuracy
263,1,Linguistic Acceptability Assessment,CoLA,2019-09,ALBERT,69.1,100.0,0.1,0.0,69.1,0.69,ito:ITO_00141,Natural Language Processing,Accuracy
264,1,Linguistic Acceptability,CoLA,2019-01,MT-DNN,68.4,96.61,68.4,0.97,70.8,0.69,ito:ITO_00141,Natural Language Processing,Accuracy
265,1,Linguistic Acceptability,CoLA,2019-06,XLNet (single model),69.0,97.46,0.6,0.01,70.8,0.69,ito:ITO_00141,Natural Language Processing,Accuracy
266,1,Linguistic Acceptability,CoLA,2019-09,ALBERT,69.1,97.6,0.1,0.0,70.8,0.69,ito:ITO_00141,Natural Language Processing,Accuracy
267,1,Linguistic Acceptability,CoLA,2019-10,T5-11B,70.8,100.0,1.7,0.02,70.8,0.71,ito:ITO_00141,Natural Language Processing,Accuracy
268,1,Visual Question Answering,GQA test-std,2019-02,MAC,54.06,85.58,54.06,0.86,63.17,0.54,ito:ITO_00141,Natural Language Processing,Accuracy
269,1,Visual Question Answering,GQA test-std,2019-07,NSM,63.17,100.0,9.1,0.14,63.17,0.63,ito:ITO_00141,Natural Language Processing,Accuracy
270,1,Visual Question Answering,TDIUC,2019-02,Accuracy,88.2,100.0,88.2,1.0,88.2,0.89,ito:ITO_00141,Natural Language Processing,Accuracy
271,1,Sentiment Analysis,Twitter,2019-02,AEN-BERT,74.71,100.0,74.71,1.0,74.71,0.75,ito:ITO_00141,Natural Language Processing,Accuracy
272,1,Document Classification,BBCSport,2019-04,ApproxRepSet,95.73,96.12,95.73,0.96,99.59,0.96,ito:ITO_00141,Natural Language Processing,Accuracy
273,1,Document Classification,BBCSport,2019-08,MPAD-path,99.59,100.0,3.9,0.04,99.59,1.0,ito:ITO_00141,Natural Language Processing,Accuracy
274,1,Document Classification,Twitter,2019-04,ApproxRepSet,72.6,100.0,72.6,1.0,72.6,0.73,ito:ITO_00141,Natural Language Processing,Accuracy
275,1,Document Classification,Amazon,2019-04,ApproxRepSet,94.31,100.0,94.31,1.0,94.31,0.95,ito:ITO_00141,Natural Language Processing,Accuracy
276,1,Document Classification,Classic,2019-04,ApproxRepSet,96.24,99.37,96.24,0.99,96.85,0.97,ito:ITO_00141,Natural Language Processing,Accuracy
277,1,Document Classification,Classic,2019-12,REL-RWMD k-NN,96.85,100.0,0.6,0.01,96.85,0.97,ito:ITO_00141,Natural Language Processing,Accuracy
278,1,Document Classification,Recipe,2019-04,ApproxRepSet,59.06,100.0,59.06,1.0,59.06,0.59,ito:ITO_00141,Natural Language Processing,Accuracy
279,1,Question Answering,CODAH,2019-04,BERT Large,69.6,100.0,69.6,1.0,69.6,0.7,ito:ITO_00141,Natural Language Processing,Accuracy
280,1,Document Classification,Yelp-14,2019-04,KD-LSTMreg,69.4,100.0,69.4,1.0,69.4,0.7,ito:ITO_00141,Natural Language Processing,Accuracy
281,1,Visual Question Answering,TextVQA Val,2019-04,Pythia + LoRRA,26.56,100.0,26.56,1.0,26.56,0.27,ito:ITO_00141,Natural Language Processing,Accuracy
282,1,Visual Question Answering,TextVQA Test,2019-04,Pythia + LoRRA,27.63,100.0,27.63,1.0,27.63,0.28,ito:ITO_00141,Natural Language Processing,Accuracy
283,1,Natural Language Inference,XNLI Chinese,2019-04,ERNIE,78.4,96.79,78.4,0.97,81.0,0.79,ito:ITO_00141,Natural Language Processing,Accuracy
284,1,Natural Language Inference,XNLI Chinese,2019-07,ERNIE 2.0 Large,81.0,100.0,2.6,0.03,81.0,0.81,ito:ITO_00141,Natural Language Processing,Accuracy
285,1,Natural Language Inference,XNLI Chinese Dev,2019-04,ERNIE,79.9,96.73,79.9,0.97,82.6,0.8,ito:ITO_00141,Natural Language Processing,Accuracy
286,1,Natural Language Inference,XNLI Chinese Dev,2019-07,ERNIE 2.0 Large,82.6,100.0,2.7,0.03,82.6,0.83,ito:ITO_00141,Natural Language Processing,Accuracy
287,1,Text Classification,Yelp-2,2019-04,BERT Finetune + UDA,97.95,99.31,97.95,0.99,98.63,0.98,ito:ITO_00141,Natural Language Processing,Accuracy
288,1,Text Classification,Yelp-2,2019-05,BERT-ITPT-FiT,98.08,99.44,0.1,0.0,98.63,0.98,ito:ITO_00141,Natural Language Processing,Accuracy
289,1,Text Classification,Yelp-2,2019-06,XLNet,98.63,100.0,0.5,0.01,98.63,0.99,ito:ITO_00141,Natural Language Processing,Accuracy
290,1,Emotion Recognition,MPED,2019-05,BiHDM,40.34,100.0,40.34,1.0,40.34,0.41,ito:ITO_00141,Natural Language Processing,Accuracy
291,1,Natural Language Inference,RTE,2019-05,ERNIE,68.8,74.38,68.8,0.74,92.5,0.69,ito:ITO_00141,Natural Language Processing,Accuracy
292,1,Natural Language Inference,RTE,2019-06,XLNet (single model),85.9,92.86,17.1,0.18,92.5,0.86,ito:ITO_00141,Natural Language Processing,Accuracy
293,1,Natural Language Inference,RTE,2019-07,RoBERTa,88.2,95.35,2.3,0.02,92.5,0.89,ito:ITO_00141,Natural Language Processing,Accuracy
294,1,Natural Language Inference,RTE,2019-09,ALBERT,89.2,96.43,1.0,0.01,92.5,0.9,ito:ITO_00141,Natural Language Processing,Accuracy
295,1,Natural Language Inference,RTE,2019-10,T5-11B,92.5,100.0,3.3,0.04,92.5,0.93,ito:ITO_00141,Natural Language Processing,Accuracy
296,1,Natural Language Inference,QNLI,2019-05,ERNIE,91.3,92.04,91.3,0.92,99.2,0.92,ito:ITO_00141,Natural Language Processing,Accuracy
297,1,Natural Language Inference,QNLI,2019-06,XLNet (single model),94.9,95.67,3.6,0.04,99.2,0.95,ito:ITO_00141,Natural Language Processing,Accuracy
298,1,Natural Language Inference,QNLI,2019-07,RoBERTa,98.9,99.7,4.0,0.04,99.2,0.99,ito:ITO_00141,Natural Language Processing,Accuracy
299,1,Natural Language Inference,QNLI,2019-09,ALBERT,99.2,100.0,0.3,0.0,99.2,1.0,ito:ITO_00141,Natural Language Processing,Accuracy
300,1,Entity Linking,FIGER,2019-05,ERNIE,57.19,100.0,57.19,1.0,57.19,0.57,ito:ITO_00141,Natural Language Processing,Accuracy
301,1,Document Classification,IMDb-M,2019-06,LSTM-reg (single model),52.8,100.0,52.8,1.0,52.8,0.53,ito:ITO_00141,Natural Language Processing,Accuracy
302,1,Reading Comprehension,RACE,2019-06,XLNet,85.4,93.95,85.4,0.94,90.9,0.86,ito:ITO_00141,Natural Language Processing,Accuracy
303,1,Reading Comprehension,RACE,2019-09,Megatron-BERT,89.5,98.46,4.1,0.05,90.9,0.9,ito:ITO_00141,Natural Language Processing,Accuracy
304,1,Reading Comprehension,RACE,2019-09,Megatron-BERT (ensemble),90.9,100.0,1.4,0.02,90.9,0.91,ito:ITO_00141,Natural Language Processing,Accuracy
305,1,Natural Language Inference,WNLI,2019-06,XLNet,92.5,99.25,92.5,0.99,93.2,0.93,ito:ITO_00141,Natural Language Processing,Accuracy
306,1,Natural Language Inference,WNLI,2019-10,T5-11B,93.2,100.0,0.7,0.01,93.2,0.94,ito:ITO_00141,Natural Language Processing,Accuracy
307,1,Visual Question Answering,GQA test-dev,2019-07,NSM,62.95,100.0,62.95,1.0,62.95,0.63,ito:ITO_00141,Natural Language Processing,Accuracy
308,1,Emotion Recognition,SEED-IV,2019-07,RGNN,79.37,100.0,79.37,1.0,79.37,0.8,ito:ITO_00141,Natural Language Processing,Accuracy
309,1,Prosody Prediction,Helsinki Prosody Corpus,2019-08,BERT,83.2,100.0,83.2,1.0,83.2,0.84,ito:ITO_00141,Natural Language Processing,Accuracy
310,1,Document Classification,MPQA,2019-08,MPAD-path,89.81,100.0,89.81,1.0,89.81,0.9,ito:ITO_00141,Natural Language Processing,Accuracy
311,1,Sentiment Analysis,Financial PhraseBank,2019-08,FinBERT,86.0,100.0,86,1.0,86,0.86,ito:ITO_00141,Natural Language Processing,Accuracy
312,1,Semantic Textual Similarity,MRPC Dev,2019-09,TinyBERT (M=6;d'=768;d'i=3072),86.3,100.0,86.3,1.0,86.3,0.87,ito:ITO_00141,Natural Language Processing,Accuracy
313,1,Linguistic Acceptability,CoLA Dev,2019-09,TinyBERT (M=6;d' =768;d'i=3072),54.0,100.0,54,1.0,54,0.54,ito:ITO_00141,Natural Language Processing,Accuracy
314,1,Semantic Parsing,WikiSQL,2019-10,NL2SQL-BERT,89.0,100.0,89,1.0,89,0.89,ito:ITO_00141,Natural Language Processing,Accuracy
315,1,Question Answering,COPA,2019-10,T5-11B,94.8,100.0,94.8,1.0,94.8,0.95,ito:ITO_00141,Natural Language Processing,Accuracy
316,1,Word Sense Disambiguation,Words in Context,2019-10,T5-11B,76.1,100.0,76.1,1.0,76.1,0.76,ito:ITO_00141,Natural Language Processing,Accuracy
317,1,Question Answering,BoolQ,2019-10,T5-11B,91.0,100.0,91,1.0,91,0.91,ito:ITO_00141,Natural Language Processing,Accuracy
318,1,Node Classification,AMZ Comp,2019-10,GCN (Heat Diffusion),86.77,100.0,86.77,1.0,86.77,0.87,ito:ITO_00141,Natural Language Processing,Accuracy
319,1,End-To-End Dialogue Modelling,End-To-End Dialogue Modelling,2019-10,GCN (Heat Diffusion),86.77,100.0,86.77,1.0,86.77,0.87,ito:ITO_00141,Natural Language Processing,Accuracy
320,1,Twitter Bot Detection,MIB Datasets,2019-12,DNA String Compression,0.984,100.0,0.984,1.0,0.984,0.01,ito:ITO_00141,Natural Language Processing,Accuracy
321,1,Drug–drug Interaction Extraction,Drug–drug Interaction Extraction,2019-12,DNA String Compression,0.984,100.0,0.984,1.0,0.984,0.01,ito:ITO_00141,Natural Language Processing,Accuracy
322,1,Entity Linking,CoNLL-Aida,2020-01,RELIC + CoNLL-Aida tuning,94.9,100.0,94.9,1.0,94.9,0.95,ito:ITO_00141,Natural Language Processing,Accuracy
323,1,Entity Linking,TAC-KBP 2010,2020-01,RELIC + CoNLL-Aida tuning,89.8,100.0,89.8,1.0,89.8,0.9,ito:ITO_00141,Natural Language Processing,Accuracy
324,1,Sentiment Analysis,DBRD,2020-01,RobBERT,94.422,100.0,94.422,1.0,94.422,0.95,ito:ITO_00141,Natural Language Processing,Accuracy
325,1,Sentiment Analysis,AJGT,2020-02,AraBERTv1,93.8,100.0,93.8,1.0,93.8,0.94,ito:ITO_00141,Natural Language Processing,Accuracy
326,1,Sentiment Analysis,HARD,2020-02,AraBERTv1,96.1,100.0,96.1,1.0,96.1,0.96,ito:ITO_00141,Natural Language Processing,Accuracy
327,1,Handwritten Digit Recognition,MNIST,2020-04,CNN,96.95,100.0,96.95,1.0,96.95,0.97,ito:ITO_00141,Natural Language Processing,Accuracy
0,1,Language Modelling,One Billion Word,2013-12,RNN-1024 + 9 Gram,51.3,96.98,51.3,0.97,52.9,0.06,ito:ITO_00141,Natural Language Processing,PPL
1,1,Language Modelling,One Billion Word,2014-12,Sparse Non-Negative,52.9,100.0,1.6,0.03,52.9,0.06,ito:ITO_00141,Natural Language Processing,PPL
2,1,Document Summarization,CNN / Daily Mail,2017-09,C2F + ALTERNATE,23.6,72.06,23.6,0.72,32.75,0.03,ito:ITO_00141,Natural Language Processing,PPL
3,1,Document Summarization,CNN / Daily Mail,2018-08,Bottom-Up Sum,32.75,100.0,9.1,0.28,32.75,0.04,ito:ITO_00141,Natural Language Processing,PPL
4,1,Topic Models,20NEWS,2019-08,Bayesian SMM,851.0,100.0,851,1.0,851,1.0,ito:ITO_00141,Natural Language Processing,PPL
5,1,Language Modelling,PTB,2019-11,I-DARTS,56.0,100.0,56,1.0,56,0.07,ito:ITO_00141,Natural Language Processing,PPL
0,1,Node Classification,BlogCatalog,2014-03,DeepWalk,0.214,69.19,0.214,0.69,0.3093,0.0,ito:ITO_00141,Natural Language Processing,Macro\\-F1
1,1,Node Classification,BlogCatalog,2015-10,GraRep,0.3093,100.0,0.1,0.32,0.3093,0.0,ito:ITO_00141,Natural Language Processing,Macro\\-F1
2,1,Spoken language identification,Spoken language identification,2014-03,DeepWalk,0.214,69.19,0.214,0.69,0.3093,0.0,ito:ITO_00141,Natural Language Processing,Macro\\-F1
3,1,Spoken language identification,Spoken language identification,2015-10,GraRep,0.3093,100.0,0.1,0.32,0.3093,0.0,ito:ITO_00141,Natural Language Processing,Macro\\-F1
4,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,bc-LSTM+Att,54.84,86.46,54.84,0.86,63.43,0.86,ito:ITO_00141,Natural Language Processing,Macro\\-F1
5,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,ICON,56.52,89.11,1.7,0.03,63.43,0.89,ito:ITO_00141,Natural Language Processing,Macro\\-F1
6,1,Emotion Recognition in Conversation,IEMOCAP,2018-11,DialogueRNN,60.66,95.63,4.1,0.06,63.43,0.96,ito:ITO_00141,Natural Language Processing,Macro\\-F1
7,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,DialogueGCN,63.43,100.0,2.8,0.04,63.43,1.0,ito:ITO_00141,Natural Language Processing,Macro\\-F1
8,1,Emotion Classification,SemEval 2018 Task 1E-c,2018-12,Transformer (finetune),56.1,100.0,56.1,1.0,56.1,0.88,ito:ITO_00141,Natural Language Processing,Macro\\-F1
0,1,Natural Language Inference,SNLI,2014-04,DCNN [[Blunsom et al.2014]],86.8,94.45,86.8,0.94,91.9,0.94,ito:ITO_00141,Natural Language Processing,%\\ Test\\ Accuracy
1,1,Natural Language Inference,SNLI,2014-08,CNN-MC [[Kim2014]],88.1,95.87,1.3,0.01,91.9,0.96,ito:ITO_00141,Natural Language Processing,%\\ Test\\ Accuracy
2,1,Natural Language Inference,SNLI,2016-09,600D ESIM + 300D Syntactic TreeLSTM,88.6,96.41,0.5,0.01,91.9,0.96,ito:ITO_00141,Natural Language Processing,%\\ Test\\ Accuracy
3,1,Natural Language Inference,SNLI,2017-02,BiMPM Ensemble,88.8,96.63,0.2,0.0,91.9,0.97,ito:ITO_00141,Natural Language Processing,%\\ Test\\ Accuracy
4,1,Natural Language Inference,SNLI,2017-09,"448D Densely Interactive Inference Network (DIIN, code) Ensemble",88.9,96.74,0.1,0.0,91.9,0.97,ito:ITO_00141,Natural Language Processing,%\\ Test\\ Accuracy
5,1,Natural Language Inference,SNLI,2017-11,KIM Ensemble,89.1,96.95,0.2,0.0,91.9,0.97,ito:ITO_00141,Natural Language Processing,%\\ Test\\ Accuracy
6,1,Natural Language Inference,SNLI,2017-12,300D CAFE Ensemble,89.3,97.17,0.2,0.0,91.9,0.97,ito:ITO_00141,Natural Language Processing,%\\ Test\\ Accuracy
7,1,Natural Language Inference,SNLI,2018-05,Densely-Connected Recurrent and Co-Attentive Network Ensemble,90.1,98.04,0.8,0.01,91.9,0.98,ito:ITO_00141,Natural Language Processing,%\\ Test\\ Accuracy
8,1,Natural Language Inference,SNLI,2018-09,SJRC (BERT-Large +SRL),91.3,99.35,1.2,0.01,91.9,0.99,ito:ITO_00141,Natural Language Processing,%\\ Test\\ Accuracy
9,1,Natural Language Inference,SNLI,2019-01,MT-DNN,91.6,99.67,0.3,0.0,91.9,1.0,ito:ITO_00141,Natural Language Processing,%\\ Test\\ Accuracy
10,1,Natural Language Inference,SNLI,2019-09,SemBERT,91.9,100.0,0.3,0.0,91.9,1.0,ito:ITO_00141,Natural Language Processing,%\\ Test\\ Accuracy
0,1,Text Classification,IMDb,2014-05,Paragraph Vectors Le & Mikolov (2014),92.58,95.64,92.58,0.96,96.8,0.96,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(2\\ classes\\)
1,1,Text Classification,IMDb,2019-01,HAHNN (CNN),95.17,98.32,2.6,0.03,96.8,0.98,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(2\\ classes\\)
2,1,Text Classification,IMDb,2019-05,BERT-ITPT-FiT,95.63,98.79,0.5,0.01,96.8,0.99,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(2\\ classes\\)
3,1,Text Classification,IMDb,2019-06,XLNet,96.8,100.0,1.2,0.01,96.8,1.0,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(2\\ classes\\)
0,1,Question Answering,QASent,2014-05,Paragraph vector (lexical overlap + dist output),0.7514,92.57,0.7514,0.93,0.8117,0.01,ito:ITO_00141,Natural Language Processing,MRR
1,1,Question Answering,QASent,2014-12,Bigram-CNN (lexical overlap + dist output),0.7846,96.66,0.0,0.0,0.8117,0.01,ito:ITO_00141,Natural Language Processing,MRR
2,1,Question Answering,QASent,2015-11,Attentive LSTM,0.8117,100.0,0.0,0.0,0.8117,0.01,ito:ITO_00141,Natural Language Processing,MRR
3,1,Question Answering,WikiQA,2014-05,Paragraph vector (lexical overlap + dist output),0.6058,64.93,0.6058,0.65,0.933,0.01,ito:ITO_00141,Natural Language Processing,MRR
4,1,Question Answering,WikiQA,2014-12,Bigram-CNN (lexical overlap + dist output),0.6652,71.3,0.1,0.11,0.933,0.01,ito:ITO_00141,Natural Language Processing,MRR
5,1,Question Answering,WikiQA,2015-11,LSTM (lexical overlap + dist output),0.6988,74.9,0.0,0.0,0.933,0.01,ito:ITO_00141,Natural Language Processing,MRR
6,1,Question Answering,WikiQA,2015-11,Attentive LSTM,0.7069,75.77,0.0,0.0,0.933,0.01,ito:ITO_00141,Natural Language Processing,MRR
7,1,Question Answering,WikiQA,2016-02,LDC,0.7226,77.45,0.0,0.0,0.933,0.01,ito:ITO_00141,Natural Language Processing,MRR
8,1,Question Answering,WikiQA,2016-06,PWIM,0.7234,77.53,0.0,0.0,0.933,0.01,ito:ITO_00141,Natural Language Processing,MRR
9,1,Question Answering,WikiQA,2016-06,Key-Value Memory Network,0.7265,77.87,0.0,0.0,0.933,0.01,ito:ITO_00141,Natural Language Processing,MRR
10,1,Question Answering,WikiQA,2017-07,HyperQA,0.727,77.92,0.0,0.0,0.933,0.01,ito:ITO_00141,Natural Language Processing,MRR
11,1,Question Answering,WikiQA,2019-05,Comp-Clip + LM + LC,0.784,84.03,0.1,0.11,0.933,0.01,ito:ITO_00141,Natural Language Processing,MRR
12,1,Question Answering,WikiQA,2019-11,"TANDA-RoBERTa (ASNQ, WikiQA)",0.933,100.0,0.1,0.11,0.933,0.01,ito:ITO_00141,Natural Language Processing,MRR
13,1,Question Answering,TrecQA,2014-12,CNN,0.785,80.6,0.785,0.81,0.974,0.01,ito:ITO_00141,Natural Language Processing,MRR
14,1,Question Answering,TrecQA,2016-06,PWIN,0.8219,84.38,0.0,0.0,0.974,0.01,ito:ITO_00141,Natural Language Processing,MRR
15,1,Question Answering,TrecQA,2017-07,HyperQA,0.825,84.7,0.0,0.0,0.974,0.01,ito:ITO_00141,Natural Language Processing,MRR
16,1,Question Answering,TrecQA,2019-05,Comp-Clip + LM + LC,0.928,95.28,0.1,0.1,0.974,0.01,ito:ITO_00141,Natural Language Processing,MRR
17,1,Question Answering,TrecQA,2019-11,"TANDA-RoBERTa (ASNQ, TREC-QA)",0.974,100.0,0.0,0.0,0.974,0.01,ito:ITO_00141,Natural Language Processing,MRR
18,1,Question Answering,YahooCQA,2016-02,AP-BiLSTM,0.731,84.9,0.731,0.85,0.861,0.01,ito:ITO_00141,Natural Language Processing,MRR
19,1,Question Answering,YahooCQA,2017-07,HyperQA,0.801,93.03,0.1,0.12,0.861,0.01,ito:ITO_00141,Natural Language Processing,MRR
20,1,Question Answering,YahooCQA,2020-02,sMIM (1024) +,0.861,100.0,0.1,0.12,0.861,0.01,ito:ITO_00141,Natural Language Processing,MRR
21,1,Visual Dialog,VisDial v0.9 val,2016-05,HieCoAtt-QI,57.88,83.98,57.88,0.84,68.92,0.84,ito:ITO_00141,Natural Language Processing,MRR
22,1,Visual Dialog,VisDial v0.9 val,2017-09,AMEM Seo et al. (2017),62.27,90.35,4.4,0.06,68.92,0.9,ito:ITO_00141,Natural Language Processing,MRR
23,1,Visual Dialog,VisDial v0.9 val,2017-11,CoAtt Wu et al. (2018),63.98,92.83,1.7,0.02,68.92,0.92,ito:ITO_00141,Natural Language Processing,MRR
24,1,Visual Dialog,VisDial v0.9 val,2018-09,CorefNMN (ResNet-152),64.1,93.01,0.1,0.0,68.92,0.92,ito:ITO_00141,Natural Language Processing,MRR
25,1,Visual Dialog,VisDial v0.9 val,2019-02,DAN,66.38,96.31,2.3,0.03,68.92,0.96,ito:ITO_00141,Natural Language Processing,MRR
26,1,Visual Dialog,VisDial v0.9 val,2019-04,9xFGA (VGG),68.92,100.0,2.5,0.04,68.92,0.99,ito:ITO_00141,Natural Language Processing,MRR
27,1,Hypernym Discovery,Medical domain,2016-11,vTE,41.07,75.16,41.07,0.75,54.64,0.59,ito:ITO_00141,Natural Language Processing,MRR
28,1,Hypernym Discovery,Medical domain,2018-06,CRIM,54.64,100.0,13.6,0.25,54.64,0.79,ito:ITO_00141,Natural Language Processing,MRR
29,1,Hypernym Discovery,Music domain,2016-11,vTE,39.36,64.6,39.36,0.65,60.93,0.57,ito:ITO_00141,Natural Language Processing,MRR
30,1,Hypernym Discovery,Music domain,2018-06,CRIM,60.93,100.0,21.6,0.35,60.93,0.88,ito:ITO_00141,Natural Language Processing,MRR
31,1,Hypernym Discovery,General,2016-11,vTE,23.83,66.01,23.83,0.66,36.1,0.34,ito:ITO_00141,Natural Language Processing,MRR
32,1,Hypernym Discovery,General,2018-06,CRIM,36.1,100.0,12.3,0.34,36.1,0.52,ito:ITO_00141,Natural Language Processing,MRR
33,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),61.5,88.74,61.5,0.89,69.3,0.89,ito:ITO_00141,Natural Language Processing,MRR
34,1,Visual Dialog,VisDial v1.0 test-std,2019-02,DAN,63.2,91.2,1.7,0.02,69.3,0.91,ito:ITO_00141,Natural Language Processing,MRR
35,1,Visual Dialog,VisDial v1.0 test-std,2019-04,5xFGA (F-RCNNx101),69.3,100.0,6.1,0.09,69.3,1.0,ito:ITO_00141,Natural Language Processing,MRR
36,1,Passage Re-Ranking,MS MARCO,2019-01,BERT + Small Training,0.359,97.55,0.359,0.98,0.368,0.01,ito:ITO_00141,Natural Language Processing,MRR
37,1,Passage Re-Ranking,MS MARCO,2019-04,BERT + Doc2query,0.368,100.0,0.0,0.0,0.368,0.01,ito:ITO_00141,Natural Language Processing,MRR
38,1,Visual Dialog,Visual Dialog v1.0,2019-02,HACAN,64.22,99.04,64.22,0.99,64.84,0.93,ito:ITO_00141,Natural Language Processing,MRR
39,1,Visual Dialog,Visual Dialog v1.0,2020-04,MVAN,64.84,100.0,0.6,0.01,64.84,0.94,ito:ITO_00141,Natural Language Processing,MRR
0,1,Question Answering,QASent,2014-05,Paragraph vector (lexical overlap + dist output),0.6762,92.14,0.6762,0.92,0.7339,0.02,ito:ITO_00141,Natural Language Processing,MAP
1,1,Question Answering,QASent,2014-12,Bigram-CNN (lexical overlap + dist output),0.7113,96.92,0.0,0.0,0.7339,0.02,ito:ITO_00141,Natural Language Processing,MAP
2,1,Question Answering,QASent,2015-11,Attentive LSTM,0.7339,100.0,0.0,0.0,0.7339,0.02,ito:ITO_00141,Natural Language Processing,MAP
3,1,Question Answering,WikiQA,2014-05,Paragraph vector (lexical overlap + dist output),0.5976,64.96,0.5976,0.65,0.92,0.01,ito:ITO_00141,Natural Language Processing,MAP
4,1,Question Answering,WikiQA,2014-12,Bigram-CNN (lexical overlap + dist output),0.652,70.87,0.1,0.11,0.92,0.02,ito:ITO_00141,Natural Language Processing,MAP
5,1,Question Answering,WikiQA,2015-11,LSTM (lexical overlap + dist output),0.682,74.13,0.0,0.0,0.92,0.02,ito:ITO_00141,Natural Language Processing,MAP
6,1,Question Answering,WikiQA,2015-11,Attentive LSTM,0.6886,74.85,0.0,0.0,0.92,0.02,ito:ITO_00141,Natural Language Processing,MAP
7,1,Question Answering,WikiQA,2016-02,LDC,0.7058,76.72,0.0,0.0,0.92,0.02,ito:ITO_00141,Natural Language Processing,MAP
8,1,Question Answering,WikiQA,2016-06,PWIM,0.709,77.07,0.0,0.0,0.92,0.02,ito:ITO_00141,Natural Language Processing,MAP
9,1,Question Answering,WikiQA,2017-07,HyperQA,0.712,77.39,0.0,0.0,0.92,0.02,ito:ITO_00141,Natural Language Processing,MAP
10,1,Question Answering,WikiQA,2019-05,Comp-Clip + LM + LC,0.764,83.04,0.1,0.11,0.92,0.02,ito:ITO_00141,Natural Language Processing,MAP
11,1,Question Answering,WikiQA,2019-11,"TANDA-RoBERTa (ASNQ, WikiQA)",0.92,100.0,0.2,0.22,0.92,0.02,ito:ITO_00141,Natural Language Processing,MAP
12,1,Question Answering,TrecQA,2014-12,CNN,0.711,75.4,0.711,0.75,0.943,0.02,ito:ITO_00141,Natural Language Processing,MAP
13,1,Question Answering,TrecQA,2016-06,PWIN,0.7588,80.47,0.0,0.0,0.943,0.02,ito:ITO_00141,Natural Language Processing,MAP
14,1,Question Answering,TrecQA,2017-07,HyperQA,0.77,81.65,0.0,0.0,0.943,0.02,ito:ITO_00141,Natural Language Processing,MAP
15,1,Question Answering,TrecQA,2019-05,Comp-Clip + LM + LC,0.868,92.05,0.1,0.11,0.943,0.02,ito:ITO_00141,Natural Language Processing,MAP
16,1,Question Answering,TrecQA,2019-11,"TANDA-RoBERTa (ASNQ, TREC-QA)",0.943,100.0,0.1,0.11,0.943,0.02,ito:ITO_00141,Natural Language Processing,MAP
17,1,Question Answering,SemEvalCQA,2015-03,ARC-II,0.78,98.11,0.78,0.98,0.795,0.02,ito:ITO_00141,Natural Language Processing,MAP
18,1,Question Answering,SemEvalCQA,2016-06,Kelp,0.792,99.62,0.0,0.0,0.795,0.02,ito:ITO_00141,Natural Language Processing,MAP
19,1,Question Answering,SemEvalCQA,2017-07,HyperQA,0.795,100.0,0.0,0.0,0.795,0.02,ito:ITO_00141,Natural Language Processing,MAP
20,1,Hypernym Discovery,Medical domain,2016-11,vTE,18.84,55.33,18.84,0.55,34.05,0.46,ito:ITO_00141,Natural Language Processing,MAP
21,1,Hypernym Discovery,Medical domain,2018-06,CRIM,34.05,100.0,15.2,0.45,34.05,0.83,ito:ITO_00141,Natural Language Processing,MAP
22,1,Hypernym Discovery,Music domain,2016-11,vTE,12.99,31.71,12.99,0.32,40.97,0.32,ito:ITO_00141,Natural Language Processing,MAP
23,1,Hypernym Discovery,Music domain,2018-06,CRIM,40.97,100.0,28.0,0.68,40.97,1.0,ito:ITO_00141,Natural Language Processing,MAP
24,1,Hypernym Discovery,General,2016-11,vTE,10.6,53.59,10.6,0.54,19.78,0.26,ito:ITO_00141,Natural Language Processing,MAP
25,1,Hypernym Discovery,General,2018-06,CRIM,19.78,100.0,9.2,0.47,19.78,0.48,ito:ITO_00141,Natural Language Processing,MAP
26,1,Ad-Hoc Information Retrieval,TREC Robust04,2017-04,FNRM-RankProb_Embed,0.2837,86.55,0.2837,0.87,0.3278,0.01,ito:ITO_00141,Natural Language Processing,MAP
27,1,Ad-Hoc Information Retrieval,TREC Robust04,2018-10,SNRM,0.2856,87.13,0.0,0.0,0.3278,0.01,ito:ITO_00141,Natural Language Processing,MAP
28,1,Ad-Hoc Information Retrieval,TREC Robust04,2018-10,SNRM-PRF,0.2971,90.63,0.0,0.0,0.3278,0.01,ito:ITO_00141,Natural Language Processing,MAP
29,1,Ad-Hoc Information Retrieval,TREC Robust04,2018-12,Anserini BM25+RM3,0.302,92.13,0.0,0.0,0.3278,0.01,ito:ITO_00141,Natural Language Processing,MAP
30,1,Ad-Hoc Information Retrieval,TREC Robust04,2019-03,BERT FT(Microblog),0.3278,100.0,0.0,0.0,0.3278,0.01,ito:ITO_00141,Natural Language Processing,MAP
31,1,Cover song identification,Covers80,2019-10,MOVE,0.844,100.0,0.844,1.0,0.844,0.02,ito:ITO_00141,Natural Language Processing,MAP
32,1,Aspect Term Extraction and Sentiment Classification,Aspect Term Extraction and Sentiment Classification,2019-10,MOVE,0.844,100.0,0.844,1.0,0.844,0.02,ito:ITO_00141,Natural Language Processing,MAP
0,1,Relation Extraction,ACE 2005,2014-06,Joint w/ Global,49.5,82.23,49.5,0.82,60.2,0.72,ito:ITO_00141,Natural Language Processing,RE\\+\\ Micro\\ F1
1,1,Relation Extraction,ACE 2005,2016-01,SPTree,55.6,92.36,6.1,0.1,60.2,0.81,ito:ITO_00141,Natural Language Processing,RE\\+\\ Micro\\ F1
2,1,Relation Extraction,ACE 2005,2017-09,Global,57.5,95.51,1.9,0.03,60.2,0.83,ito:ITO_00141,Natural Language Processing,RE\\+\\ Micro\\ F1
3,1,Relation Extraction,ACE 2005,2018-10,MRT,59.6,99.0,2.1,0.03,60.2,0.87,ito:ITO_00141,Natural Language Processing,RE\\+\\ Micro\\ F1
4,1,Relation Extraction,ACE 2005,2019-05,Multi-turn QA,60.2,100.0,0.6,0.01,60.2,0.87,ito:ITO_00141,Natural Language Processing,RE\\+\\ Micro\\ F1
5,1,Relation Extraction,ACE 2004,2014-06,Joint w/ Global,45.3,91.7,45.3,0.92,49.4,0.66,ito:ITO_00141,Natural Language Processing,RE\\+\\ Micro\\ F1
6,1,Relation Extraction,ACE 2004,2016-01,SPTree,48.4,97.98,3.1,0.06,49.4,0.7,ito:ITO_00141,Natural Language Processing,RE\\+\\ Micro\\ F1
7,1,Relation Extraction,ACE 2004,2019-05,Multi-turn QA,49.4,100.0,1.0,0.02,49.4,0.72,ito:ITO_00141,Natural Language Processing,RE\\+\\ Micro\\ F1
8,1,Relation Extraction,CoNLL04,2014-10,Table Representation,61.0,88.53,61.0,0.89,68.9,0.89,ito:ITO_00141,Natural Language Processing,RE\\+\\ Micro\\ F1
9,1,Relation Extraction,CoNLL04,2017-09,Global,67.8,98.4,6.8,0.1,68.9,0.98,ito:ITO_00141,Natural Language Processing,RE\\+\\ Micro\\ F1
10,1,Relation Extraction,CoNLL04,2019-05,Multi-turn QA,68.9,100.0,1.1,0.02,68.9,1.0,ito:ITO_00141,Natural Language Processing,RE\\+\\ Micro\\ F1
0,1,Relation Extraction,ACE 2004,2014-06,Joint w/ Global,48.3,80.9,48.3,0.81,59.7,0.76,ito:ITO_00141,Natural Language Processing,RE\\ Micro\\ F1
1,1,Relation Extraction,ACE 2004,2017-07,Attention,49.3,82.58,1.0,0.02,59.7,0.78,ito:ITO_00141,Natural Language Processing,RE\\ Micro\\ F1
2,1,Relation Extraction,ACE 2004,2019-04,DYGIE,59.7,100.0,10.4,0.17,59.7,0.94,ito:ITO_00141,Natural Language Processing,RE\\ Micro\\ F1
3,1,Relation Extraction,ACE 2005,2014-06,Joint w/ Global,52.1,82.18,52.1,0.82,63.4,0.82,ito:ITO_00141,Natural Language Processing,RE\\ Micro\\ F1
4,1,Relation Extraction,ACE 2005,2017-07,Attention,55.9,88.17,3.8,0.06,63.4,0.88,ito:ITO_00141,Natural Language Processing,RE\\ Micro\\ F1
5,1,Relation Extraction,ACE 2005,2019-04,DYGIE,63.2,99.68,7.3,0.12,63.4,1.0,ito:ITO_00141,Natural Language Processing,RE\\ Micro\\ F1
6,1,Relation Extraction,ACE 2005,2019-09,DYGIE++,63.4,100.0,0.2,0.0,63.4,1.0,ito:ITO_00141,Natural Language Processing,RE\\ Micro\\ F1
0,1,Relation Extraction,ACE 2004,2014-06,Joint w/ Global,79.7,91.19,79.7,0.91,87.4,0.9,ito:ITO_00141,Natural Language Processing,NER\\ Micro\\ F1
1,1,Relation Extraction,ACE 2004,2016-01,SPTree,81.8,93.59,2.1,0.02,87.4,0.92,ito:ITO_00141,Natural Language Processing,NER\\ Micro\\ F1
2,1,Relation Extraction,ACE 2004,2019-04,DYGIE,87.4,100.0,5.6,0.06,87.4,0.99,ito:ITO_00141,Natural Language Processing,NER\\ Micro\\ F1
3,1,Relation Extraction,ACE 2005,2014-06,Joint w/ Global,80.8,91.2,80.8,0.91,88.6,0.91,ito:ITO_00141,Natural Language Processing,NER\\ Micro\\ F1
4,1,Relation Extraction,ACE 2005,2016-01,SPTree,83.4,94.13,2.6,0.03,88.6,0.94,ito:ITO_00141,Natural Language Processing,NER\\ Micro\\ F1
5,1,Relation Extraction,ACE 2005,2017-09,Global,83.6,94.36,0.2,0.0,88.6,0.94,ito:ITO_00141,Natural Language Processing,NER\\ Micro\\ F1
6,1,Relation Extraction,ACE 2005,2019-04,DYGIE,88.4,99.77,4.8,0.05,88.6,1.0,ito:ITO_00141,Natural Language Processing,NER\\ Micro\\ F1
7,1,Relation Extraction,ACE 2005,2019-09,DYGIE++,88.6,100.0,0.2,0.0,88.6,1.0,ito:ITO_00141,Natural Language Processing,NER\\ Micro\\ F1
8,1,Relation Extraction,CoNLL04,2014-10,Table Representation,80.7,91.91,80.7,0.92,87.8,0.91,ito:ITO_00141,Natural Language Processing,NER\\ Micro\\ F1
9,1,Relation Extraction,CoNLL04,2017-09,Global,85.6,97.49,4.9,0.06,87.8,0.97,ito:ITO_00141,Natural Language Processing,NER\\ Micro\\ F1
10,1,Relation Extraction,CoNLL04,2019-05,Multi-turn QA,87.8,100.0,2.2,0.03,87.8,0.99,ito:ITO_00141,Natural Language Processing,NER\\ Micro\\ F1
0,1,Relation Extraction,ACE 2004,2014-06,Joint w/ Global,45.3,75.88,45.3,0.76,59.7,0.57,ito:ITO_00141,Natural Language Processing,Entity\\+Relation\\ F1
1,1,Relation Extraction,ACE 2004,2016-01,SPTree,48.4,81.07,3.1,0.05,59.7,0.61,ito:ITO_00141,Natural Language Processing,Entity\\+Relation\\ F1
2,1,Relation Extraction,ACE 2004,2019-04,DYGIE,59.7,100.0,11.3,0.19,59.7,0.76,ito:ITO_00141,Natural Language Processing,Entity\\+Relation\\ F1
3,1,Relation Extraction,ADE Corpus,2018-04,multi-head,74.58,94.6,74.58,0.95,78.84,0.95,ito:ITO_00141,Natural Language Processing,Entity\\+Relation\\ F1
4,1,Relation Extraction,ADE Corpus,2018-08,multi-head + AT,75.52,95.79,0.9,0.01,78.84,0.96,ito:ITO_00141,Natural Language Processing,Entity\\+Relation\\ F1
5,1,Relation Extraction,ADE Corpus,2019-05,Relation-Metric,77.19,97.91,1.7,0.02,78.84,0.98,ito:ITO_00141,Natural Language Processing,Entity\\+Relation\\ F1
6,1,Relation Extraction,ADE Corpus,2019-09,SpERT,78.84,100.0,1.7,0.02,78.84,1.0,ito:ITO_00141,Natural Language Processing,Entity\\+Relation\\ F1
0,1,Relation Extraction,ACE 2004,2014-06,Joint w/ Global,79.7,91.19,79.7,0.91,87.4,0.86,ito:ITO_00141,Natural Language Processing,Entity\\ F1
1,1,Relation Extraction,ACE 2004,2016-01,SPTree,81.8,93.59,2.1,0.02,87.4,0.88,ito:ITO_00141,Natural Language Processing,Entity\\ F1
2,1,Relation Extraction,ACE 2004,2019-04,DYGIE,87.4,100.0,5.6,0.06,87.4,0.94,ito:ITO_00141,Natural Language Processing,Entity\\ F1
3,1,Relation Extraction,ACE 2005,2014-06,Joint w/ Global,80.8,91.4,80.8,0.91,88.4,0.87,ito:ITO_00141,Natural Language Processing,Entity\\ F1
4,1,Relation Extraction,ACE 2005,2016-01,SPTree,83.4,94.34,2.6,0.03,88.4,0.9,ito:ITO_00141,Natural Language Processing,Entity\\ F1
5,1,Relation Extraction,ACE 2005,2017-09,Global,83.6,94.57,0.2,0.0,88.4,0.9,ito:ITO_00141,Natural Language Processing,Entity\\ F1
6,1,Relation Extraction,ACE 2005,2019-04,DYGIE,88.4,100.0,4.8,0.05,88.4,0.96,ito:ITO_00141,Natural Language Processing,Entity\\ F1
7,1,Relation Extraction,CoNLL04,2014-10,Table Representation,80.7,90.74,80.7,0.91,88.94,0.87,ito:ITO_00141,Natural Language Processing,Entity\\ F1
8,1,Relation Extraction,CoNLL04,2017-09,Global,85.6,96.24,4.9,0.06,88.94,0.93,ito:ITO_00141,Natural Language Processing,Entity\\ F1
9,1,Relation Extraction,CoNLL04,2018-12,Biaffine attention,86.2,96.92,0.6,0.01,88.94,0.93,ito:ITO_00141,Natural Language Processing,Entity\\ F1
10,1,Relation Extraction,CoNLL04,2019-05,Multi-turn QA,87.8,98.72,1.6,0.02,88.94,0.95,ito:ITO_00141,Natural Language Processing,Entity\\ F1
11,1,Relation Extraction,CoNLL04,2019-09,SpERT,88.94,100.0,1.1,0.01,88.94,0.96,ito:ITO_00141,Natural Language Processing,Entity\\ F1
12,1,Relation Extraction,ADE Corpus,2018-04,multi-head,86.4,96.77,86.4,0.97,89.28,0.93,ito:ITO_00141,Natural Language Processing,Entity\\ F1
13,1,Relation Extraction,ADE Corpus,2018-08,multi-head + AT,86.73,97.14,0.3,0.0,89.28,0.94,ito:ITO_00141,Natural Language Processing,Entity\\ F1
14,1,Relation Extraction,ADE Corpus,2019-05,Relation-Metric,87.02,97.47,0.3,0.0,89.28,0.94,ito:ITO_00141,Natural Language Processing,Entity\\ F1
15,1,Relation Extraction,ADE Corpus,2019-09,SpERT,89.28,100.0,2.3,0.03,89.28,0.97,ito:ITO_00141,Natural Language Processing,Entity\\ F1
16,1,Joint Entity and Relation Extraction,SciERC,2018-08,SciIE,64.2,91.28,64.2,0.91,70.33,0.69,ito:ITO_00141,Natural Language Processing,Entity\\ F1
17,1,Joint Entity and Relation Extraction,SciERC,2019-04,DyGIE,65.2,92.71,1.0,0.01,70.33,0.7,ito:ITO_00141,Natural Language Processing,Entity\\ F1
18,1,Joint Entity and Relation Extraction,SciERC,2019-09,DyGIE++,67.5,95.98,2.3,0.03,70.33,0.73,ito:ITO_00141,Natural Language Processing,Entity\\ F1
19,1,Joint Entity and Relation Extraction,SciERC,2019-09,SpERT,70.33,100.0,2.8,0.04,70.33,0.76,ito:ITO_00141,Natural Language Processing,Entity\\ F1
20,1,Coreference Resolution,GAP,2019-08,ProBERT,92.5,100.0,92.5,1.0,92.5,1.0,ito:ITO_00141,Natural Language Processing,Entity\\ F1
0,1,Relation Extraction,ACE 2005,2014-06,Joint w/ Global,52.1,82.44,52.1,0.82,63.2,0.73,ito:ITO_00141,Natural Language Processing,Relation\\ F1
1,1,Relation Extraction,ACE 2005,2016-01,SPTree,55.6,87.97,3.5,0.06,63.2,0.78,ito:ITO_00141,Natural Language Processing,Relation\\ F1
2,1,Relation Extraction,ACE 2005,2017-07,Attention,55.9,88.45,0.3,0.0,63.2,0.78,ito:ITO_00141,Natural Language Processing,Relation\\ F1
3,1,Relation Extraction,ACE 2005,2017-09,Global,57.5,90.98,1.6,0.03,63.2,0.8,ito:ITO_00141,Natural Language Processing,Relation\\ F1
4,1,Relation Extraction,ACE 2005,2018-10,MRT,59.6,94.3,2.1,0.03,63.2,0.83,ito:ITO_00141,Natural Language Processing,Relation\\ F1
5,1,Relation Extraction,ACE 2005,2019-04,DYGIE,63.2,100.0,3.6,0.06,63.2,0.88,ito:ITO_00141,Natural Language Processing,Relation\\ F1
6,1,Relation Extraction,CoNLL04,2014-10,Table Representation,61.0,85.35,61.0,0.85,71.47,0.85,ito:ITO_00141,Natural Language Processing,Relation\\ F1
7,1,Relation Extraction,CoNLL04,2014-10,Table Representation,62.8,87.87,1.8,0.03,71.47,0.88,ito:ITO_00141,Natural Language Processing,Relation\\ F1
8,1,Relation Extraction,CoNLL04,2017-09,Global,67.8,94.86,5.0,0.07,71.47,0.95,ito:ITO_00141,Natural Language Processing,Relation\\ F1
9,1,Relation Extraction,CoNLL04,2019-05,Multi-turn QA,68.9,96.4,1.1,0.02,71.47,0.96,ito:ITO_00141,Natural Language Processing,Relation\\ F1
10,1,Relation Extraction,CoNLL04,2019-09,SpERT,71.47,100.0,2.6,0.04,71.47,1.0,ito:ITO_00141,Natural Language Processing,Relation\\ F1
11,1,Joint Entity and Relation Extraction,SciERC,2018-08,SciIE,39.3,77.3,39.3,0.77,50.84,0.55,ito:ITO_00141,Natural Language Processing,Relation\\ F1
12,1,Joint Entity and Relation Extraction,SciERC,2019-04,DyGIE,41.6,81.83,2.3,0.05,50.84,0.58,ito:ITO_00141,Natural Language Processing,Relation\\ F1
13,1,Joint Entity and Relation Extraction,SciERC,2019-09,DyGIE++,48.4,95.2,6.8,0.13,50.84,0.68,ito:ITO_00141,Natural Language Processing,Relation\\ F1
14,1,Joint Entity and Relation Extraction,SciERC,2019-09,SpERT,50.84,100.0,2.4,0.05,50.84,0.71,ito:ITO_00141,Natural Language Processing,Relation\\ F1
0,1,Machine Translation,WMT2014 English-French,2014-06,CSLM + RNN + WP,34.54,75.75,34.54,0.76,45.6,0.76,ito:ITO_00141,Natural Language Processing,BLEU\\ score
1,1,Machine Translation,WMT2014 English-French,2014-09,RNN-search50*,36.2,79.39,1.7,0.04,45.6,0.79,ito:ITO_00141,Natural Language Processing,BLEU\\ score
2,1,Machine Translation,WMT2014 English-French,2014-09,SMT+LSTM5,36.5,80.04,0.3,0.01,45.6,0.8,ito:ITO_00141,Natural Language Processing,BLEU\\ score
3,1,Machine Translation,WMT2014 English-French,2014-10,LSTM6 + PosUnk,37.5,82.24,1.0,0.02,45.6,0.82,ito:ITO_00141,Natural Language Processing,BLEU\\ score
4,1,Machine Translation,WMT2014 English-French,2016-06,Deep-Att + PosUnk,39.2,85.96,1.7,0.04,45.6,0.86,ito:ITO_00141,Natural Language Processing,BLEU\\ score
5,1,Machine Translation,WMT2014 English-French,2016-09,GNMT+RL,39.9,87.5,0.7,0.02,45.6,0.87,ito:ITO_00141,Natural Language Processing,BLEU\\ score
6,1,Machine Translation,WMT2014 English-French,2017-01,MoE,40.56,88.95,0.7,0.02,45.6,0.89,ito:ITO_00141,Natural Language Processing,BLEU\\ score
7,1,Machine Translation,WMT2014 English-French,2017-05,ConvS2S (ensemble),41.3,90.57,0.7,0.02,45.6,0.91,ito:ITO_00141,Natural Language Processing,BLEU\\ score
8,1,Machine Translation,WMT2014 English-French,2017-11,Weighted Transformer (large),41.4,90.79,0.1,0.0,45.6,0.91,ito:ITO_00141,Natural Language Processing,BLEU\\ score
9,1,Machine Translation,WMT2014 English-French,2018-03,Transformer (big) + Relative Position Representations,41.5,91.01,0.1,0.0,45.6,0.91,ito:ITO_00141,Natural Language Processing,BLEU\\ score
10,1,Machine Translation,WMT2014 English-French,2018-06,Transformer Big,43.2,94.74,1.7,0.04,45.6,0.95,ito:ITO_00141,Natural Language Processing,BLEU\\ score
11,1,Machine Translation,WMT2014 English-French,2018-08,Transformer Big + BT,45.6,100.0,2.4,0.05,45.6,1.0,ito:ITO_00141,Natural Language Processing,BLEU\\ score
12,1,Machine Translation,IWSLT2015 German-English,2014-09,Bi-GRU (MLE+SLE),28.53,80.37,28.53,0.8,35.5,0.63,ito:ITO_00141,Natural Language Processing,BLEU\\ score
13,1,Machine Translation,IWSLT2015 German-English,2016-07,RNNsearch,29.98,84.45,1.4,0.04,35.5,0.66,ito:ITO_00141,Natural Language Processing,BLEU\\ score
14,1,Machine Translation,IWSLT2015 German-English,2016-11,Conv-LSTM (deep+pos),30.4,85.63,0.4,0.01,35.5,0.67,ito:ITO_00141,Natural Language Processing,BLEU\\ score
15,1,Machine Translation,IWSLT2015 German-English,2017-05,ConvS2S,32.31,91.01,1.9,0.05,35.5,0.71,ito:ITO_00141,Natural Language Processing,BLEU\\ score
16,1,Machine Translation,IWSLT2015 German-English,2017-06,Transformer,34.44,97.01,2.1,0.06,35.5,0.76,ito:ITO_00141,Natural Language Processing,BLEU\\ score
17,1,Machine Translation,IWSLT2015 German-English,2019-06,Transformer Base + adversarial MLE,35.18,99.1,0.7,0.02,35.5,0.77,ito:ITO_00141,Natural Language Processing,BLEU\\ score
18,1,Machine Translation,IWSLT2015 German-English,2020-02,TaLK Convolutions,35.5,100.0,0.3,0.01,35.5,0.78,ito:ITO_00141,Natural Language Processing,BLEU\\ score
19,1,Machine Translation,WMT2014 English-German,2015-08,RNN Enc-Dec,11.3,32.29,11.3,0.32,35.0,0.25,ito:ITO_00141,Natural Language Processing,BLEU\\ score
20,1,Machine Translation,WMT2014 English-German,2015-08,RNN Enc-Dec Att,20.9,59.71,9.6,0.27,35.0,0.46,ito:ITO_00141,Natural Language Processing,BLEU\\ score
21,1,Machine Translation,WMT2014 English-German,2016-09,GNMT+RL,26.3,75.14,5.4,0.15,35.0,0.58,ito:ITO_00141,Natural Language Processing,BLEU\\ score
22,1,Machine Translation,WMT2014 English-German,2017-05,ConvS2S (ensemble),26.4,75.43,0.1,0.0,35.0,0.58,ito:ITO_00141,Natural Language Processing,BLEU\\ score
23,1,Machine Translation,WMT2014 English-German,2017-06,Transformer Big,28.4,81.14,2.0,0.06,35.0,0.62,ito:ITO_00141,Natural Language Processing,BLEU\\ score
24,1,Machine Translation,WMT2014 English-German,2017-11,Weighted Transformer (large),28.9,82.57,0.5,0.01,35.0,0.63,ito:ITO_00141,Natural Language Processing,BLEU\\ score
25,1,Machine Translation,WMT2014 English-German,2018-03,Transformer (big) + Relative Position Representations,29.2,83.43,0.3,0.01,35.0,0.64,ito:ITO_00141,Natural Language Processing,BLEU\\ score
26,1,Machine Translation,WMT2014 English-German,2018-06,Transformer Big,29.3,83.71,0.1,0.0,35.0,0.64,ito:ITO_00141,Natural Language Processing,BLEU\\ score
27,1,Machine Translation,WMT2014 English-German,2018-08,Noisy back-translation,35.0,100.0,5.7,0.16,35.0,0.77,ito:ITO_00141,Natural Language Processing,BLEU\\ score
28,1,Machine Translation,WMT2015 English-German,2015-08,BPE word segmentation,22.8,86.69,22.8,0.87,26.3,0.5,ito:ITO_00141,Natural Language Processing,BLEU\\ score
29,1,Machine Translation,WMT2015 English-German,2016-03,Enc-Dec Att (char),23.5,89.35,0.7,0.03,26.3,0.52,ito:ITO_00141,Natural Language Processing,BLEU\\ score
30,1,Machine Translation,WMT2015 English-German,2016-10,ByteNet,26.3,100.0,2.8,0.11,26.3,0.58,ito:ITO_00141,Natural Language Processing,BLEU\\ score
31,1,Machine Translation,WMT2015 English-Russian,2015-08,C2-50k Segmentation,20.9,100.0,20.9,1.0,20.9,0.46,ito:ITO_00141,Natural Language Processing,BLEU\\ score
32,1,Machine Translation,WMT2016 Russian-English,2016-06,Attentional encoder-decoder + BPE,28.0,100.0,28,1.0,28,0.61,ito:ITO_00141,Natural Language Processing,BLEU\\ score
33,1,Machine Translation,WMT2016 Romanian-English,2016-06,Attentional encoder-decoder + BPE,33.3,94.33,33.3,0.94,35.3,0.73,ito:ITO_00141,Natural Language Processing,BLEU\\ score
34,1,Machine Translation,WMT2016 Romanian-English,2019-01,MLM pretraining,35.3,100.0,2.0,0.06,35.3,0.77,ito:ITO_00141,Natural Language Processing,BLEU\\ score
35,1,Machine Translation,WMT2016 English-Russian,2016-06,Attentional encoder-decoder + BPE,26.0,100.0,26.0,1.0,26.0,0.57,ito:ITO_00141,Natural Language Processing,BLEU\\ score
36,1,Machine Translation,WMT2016 Czech-English,2016-06,Attentional encoder-decoder + BPE,31.4,100.0,31.4,1.0,31.4,0.69,ito:ITO_00141,Natural Language Processing,BLEU\\ score
37,1,Machine Translation,WMT2016 English-German,2016-06,Attentional encoder-decoder + BPE,34.2,84.07,34.2,0.84,40.68,0.75,ito:ITO_00141,Natural Language Processing,BLEU\\ score
38,1,Machine Translation,WMT2016 English-German,2019-05,MADL,40.68,100.0,6.5,0.16,40.68,0.89,ito:ITO_00141,Natural Language Processing,BLEU\\ score
39,1,Machine Translation,WMT2016 English-Romanian,2016-06,BiGRU,28.1,86.86,28.1,0.87,32.35,0.62,ito:ITO_00141,Natural Language Processing,BLEU\\ score
40,1,Machine Translation,WMT2016 English-Romanian,2016-08,GRU BPE90k,28.9,89.34,0.8,0.02,32.35,0.63,ito:ITO_00141,Natural Language Processing,BLEU\\ score
41,1,Machine Translation,WMT2016 English-Romanian,2017-05,ConvS2S BPE40k,29.9,92.43,1.0,0.03,32.35,0.66,ito:ITO_00141,Natural Language Processing,BLEU\\ score
42,1,Machine Translation,WMT2016 English-Romanian,2019-09,FlowSeq-large (NPD n = 30),32.35,100.0,2.5,0.08,32.35,0.71,ito:ITO_00141,Natural Language Processing,BLEU\\ score
43,1,Machine Translation,WMT2016 English-Czech,2016-06,Attentional encoder-decoder + BPE,25.8,100.0,25.8,1.0,25.8,0.57,ito:ITO_00141,Natural Language Processing,BLEU\\ score
44,1,Machine Translation,WMT2016 German-English,2016-06,Attentional encoder-decoder + BPE,38.6,100.0,38.6,1.0,38.6,0.85,ito:ITO_00141,Natural Language Processing,BLEU\\ score
45,1,Machine Translation,IWSLT2015 Thai-English,2016-06,Seq-KD + Seq-Inter + Word-KD,14.2,100.0,14.2,1.0,14.2,0.31,ito:ITO_00141,Natural Language Processing,BLEU\\ score
46,1,Machine Translation,IWSLT2015 English-German,2016-07,RNNsearch,25.04,88.7,25.04,0.89,28.23,0.55,ito:ITO_00141,Natural Language Processing,BLEU\\ score
47,1,Machine Translation,IWSLT2015 English-German,2017-05,ConvS2S,26.73,94.69,1.7,0.06,28.23,0.59,ito:ITO_00141,Natural Language Processing,BLEU\\ score
48,1,Machine Translation,IWSLT2015 English-German,2017-06,Transformer,28.23,100.0,1.5,0.05,28.23,0.62,ito:ITO_00141,Natural Language Processing,BLEU\\ score
49,1,Machine Translation,IWSLT2014 German-English,2016-07,Actor-Critic [Bahdanau2017],28.53,78.6,28.53,0.79,36.3,0.63,ito:ITO_00141,Natural Language Processing,BLEU\\ score
50,1,Machine Translation,IWSLT2014 German-English,2017-06,Transformer,34.44,94.88,5.9,0.16,36.3,0.76,ito:ITO_00141,Natural Language Processing,BLEU\\ score
51,1,Machine Translation,IWSLT2014 German-English,2019-01,DynamicConv,35.2,96.97,0.8,0.02,36.3,0.77,ito:ITO_00141,Natural Language Processing,BLEU\\ score
52,1,Machine Translation,IWSLT2014 German-English,2019-05,Local Joint Self-attention,35.7,98.35,0.5,0.01,36.3,0.78,ito:ITO_00141,Natural Language Processing,BLEU\\ score
53,1,Machine Translation,IWSLT2014 German-English,2020-01,MUSE(Parallel Multi-scale Attention),36.3,100.0,0.6,0.02,36.3,0.8,ito:ITO_00141,Natural Language Processing,BLEU\\ score
54,1,Machine Translation,WMT2014 German-English,2017-11,NAT +FT + NPD,23.2,82.01,23.2,0.82,28.29,0.51,ito:ITO_00141,Natural Language Processing,BLEU\\ score
55,1,Machine Translation,WMT2014 German-English,2018-02,Denoising autoencoders (non-autoregressive),25.43,89.89,2.2,0.08,28.29,0.56,ito:ITO_00141,Natural Language Processing,BLEU\\ score
56,1,Machine Translation,WMT2014 German-English,2019-09,FlowSeq-large (NPD n = 30),28.29,100.0,2.9,0.1,28.29,0.62,ito:ITO_00141,Natural Language Processing,BLEU\\ score
57,1,Machine Translation,WMT 2017 English-Chinese,2018-03,Hassan et al. (2018),24.2,99.18,24.2,0.99,24.4,0.53,ito:ITO_00141,Natural Language Processing,BLEU\\ score
58,1,Machine Translation,WMT 2017 English-Chinese,2019-01,DynamicConv,24.4,100.0,0.2,0.01,24.4,0.54,ito:ITO_00141,Natural Language Processing,BLEU\\ score
59,1,Machine Translation,WMT2014 French-English,2018-09,SMT + iterative backtranslation (unsupervised),25.87,100.0,25.87,1.0,25.87,0.57,ito:ITO_00141,Natural Language Processing,BLEU\\ score
60,1,Machine Translation,WMT2014 English-Czech,2019-01,Evolved Transformer Big,28.2,100.0,28.2,1.0,28.2,0.62,ito:ITO_00141,Natural Language Processing,BLEU\\ score
61,1,Machine Translation,WMT2019 English-German,2019-07,Facebook-FAIR (ensemble),43.1,100.0,43.1,1.0,43.1,0.95,ito:ITO_00141,Natural Language Processing,BLEU\\ score
0,1,Dialog Generation,Persona-Chat,2014-09,Seq2Seq + Attention,16.18,81.84,16.18,0.82,19.77,0.21,ito:ITO_00141,Natural Language Processing,Avg\\ F1
1,1,Dialog Generation,Persona-Chat,2020-04,P^2 Bot,19.77,100.0,3.6,0.18,19.77,0.26,ito:ITO_00141,Natural Language Processing,Avg\\ F1
2,1,Coreference Resolution,CoNLL 2012,2017-07,Lee et al. (2017) + ELMo,70.4,91.55,70.4,0.92,76.9,0.92,ito:ITO_00141,Natural Language Processing,Avg\\ F1
3,1,Coreference Resolution,CoNLL 2012,2018-04,c2f-coref + ELMo,73.0,94.93,2.6,0.03,76.9,0.95,ito:ITO_00141,Natural Language Processing,Avg\\ F1
4,1,Coreference Resolution,CoNLL 2012,2019-07,EE + BERT-large,76.61,99.62,3.6,0.05,76.9,1.0,ito:ITO_00141,Natural Language Processing,Avg\\ F1
5,1,Coreference Resolution,CoNLL 2012,2019-08,c2f-coref + BERT-large,76.9,100.0,0.3,0.0,76.9,1.0,ito:ITO_00141,Natural Language Processing,Avg\\ F1
6,1,Knowledge Base Question Answering,WebQSP-WD,2018-08,GGNN,0.2588,100.0,0.2588,1.0,0.2588,0.0,ito:ITO_00141,Natural Language Processing,Avg\\ F1
7,1,Aspect Term Extraction and Sentiment Classification,SemEval,2019-06,IMN-BERT,64.23,100.0,64.23,1.0,64.23,0.84,ito:ITO_00141,Natural Language Processing,Avg\\ F1
0,1,Language Modelling,WikiText-2,2016-11,Inan et al. (2016),92.3,100.0,92.3,1.0,92.3,1.0,ito:ITO_00141,Natural Language Processing,Validation\\ perplexity
1,1,Language Modelling,WikiText-103,2018-03,4 layer QRNN,32.0,88.89,32.0,0.89,36.0,0.35,ito:ITO_00141,Natural Language Processing,Validation\\ perplexity
2,1,Language Modelling,WikiText-103,2018-03,LSTM,36.0,100.0,4.0,0.11,36.0,0.39,ito:ITO_00141,Natural Language Processing,Validation\\ perplexity
3,1,Language Modelling,One Billion Word,2018-09,Adaptive Input Very Large,22.92,96.18,22.92,0.96,23.83,0.25,ito:ITO_00141,Natural Language Processing,Validation\\ perplexity
4,1,Language Modelling,One Billion Word,2018-09,Adaptive Input Large,23.83,100.0,0.9,0.04,23.83,0.26,ito:ITO_00141,Natural Language Processing,Validation\\ perplexity
0,1,Topic modeling,20 Newsgroups,2015-11,NVDM,836.0,100.0,836,1.0,836,1.0,ito:ITO_00141,Natural Language Processing,Test\\ perplexity
1,1,Language Modelling,WikiText-2,2016-11,Inan et al. (2016),87.7,88.32,87.7,0.88,99.3,0.1,ito:ITO_00141,Natural Language Processing,Test\\ perplexity
2,1,Language Modelling,WikiText-2,2016-12,Grave et al. (2016),99.3,100.0,11.6,0.12,99.3,0.12,ito:ITO_00141,Natural Language Processing,Test\\ perplexity
3,1,Language Modelling,WikiText-103,2016-12,LSTM,48.7,100.0,48.7,1.0,48.7,0.06,ito:ITO_00141,Natural Language Processing,Test\\ perplexity
4,1,Language Modelling,Yelp15,2020-02,sMIM (1024) +,8.19,82.06,8.19,0.82,9.98,0.01,ito:ITO_00141,Natural Language Processing,Test\\ perplexity
5,1,Language Modelling,Yelp15,2020-02,sMIM (1024),9.98,100.0,1.8,0.18,9.98,0.01,ito:ITO_00141,Natural Language Processing,Test\\ perplexity
6,1,Language Modelling,Yahoo! Answers,2020-02,sMIM (1024) +,12.62,69.46,12.62,0.69,18.17,0.02,ito:ITO_00141,Natural Language Processing,Test\\ perplexity
7,1,Language Modelling,Yahoo! Answers,2020-02,sMIM (1024),18.17,100.0,5.6,0.31,18.17,0.02,ito:ITO_00141,Natural Language Processing,Test\\ perplexity
0,1,Question Answering,NarrativeQA,2016-11,BiDAF,33.45,61.82,33.45,0.62,54.11,0.52,ito:ITO_00141,Natural Language Processing,BLEU\\-1
1,1,Question Answering,NarrativeQA,2018-09,MHPGM + NOIC,43.63,80.63,10.2,0.19,54.11,0.68,ito:ITO_00141,Natural Language Processing,BLEU\\-1
2,1,Question Answering,NarrativeQA,2018-11,DecaProp,44.35,81.96,0.7,0.01,54.11,0.69,ito:ITO_00141,Natural Language Processing,BLEU\\-1
3,1,Question Answering,NarrativeQA,2019-01,Masque (NarrativeQA + MS MARCO),54.11,100.0,9.8,0.18,54.11,0.84,ito:ITO_00141,Natural Language Processing,BLEU\\-1
4,1,Question Answering,MS MARCO,2016-11,BiDaF Baseline,10.64,19.47,10.64,0.19,54.64,0.17,ito:ITO_00141,Natural Language Processing,BLEU\\-1
5,1,Question Answering,MS MARCO,2018-05,VNET,54.37,99.51,43.7,0.8,54.64,0.85,ito:ITO_00141,Natural Language Processing,BLEU\\-1
6,1,Question Answering,MS MARCO,2018-11,Deep Cascade QA,54.64,100.0,0.3,0.01,54.64,0.85,ito:ITO_00141,Natural Language Processing,BLEU\\-1
7,1,Paraphrase Generation,quora,2017-09,VAE-SVG-eq,22.9,50.11,22.9,0.5,45.7,0.36,ito:ITO_00141,Natural Language Processing,BLEU\\-1
8,1,Paraphrase Generation,quora,2018-06,EDD-LG,45.7,100.0,22.8,0.5,45.7,0.71,ito:ITO_00141,Natural Language Processing,BLEU\\-1
9,1,Question Generation,Visual Question Generation,2018-08,MDN,36.0,100.0,36,1.0,36,0.56,ito:ITO_00141,Natural Language Processing,BLEU\\-1
10,1,Text Generation,DailyDialog,2018-08,AEM+Attention,14.17,100.0,14.17,1.0,14.17,0.22,ito:ITO_00141,Natural Language Processing,BLEU\\-1
11,1,Image Captioning,COCO,2019-05,"NIC (ResNet-50, CutMix)",64.2,100.0,64.2,1.0,64.2,1.0,ito:ITO_00141,Natural Language Processing,BLEU\\-1
0,1,Constituency Parsing,Penn Treebank,2014-12,Semi-supervised LSTM,92.1,96.34,92.1,0.96,95.6,0.95,ito:ITO_00141,Natural Language Processing,F1\\ score
1,1,Constituency Parsing,Penn Treebank,2016-11,Semi-supervised LSTM-LM,93.8,98.12,1.7,0.02,95.6,0.97,ito:ITO_00141,Natural Language Processing,F1\\ score
2,1,Constituency Parsing,Penn Treebank,2017-01,In-order,94.2,98.54,0.4,0.0,95.6,0.97,ito:ITO_00141,Natural Language Processing,F1\\ score
3,1,Constituency Parsing,Penn Treebank,2017-07,Model combination,94.66,99.02,0.5,0.01,95.6,0.98,ito:ITO_00141,Natural Language Processing,F1\\ score
4,1,Constituency Parsing,Penn Treebank,2018-05,Self-attentive encoder + ELMo,95.13,99.51,0.5,0.01,95.6,0.98,ito:ITO_00141,Natural Language Processing,F1\\ score
5,1,Constituency Parsing,Penn Treebank,2019-03,CNN Large + fine-tune,95.6,100.0,0.5,0.01,95.6,0.99,ito:ITO_00141,Natural Language Processing,F1\\ score
6,1,Cross-Lingual Bitext Mining,BUCC French-to-English,2015-11,Monolingual training data,75.8,80.72,75.8,0.81,93.91,0.78,ito:ITO_00141,Natural Language Processing,F1\\ score
7,1,Cross-Lingual Bitext Mining,BUCC French-to-English,2018-11,Multilingual Sentence Embeddings,92.89,98.91,17.1,0.18,93.91,0.96,ito:ITO_00141,Natural Language Processing,F1\\ score
8,1,Cross-Lingual Bitext Mining,BUCC French-to-English,2018-12,Massively Multilingual Sentence Embeddings,93.91,100.0,1.0,0.01,93.91,0.97,ito:ITO_00141,Natural Language Processing,F1\\ score
9,1,Cross-Lingual Bitext Mining,BUCC German-to-English,2015-11,Monolingual training data,76.9,79.95,76.9,0.8,96.19,0.8,ito:ITO_00141,Natural Language Processing,F1\\ score
10,1,Cross-Lingual Bitext Mining,BUCC German-to-English,2018-11,Multilingual Sentence Embeddings,95.58,99.37,18.7,0.19,96.19,0.99,ito:ITO_00141,Natural Language Processing,F1\\ score
11,1,Cross-Lingual Bitext Mining,BUCC German-to-English,2018-12,Massively Multilingual Sentence Embeddings,96.19,100.0,0.6,0.01,96.19,0.99,ito:ITO_00141,Natural Language Processing,F1\\ score
12,1,Chunking,Penn Treebank,2016-08,Low supervision,95.57,98.81,95.57,0.99,96.72,0.99,ito:ITO_00141,Natural Language Processing,F1\\ score
13,1,Chunking,Penn Treebank,2016-11,JMT,95.77,99.02,0.2,0.0,96.72,0.99,ito:ITO_00141,Natural Language Processing,F1\\ score
14,1,Chunking,Penn Treebank,2018-08,Flair embeddings,96.72,100.0,1.0,0.01,96.72,1.0,ito:ITO_00141,Natural Language Processing,F1\\ score
15,1,Temporal Information Extraction,TimeBank,2016-12,Catena,0.511,100.0,0.511,1.0,0.511,0.01,ito:ITO_00141,Natural Language Processing,F1\\ score
16,1,Extract aspect-polarity tuple,SemEval 2015 Task 12,2017-10,Syntactic Grammer Model,0.51,100.0,0.51,1.0,0.51,0.01,ito:ITO_00141,Natural Language Processing,F1\\ score
17,1,Extract Aspect,SemEval 2015 Task 12,2017-10,EliXa,0.7,100.0,0.7,1.0,0.7,0.01,ito:ITO_00141,Natural Language Processing,F1\\ score
18,1,Cross-Lingual Bitext Mining,BUCC Russian-to-English,2018-12,Massively Multilingual Sentence Embeddings,93.3,100.0,93.3,1.0,93.3,0.96,ito:ITO_00141,Natural Language Processing,F1\\ score
19,1,Cross-Lingual Bitext Mining,BUCC Chinese-to-English,2018-12,Massively Multilingual Sentence Embeddings,92.27,100.0,92.27,1.0,92.27,0.95,ito:ITO_00141,Natural Language Processing,F1\\ score
20,1,Low Resource Named Entity Recognition,Uyghur Unsequestered Set,2019-02,Low Resource Named Entity Recognition using Contextual Word Representation and Neural Cross-Lingual Knowledge Transfer,42.88,100.0,42.88,1.0,42.88,0.44,ito:ITO_00141,Natural Language Processing,F1\\ score
21,1,Low Resource Named Entity Recognition,CONLL 2003 German,2019-02,Low Resource Named Entity Recognition using Contextual Word Representation and Neural Cross-Lingual Knowledge Transfer,58.63,89.87,58.63,0.9,65.24,0.61,ito:ITO_00141,Natural Language Processing,F1\\ score
22,1,Low Resource Named Entity Recognition,CONLL 2003 German,2019-11,Zero-Resource Transfer From CoNLL-2003 English dataset.,65.24,100.0,6.6,0.1,65.24,0.67,ito:ITO_00141,Natural Language Processing,F1\\ score
23,1,Low Resource Named Entity Recognition,Conll 2003 Spanish,2019-02,Low Resource Named Entity Recognition using Contextual Word Representation and Neural Cross-Lingual Knowledge Transfer,75.34,99.22,75.34,0.99,75.93,0.78,ito:ITO_00141,Natural Language Processing,F1\\ score
24,1,Low Resource Named Entity Recognition,Conll 2003 Spanish,2019-11,Zero-Resource Cross-lingual Transfer From CoNLL-2003 English dataset.,75.93,100.0,0.6,0.01,75.93,0.79,ito:ITO_00141,Natural Language Processing,F1\\ score
25,1,Low Resource Named Entity Recognition,CONLL 2003 Dutch,2019-02,Low Resource Named Entity Recognition using Contextual Word Representation and Neural Cross-Lingual Knowledge Transfer,75.1,100.0,75.1,1.0,75.1,0.78,ito:ITO_00141,Natural Language Processing,F1\\ score
26,1,Counterspeech Detection,Youtube counterspeech dataset,2019-07,XGBoost,0.715,100.0,0.715,1.0,0.715,0.01,ito:ITO_00141,Natural Language Processing,F1\\ score
27,1,Sentiment Analysis,Financial PhraseBank,2019-08,FinBERT,84.0,100.0,84,1.0,84,0.87,ito:ITO_00141,Natural Language Processing,F1\\ score
28,1,Question Similarity,Q2Q Arabic Benchmark,2019-12,Tha3aroon,0.94848,98.88,0.94848,0.99,0.95924,0.01,ito:ITO_00141,Natural Language Processing,F1\\ score
29,1,Question Similarity,Q2Q Arabic Benchmark,2020-04,Ensemble multilingual BERT model,0.95924,100.0,0.0,0.0,0.95924,0.01,ito:ITO_00141,Natural Language Processing,F1\\ score
0,1,Semantic Similarity Estimation,SICK,2015-02,"Dependency Tree-LSTM (Tai et al., 2015)",0.8676,100.0,0.8676,1.0,0.8676,0.94,ito:ITO_00141,Natural Language Processing,Pearson\\ Correlation
1,1,Semantic Textual Similarity,STS Benchmark,2018-03,USE_T,0.782,84.54,0.782,0.85,0.925,0.85,ito:ITO_00141,Natural Language Processing,Pearson\\ Correlation
2,1,Semantic Textual Similarity,STS Benchmark,2019-05,ERNIE,0.832,89.95,0.0,0.0,0.925,0.9,ito:ITO_00141,Natural Language Processing,Pearson\\ Correlation
3,1,Semantic Textual Similarity,STS Benchmark,2019-06,XLNet (single model),0.925,100.0,0.1,0.11,0.925,1.0,ito:ITO_00141,Natural Language Processing,Pearson\\ Correlation
0,1,Semantic Similarity Estimation,SICK,2015-02,"Dependency Tree-LSTM (Tai et al., 2015)",0.8083,100.0,0.8083,1.0,0.8083,0.88,ito:ITO_00141,Natural Language Processing,Spearman\\ Correlation
1,1,Semantic Textual Similarity,STS Benchmark,2019-10,T5-11B,0.921,100.0,0.921,1.0,0.921,1.0,ito:ITO_00141,Natural Language Processing,Spearman\\ Correlation
0,1,Semantic Similarity Estimation,SICK,2015-02,"Dependency Tree-LSTM (Tai et al., 2015)",0.2532,82.93,0.2532,0.83,0.3053,0.83,ito:ITO_00141,Natural Language Processing,MSE
1,1,Semantic Similarity Estimation,SICK,2015-02,"Bidirectional LSTM (Tai et al., 2015)",0.2736,89.62,0.0,0.0,0.3053,0.9,ito:ITO_00141,Natural Language Processing,MSE
2,1,Semantic Similarity Estimation,SICK,2015-02,"LSTM (Tai et al., 2015)",0.2831,92.73,0.0,0.0,0.3053,0.93,ito:ITO_00141,Natural Language Processing,MSE
3,1,Semantic Similarity Estimation,SICK,2017-07,Doc2VecC,0.3053,100.0,0.0,0.0,0.3053,1.0,ito:ITO_00141,Natural Language Processing,MSE
4,1,Sentiment Analysis,FiQA,2019-08,FinBERT,0.07,100.0,0.07,1.0,0.07,0.23,ito:ITO_00141,Natural Language Processing,MSE
5,1,Reading Comprehension,CrowdSource QA,2020-02,BERT,0.046,100.0,0.046,1.0,0.046,0.15,ito:ITO_00141,Natural Language Processing,MSE
6,1,Community Question Answering,CrowdSource QA,2020-02,BERT,0.046,100.0,0.046,1.0,0.046,0.15,ito:ITO_00141,Natural Language Processing,MSE
7,1,Question Quality Assessment,CrowdSource QA,2020-02,BERT,0.046,100.0,0.046,1.0,0.046,0.15,ito:ITO_00141,Natural Language Processing,MSE
0,1,Question Answering,SemEvalCQA,2015-03,ARC-II,0.753,93.08,0.753,0.93,0.809,0.01,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
1,1,Question Answering,SemEvalCQA,2016-02,AP-CNN,0.755,93.33,0.0,0.0,0.809,0.01,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
2,1,Question Answering,SemEvalCQA,2017-07,HyperQA,0.809,100.0,0.1,0.12,0.809,0.01,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
3,1,Question Answering,YahooCQA,2016-02,AP-BiLSTM,0.568,75.43,0.568,0.75,0.753,0.01,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
4,1,Question Answering,YahooCQA,2017-07,HyperQA,0.683,90.7,0.1,0.13,0.753,0.01,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
5,1,Question Answering,YahooCQA,2020-02,sMIM (1024) +,0.753,100.0,0.1,0.13,0.753,0.01,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
6,1,Question Answering,AI2 Kaggle Dataset,2017-08,IR Baseline,47.2,87.41,47.2,0.87,54.0,0.49,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
7,1,Question Answering,AI2 Kaggle Dataset,2017-08,Our Approach w/o IR,50.54,93.59,3.3,0.06,54.0,0.52,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
8,1,Question Answering,AI2 Kaggle Dataset,2017-08,IR++,50.7,93.89,0.2,0.0,54.0,0.52,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
9,1,Question Answering,AI2 Kaggle Dataset,2017-08,OUR APPROACH,54.0,100.0,3.3,0.06,54.0,0.56,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
10,1,Word Alignment,fr-en,2017-10,Adv,82.1,100.0,82.1,1.0,82.1,0.85,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
11,1,Word Alignment,en-es,2017-10,Adv,81.7,100.0,81.7,1.0,81.7,0.84,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
12,1,Word Alignment,en-fr,2017-10,Adv,82.3,100.0,82.3,1.0,82.3,0.85,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
13,1,Word Alignment,es-en,2017-10,Adv,83.3,100.0,83.3,1.0,83.3,0.86,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
14,1,Entity Typing,Freebase FIGER,2018-06,TextEnt-full,93.2,100.0,93.2,1.0,93.2,0.96,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
15,1,Question-Answer-Generation,Question-Answer-Generation,2018-06,TextEnt-full,93.2,100.0,93.2,1.0,93.2,0.96,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
16,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,LAHA,54.38,100.0,54.38,1.0,54.38,0.56,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
17,1,Multi-Label Text Classification,EUR-Lex,2019-05,LAHA,74.95,93.45,74.95,0.93,80.2,0.77,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
18,1,Multi-Label Text Classification,EUR-Lex,2019-06,NLP-Cap,80.2,100.0,5.2,0.06,80.2,0.83,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
19,1,Multi-Label Text Classification,Amazon-12K,2019-05,LAHA,94.87,100.0,94.87,1.0,94.87,0.98,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
20,1,Multi-Label Text Classification,Wiki-30K,2019-05,LAHA,84.18,100.0,84.18,1.0,84.18,0.87,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
21,1,Multi-Label Text Classification,AAPD,2019-05,LAHA,84.48,100.0,84.48,1.0,84.48,0.87,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
22,1,Text Classification,RCV1,2019-06,NLP-Cap,97.05,100.0,97.05,1.0,97.05,1.0,ito:ITO_00141,Natural Language Processing,P\\-at\\-1
0,1,Question Answering,bAbi,2015-03,End-To-End Memory Networks,7.5,26.13,7.5,0.26,28.7,0.26,ito:ITO_00141,Natural Language Processing,Mean\\ Error\\ Rate
1,1,Question Answering,bAbi,2016-10,LSTM,28.7,100.0,21.2,0.74,28.7,1.0,ito:ITO_00141,Natural Language Processing,Mean\\ Error\\ Rate
0,1,Question Answering,bAbi,2015-03,End-To-End Memory Networks,93.4,93.54,93.4,0.94,99.85,0.94,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(trained\\ on\\ 10k\\)
1,1,Question Answering,bAbi,2016-06,QRN,99.7,99.85,6.3,0.06,99.85,1.0,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(trained\\ on\\ 10k\\)
2,1,Question Answering,bAbi,2020-02,STM,99.85,100.0,0.1,0.0,99.85,1.0,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(trained\\ on\\ 10k\\)
0,1,Question Answering,bAbi,2015-03,End-To-End Memory Networks,86.1,95.56,86.1,0.96,90.1,0.96,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(trained\\ on\\ 1k\\)
1,1,Question Answering,bAbi,2016-06,QRN,90.1,100.0,4.0,0.04,90.1,1.0,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(trained\\ on\\ 1k\\)
0,1,Text Classification,TREC-6,2015-04,TBCNN,4.0,41.67,4.0,0.42,9.6,0.09,ito:ITO_00141,Natural Language Processing,Error
1,1,Text Classification,TREC-6,2015-11,C-LSTM,5.4,56.25,1.4,0.15,9.6,0.12,ito:ITO_00141,Natural Language Processing,Error
2,1,Text Classification,TREC-6,2017-02,GRU-RNN-GLOVE,7.0,72.92,1.6,0.17,9.6,0.15,ito:ITO_00141,Natural Language Processing,Error
3,1,Text Classification,TREC-6,2018-03,Capsule-B,7.2,75.0,0.2,0.02,9.6,0.15,ito:ITO_00141,Natural Language Processing,Error
4,1,Text Classification,TREC-6,2018-05,byte mLSTM7,9.6,100.0,2.4,0.25,9.6,0.21,ito:ITO_00141,Natural Language Processing,Error
5,1,Sentiment Analysis,Yelp Fine-grained classification,2015-09,Char-level CNN,37.95,81.09,37.95,0.81,46.8,0.81,ito:ITO_00141,Natural Language Processing,Error
6,1,Sentiment Analysis,Yelp Fine-grained classification,2019-01,SVDCNN,46.8,100.0,8.8,0.19,46.8,1.0,ito:ITO_00141,Natural Language Processing,Error
7,1,Sentiment Analysis,Yelp Binary classification,2015-09,Char-level CNN,4.88,100.0,4.88,1.0,4.88,0.1,ito:ITO_00141,Natural Language Processing,Error
8,1,Text Classification,DBpedia,2015-09,Char-level CNN,1.55,55.96,1.55,0.56,2.77,0.03,ito:ITO_00141,Natural Language Processing,Error
9,1,Text Classification,DBpedia,2018-05,Seq2CNN(50),2.77,100.0,1.2,0.43,2.77,0.06,ito:ITO_00141,Natural Language Processing,Error
10,1,Text Classification,AG News,2015-09,Char-level CNN,9.51,67.93,9.51,0.68,14.0,0.2,ito:ITO_00141,Natural Language Processing,Error
11,1,Text Classification,AG News,2018-05,Seq2CNN with GWS(50),9.64,68.86,0.1,0.01,14.0,0.21,ito:ITO_00141,Natural Language Processing,Error
12,1,Text Classification,AG News,2018-08,ToWE-SG,14.0,100.0,4.4,0.31,14.0,0.3,ito:ITO_00141,Natural Language Processing,Error
13,1,Text Classification,TREC-50,2016-12,Rules,2.8,100.0,2.8,1.0,2.8,0.06,ito:ITO_00141,Natural Language Processing,Error
14,1,Text Classification,Amazon-5,2019-04,BERT Finetune + UDA,37.12,100.0,37.12,1.0,37.12,0.79,ito:ITO_00141,Natural Language Processing,Error
15,1,Text Classification,Amazon-2,2019-04,BERT Finetune + UDA,3.5,89.74,3.5,0.9,3.9,0.07,ito:ITO_00141,Natural Language Processing,Error
16,1,Text Classification,Amazon-2,2019-09,ULMFiT (Small data),3.9,100.0,0.4,0.1,3.9,0.08,ito:ITO_00141,Natural Language Processing,Error
0,1,Visual Question Answering,Visual7W,2016-06,MCB+Att.,62.2,85.76,62.2,0.86,72.53,0.86,ito:ITO_00141,Natural Language Processing,Percentage\\ correct
1,1,Visual Question Answering,Visual7W,2016-11,CMN,72.53,100.0,10.3,0.14,72.53,1.0,ito:ITO_00141,Natural Language Processing,Percentage\\ correct
0,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-05,DANN,76.26,91.55,76.26,0.92,83.3,0.92,ito:ITO_00141,Natural Language Processing,Average
1,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-11,VFAE,78.36,94.07,2.1,0.03,83.3,0.94,ito:ITO_00141,Natural Language Processing,Average
2,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2017-02,Asymmetric tri-training,78.39,94.11,0.0,0.0,83.3,0.94,ito:ITO_00141,Natural Language Processing,Average
3,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2018-04,Multi-task tri-training,79.15,95.02,0.8,0.01,83.3,0.95,ito:ITO_00141,Natural Language Processing,Average
4,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2018-10,Distributional Correspondence Indexing,83.3,100.0,4.1,0.05,83.3,1.0,ito:ITO_00141,Natural Language Processing,Average
0,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-05,DANN,75.4,93.09,75.4,0.93,81.0,0.93,ito:ITO_00141,Natural Language Processing,DVD
1,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-11,VFAE,76.57,94.53,1.2,0.01,81.0,0.95,ito:ITO_00141,Natural Language Processing,DVD
2,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2018-04,Multi-task tri-training,78.14,96.47,1.6,0.02,81.0,0.96,ito:ITO_00141,Natural Language Processing,DVD
3,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2018-10,Distributional Correspondence Indexing,81.0,100.0,2.9,0.04,81.0,1.0,ito:ITO_00141,Natural Language Processing,DVD
0,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-05,DANN,71.43,87.75,71.43,0.88,81.4,0.88,ito:ITO_00141,Natural Language Processing,Books
1,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-11,VFAE,73.4,90.17,2.0,0.02,81.4,0.9,ito:ITO_00141,Natural Language Processing,Books
2,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2018-04,Multi-task tri-training,74.86,91.97,1.5,0.02,81.4,0.92,ito:ITO_00141,Natural Language Processing,Books
3,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2018-10,Distributional Correspondence Indexing,81.4,100.0,6.5,0.08,81.4,1.0,ito:ITO_00141,Natural Language Processing,Books
0,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-05,DANN,77.67,95.36,77.67,0.95,81.45,0.95,ito:ITO_00141,Natural Language Processing,Electronics
1,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-11,VFAE,80.53,98.87,2.9,0.04,81.45,0.99,ito:ITO_00141,Natural Language Processing,Electronics
2,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2018-04,Multi-task tri-training,81.45,100.0,0.9,0.01,81.45,1.0,ito:ITO_00141,Natural Language Processing,Electronics
0,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-05,DANN,80.53,93.75,80.53,0.94,85.9,0.94,ito:ITO_00141,Natural Language Processing,Kitchen
1,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2015-11,VFAE,82.93,96.54,2.4,0.03,85.9,0.97,ito:ITO_00141,Natural Language Processing,Kitchen
2,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2017-02,Asymmetric tri-training,83.97,97.75,1.0,0.01,85.9,0.98,ito:ITO_00141,Natural Language Processing,Kitchen
3,1,Sentiment Analysis,Multi-Domain Sentiment Dataset,2018-10,Distributional Correspondence Indexing,85.9,100.0,1.9,0.02,85.9,1.0,ito:ITO_00141,Natural Language Processing,Kitchen
0,1,Question Answering,CNN / Daily Mail,2015-06,MemNNs (ensemble),69.4,88.3,69.4,0.88,78.6,0.88,ito:ITO_00141,Natural Language Processing,CNN
1,1,Question Answering,CNN / Daily Mail,2016-03,AS Reader (single model),69.5,88.42,0.1,0.0,78.6,0.88,ito:ITO_00141,Natural Language Processing,CNN
2,1,Question Answering,CNN / Daily Mail,2016-03,AS Reader (ensemble model),75.4,95.93,5.9,0.08,78.6,0.96,ito:ITO_00141,Natural Language Processing,CNN
3,1,Question Answering,CNN / Daily Mail,2016-06,GA Reader,77.9,99.11,2.5,0.03,78.6,0.99,ito:ITO_00141,Natural Language Processing,CNN
4,1,Question Answering,CNN / Daily Mail,2017-03,GA+MAGE (32),78.6,100.0,0.7,0.01,78.6,1.0,ito:ITO_00141,Natural Language Processing,CNN
0,1,Question Answering,CNN / Daily Mail,2015-06,Impatient Reader,68.0,84.05,68.0,0.84,80.9,0.84,ito:ITO_00141,Natural Language Processing,Daily\\ Mail
1,1,Question Answering,CNN / Daily Mail,2015-06,Attentive Reader,69.0,85.29,1.0,0.01,80.9,0.85,ito:ITO_00141,Natural Language Processing,Daily\\ Mail
2,1,Question Answering,CNN / Daily Mail,2016-03,AS Reader (single model),73.9,91.35,4.9,0.06,80.9,0.91,ito:ITO_00141,Natural Language Processing,Daily\\ Mail
3,1,Question Answering,CNN / Daily Mail,2016-03,AS Reader (ensemble model),77.7,96.04,3.8,0.05,80.9,0.96,ito:ITO_00141,Natural Language Processing,Daily\\ Mail
4,1,Question Answering,CNN / Daily Mail,2016-06,GA Reader,80.9,100.0,3.2,0.04,80.9,1.0,ito:ITO_00141,Natural Language Processing,Daily\\ Mail
0,1,Dependency Parsing,Penn Treebank,2015-06,Weiss et al.,92.06,96.15,92.06,0.96,95.75,0.96,ito:ITO_00141,Natural Language Processing,LAS
1,1,Dependency Parsing,Penn Treebank,2016-03,Andor et al.,92.79,96.91,0.7,0.01,95.75,0.97,ito:ITO_00141,Natural Language Processing,LAS
2,1,Dependency Parsing,Penn Treebank,2016-11,Deep Biaffine,93.76,97.92,1.0,0.01,95.75,0.98,ito:ITO_00141,Natural Language Processing,LAS
3,1,Dependency Parsing,Penn Treebank,2016-11,Deep Biaffine,94.22,98.4,0.5,0.01,95.75,0.98,ito:ITO_00141,Natural Language Processing,LAS
4,1,Dependency Parsing,Penn Treebank,2016-11,Deep Biaffine + RoBERTa,95.75,100.0,1.5,0.02,95.75,1.0,ito:ITO_00141,Natural Language Processing,LAS
5,1,Dependency Parsing,CoNLL-2009,2016-11,Biaffine Parser,85.38,100.0,85.38,1.0,85.38,0.89,ito:ITO_00141,Natural Language Processing,LAS
6,1,Dependency Parsing,Sequoia Treebank,2019-11,CamemBERT,94.39,100.0,94.39,1.0,94.39,0.99,ito:ITO_00141,Natural Language Processing,LAS
7,1,Dependency Parsing,Spoken Corpus,2019-11,CamemBERT,80.07,100.0,80.07,1.0,80.07,0.84,ito:ITO_00141,Natural Language Processing,LAS
8,1,Dependency Parsing,French GSD,2019-11,CamemBERT,92.47,100.0,92.47,1.0,92.47,0.97,ito:ITO_00141,Natural Language Processing,LAS
9,1,Dependency Parsing,ParTUT,2019-11,CamemBERT,92.9,100.0,92.9,1.0,92.9,0.97,ito:ITO_00141,Natural Language Processing,LAS
0,1,Dependency Parsing,Penn Treebank,2015-06,Weiss et al.,93.99,96.61,93.99,0.97,97.29,0.97,ito:ITO_00141,Natural Language Processing,UAS
1,1,Dependency Parsing,Penn Treebank,2015-06,Weiss et al.,94.01,96.63,0.0,0.0,97.29,0.97,ito:ITO_00141,Natural Language Processing,UAS
2,1,Dependency Parsing,Penn Treebank,2016-03,Andor et al.,94.61,97.25,0.6,0.01,97.29,0.97,ito:ITO_00141,Natural Language Processing,UAS
3,1,Dependency Parsing,Penn Treebank,2016-11,Deep Biaffine,95.44,98.1,0.8,0.01,97.29,0.98,ito:ITO_00141,Natural Language Processing,UAS
4,1,Dependency Parsing,Penn Treebank,2016-11,Deep Biaffine,95.87,98.54,0.4,0.0,97.29,0.99,ito:ITO_00141,Natural Language Processing,UAS
5,1,Dependency Parsing,Penn Treebank,2016-11,Deep Biaffine + RoBERTa,97.29,100.0,1.4,0.01,97.29,1.0,ito:ITO_00141,Natural Language Processing,UAS
6,1,Dependency Parsing,CoNLL-2009,2016-11,Biaffine Parser,88.9,100.0,88.9,1.0,88.9,0.91,ito:ITO_00141,Natural Language Processing,UAS
7,1,Dependency Grammar Induction,WSJ10,2019-07,D-NDMV,75.6,100.0,75.6,1.0,75.6,0.78,ito:ITO_00141,Natural Language Processing,UAS
8,1,Dependency Parsing,French GSD,2019-11,CamemBERT,94.82,100.0,94.82,1.0,94.82,0.97,ito:ITO_00141,Natural Language Processing,UAS
9,1,Dependency Parsing,ParTUT,2019-11,CamemBERT,95.21,100.0,95.21,1.0,95.21,0.98,ito:ITO_00141,Natural Language Processing,UAS
10,1,Dependency Parsing,Sequoia Treebank,2019-11,CamemBERT,95.56,100.0,95.56,1.0,95.56,0.98,ito:ITO_00141,Natural Language Processing,UAS
11,1,Dependency Parsing,Spoken Corpus,2019-11,CamemBERT,86.05,100.0,86.05,1.0,86.05,0.88,ito:ITO_00141,Natural Language Processing,UAS
0,1,Dependency Parsing,Penn Treebank,2015-06,Weiss et al.,97.44,99.46,97.44,0.99,97.97,0.99,ito:ITO_00141,Natural Language Processing,POS
1,1,Dependency Parsing,Penn Treebank,2018-07,jPTDP,97.97,100.0,0.5,0.01,97.97,1.0,ito:ITO_00141,Natural Language Processing,POS
0,1,Natural Language Inference,SNLI,2015-08,Unlexicalized features,49.4,49.55,49.4,0.5,99.7,0.5,ito:ITO_00141,Natural Language Processing,%\\ Train\\ Accuracy
1,1,Natural Language Inference,SNLI,2015-08,100D LSTM encoders,84.8,85.06,35.4,0.36,99.7,0.85,ito:ITO_00141,Natural Language Processing,%\\ Train\\ Accuracy
2,1,Natural Language Inference,SNLI,2015-08,+ Unigram and bigram features,99.7,100.0,14.9,0.15,99.7,1.0,ito:ITO_00141,Natural Language Processing,%\\ Train\\ Accuracy
0,1,Natural Language Inference,SNLI,2015-08,100D LSTM encoders,220000.0,0.06,220000,0.0,339000000,0.0,ito:ITO_00141,Natural Language Processing,Parameters
1,1,Natural Language Inference,SNLI,2015-09,100D LSTMs w/ word-by-word attention,250000.0,0.07,30000,0.0,339000000,0.0,ito:ITO_00141,Natural Language Processing,Parameters
2,1,Natural Language Inference,SNLI,2015-11,1024D GRU encoders w/ unsupervised 'skip-thoughts' pre-training,15000000.0,4.42,14750000,0.04,339000000,0.04,ito:ITO_00141,Natural Language Processing,Parameters
3,1,Natural Language Inference,SNLI,2017-05,4096D BiLSTM with max-pooling,40000000.0,11.8,25000000,0.07,339000000,0.12,ito:ITO_00141,Natural Language Processing,Parameters
4,1,Natural Language Inference,SNLI,2017-11,KIM Ensemble,43000000.0,12.68,3000000,0.01,339000000,0.13,ito:ITO_00141,Natural Language Processing,Parameters
5,1,Natural Language Inference,SNLI,2018-02,450D DR-BiLSTM Ensemble,45000000.0,13.27,2000000,0.01,339000000,0.13,ito:ITO_00141,Natural Language Processing,Parameters
6,1,Natural Language Inference,SNLI,2018-05,Densely-Connected Recurrent and Co-Attentive Network Ensemble,53300000.0,15.72,8300000,0.02,339000000,0.16,ito:ITO_00141,Natural Language Processing,Parameters
7,1,Natural Language Inference,SNLI,2018-06,Fine-Tuned LM-Pretrained Transformer,85000000.0,25.07,31700000,0.09,339000000,0.25,ito:ITO_00141,Natural Language Processing,Parameters
8,1,Natural Language Inference,SNLI,2018-09,SJRC (BERT-Large +SRL),308000000.0,90.86,223000000,0.66,339000000,0.91,ito:ITO_00141,Natural Language Processing,Parameters
9,1,Natural Language Inference,SNLI,2019-01,MT-DNN,330000000.0,97.35,22000000,0.06,339000000,0.97,ito:ITO_00141,Natural Language Processing,Parameters
10,1,Natural Language Inference,SNLI,2019-09,SemBERT,339000000.0,100.0,9000000,0.03,339000000,1.0,ito:ITO_00141,Natural Language Processing,Parameters
0,1,Relationship extraction using distant supervision,New York Times Corpus,2015-09,PCNN,61.3,86.46,61.3,0.86,70.9,0.83,ito:ITO_00141,Natural Language Processing,P\\-at\\-10%
1,1,Relationship extraction using distant supervision,New York Times Corpus,2018-04,BGWA,70.9,100.0,9.6,0.14,70.9,0.96,ito:ITO_00141,Natural Language Processing,P\\-at\\-10%
2,1,Relation Extraction,NYT Corpus,2016-08,PCNN+ATT,69.4,94.29,69.4,0.94,73.6,0.94,ito:ITO_00141,Natural Language Processing,P\\-at\\-10%
3,1,Relation Extraction,NYT Corpus,2018-12,RESIDE,73.6,100.0,4.2,0.06,73.6,1.0,ito:ITO_00141,Natural Language Processing,P\\-at\\-10%
0,1,Relationship extraction using distant supervision,New York Times Corpus,2015-09,PCNN,46.5,88.74,46.5,0.89,52.4,0.78,ito:ITO_00141,Natural Language Processing,P\\-at\\-30%
1,1,Relationship extraction using distant supervision,New York Times Corpus,2018-04,BGWA,52.4,100.0,5.9,0.11,52.4,0.88,ito:ITO_00141,Natural Language Processing,P\\-at\\-30%
2,1,Relation Extraction,NYT Corpus,2016-08,PCNN+ATT,51.8,87.06,51.8,0.87,59.5,0.87,ito:ITO_00141,Natural Language Processing,P\\-at\\-30%
3,1,Relation Extraction,NYT Corpus,2018-12,RESIDE,59.5,100.0,7.7,0.13,59.5,1.0,ito:ITO_00141,Natural Language Processing,P\\-at\\-30%
0,1,Sentence Compression,Google Dataset,2015-09,LSTM,0.38,88.37,0.38,0.88,0.43,0.88,ito:ITO_00141,Natural Language Processing,CR
1,1,Sentence Compression,Google Dataset,2017-07,BiLSTM,0.43,100.0,0.0,0.0,0.43,1.0,ito:ITO_00141,Natural Language Processing,CR
0,1,Text Summarization,DUC 2004 Task 1,2015-09,Abs+,23.81,83.49,23.81,0.83,28.52,0.34,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
1,1,Text Summarization,DUC 2004 Task 1,2016-02,words-lvt5k-1sent,25.24,88.5,1.4,0.05,28.52,0.36,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
2,1,Text Summarization,DUC 2004 Task 1,2017-04,EndDec+WFE,27.8,97.48,2.6,0.09,28.52,0.39,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
3,1,Text Summarization,DUC 2004 Task 1,2019-04,Transformer+LRPE+PE+Re-ranking+Ensemble,28.52,100.0,0.7,0.02,28.52,0.4,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
4,1,Text Summarization,GigaWord,2016-02,words-lvt5k-1sent,33.71,91.88,33.71,0.92,36.69,0.48,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
5,1,Text Summarization,GigaWord,2017-04,EndDec+WFE,33.88,92.34,0.2,0.01,36.69,0.48,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
6,1,Text Summarization,GigaWord,2017-11,FTSum_g,34.24,93.32,0.4,0.01,36.69,0.48,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
7,1,Text Summarization,GigaWord,2018-06,Seq2seq + E2T_cnn,34.93,95.2,0.7,0.02,36.69,0.49,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
8,1,Text Summarization,GigaWord,2019-05,MASS,35.96,98.01,1.0,0.03,36.69,0.51,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
9,1,Text Summarization,GigaWord,2019-05,UniLM,36.0,98.12,0.0,0.0,36.69,0.51,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
10,1,Text Summarization,GigaWord,2019-12,PEGASUS,36.24,98.77,0.2,0.01,36.69,0.51,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
11,1,Text Summarization,GigaWord,2020-01,ProphetNet,36.69,100.0,0.4,0.01,36.69,0.52,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
12,1,Document Summarization,CNN / Daily Mail,2017-05,"ML + Intra-Attention (Paulus et al., 2017)",35.49,87.22,35.49,0.87,40.69,0.5,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
13,1,Document Summarization,CNN / Daily Mail,2017-05,"ML + RL (Paulus et al., 2017)",36.9,90.69,1.4,0.03,40.69,0.52,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
14,1,Document Summarization,CNN / Daily Mail,2018-08,Bottom-Up Sum,38.34,94.22,1.4,0.03,40.69,0.54,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
15,1,Document Summarization,CNN / Daily Mail,2019-03,BERTSUM+Transformer,39.63,97.39,1.3,0.03,40.69,0.56,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
16,1,Document Summarization,CNN / Daily Mail,2019-05,UniLM (Abstractive Summarization),40.34,99.14,0.7,0.02,40.69,0.57,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
17,1,Document Summarization,CNN / Daily Mail,2019-10,T5-11B,40.69,100.0,0.3,0.01,40.69,0.57,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
18,1,Data-to-Text Generation,E2E NLG Challenge,2017-12,Gong,66.45,93.82,66.45,0.94,70.83,0.94,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
19,1,Data-to-Text Generation,E2E NLG Challenge,2018-03,Zhang,70.83,100.0,4.4,0.06,70.83,1.0,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
20,1,Paper generation,ACL Title and Abstract Dataset,2018-05,Writing-editing Network,20.3,100.0,20.3,1.0,20.3,0.29,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
21,1,Extractive Document Summarization,CNN / Daily Mail,2019-03,BERTSUM,39.63,99.32,39.63,0.99,39.9,0.56,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
22,1,Extractive Document Summarization,CNN / Daily Mail,2019-08,BertSumExt,39.9,100.0,0.3,0.01,39.9,0.56,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
23,1,Abstractive Text Summarization,CNN / Daily Mail,2019-05,UniLM,40.34,97.46,40.34,0.97,41.39,0.57,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
24,1,Abstractive Text Summarization,CNN / Daily Mail,2019-12,PEGASUS,41.11,99.32,0.8,0.02,41.39,0.58,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
25,1,Abstractive Text Summarization,CNN / Daily Mail,2020-01,ProphetNet,41.39,100.0,0.3,0.01,41.39,0.58,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
26,1,Unsupervised Sentence Summarization,GigaWord,2019-07,Contextual Match,24.41,100.0,24.41,1.0,24.41,0.34,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
27,1,Sentence Summarization,GigaWord,2019-07,Contextual Match,24.41,100.0,24.41,1.0,24.41,0.34,ito:ITO_00141,Natural Language Processing,ROUGE\\-L
0,1,Text Summarization,DUC 2004 Task 1,2015-09,Abs+,28.18,85.78,28.18,0.86,32.85,0.53,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
1,1,Text Summarization,DUC 2004 Task 1,2016-02,words-lvt5k-1sent,28.61,87.09,0.4,0.01,32.85,0.54,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
2,1,Text Summarization,DUC 2004 Task 1,2016-06,RAS-Elman,28.97,88.19,0.4,0.01,32.85,0.55,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
3,1,Text Summarization,DUC 2004 Task 1,2017-04,EndDec+WFE,32.28,98.26,3.3,0.1,32.85,0.61,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
4,1,Text Summarization,DUC 2004 Task 1,2019-04,Transformer+LRPE+PE+Re-ranking+Ensemble,32.85,100.0,0.6,0.02,32.85,0.62,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
5,1,Text Summarization,GigaWord,2016-02,words-lvt5k-1sent,36.4,92.13,36.4,0.92,39.51,0.69,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
6,1,Text Summarization,GigaWord,2017-11,FTSum_g,37.27,94.33,0.9,0.02,39.51,0.7,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
7,1,Text Summarization,GigaWord,2019-05,MASS,38.73,98.03,1.5,0.04,39.51,0.73,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
8,1,Text Summarization,GigaWord,2019-05,UniLM,38.9,98.46,0.2,0.01,39.51,0.73,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
9,1,Text Summarization,GigaWord,2019-12,PEGASUS,39.12,99.01,0.2,0.01,39.51,0.74,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
10,1,Text Summarization,GigaWord,2020-01,ProphetNet,39.51,100.0,0.4,0.01,39.51,0.74,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
11,1,Abstractive Text Summarization,CNN / Daily Mail,2017-04,Pointer-Generator + Coverage,39.53,89.43,39.53,0.89,44.2,0.74,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
12,1,Abstractive Text Summarization,CNN / Daily Mail,2019-05,UniLM,43.08,97.47,3.5,0.08,44.2,0.81,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
13,1,Abstractive Text Summarization,CNN / Daily Mail,2019-12,PEGASUS,44.17,99.93,1.1,0.02,44.2,0.83,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
14,1,Abstractive Text Summarization,CNN / Daily Mail,2020-01,ProphetNet,44.2,100.0,0.0,0.0,44.2,0.83,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
15,1,Query-Based Extractive Summarization,Debatepedia,2017-04,SD2,41.26,77.72,41.26,0.78,53.09,0.78,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
16,1,Query-Based Extractive Summarization,Debatepedia,2018-01,RSA Word Count,53.09,100.0,11.8,0.22,53.09,1.0,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
17,1,Document Summarization,CNN / Daily Mail,2017-05,"ML + Intra-Attention (Paulus et al., 2017)",38.3,87.34,38.3,0.87,43.85,0.72,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
18,1,Document Summarization,CNN / Daily Mail,2017-05,"ML + RL (Paulus et al., 2017)",39.87,90.92,1.6,0.04,43.85,0.75,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
19,1,Document Summarization,CNN / Daily Mail,2018-08,Bottom-Up Sum,41.22,94.0,1.4,0.03,43.85,0.78,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
20,1,Document Summarization,CNN / Daily Mail,2019-03,BERTSUM+Transformer,43.25,98.63,2.0,0.05,43.85,0.81,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
21,1,Document Summarization,CNN / Daily Mail,2019-08,BertSumExt,43.85,100.0,0.6,0.01,43.85,0.83,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
22,1,Extractive Document Summarization,CNN / Daily Mail,2018-09,ITS,30.8,70.24,30.8,0.7,43.85,0.58,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
23,1,Extractive Document Summarization,CNN / Daily Mail,2019-03,BERTSUM,43.25,98.63,12.4,0.28,43.85,0.81,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
24,1,Extractive Document Summarization,CNN / Daily Mail,2019-08,BertSumExt,43.85,100.0,0.6,0.01,43.85,0.83,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
25,1,Reader-Aware Summarization,RASG,2018-12,RASG,30.33,100.0,30.33,1.0,30.33,0.57,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
26,1,Unsupervised Sentence Summarization,GigaWord,2019-07,Contextual Match,26.48,100.0,26.48,1.0,26.48,0.5,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
27,1,Sentence Summarization,GigaWord,2019-07,Contextual Match,26.48,100.0,26.48,1.0,26.48,0.5,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
28,1,Timeline Summarization,MTS,2019-08,MTS,39.78,100.0,39.78,1.0,39.78,0.75,ito:ITO_00141,Natural Language Processing,ROUGE\\-1
0,1,Text Summarization,DUC 2004 Task 1,2015-09,Abs+,8.49,72.07,8.49,0.72,11.78,0.39,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
1,1,Text Summarization,DUC 2004 Task 1,2016-02,words-lvt5k-1sent,9.42,79.97,0.9,0.08,11.78,0.44,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
2,1,Text Summarization,DUC 2004 Task 1,2017-04,EndDec+WFE,10.54,89.47,1.1,0.09,11.78,0.49,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
3,1,Text Summarization,DUC 2004 Task 1,2017-09,DRGD,10.75,91.26,0.2,0.02,11.78,0.5,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
4,1,Text Summarization,DUC 2004 Task 1,2019-04,Transformer+LRPE+PE+Re-ranking+Ensemble,11.78,100.0,1.0,0.08,11.78,0.55,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
5,1,Text Summarization,GigaWord,2016-02,words-lvt5k-1sent,17.7,86.68,17.7,0.87,20.42,0.82,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
6,1,Text Summarization,GigaWord,2018-07,CGU,18.0,88.15,0.3,0.01,20.42,0.84,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
7,1,Text Summarization,GigaWord,2018-07,Re^3 Sum,19.03,93.19,1.0,0.05,20.42,0.88,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
8,1,Text Summarization,GigaWord,2019-05,MASS,19.71,96.52,0.7,0.03,20.42,0.91,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
9,1,Text Summarization,GigaWord,2019-05,UniLM,20.05,98.19,0.3,0.01,20.42,0.93,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
10,1,Text Summarization,GigaWord,2020-01,ProphetNet,20.42,100.0,0.4,0.02,20.42,0.95,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
11,1,Abstractive Text Summarization,CNN / Daily Mail,2017-04,Pointer-Generator + Coverage,17.28,80.48,17.28,0.8,21.47,0.8,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
12,1,Abstractive Text Summarization,CNN / Daily Mail,2019-05,UniLM,20.43,95.16,3.1,0.14,21.47,0.95,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
13,1,Abstractive Text Summarization,CNN / Daily Mail,2019-12,PEGASUS,21.47,100.0,1.0,0.05,21.47,1.0,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
14,1,Document Summarization,CNN / Daily Mail,2017-05,"ML + Intra-Attention (Paulus et al., 2017)",14.81,68.72,14.81,0.69,21.55,0.69,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
15,1,Document Summarization,CNN / Daily Mail,2017-05,"ML + RL (Paulus et al., 2017)",15.82,73.41,1.0,0.05,21.55,0.73,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
16,1,Document Summarization,CNN / Daily Mail,2018-08,Bottom-Up Sum,18.68,86.68,2.9,0.13,21.55,0.87,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
17,1,Document Summarization,CNN / Daily Mail,2019-03,BERTSUM+Transformer,20.24,93.92,1.6,0.07,21.55,0.94,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
18,1,Document Summarization,CNN / Daily Mail,2019-05,UniLM (Abstractive Summarization),20.43,94.8,0.2,0.01,21.55,0.95,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
19,1,Document Summarization,CNN / Daily Mail,2019-10,T5-11B,21.55,100.0,1.1,0.05,21.55,1.0,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
20,1,Extractive Document Summarization,CNN / Daily Mail,2018-09,ITS,12.6,61.95,12.6,0.62,20.34,0.58,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
21,1,Extractive Document Summarization,CNN / Daily Mail,2019-03,BERTSUM,20.24,99.51,7.6,0.37,20.34,0.94,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
22,1,Extractive Document Summarization,CNN / Daily Mail,2019-08,BertSumExt,20.34,100.0,0.1,0.0,20.34,0.94,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
23,1,Sentence Summarization,GigaWord,2019-07,Contextual Match,10.05,100.0,10.05,1.0,10.05,0.47,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
24,1,Unsupervised Sentence Summarization,GigaWord,2019-07,Contextual Match,10.05,100.0,10.05,1.0,10.05,0.47,ito:ITO_00141,Natural Language Processing,ROUGE\\-2
0,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2015-12,TD-LSTM,71.88,83.35,71.88,0.83,86.24,0.83,ito:ITO_00141,Natural Language Processing,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
1,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2016-05,MemNet,76.58,88.8,4.7,0.05,86.24,0.89,ito:ITO_00141,Natural Language Processing,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
2,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2017-09,RAM,77.36,89.7,0.8,0.01,86.24,0.9,ito:ITO_00141,Natural Language Processing,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
3,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-02,LCR-Rot,78.29,90.78,0.9,0.01,86.24,0.91,ito:ITO_00141,Natural Language Processing,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
4,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-04,SA-LSTM-P,78.35,90.85,0.1,0.0,86.24,0.91,ito:ITO_00141,Natural Language Processing,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
5,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-05,TNet-LF,78.4,90.91,0.1,0.0,86.24,0.91,ito:ITO_00141,Natural Language Processing,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
6,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-10,HAPN,79.75,92.47,1.3,0.02,86.24,0.92,ito:ITO_00141,Natural Language Processing,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
7,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-02,AEN-BERT,81.53,94.54,1.8,0.02,86.24,0.95,ito:ITO_00141,Natural Language Processing,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
8,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-02,BERT-SPC,81.73,94.77,0.2,0.0,86.24,0.95,ito:ITO_00141,Natural Language Processing,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
9,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-06,SDGCN-BERT,82.46,95.62,0.7,0.01,86.24,0.96,ito:ITO_00141,Natural Language Processing,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
10,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-08,BERT-ADA,84.06,97.47,1.6,0.02,86.24,0.97,ito:ITO_00141,Natural Language Processing,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
11,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-12,LCF-ATEPC,86.24,100.0,2.2,0.03,86.24,1.0,ito:ITO_00141,Natural Language Processing,Mean\\ Acc\\ \\(Restaurant\\ \\+\\ Laptop\\)
0,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2015-12,TD-LSTM,75.63,83.87,75.63,0.84,90.18,0.84,ito:ITO_00141,Natural Language Processing,Restaurant\\ \\(Acc\\)
1,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2016-05,MemNet,80.95,89.76,5.3,0.06,90.18,0.9,ito:ITO_00141,Natural Language Processing,Restaurant\\ \\(Acc\\)
2,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-02,LCR-Rot,81.34,90.2,0.4,0.0,90.18,0.9,ito:ITO_00141,Natural Language Processing,Restaurant\\ \\(Acc\\)
3,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-04,SA-LSTM-P,81.6,90.49,0.3,0.0,90.18,0.9,ito:ITO_00141,Natural Language Processing,Restaurant\\ \\(Acc\\)
4,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-10,HAPN,82.23,91.18,0.6,0.01,90.18,0.91,ito:ITO_00141,Natural Language Processing,Restaurant\\ \\(Acc\\)
5,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-02,AEN-BERT,83.12,92.17,0.9,0.01,90.18,0.92,ito:ITO_00141,Natural Language Processing,Restaurant\\ \\(Acc\\)
6,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-02,BERT-SPC,84.46,93.66,1.3,0.01,90.18,0.94,ito:ITO_00141,Natural Language Processing,Restaurant\\ \\(Acc\\)
7,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-04,BERT-PT,84.95,94.2,0.5,0.01,90.18,0.94,ito:ITO_00141,Natural Language Processing,Restaurant\\ \\(Acc\\)
8,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-08,BERT-ADA,87.89,97.46,2.9,0.03,90.18,0.97,ito:ITO_00141,Natural Language Processing,Restaurant\\ \\(Acc\\)
9,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-12,LCF-ATEPC,90.18,100.0,2.3,0.03,90.18,1.0,ito:ITO_00141,Natural Language Processing,Restaurant\\ \\(Acc\\)
10,1,Aspect-Based Sentiment Analysis,SemEval-2016 Task 5 Subtask 1,2019-03,HAABSA,88.0,100.0,88,1.0,88,0.98,ito:ITO_00141,Natural Language Processing,Restaurant\\ \\(Acc\\)
11,1,Aspect-Based Sentiment Analysis,SemEval 2015 Task 12,2019-03,HAABSA,80.6,98.65,80.6,0.99,81.7,0.89,ito:ITO_00141,Natural Language Processing,Restaurant\\ \\(Acc\\)
12,1,Aspect-Based Sentiment Analysis,SemEval 2015 Task 12,2020-04,HAABSA++,81.7,100.0,1.1,0.01,81.7,0.91,ito:ITO_00141,Natural Language Processing,Restaurant\\ \\(Acc\\)
0,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2015-12,TD-LSTM,68.13,82.79,68.13,0.83,82.29,0.83,ito:ITO_00141,Natural Language Processing,Laptop\\ \\(Acc\\)
1,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2016-05,MemNet,72.21,87.75,4.1,0.05,82.29,0.88,ito:ITO_00141,Natural Language Processing,Laptop\\ \\(Acc\\)
2,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2017-09,RAM,74.49,90.52,2.3,0.03,82.29,0.91,ito:ITO_00141,Natural Language Processing,Laptop\\ \\(Acc\\)
3,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-02,LCR-Rot,75.24,91.43,0.8,0.01,82.29,0.91,ito:ITO_00141,Natural Language Processing,Laptop\\ \\(Acc\\)
4,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-05,TNet-LF,76.01,92.37,0.8,0.01,82.29,0.92,ito:ITO_00141,Natural Language Processing,Laptop\\ \\(Acc\\)
5,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2018-10,HAPN,77.27,93.9,1.3,0.02,82.29,0.94,ito:ITO_00141,Natural Language Processing,Laptop\\ \\(Acc\\)
6,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-02,AEN-BERT,79.93,97.13,2.7,0.03,82.29,0.97,ito:ITO_00141,Natural Language Processing,Laptop\\ \\(Acc\\)
7,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-06,SDGCN-BERT,81.35,98.86,1.4,0.02,82.29,0.99,ito:ITO_00141,Natural Language Processing,Laptop\\ \\(Acc\\)
8,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,2019-12,LCF-ATEPC,82.29,100.0,0.9,0.01,82.29,1.0,ito:ITO_00141,Natural Language Processing,Laptop\\ \\(Acc\\)
0,1,Machine Translation,IWSLT2015 English-Vietnamese,2015-12,LSTM+Attention+Ensemble,26.4,79.35,26.4,0.79,33.27,0.38,ito:ITO_00141,Natural Language Processing,BLEU
1,1,Machine Translation,IWSLT2015 English-Vietnamese,2018-06,DeconvDec,28.47,85.57,2.1,0.06,33.27,0.42,ito:ITO_00141,Natural Language Processing,BLEU
2,1,Machine Translation,IWSLT2015 English-Vietnamese,2018-08,Self-Adaptive Control of Temperature,29.12,87.53,0.7,0.02,33.27,0.42,ito:ITO_00141,Natural Language Processing,BLEU
3,1,Machine Translation,IWSLT2015 English-Vietnamese,2018-09,CVT,29.6,88.97,0.5,0.02,33.27,0.43,ito:ITO_00141,Natural Language Processing,BLEU
4,1,Machine Translation,IWSLT2015 English-Vietnamese,2019-10,Transformer+BPE+FixNorm+ScaleNorm,32.8,98.59,3.2,0.1,33.27,0.48,ito:ITO_00141,Natural Language Processing,BLEU
5,1,Machine Translation,IWSLT2015 English-Vietnamese,2019-10,Transformer+BPE-dropout,33.27,100.0,0.5,0.02,33.27,0.48,ito:ITO_00141,Natural Language Processing,BLEU
6,1,Table-to-Text Generation,WikiBio,2016-03,Table NLM,34.7,77.3,34.7,0.77,44.89,0.51,ito:ITO_00141,Natural Language Processing,BLEU
7,1,Table-to-Text Generation,WikiBio,2017-11,Field-gating Seq2seq + dual attention,44.89,100.0,10.2,0.23,44.89,0.65,ito:ITO_00141,Natural Language Processing,BLEU
8,1,Data-to-Text Generation,RotoWire,2017-07,Encoder-decoder + conditional copy,14.19,81.09,14.19,0.81,17.5,0.21,ito:ITO_00141,Natural Language Processing,BLEU
9,1,Data-to-Text Generation,RotoWire,2018-09,Neural Content Planning + conditional copy,16.5,94.29,2.3,0.13,17.5,0.24,ito:ITO_00141,Natural Language Processing,BLEU
10,1,Data-to-Text Generation,RotoWire,2019-12,Hierarchical transformer encoder + conditional copy,17.5,100.0,1.0,0.06,17.5,0.26,ito:ITO_00141,Natural Language Processing,BLEU
11,1,Machine Translation,WMT 2017 Latvian-English,2017-09,mLSTM with factored data,20.8,85.35,20.8,0.85,24.37,0.3,ito:ITO_00141,Natural Language Processing,BLEU
12,1,Machine Translation,WMT 2017 Latvian-English,2018-10,Transformer trained on highly filtered data,24.37,100.0,3.6,0.15,24.37,0.36,ito:ITO_00141,Natural Language Processing,BLEU
13,1,Data-to-Text Generation,E2E NLG Challenge,2017-12,Gong,64.22,93.62,64.22,0.94,68.6,0.94,ito:ITO_00141,Natural Language Processing,BLEU
14,1,Data-to-Text Generation,E2E NLG Challenge,2018-03,Zhang,65.45,95.41,1.2,0.02,68.6,0.95,ito:ITO_00141,Natural Language Processing,BLEU
15,1,Data-to-Text Generation,E2E NLG Challenge,2018-04,Sys1-Primary,65.61,95.64,0.2,0.0,68.6,0.96,ito:ITO_00141,Natural Language Processing,BLEU
16,1,Data-to-Text Generation,E2E NLG Challenge,2018-05,Slug,66.19,96.49,0.6,0.01,68.6,0.96,ito:ITO_00141,Natural Language Processing,BLEU
17,1,Data-to-Text Generation,E2E NLG Challenge,2019-04,S_1^R,68.6,100.0,2.4,0.03,68.6,1.0,ito:ITO_00141,Natural Language Processing,BLEU
18,1,Unsupervised Machine Translation,WMT2016 English-German,2018-04,PBSMT + NMT,20.2,71.38,20.2,0.71,28.3,0.29,ito:ITO_00141,Natural Language Processing,BLEU
19,1,Unsupervised Machine Translation,WMT2016 English-German,2019-01,SMT as posterior regularization,21.7,76.68,1.5,0.05,28.3,0.32,ito:ITO_00141,Natural Language Processing,BLEU
20,1,Unsupervised Machine Translation,WMT2016 English-German,2019-01,MLM pretraining for encoder and decoder,26.4,93.29,4.7,0.17,28.3,0.38,ito:ITO_00141,Natural Language Processing,BLEU
21,1,Unsupervised Machine Translation,WMT2016 English-German,2019-02,SMT + NMT (tuning and joint refinement),26.9,95.05,0.5,0.02,28.3,0.39,ito:ITO_00141,Natural Language Processing,BLEU
22,1,Unsupervised Machine Translation,WMT2016 English-German,2019-05,MASS (6-layer Transformer),28.3,100.0,1.4,0.05,28.3,0.41,ito:ITO_00141,Natural Language Processing,BLEU
23,1,Unsupervised Machine Translation,WMT2014 English-French,2018-04,PBSMT + NMT,27.6,73.6,27.6,0.74,37.5,0.4,ito:ITO_00141,Natural Language Processing,BLEU
24,1,Unsupervised Machine Translation,WMT2014 English-French,2019-01,SMT as posterior regularization,29.5,78.67,1.9,0.05,37.5,0.43,ito:ITO_00141,Natural Language Processing,BLEU
25,1,Unsupervised Machine Translation,WMT2014 English-French,2019-01,MLM pretraining for encoder and decoder,33.4,89.07,3.9,0.1,37.5,0.49,ito:ITO_00141,Natural Language Processing,BLEU
26,1,Unsupervised Machine Translation,WMT2014 English-French,2019-02,SMT + NMT (tuning and joint refinement),36.2,96.53,2.8,0.07,37.5,0.53,ito:ITO_00141,Natural Language Processing,BLEU
27,1,Unsupervised Machine Translation,WMT2014 English-French,2019-05,MASS (6-layer Transformer),37.5,100.0,1.3,0.03,37.5,0.55,ito:ITO_00141,Natural Language Processing,BLEU
28,1,Unsupervised Machine Translation,WMT2014 French-English,2018-04,PBSMT + NMT,27.7,79.37,27.7,0.79,34.9,0.4,ito:ITO_00141,Natural Language Processing,BLEU
29,1,Unsupervised Machine Translation,WMT2014 French-English,2019-01,SMT as posterior regularization,28.9,82.81,1.2,0.03,34.9,0.42,ito:ITO_00141,Natural Language Processing,BLEU
30,1,Unsupervised Machine Translation,WMT2014 French-English,2019-01,MLM pretraining for encoder and decoder,33.3,95.42,4.4,0.13,34.9,0.49,ito:ITO_00141,Natural Language Processing,BLEU
31,1,Unsupervised Machine Translation,WMT2014 French-English,2019-02,SMT + NMT (tuning and joint refinement),33.5,95.99,0.2,0.01,34.9,0.49,ito:ITO_00141,Natural Language Processing,BLEU
32,1,Unsupervised Machine Translation,WMT2014 French-English,2019-05,MASS (6-layer Transformer),34.9,100.0,1.4,0.04,34.9,0.51,ito:ITO_00141,Natural Language Processing,BLEU
33,1,Unsupervised Machine Translation,WMT2016 German-English,2018-04,PBSMT,25.2,71.59,25.2,0.72,35.2,0.37,ito:ITO_00141,Natural Language Processing,BLEU
34,1,Unsupervised Machine Translation,WMT2016 German-English,2018-10,Synthetic bilingual data init,26.7,75.85,1.5,0.04,35.2,0.39,ito:ITO_00141,Natural Language Processing,BLEU
35,1,Unsupervised Machine Translation,WMT2016 German-English,2019-01,MLM pretraining for encoder and decoder,34.3,97.44,7.6,0.22,35.2,0.5,ito:ITO_00141,Natural Language Processing,BLEU
36,1,Unsupervised Machine Translation,WMT2016 German-English,2019-02,SMT + NMT (tuning and joint refinement),34.4,97.73,0.1,0.0,35.2,0.5,ito:ITO_00141,Natural Language Processing,BLEU
37,1,Unsupervised Machine Translation,WMT2016 German-English,2019-05,MASS (6-layer Transformer),35.2,100.0,0.8,0.02,35.2,0.51,ito:ITO_00141,Natural Language Processing,BLEU
38,1,Machine Translation,ACCURAT balanced test corpus for under resourced languages Russian-Estonian,2018-05,Multilingual Transformer,18.03,100.0,18.03,1.0,18.03,0.26,ito:ITO_00141,Natural Language Processing,BLEU
39,1,Machine Translation,ACCURAT balanced test corpus for under resourced languages Estonian-Russian,2018-05,Multilingual Transformer,19.18,100.0,19.18,1.0,19.18,0.28,ito:ITO_00141,Natural Language Processing,BLEU
40,1,Text Generation,LDC2016E25,2018-05,Graph2Seq,22.0,100.0,22,1.0,22,0.32,ito:ITO_00141,Natural Language Processing,BLEU
41,1,Graph-to-Sequence,LDC2015E86:,2018-05,GRN,33.6,100.0,33.6,1.0,33.6,0.49,ito:ITO_00141,Natural Language Processing,BLEU
42,1,Table-to-Text Generation,Wikipedia Person and Animal Dataset,2018-09,KB-to-Language Generation Model,23.2,100.0,23.2,1.0,23.2,0.34,ito:ITO_00141,Natural Language Processing,BLEU
43,1,KB-to-Language Generation,Wikipedia Person and Animal Dataset,2018-09,KB-to-Language Generation Model,23.2,100.0,23.2,1.0,23.2,0.34,ito:ITO_00141,Natural Language Processing,BLEU
44,1,Machine Translation,WMT 2018 Estonian-English,2018-10,Multi-pass backtranslated adapted transformer,29.0,100.0,29,1.0,29,0.42,ito:ITO_00141,Natural Language Processing,BLEU
45,1,Machine Translation,WMT 2018 English-Estonian,2018-10,Multi-pass backtranslated adapted transformer,24.1,100.0,24.1,1.0,24.1,0.35,ito:ITO_00141,Natural Language Processing,BLEU
46,1,Code Generation,CoNaLa-Ext,2018-10,TranX,18.85,100.0,18.85,1.0,18.85,0.27,ito:ITO_00141,Natural Language Processing,BLEU
47,1,Code Generation,CoNaLa,2018-10,TranX,24.3,100.0,24.3,1.0,24.3,0.35,ito:ITO_00141,Natural Language Processing,BLEU
48,1,Machine Translation,WMT 2018 English-Finnish,2018-10,Transformer trained on highly filtered data,17.4,100.0,17.4,1.0,17.4,0.25,ito:ITO_00141,Natural Language Processing,BLEU
49,1,Machine Translation,WMT 2017 English-Latvian,2018-10,Transformer trained on highly filtered data,22.89,100.0,22.89,1.0,22.89,0.33,ito:ITO_00141,Natural Language Processing,BLEU
50,1,Machine Translation,WMT 2018 Finnish-English,2018-10,Transformer trained on highly filtered data,24.0,90.57,24.0,0.91,26.5,0.35,ito:ITO_00141,Natural Language Processing,BLEU
51,1,Machine Translation,WMT 2018 Finnish-English,2019-06,CT+B/S construction,26.5,100.0,2.5,0.09,26.5,0.39,ito:ITO_00141,Natural Language Processing,BLEU
52,1,Data-to-Text Generation,SR11Deep,2018-10,GCN + feat,0.666,100.0,0.666,1.0,0.666,0.01,ito:ITO_00141,Natural Language Processing,BLEU
53,1,Data-to-Text Generation,WebNLG,2018-10,GCN EC,0.559,100.0,0.559,1.0,0.559,0.01,ito:ITO_00141,Natural Language Processing,BLEU
54,1,Unsupervised Machine Translation,WMT2014 English-German,2019-01,SMT as posterior regularization,17.0,75.56,17.0,0.76,22.5,0.25,ito:ITO_00141,Natural Language Processing,BLEU
55,1,Unsupervised Machine Translation,WMT2014 English-German,2019-02,SMT + NMT (tuning and joint refinement),22.5,100.0,5.5,0.24,22.5,0.33,ito:ITO_00141,Natural Language Processing,BLEU
56,1,Unsupervised Machine Translation,WMT2014 German-English,2019-01,SMT as posterior regularization,20.4,75.56,20.4,0.76,27.0,0.3,ito:ITO_00141,Natural Language Processing,BLEU
57,1,Unsupervised Machine Translation,WMT2014 German-English,2019-02,SMT + NMT (tuning and joint refinement),27.0,100.0,6.6,0.24,27.0,0.39,ito:ITO_00141,Natural Language Processing,BLEU
58,1,Unsupervised Machine Translation,WMT2016 English-Romanian,2019-01,MLM pretraining for encoder and decoder,33.3,94.6,33.3,0.95,35.2,0.49,ito:ITO_00141,Natural Language Processing,BLEU
59,1,Unsupervised Machine Translation,WMT2016 English-Romanian,2019-05,MASS (6-layer Transformer),35.2,100.0,1.9,0.05,35.2,0.51,ito:ITO_00141,Natural Language Processing,BLEU
60,1,Unsupervised Machine Translation,WMT2016 Romanian-English,2019-01,MLM pretraining for encoder and decoder,31.8,96.07,31.8,0.96,33.1,0.46,ito:ITO_00141,Natural Language Processing,BLEU
61,1,Unsupervised Machine Translation,WMT2016 Romanian-English,2019-05,MASS (6-layer Transformer),33.1,100.0,1.3,0.04,33.1,0.48,ito:ITO_00141,Natural Language Processing,BLEU
62,1,Unsupervised Machine Translation,WMT2016 English--Romanian,2019-01,MLM pretraining for encoder and decoder,33.3,100.0,33.3,1.0,33.3,0.49,ito:ITO_00141,Natural Language Processing,BLEU
63,1,Question Answering,JD Product Question Answer,2019-01,PAAG,2.0189,100.0,2.0189,1.0,2.0189,0.03,ito:ITO_00141,Natural Language Processing,BLEU
64,1,Machine Translation,WMT2019 Finnish-English,2019-06,CT+B/S construction,34.1,100.0,34.1,1.0,34.1,0.5,ito:ITO_00141,Natural Language Processing,BLEU
65,1,Machine Translation,WMT2016 Finnish-English,2019-06,CT+B/S construction,32.4,100.0,32.4,1.0,32.4,0.47,ito:ITO_00141,Natural Language Processing,BLEU
66,1,Machine Translation,WMT2017 Finnish-English,2019-06,CT+B/S construction,35.5,100.0,35.5,1.0,35.5,0.52,ito:ITO_00141,Natural Language Processing,BLEU
67,1,Data-to-Text Generation,WebNLG Full,2019-08,Transformer (Pipeline),51.68,97.69,51.68,0.98,52.9,0.75,ito:ITO_00141,Natural Language Processing,BLEU
68,1,Data-to-Text Generation,WebNLG Full,2020-04,DATATUNER_NO_FC,52.9,100.0,1.2,0.02,52.9,0.77,ito:ITO_00141,Natural Language Processing,BLEU
69,1,Data-to-Text Generation,LDC2017T10,2019-09,DualGraph,28.26,74.96,28.26,0.75,37.7,0.41,ito:ITO_00141,Natural Language Processing,BLEU
70,1,Data-to-Text Generation,LDC2017T10,2020-04,DataTuner_FC,37.7,100.0,9.4,0.25,37.7,0.55,ito:ITO_00141,Natural Language Processing,BLEU
71,1,Data-to-Text Generation,ViGGO,2019-10,Bo3,52.1,97.2,52.1,0.97,53.6,0.76,ito:ITO_00141,Natural Language Processing,BLEU
72,1,Data-to-Text Generation,ViGGO,2020-04,DataTuner_FC,53.6,100.0,1.5,0.03,53.6,0.78,ito:ITO_00141,Natural Language Processing,BLEU
73,1,Data-to-Text Generation,Cleaned E2E NLG Challenge,2019-11,TGen,40.73,93.42,40.73,0.93,43.6,0.59,ito:ITO_00141,Natural Language Processing,BLEU
74,1,Data-to-Text Generation,Cleaned E2E NLG Challenge,2020-04,DataTuner_FC,43.6,100.0,2.9,0.07,43.6,0.64,ito:ITO_00141,Natural Language Processing,BLEU
75,1,Machine Translation,IWSLT2015 Chinese-English,2019-11,BP-Transformer,19.84,100.0,19.84,1.0,19.84,0.29,ito:ITO_00141,Natural Language Processing,BLEU
0,1,Entity Disambiguation,AIDA-CoNLL,2016-01,Wikipedia2Vec-GBRT,93.1,98.0,93.1,0.98,95.0,0.98,ito:ITO_00141,Natural Language Processing,In\\-KB\\ Accuracy
1,1,Entity Disambiguation,AIDA-CoNLL,2017-05,NTEE,94.7,99.68,1.6,0.02,95.0,1.0,ito:ITO_00141,Natural Language Processing,In\\-KB\\ Accuracy
2,1,Entity Disambiguation,AIDA-CoNLL,2019-09,confidence-order,95.0,100.0,0.3,0.0,95.0,1.0,ito:ITO_00141,Natural Language Processing,In\\-KB\\ Accuracy
0,1,Entity Disambiguation,TAC2010,2016-01,Wikipedia2Vec,85.2,97.15,85.2,0.97,87.7,0.97,ito:ITO_00141,Natural Language Processing,Micro\\ Precision
1,1,Entity Disambiguation,TAC2010,2017-05,NTEE,87.7,100.0,2.5,0.03,87.7,1.0,ito:ITO_00141,Natural Language Processing,Micro\\ Precision
0,1,Entity Disambiguation,TAC2010,2016-01,Wikipedia2Vec,85.2,97.15,85.2,0.97,87.7,0.88,ito:ITO_00141,Natural Language Processing,Micro\\-F1
1,1,Entity Disambiguation,TAC2010,2017-05,NTEE,87.7,100.0,2.5,0.03,87.7,0.91,ito:ITO_00141,Natural Language Processing,Micro\\-F1
2,1,Entity Disambiguation,AIDA-CoNLL,2016-01,Wikipedia2Vec-GBRT,93.1,98.0,93.1,0.98,95.0,0.97,ito:ITO_00141,Natural Language Processing,Micro\\-F1
3,1,Entity Disambiguation,AIDA-CoNLL,2017-05,NTEE,94.7,99.68,1.6,0.02,95.0,0.98,ito:ITO_00141,Natural Language Processing,Micro\\-F1
4,1,Entity Disambiguation,AIDA-CoNLL,2019-09,confidence-order,95.0,100.0,0.3,0.0,95.0,0.99,ito:ITO_00141,Natural Language Processing,Micro\\-F1
5,1,Junction Detection,Junction Detection,2016-01,Wikipedia2Vec-GBRT,93.1,98.0,93.1,0.98,95.0,0.97,ito:ITO_00141,Natural Language Processing,Micro\\-F1
6,1,Junction Detection,Junction Detection,2017-05,NTEE,94.7,99.68,1.6,0.02,95.0,0.98,ito:ITO_00141,Natural Language Processing,Micro\\-F1
7,1,Junction Detection,Junction Detection,2019-09,confidence-order,95.0,100.0,0.3,0.0,95.0,0.99,ito:ITO_00141,Natural Language Processing,Micro\\-F1
8,1,Entity Disambiguation,WNED-CWEB,2017-04,Global,77.9,98.73,77.9,0.99,78.9,0.81,ito:ITO_00141,Natural Language Processing,Micro\\-F1
9,1,Entity Disambiguation,WNED-CWEB,2019-09,confidence-order,78.9,100.0,1.0,0.01,78.9,0.82,ito:ITO_00141,Natural Language Processing,Micro\\-F1
10,1,Entity Disambiguation,ACE2004,2017-04,Global,88.5,96.3,88.5,0.96,91.9,0.92,ito:ITO_00141,Natural Language Processing,Micro\\-F1
11,1,Entity Disambiguation,ACE2004,2019-09,confidence-order,91.9,100.0,3.4,0.04,91.9,0.95,ito:ITO_00141,Natural Language Processing,Micro\\-F1
12,1,Few-Shot Transfer Learning for Saliency Prediction,Few-Shot Transfer Learning for Saliency Prediction,2017-04,Global,88.5,96.3,88.5,0.96,91.9,0.92,ito:ITO_00141,Natural Language Processing,Micro\\-F1
13,1,Few-Shot Transfer Learning for Saliency Prediction,Few-Shot Transfer Learning for Saliency Prediction,2019-09,confidence-order,91.9,100.0,3.4,0.04,91.9,0.95,ito:ITO_00141,Natural Language Processing,Micro\\-F1
14,1,Entity Disambiguation,MSNBC,2017-04,Global,93.7,97.3,93.7,0.97,96.3,0.97,ito:ITO_00141,Natural Language Processing,Micro\\-F1
15,1,Entity Disambiguation,MSNBC,2019-09,confidence-order,96.3,100.0,2.6,0.03,96.3,1.0,ito:ITO_00141,Natural Language Processing,Micro\\-F1
16,1,Hope Speech Detection for English,Hope Speech Detection for English,2017-04,Global,93.7,97.3,93.7,0.97,96.3,0.97,ito:ITO_00141,Natural Language Processing,Micro\\-F1
17,1,Hope Speech Detection for English,Hope Speech Detection for English,2019-09,confidence-order,96.3,100.0,2.6,0.03,96.3,1.0,ito:ITO_00141,Natural Language Processing,Micro\\-F1
18,1,Entity Disambiguation,AQUAINT,2017-04,Global,88.5,94.45,88.5,0.94,93.7,0.92,ito:ITO_00141,Natural Language Processing,Micro\\-F1
19,1,Entity Disambiguation,AQUAINT,2019-09,confidence-order,93.5,99.79,5.0,0.05,93.7,0.97,ito:ITO_00141,Natural Language Processing,Micro\\-F1
20,1,Entity Disambiguation,AQUAINT,2019-09,MEP + pseudo entities,93.7,100.0,0.2,0.0,93.7,0.97,ito:ITO_00141,Natural Language Processing,Micro\\-F1
21,1,Hope Speech Detection for Malayalam,Hope Speech Detection for Malayalam,2017-04,Global,88.5,94.45,88.5,0.94,93.7,0.92,ito:ITO_00141,Natural Language Processing,Micro\\-F1
22,1,Hope Speech Detection for Malayalam,Hope Speech Detection for Malayalam,2019-09,MEP + pseudo entities,93.7,100.0,5.2,0.06,93.7,0.97,ito:ITO_00141,Natural Language Processing,Micro\\-F1
23,1,Outlier Interpretation,Outlier Interpretation,2017-04,Global,77.9,98.73,77.9,0.99,78.9,0.81,ito:ITO_00141,Natural Language Processing,Micro\\-F1
24,1,Outlier Interpretation,Outlier Interpretation,2019-09,confidence-order,78.9,100.0,1.0,0.01,78.9,0.82,ito:ITO_00141,Natural Language Processing,Micro\\-F1
25,1,Entity Disambiguation,WNED-WIKI,2017-04,Glonal,77.5,86.98,77.5,0.87,89.1,0.8,ito:ITO_00141,Natural Language Processing,Micro\\-F1
26,1,Entity Disambiguation,WNED-WIKI,2019-09,confidence-order,89.1,100.0,11.6,0.13,89.1,0.93,ito:ITO_00141,Natural Language Processing,Micro\\-F1
27,1,Adversarial Attack Detection,Adversarial Attack Detection,2017-04,Glonal,77.5,86.98,77.5,0.87,89.1,0.8,ito:ITO_00141,Natural Language Processing,Micro\\-F1
28,1,Adversarial Attack Detection,Adversarial Attack Detection,2019-09,confidence-order,89.1,100.0,11.6,0.13,89.1,0.93,ito:ITO_00141,Natural Language Processing,Micro\\-F1
29,1,Entity Linking,OKE-2015,2018-08,E2E,66.9,100.0,66.9,1.0,66.9,0.69,ito:ITO_00141,Natural Language Processing,Micro\\-F1
30,1,Entity Linking,OKE-2016,2018-08,E2E,58.4,100.0,58.4,1.0,58.4,0.61,ito:ITO_00141,Natural Language Processing,Micro\\-F1
31,1,Entity Linking,MSNBC,2018-08,E2E,72.4,100.0,72.4,1.0,72.4,0.75,ito:ITO_00141,Natural Language Processing,Micro\\-F1
32,1,Entity Linking,N3-Reuters-128,2018-08,E2E,54.6,100.0,54.6,1.0,54.6,0.57,ito:ITO_00141,Natural Language Processing,Micro\\-F1
33,1,Entity Linking,Derczynski,2018-08,E2E,42.3,100.0,42.3,1.0,42.3,0.44,ito:ITO_00141,Natural Language Processing,Micro\\-F1
34,1,Emotion Recognition in Conversation,EC,2019-03,HRLCE + BERT,0.7709,99.28,0.7709,0.99,0.7765,0.01,ito:ITO_00141,Natural Language Processing,Micro\\-F1
35,1,Emotion Recognition in Conversation,EC,2019-04,NELEC,0.7765,100.0,0.0,0.0,0.7765,0.01,ito:ITO_00141,Natural Language Processing,Micro\\-F1
36,1,Emotion Recognition in Conversation,DailyDialog,2019-09,KET,53.37,100.0,53.37,1.0,53.37,0.55,ito:ITO_00141,Natural Language Processing,Micro\\-F1
37,1,Multi-Label Text Classification,Slashdot,2020-02,MAGNET,56.8,100.0,56.8,1.0,56.8,0.59,ito:ITO_00141,Natural Language Processing,Micro\\-F1
38,1,Multi-Label Text Classification,RCV1-v2,2020-02,MAGNET,88.5,100.0,88.5,1.0,88.5,0.92,ito:ITO_00141,Natural Language Processing,Micro\\-F1
39,1,Multi-Label Text Classification,Reuters-21578,2020-02,MAGNET,89.9,100.0,89.9,1.0,89.9,0.93,ito:ITO_00141,Natural Language Processing,Micro\\-F1
0,1,Click-Through Rate Prediction,Company_,2016-01,FNN,0.8683,99.63,0.8683,1.0,0.8715,1.0,ito:ITO_00141,Natural Language Processing,AUC
1,1,Click-Through Rate Prediction,Company_,2017-03,DeepFM,0.8715,100.0,0.0,0.0,0.8715,1.0,ito:ITO_00141,Natural Language Processing,AUC
2,1,Bilingual Lexicon Induction,Bilingual Lexicon Induction,2016-01,FNN,0.8683,99.63,0.8683,1.0,0.8715,1.0,ito:ITO_00141,Natural Language Processing,AUC
3,1,Bilingual Lexicon Induction,Bilingual Lexicon Induction,2017-03,DeepFM,0.8715,100.0,0.0,0.0,0.8715,1.0,ito:ITO_00141,Natural Language Processing,AUC
4,1,Language Acquisition,SLAM 2018,2018-06,Context Based Model,0.821,100.0,0.821,1.0,0.821,0.94,ito:ITO_00141,Natural Language Processing,AUC
5,1,Relationship extraction using distant supervision,New York Times Corpus,2018-08,BGRU-SET,0.39,100.0,0.39,1.0,0.39,0.45,ito:ITO_00141,Natural Language Processing,AUC
6,1,Click-Through Rate Prediction,Avazu,2018-10,AutoInt,0.7752,95.47,0.7752,0.95,0.812,0.89,ito:ITO_00141,Natural Language Processing,AUC
7,1,Click-Through Rate Prediction,Avazu,2019-04,FGCNN+IPNN,0.7883,97.08,0.0,0.0,0.812,0.9,ito:ITO_00141,Natural Language Processing,AUC
8,1,Click-Through Rate Prediction,Avazu,2019-10,Fi-GNN,0.812,100.0,0.0,0.0,0.812,0.93,ito:ITO_00141,Natural Language Processing,AUC
9,1,Logical Reasoning Reading Comprehension,Logical Reasoning Reading Comprehension,2018-10,AutoInt,0.7752,95.47,0.7752,0.95,0.812,0.89,ito:ITO_00141,Natural Language Processing,AUC
10,1,Logical Reasoning Reading Comprehension,Logical Reasoning Reading Comprehension,2019-04,FGCNN+IPNN,0.7883,97.08,0.0,0.0,0.812,0.9,ito:ITO_00141,Natural Language Processing,AUC
11,1,Logical Reasoning Reading Comprehension,Logical Reasoning Reading Comprehension,2019-10,Fi-GNN,0.812,100.0,0.0,0.0,0.812,0.93,ito:ITO_00141,Natural Language Processing,AUC
0,1,Click-Through Rate Prediction,Company_,2016-01,FNN,0.02629,11.23,0.02629,0.11,0.2341,0.11,ito:ITO_00141,Natural Language Processing,Log\\ Loss
1,1,Click-Through Rate Prediction,Company_,2016-06,Wide & Deep (LR & DNN),0.02634,11.25,0.0,0.0,0.2341,0.11,ito:ITO_00141,Natural Language Processing,Log\\ Loss
2,1,Click-Through Rate Prediction,Company_,2016-06,Wide & Deep (FM & DNN),0.0264,11.28,0.0,0.0,0.2341,0.11,ito:ITO_00141,Natural Language Processing,Log\\ Loss
3,1,Click-Through Rate Prediction,Company_,2016-11,OPNN,0.02641,11.28,0.0,0.0,0.2341,0.11,ito:ITO_00141,Natural Language Processing,Log\\ Loss
4,1,Click-Through Rate Prediction,Company_,2019-06,DeepMCP,0.2341,100.0,0.2,0.85,0.2341,1.0,ito:ITO_00141,Natural Language Processing,Log\\ Loss
5,1,Bilingual Lexicon Induction,Bilingual Lexicon Induction,2016-01,FNN,0.02629,11.23,0.02629,0.11,0.2341,0.11,ito:ITO_00141,Natural Language Processing,Log\\ Loss
6,1,Bilingual Lexicon Induction,Bilingual Lexicon Induction,2016-06,Wide & Deep (LR & DNN),0.02634,11.25,0.0,0.0,0.2341,0.11,ito:ITO_00141,Natural Language Processing,Log\\ Loss
7,1,Bilingual Lexicon Induction,Bilingual Lexicon Induction,2016-06,Wide & Deep (FM & DNN),0.0264,11.28,0.0,0.0,0.2341,0.11,ito:ITO_00141,Natural Language Processing,Log\\ Loss
8,1,Bilingual Lexicon Induction,Bilingual Lexicon Induction,2016-11,OPNN,0.02641,11.28,0.0,0.0,0.2341,0.11,ito:ITO_00141,Natural Language Processing,Log\\ Loss
9,1,Bilingual Lexicon Induction,Bilingual Lexicon Induction,2019-06,DeepMCP,0.2341,100.0,0.2,0.85,0.2341,1.0,ito:ITO_00141,Natural Language Processing,Log\\ Loss
0,1,Language Modelling,Text8,2016-02,"td-LSTM (Zhang et al., 2016)",1.63,100.0,1.63,1.0,1.63,1.0,ito:ITO_00141,Natural Language Processing,Bit\\ per\\ Character\\ \\(BPC\\)
1,1,Language Modelling,Hutter Prize,2016-07,Large RHN,1.27,96.95,1.27,0.97,1.31,0.78,ito:ITO_00141,Natural Language Processing,Bit\\ per\\ Character\\ \\(BPC\\)
2,1,Language Modelling,Hutter Prize,2016-07,RHN,1.31,100.0,0.0,0.0,1.31,0.8,ito:ITO_00141,Natural Language Processing,Bit\\ per\\ Character\\ \\(BPC\\)
3,1,Language Modelling,enwiki8,2016-07,Recurrent highway networks,1.27,94.78,1.27,0.95,1.34,0.78,ito:ITO_00141,Natural Language Processing,Bit\\ per\\ Character\\ \\(BPC\\)
4,1,Language Modelling,enwiki8,2016-09,LN HM-LSTM,1.32,98.51,0.1,0.07,1.34,0.81,ito:ITO_00141,Natural Language Processing,Bit\\ per\\ Character\\ \\(BPC\\)
5,1,Language Modelling,enwiki8,2016-09,Hypernetworks,1.34,100.0,0.0,0.0,1.34,0.82,ito:ITO_00141,Natural Language Processing,Bit\\ per\\ Character\\ \\(BPC\\)
6,1,Language Modelling,enwik8,2016-07,Recurrent Highway Networks,1.27,94.78,1.27,0.95,1.34,0.78,ito:ITO_00141,Natural Language Processing,Bit\\ per\\ Character\\ \\(BPC\\)
7,1,Language Modelling,enwik8,2016-09,LN HM-LSTM,1.32,98.51,0.1,0.07,1.34,0.81,ito:ITO_00141,Natural Language Processing,Bit\\ per\\ Character\\ \\(BPC\\)
8,1,Language Modelling,enwik8,2016-09,Hypernetworks,1.34,100.0,0.0,0.0,1.34,0.82,ito:ITO_00141,Natural Language Processing,Bit\\ per\\ Character\\ \\(BPC\\)
0,1,Question Answering,Children's Book Test,2016-03,AS reader (avg),68.9,73.85,68.9,0.74,93.3,0.74,ito:ITO_00141,Natural Language Processing,Accuracy\\-CN
1,1,Question Answering,Children's Book Test,2016-06,NSE,71.9,77.06,3.0,0.03,93.3,0.77,ito:ITO_00141,Natural Language Processing,Accuracy\\-CN
2,1,Question Answering,Children's Book Test,2019-02,GPT-2,93.3,100.0,21.4,0.23,93.3,1.0,ito:ITO_00141,Natural Language Processing,Accuracy\\-CN
0,1,Question Answering,Children's Book Test,2016-03,AS reader (avg),70.6,79.28,70.6,0.79,89.05,0.79,ito:ITO_00141,Natural Language Processing,Accuracy\\-NE
1,1,Question Answering,Children's Book Test,2016-03,AS reader (greedy),71.0,79.73,0.4,0.0,89.05,0.8,ito:ITO_00141,Natural Language Processing,Accuracy\\-NE
2,1,Question Answering,Children's Book Test,2016-06,NSE,73.2,82.2,2.2,0.02,89.05,0.82,ito:ITO_00141,Natural Language Processing,Accuracy\\-NE
3,1,Question Answering,Children's Book Test,2016-06,GA + feature + fix L(w),74.9,84.11,1.7,0.02,89.05,0.84,ito:ITO_00141,Natural Language Processing,Accuracy\\-NE
4,1,Question Answering,Children's Book Test,2019-02,GPT-2,89.05,100.0,14.1,0.16,89.05,1.0,ito:ITO_00141,Natural Language Processing,Accuracy\\-NE
0,1,Open-Domain Question Answering,SearchQA,2016-03,ASR,41.3,66.4,41.3,0.66,62.2,0.66,ito:ITO_00141,Natural Language Processing,Unigram\\ Acc
1,1,Open-Domain Question Answering,SearchQA,2018-01,AMANDA,46.8,75.24,5.5,0.09,62.2,0.75,ito:ITO_00141,Natural Language Processing,Unigram\\ Acc
2,1,Open-Domain Question Answering,SearchQA,2018-10,Bi-Attention + DCU-LSTM,49.4,79.42,2.6,0.04,62.2,0.79,ito:ITO_00141,Natural Language Processing,Unigram\\ Acc
3,1,Open-Domain Question Answering,SearchQA,2018-11,DecaProp,62.2,100.0,12.8,0.21,62.2,1.0,ito:ITO_00141,Natural Language Processing,Unigram\\ Acc
0,1,Open-Domain Question Answering,SearchQA,2016-03,ASR,22.8,32.2,22.8,0.32,70.8,0.32,ito:ITO_00141,Natural Language Processing,N\\-gram\\ F1
1,1,Open-Domain Question Answering,SearchQA,2018-01,AMANDA,56.6,79.94,33.8,0.48,70.8,0.8,ito:ITO_00141,Natural Language Processing,N\\-gram\\ F1
2,1,Open-Domain Question Answering,SearchQA,2018-10,Bi-Attention + DCU-LSTM,59.5,84.04,2.9,0.04,70.8,0.84,ito:ITO_00141,Natural Language Processing,N\\-gram\\ F1
3,1,Open-Domain Question Answering,SearchQA,2018-11,DecaProp,70.8,100.0,11.3,0.16,70.8,1.0,ito:ITO_00141,Natural Language Processing,N\\-gram\\ F1
0,1,Table-to-Text Generation,WikiBio,2016-03,Table NLM,25.8,61.94,25.8,0.62,41.65,0.53,ito:ITO_00141,Natural Language Processing,ROUGE
1,1,Table-to-Text Generation,WikiBio,2017-11,Field-gating Seq2seq + dual attention,41.21,98.94,15.4,0.37,41.65,0.84,ito:ITO_00141,Natural Language Processing,ROUGE
2,1,Table-to-Text Generation,WikiBio,2017-11,Field-gating Seq2seq + dual attention + beam search,41.65,100.0,0.4,0.01,41.65,0.85,ito:ITO_00141,Natural Language Processing,ROUGE
3,1,Table-to-Text Generation,Wikipedia Person and Animal Dataset,2018-09,KB-to-Language Generation Model,23.4,100.0,23.4,1.0,23.4,0.48,ito:ITO_00141,Natural Language Processing,ROUGE
4,1,KB-to-Language Generation,Wikipedia Person and Animal Dataset,2018-09,KB-to-Language Generation Model,42.0,100.0,42,1.0,42,0.86,ito:ITO_00141,Natural Language Processing,ROUGE
5,1,Image Captioning,COCO,2019-05,"NIC (ResNet-50, CutMix)",49.0,100.0,49,1.0,49,1.0,ito:ITO_00141,Natural Language Processing,ROUGE
0,1,Language Modelling,Text8,2016-03,BN LSTM,16000000.0,1.04,16000000,0.01,1542000000,0.0,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
1,1,Language Modelling,Text8,2016-07,Large RHN,46000000.0,2.98,30000000,0.02,1542000000,0.01,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
2,1,Language Modelling,Text8,2018-08,64-layer Character Transformer Model,235000000.0,15.24,189000000,0.12,1542000000,0.03,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
3,1,Language Modelling,Text8,2019-01,Transformer-XL,277000000.0,17.96,42000000,0.03,1542000000,0.03,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
4,1,Language Modelling,Text8,2019-02,GPT-2,1542000000.0,100.0,1265000000,0.82,1542000000,0.19,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
5,1,Language Modelling,Hutter Prize,2016-07,Large RHN,46000000.0,16.61,46000000,0.17,277000000,0.01,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
6,1,Language Modelling,Hutter Prize,2017-05,Large FS-LSTM-4,47000000.0,16.97,1000000,0.0,277000000,0.01,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
7,1,Language Modelling,Hutter Prize,2018-08,64-layer Character Transformer Model,235000000.0,84.84,188000000,0.68,277000000,0.03,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
8,1,Language Modelling,Hutter Prize,2019-01,24-layer Transformer-XL,277000000.0,100.0,42000000,0.15,277000000,0.03,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
9,1,Language Modelling,enwik8,2016-07,Recurrent Highway Networks,46000000.0,2.98,46000000,0.03,1542000000,0.01,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
10,1,Language Modelling,enwik8,2017-05,Large FS-LSTM-4,47000000.0,3.05,1000000,0.0,1542000000,0.01,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
11,1,Language Modelling,enwik8,2018-08,Transformer (64 layers),235000000.0,15.24,188000000,0.12,1542000000,0.03,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
12,1,Language Modelling,enwik8,2019-01,Transformer-XL (24 layers),277000000.0,17.96,42000000,0.03,1542000000,0.03,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
13,1,Language Modelling,enwik8,2019-02,"GPT-2 (48 layers, h=1600)",1542000000.0,100.0,1265000000,0.82,1542000000,0.19,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
14,1,Language Modelling,enwiki8,2016-07,Recurrent highway networks,46000000.0,2.98,46000000,0.03,1542000000,0.01,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
15,1,Language Modelling,enwiki8,2017-05,Large FS-LSTM-4,47000000.0,3.05,1000000,0.0,1542000000,0.01,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
16,1,Language Modelling,enwiki8,2018-04,Sparse Transformer (fixed),95000000.0,6.16,48000000,0.03,1542000000,0.01,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
17,1,Language Modelling,enwiki8,2018-08,64-layer Transformer,235000000.0,15.24,140000000,0.09,1542000000,0.03,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
18,1,Language Modelling,enwiki8,2019-01,Transformer-XL,277000000.0,17.96,42000000,0.03,1542000000,0.03,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
19,1,Language Modelling,enwiki8,2019-02,GPT-2x,1542000000.0,100.0,1265000000,0.82,1542000000,0.19,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
20,1,Language Modelling,WikiText-2,2017-07,Melis et al. (2017),24000000.0,1.56,24000000,0.02,1542000000,0.0,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
21,1,Language Modelling,WikiText-2,2017-08,AWD-LSTM + continuous cache pointer,33000000.0,2.14,9000000,0.01,1542000000,0.0,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
22,1,Language Modelling,WikiText-2,2017-10,AWD-LSTM 3-layer with Fraternal dropout,34000000.0,2.2,1000000,0.0,1542000000,0.0,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
23,1,Language Modelling,WikiText-2,2017-11,AWD-LSTM-MoS + dynamic eval,35000000.0,2.27,1000000,0.0,1542000000,0.0,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
24,1,Language Modelling,WikiText-2,2018-08,AWD-LSTM-DOC,37000000.0,2.4,2000000,0.0,1542000000,0.0,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
25,1,Language Modelling,WikiText-2,2018-08,AWD-LSTM-DOC x5,185000000.0,12.0,148000000,0.1,1542000000,0.02,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
26,1,Language Modelling,WikiText-2,2019-02,GPT-2,1542000000.0,100.0,1357000000,0.88,1542000000,0.19,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
27,1,Language Modelling,WikiText-103,2018-03,4 layer QRNN,151000000.0,1.82,151000000,0.02,8300000000,0.02,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
28,1,Language Modelling,WikiText-103,2018-09,Transformer (Adaptive inputs),247000000.0,2.98,96000000,0.01,8300000000,0.03,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
29,1,Language Modelling,WikiText-103,2019-01,Transformer-XL Large,257000000.0,3.1,10000000,0.0,8300000000,0.03,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
30,1,Language Modelling,WikiText-103,2019-02,GPT-2 Medium,355000000.0,4.28,98000000,0.01,8300000000,0.04,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
31,1,Language Modelling,WikiText-103,2019-02,GPT-2 Full,1542000000.0,18.58,1187000000,0.14,8300000000,0.19,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
32,1,Language Modelling,WikiText-103,2019-09,Megatron-LM,8300000000.0,100.0,6758000000,0.81,8300000000,1.0,ito:ITO_00141,Natural Language Processing,Number\\ of\\ params
0,1,Part-Of-Speech Tagging,UD,2016-04,Bi-LSTM,96.4,99.5,96.4,1.0,96.88,1.0,ito:ITO_00141,Natural Language Processing,Avg\\ accuracy
1,1,Part-Of-Speech Tagging,UD,2017-11,Adversarial Bi-LSTM,96.73,99.85,0.3,0.0,96.88,1.0,ito:ITO_00141,Natural Language Processing,Avg\\ accuracy
2,1,Part-Of-Speech Tagging,UD,2019-08,BiLSTM-LAN,96.88,100.0,0.1,0.0,96.88,1.0,ito:ITO_00141,Natural Language Processing,Avg\\ accuracy
0,1,Visual Dialog,VisDial v0.9 val,2016-05,HieCoAtt-QI,43.51,78.88,43.51,0.79,55.16,0.61,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
1,1,Visual Dialog,VisDial v0.9 val,2017-09,AMEM Seo et al. (2017),48.53,87.98,5.0,0.09,55.16,0.68,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
2,1,Visual Dialog,VisDial v0.9 val,2017-11,CoAtt Wu et al. (2018),50.29,91.17,1.8,0.03,55.16,0.71,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
3,1,Visual Dialog,VisDial v0.9 val,2018-09,CorefNMN (ResNet-152),50.92,92.31,0.6,0.01,55.16,0.71,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
4,1,Visual Dialog,VisDial v0.9 val,2019-02,DAN,53.33,96.68,2.4,0.04,55.16,0.75,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
5,1,Visual Dialog,VisDial v0.9 val,2019-02,HACAN,54.76,99.27,1.4,0.03,55.16,0.77,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
6,1,Visual Dialog,VisDial v0.9 val,2019-04,9xFGA (VGG),55.16,100.0,0.4,0.01,55.16,0.77,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
7,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,44.15,79.34,44.15,0.79,55.65,0.62,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
8,1,Visual Dialog,Visual Dialog v1.0 test-std,2018-09,CorefNMN (ResNet-152),47.55,85.44,3.4,0.06,55.65,0.67,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
9,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,DAN,49.63,89.18,2.1,0.04,55.65,0.7,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
10,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,HACAN,50.88,91.43,1.2,0.02,55.65,0.71,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
11,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-04,5xFGA (F-RCNNx101),55.65,100.0,4.8,0.09,55.65,0.78,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
12,1,Phrase Grounding,Flickr30k Entities Test,2018-05,BAN (Bottom-Up detector),69.69,97.7,69.69,0.98,71.33,0.98,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
13,1,Phrase Grounding,Flickr30k Entities Test,2019-08,VisualBERT,71.33,100.0,1.6,0.02,71.33,1.0,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
14,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),47.55,85.44,47.55,0.85,55.65,0.67,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
15,1,Visual Dialog,VisDial v1.0 test-std,2019-02,DAN,49.63,89.18,2.1,0.04,55.65,0.7,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
16,1,Visual Dialog,VisDial v1.0 test-std,2019-04,5xFGA (F-RCNNx101),55.65,100.0,6.0,0.11,55.65,0.78,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
17,1,Phrase Grounding,Flickr30k Entities Dev,2019-08,VisualBERT,70.4,100.0,70.4,1.0,70.4,0.99,ito:ITO_00141,Natural Language Processing,R\\-at\\-1
0,1,Visual Dialog,VisDial v0.9 val,2016-05,HieCoAtt-QI,83.96,90.33,83.96,0.9,92.95,0.89,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
1,1,Visual Dialog,VisDial v0.9 val,2017-09,AMEM Seo et al. (2017),87.43,94.06,3.5,0.04,92.95,0.93,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
2,1,Visual Dialog,VisDial v0.9 val,2017-11,CoAtt Wu et al. (2018),88.81,95.55,1.4,0.02,92.95,0.94,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
3,1,Visual Dialog,VisDial v0.9 val,2019-02,DAN,90.38,97.24,1.6,0.02,92.95,0.96,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
4,1,Visual Dialog,VisDial v0.9 val,2019-02,HACAN,90.68,97.56,0.3,0.0,92.95,0.96,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
5,1,Visual Dialog,VisDial v0.9 val,2019-04,9xFGA (VGG),92.95,100.0,2.3,0.02,92.95,0.99,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
6,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,86.88,92.38,86.88,0.92,94.05,0.92,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
7,1,Visual Dialog,Visual Dialog v1.0 test-std,2018-09,CorefNMN (ResNet-152),88.8,94.42,1.9,0.02,94.05,0.94,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
8,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,DAN,89.35,95.0,0.5,0.01,94.05,0.95,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
9,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,HACAN,89.45,95.11,0.1,0.0,94.05,0.95,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
10,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-04,5xFGA (F-RCNNx101),94.05,100.0,4.6,0.05,94.05,1.0,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
11,1,Phrase Grounding,Flickr30k Entities Test,2018-05,BAN (Bottom-Up detector),86.35,99.82,86.35,1.0,86.51,0.92,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
12,1,Phrase Grounding,Flickr30k Entities Test,2019-08,VisualBERT,86.51,100.0,0.2,0.0,86.51,0.92,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
13,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),88.8,94.42,88.8,0.94,94.05,0.94,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
14,1,Visual Dialog,VisDial v1.0 test-std,2019-02,DAN,89.35,95.0,0.5,0.01,94.05,0.95,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
15,1,Visual Dialog,VisDial v1.0 test-std,2019-04,5xFGA (F-RCNNx101),94.05,100.0,4.7,0.05,94.05,1.0,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
16,1,Phrase Grounding,Flickr30k Entities Dev,2019-08,VisualBERT,86.31,100.0,86.31,1.0,86.31,0.92,ito:ITO_00141,Natural Language Processing,R\\-at\\-10
0,1,Visual Dialog,VisDial v0.9 val,2016-05,HieCoAtt-QI,74.49,86.36,74.49,0.86,86.26,0.86,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
1,1,Visual Dialog,VisDial v0.9 val,2017-09,AMEM Seo et al. (2017),78.66,91.19,4.2,0.05,86.26,0.91,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
2,1,Visual Dialog,VisDial v0.9 val,2017-11,CoAtt Wu et al. (2018),80.71,93.57,2.0,0.02,86.26,0.93,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
3,1,Visual Dialog,VisDial v0.9 val,2019-02,DAN,82.42,95.55,1.7,0.02,86.26,0.95,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
4,1,Visual Dialog,VisDial v0.9 val,2019-02,HACAN,83.03,96.26,0.6,0.01,86.26,0.96,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
5,1,Visual Dialog,VisDial v0.9 val,2019-04,9xFGA (VGG),86.26,100.0,3.2,0.04,86.26,0.99,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
6,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,76.88,88.64,76.88,0.89,86.73,0.89,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
7,1,Visual Dialog,Visual Dialog v1.0 test-std,2018-09,CorefNMN (ResNet-152),78.1,90.05,1.2,0.01,86.73,0.9,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
8,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,DAN,79.75,91.95,1.7,0.02,86.73,0.92,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
9,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,HACAN,80.63,92.97,0.9,0.01,86.73,0.93,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
10,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-04,5xFGA (F-RCNNx101),86.73,100.0,6.1,0.07,86.73,1.0,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
11,1,Phrase Grounding,Flickr30k Entities Test,2018-05,BAN (Bottom-Up detector),84.22,99.11,84.22,0.99,84.98,0.97,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
12,1,Phrase Grounding,Flickr30k Entities Test,2019-08,VisualBERT,84.98,100.0,0.8,0.01,84.98,0.98,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
13,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),78.1,90.05,78.1,0.9,86.73,0.9,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
14,1,Visual Dialog,VisDial v1.0 test-std,2019-02,DAN,79.75,91.95,1.7,0.02,86.73,0.92,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
15,1,Visual Dialog,VisDial v1.0 test-std,2019-04,5xFGA (F-RCNNx101),86.73,100.0,7.0,0.08,86.73,1.0,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
16,1,Phrase Grounding,Flickr30k Entities Dev,2019-08,VisualBERT,84.49,100.0,84.49,1.0,84.49,0.97,ito:ITO_00141,Natural Language Processing,R\\-at\\-5
0,1,Visual Dialog,VisDial v0.9 val,2016-05,HieCoAtt-QI,5.84,100.0,5.84,1.0,5.84,1.0,ito:ITO_00141,Natural Language Processing,Mean\\ Rank
1,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),4.4,100.0,4.4,1.0,4.4,0.75,ito:ITO_00141,Natural Language Processing,Mean\\ Rank
2,1,Visual Dialog,Visual Dialog v1.0,2019-02,HACAN,4.2,97.67,4.2,0.98,4.3,0.72,ito:ITO_00141,Natural Language Processing,Mean\\ Rank
3,1,Visual Dialog,Visual Dialog v1.0,2019-02,DAN,4.3,100.0,0.1,0.02,4.3,0.74,ito:ITO_00141,Natural Language Processing,Mean\\ Rank
0,1,Fact-based Text Editing,Fact-based Text Editing,2018-07,Choi et al. (2018) w augmentation,47.1,91.46,47.1,0.91,51.5,0.48,ito:ITO_00141,Natural Language Processing,Precision
1,1,Fact-based Text Editing,Fact-based Text Editing,2019-03,LabelGCN Xiong et al. (2019),50.3,97.67,3.2,0.06,51.5,0.51,ito:ITO_00141,Natural Language Processing,Precision
2,1,Fact-based Text Editing,Fact-based Text Editing,2019-05,ELMo (distant denoising data),51.5,100.0,1.2,0.02,51.5,0.52,ito:ITO_00141,Natural Language Processing,Precision
3,1,Chinese Word Segmentation,MSR,2019-01,Glyce + BERT,98.2,100.0,98.2,1.0,98.2,1.0,ito:ITO_00141,Natural Language Processing,Precision
4,1,Chinese Word Segmentation,AS,2019-01,Glyce + BERT,96.6,100.0,96.6,1.0,96.6,0.98,ito:ITO_00141,Natural Language Processing,Precision
5,1,Chinese Word Segmentation,PKU,2019-01,Glyce + BERT,97.1,100.0,97.1,1.0,97.1,0.99,ito:ITO_00141,Natural Language Processing,Precision
6,1,Chinese Word Segmentation,CITYU,2019-01,Glyce + BERT,97.9,100.0,97.9,1.0,97.9,1.0,ito:ITO_00141,Natural Language Processing,Precision
7,1,Chinese Named Entity Recognition,OntoNotes,2019-01,Glyce + BERT,81.87,100.0,81.87,1.0,81.87,0.83,ito:ITO_00141,Natural Language Processing,Precision
8,1,Chinese Named Entity Recognition,Weibo NER,2019-01,Glyce + BERT,67.68,100.0,67.68,1.0,67.68,0.69,ito:ITO_00141,Natural Language Processing,Precision
9,1,Chinese Named Entity Recognition,Resume NER,2019-01,Glyce + BERT,96.62,100.0,96.62,1.0,96.62,0.98,ito:ITO_00141,Natural Language Processing,Precision
10,1,Chinese Named Entity Recognition,MSRA,2019-01,Glyce + BERT,95.57,100.0,95.57,1.0,95.57,0.97,ito:ITO_00141,Natural Language Processing,Precision
11,1,Grammatical Error Correction,CoNLL-2014 Shared Task,2019-03,Copy-augmented Model (4 Ensemble +Denoising Autoencoder),71.57,100.0,71.57,1.0,71.57,0.73,ito:ITO_00141,Natural Language Processing,Precision
12,1,Entity Typing,Open Entity,2019-05,ERNIE,78.42,100.0,78.42,1.0,78.42,0.8,ito:ITO_00141,Natural Language Processing,Precision
13,1,Distractor Generation,Distractor Generation,2019-05,ERNIE,78.42,100.0,78.42,1.0,78.42,0.8,ito:ITO_00141,Natural Language Processing,Precision
14,1,Relation Extraction,FewRel,2019-05,ERNIE,88.49,100.0,88.49,1.0,88.49,0.9,ito:ITO_00141,Natural Language Processing,Precision
15,1,Relation Extraction,TACRED,2019-05,ERNIE,69.97,98.83,69.97,0.99,70.8,0.71,ito:ITO_00141,Natural Language Processing,Precision
16,1,Relation Extraction,TACRED,2019-07,SpanBERT,70.8,100.0,0.8,0.01,70.8,0.72,ito:ITO_00141,Natural Language Processing,Precision
17,1,Named Entity Recognition,Long-tail emerging entities,2019-08,Cross-BiLSTM-CNN,58.28,100.0,58.28,1.0,58.28,0.59,ito:ITO_00141,Natural Language Processing,Precision
18,1,Named Entity Recognition,French Treebank,2019-11,CamemBERT (subword masking),88.35,100.0,88.35,1.0,88.35,0.9,ito:ITO_00141,Natural Language Processing,Precision
19,1,Text Classification,20NEWS,2019-11,SCDV-MS,86.2,100.0,86.2,1.0,86.2,0.88,ito:ITO_00141,Natural Language Processing,Precision
20,1,Named Entity Recognition,SoSciSoCi,2020-03,Bi-LSTM-CRF (SSC->GSC),0.83,100.0,0.83,1.0,0.83,0.01,ito:ITO_00141,Natural Language Processing,Precision
0,1,Fact-based Text Editing,Fact-based Text Editing,2018-07,Choi et al. (2018) w augmentation,24.2,73.33,24.2,0.73,33.0,0.25,ito:ITO_00141,Natural Language Processing,Recall
1,1,Fact-based Text Editing,Fact-based Text Editing,2019-03,LabelGCN Xiong et al. (2019),29.2,88.48,5.0,0.15,33.0,0.3,ito:ITO_00141,Natural Language Processing,Recall
2,1,Fact-based Text Editing,Fact-based Text Editing,2019-05,ELMo (distant denoising data),33.0,100.0,3.8,0.12,33.0,0.34,ito:ITO_00141,Natural Language Processing,Recall
3,1,Chinese Word Segmentation,MSR,2019-01,Glyce + BERT,98.3,100.0,98.3,1.0,98.3,1.0,ito:ITO_00141,Natural Language Processing,Recall
4,1,Chinese Word Segmentation,AS,2019-01,Glyce + BERT,96.8,100.0,96.8,1.0,96.8,0.98,ito:ITO_00141,Natural Language Processing,Recall
5,1,Chinese Word Segmentation,PKU,2019-01,Glyce + BERT,96.4,100.0,96.4,1.0,96.4,0.98,ito:ITO_00141,Natural Language Processing,Recall
6,1,Chinese Word Segmentation,CITYU,2019-01,Glyce + BERT,98.0,100.0,98,1.0,98,1.0,ito:ITO_00141,Natural Language Processing,Recall
7,1,Chinese Named Entity Recognition,Weibo NER,2019-01,Glyce + BERT,67.71,100.0,67.71,1.0,67.71,0.69,ito:ITO_00141,Natural Language Processing,Recall
8,1,Chinese Named Entity Recognition,Resume NER,2019-01,Glyce + BERT,96.48,100.0,96.48,1.0,96.48,0.98,ito:ITO_00141,Natural Language Processing,Recall
9,1,Chinese Named Entity Recognition,MSRA,2019-01,Glyce + BERT,95.51,100.0,95.51,1.0,95.51,0.97,ito:ITO_00141,Natural Language Processing,Recall
10,1,Chinese Named Entity Recognition,OntoNotes,2019-01,Glyce + BERT,81.4,100.0,81.4,1.0,81.4,0.83,ito:ITO_00141,Natural Language Processing,Recall
11,1,Grammatical Error Correction,CoNLL-2014 Shared Task,2019-03,Copy-augmented Model (4 Ensemble +Denoising Autoencoder),38.65,100.0,38.65,1.0,38.65,0.39,ito:ITO_00141,Natural Language Processing,Recall
12,1,Relation Extraction,FewRel,2019-05,ERNIE,88.44,100.0,88.44,1.0,88.44,0.9,ito:ITO_00141,Natural Language Processing,Recall
13,1,Relation Extraction,TACRED,2019-05,ERNIE,66.08,93.2,66.08,0.93,70.9,0.67,ito:ITO_00141,Natural Language Processing,Recall
14,1,Relation Extraction,TACRED,2019-07,SpanBERT,70.9,100.0,4.8,0.07,70.9,0.72,ito:ITO_00141,Natural Language Processing,Recall
15,1,Entity Typing,Open Entity,2019-05,ERNIE,72.9,100.0,72.9,1.0,72.9,0.74,ito:ITO_00141,Natural Language Processing,Recall
16,1,Distractor Generation,Distractor Generation,2019-05,ERNIE,72.9,100.0,72.9,1.0,72.9,0.74,ito:ITO_00141,Natural Language Processing,Recall
17,1,Named Entity Recognition,Long-tail emerging entities,2019-08,Cross-BiLSTM-CNN,33.92,100.0,33.92,1.0,33.92,0.35,ito:ITO_00141,Natural Language Processing,Recall
18,1,Named Entity Recognition,French Treebank,2019-11,CamemBERT (subword masking),87.46,100.0,87.46,1.0,87.46,0.89,ito:ITO_00141,Natural Language Processing,Recall
19,1,Text Classification,20NEWS,2019-11,SCDV-MS,86.18,100.0,86.18,1.0,86.18,0.88,ito:ITO_00141,Natural Language Processing,Recall
20,1,Named Entity Recognition,SoSciSoCi,2020-03,Bi-LSTM-CRF (SSC->GSC),0.82,100.0,0.82,1.0,0.82,0.01,ito:ITO_00141,Natural Language Processing,Recall
0,1,Open-Domain Question Answering,Quasar,2016-06,GA,26.4,62.41,26.4,0.62,42.3,0.62,ito:ITO_00141,Natural Language Processing,EM\\ \\(Quasar\\-T\\)
1,1,Open-Domain Question Answering,Quasar,2017-11,Evidence Aggregation via R^3 Re-Ranking,42.3,100.0,15.9,0.38,42.3,1.0,ito:ITO_00141,Natural Language Processing,EM\\ \\(Quasar\\-T\\)
0,1,Open-Domain Question Answering,Quasar,2016-06,GA,26.4,53.23,26.4,0.53,49.6,0.53,ito:ITO_00141,Natural Language Processing,F1\\ \\(Quasar\\-T\\)
1,1,Open-Domain Question Answering,Quasar,2016-11,BiDAF,28.5,57.46,2.1,0.04,49.6,0.57,ito:ITO_00141,Natural Language Processing,F1\\ \\(Quasar\\-T\\)
2,1,Open-Domain Question Answering,Quasar,2017-11,Evidence Aggregation via R^3 Re-Ranking,49.6,100.0,21.1,0.43,49.6,1.0,ito:ITO_00141,Natural Language Processing,F1\\ \\(Quasar\\-T\\)
0,1,Dialog State Tracking,Second dialogue state tracking challenge,2016-06,Neural belief tracker,73.4,97.22,73.4,0.97,75.5,0.83,ito:ITO_00141,Natural Language Processing,Joint
1,1,Dialog State Tracking,Second dialogue state tracking challenge,2018-05,Zhong et al.,74.5,98.68,1.1,0.01,75.5,0.84,ito:ITO_00141,Natural Language Processing,Joint
2,1,Dialog State Tracking,Second dialogue state tracking challenge,2018-10,StateNet,75.5,100.0,1.0,0.01,75.5,0.85,ito:ITO_00141,Natural Language Processing,Joint
3,1,Dialog State Tracking,Wizard-of-Oz,2016-06,Neural belief tracker,84.4,94.94,84.4,0.95,88.9,0.95,ito:ITO_00141,Natural Language Processing,Joint
4,1,Dialog State Tracking,Wizard-of-Oz,2018-05,Zhong et al.,88.1,99.1,3.7,0.04,88.9,0.99,ito:ITO_00141,Natural Language Processing,Joint
5,1,Dialog State Tracking,Wizard-of-Oz,2018-10,StateNet,88.9,100.0,0.8,0.01,88.9,1.0,ito:ITO_00141,Natural Language Processing,Joint
0,1,Dialog State Tracking,Second dialogue state tracking challenge,2016-06,Neural belief tracker,90.0,100.0,90,1.0,90,1.0,ito:ITO_00141,Natural Language Processing,Area
0,1,Dialog State Tracking,Second dialogue state tracking challenge,2016-06,Neural belief tracker,84.0,100.0,84,1.0,84,1.0,ito:ITO_00141,Natural Language Processing,Food
0,1,Dialog State Tracking,Second dialogue state tracking challenge,2016-06,Neural belief tracker,94.0,100.0,94,1.0,94,1.0,ito:ITO_00141,Natural Language Processing,Price
0,1,Dialog State Tracking,Second dialogue state tracking challenge,2016-06,Neural belief tracker,96.5,98.97,96.5,0.99,97.5,0.99,ito:ITO_00141,Natural Language Processing,Request
1,1,Dialog State Tracking,Second dialogue state tracking challenge,2018-05,Zhong et al.,97.5,100.0,1.0,0.01,97.5,1.0,ito:ITO_00141,Natural Language Processing,Request
2,1,Dialog State Tracking,Wizard-of-Oz,2016-06,Neural belief tracker,96.5,99.38,96.5,0.99,97.1,0.99,ito:ITO_00141,Natural Language Processing,Request
3,1,Dialog State Tracking,Wizard-of-Oz,2018-05,Zhong et al.,97.1,100.0,0.6,0.01,97.1,1.0,ito:ITO_00141,Natural Language Processing,Request
0,1,Surgical Skills Evaluation,JIGSAWS,2016-06,Bidir. LSTM,14.6,100.0,14.6,1.0,14.6,1.0,ito:ITO_00141,Natural Language Processing,Edit\\ Distance
1,1,Zero-Shot Text-to-Image Generation,Zero-Shot Text-to-Image Generation,2016-06,Bidir. LSTM,14.6,100.0,14.6,1.0,14.6,1.0,ito:ITO_00141,Natural Language Processing,Edit\\ Distance
0,1,Grammatical Error Detection,CoNLL-2014 A2,2016-07,Bi-LSTM (unrestricted data),44.0,97.56,44.0,0.98,45.1,0.72,ito:ITO_00141,Natural Language Processing,F0\\.5
1,1,Grammatical Error Detection,CoNLL-2014 A2,2017-07,Bi-LSTM + POS (unrestricted data),45.1,100.0,1.1,0.02,45.1,0.74,ito:ITO_00141,Natural Language Processing,F0\\.5
2,1,Grammatical Error Detection,FCE,2016-07,Bi-LSTM,41.1,78.93,41.1,0.79,52.07,0.67,ito:ITO_00141,Natural Language Processing,F0\\.5
3,1,Grammatical Error Detection,FCE,2016-11,Bi-LSTM + charattn,41.88,80.43,0.8,0.02,52.07,0.68,ito:ITO_00141,Natural Language Processing,F0\\.5
4,1,Grammatical Error Detection,FCE,2017-04,Bi-LSTM + LMcost,48.48,93.11,6.6,0.13,52.07,0.79,ito:ITO_00141,Natural Language Processing,F0\\.5
5,1,Grammatical Error Detection,FCE,2017-07,Ann+PAT+MT,49.11,94.32,0.6,0.01,52.07,0.8,ito:ITO_00141,Natural Language Processing,F0\\.5
6,1,Grammatical Error Detection,FCE,2018-11,BiLSTM-JOINT,52.07,100.0,3.0,0.06,52.07,0.85,ito:ITO_00141,Natural Language Processing,F0\\.5
7,1,Grammatical Error Detection,CoNLL-2014 A1,2016-07,Bi-LSTM (unrestricted data),34.3,95.01,34.3,0.95,36.1,0.56,ito:ITO_00141,Natural Language Processing,F0\\.5
8,1,Grammatical Error Detection,CoNLL-2014 A1,2017-07,Bi-LSTM + POS (unrestricted data),36.1,100.0,1.8,0.05,36.1,0.59,ito:ITO_00141,Natural Language Processing,F0\\.5
9,1,Grammatical Error Correction,CoNLL-2014 Shared Task,2018-01,CNN Seq2Seq,54.79,89.6,54.79,0.9,61.15,0.89,ito:ITO_00141,Natural Language Processing,F0\\.5
10,1,Grammatical Error Correction,CoNLL-2014 Shared Task,2019-03,Copy-augmented Model (4 Ensemble +Denoising Autoencoder),61.15,100.0,6.4,0.1,61.15,1.0,ito:ITO_00141,Natural Language Processing,F0\\.5
11,1,Grammatical Error Correction,Restricted,2018-06,SMT + BiGRU,56.25,99.52,56.25,1.0,56.52,0.92,ito:ITO_00141,Natural Language Processing,F0\\.5
12,1,Grammatical Error Correction,Restricted,2018-10,CNN Seq2Seq + Quality Estimation,56.52,100.0,0.3,0.01,56.52,0.92,ito:ITO_00141,Natural Language Processing,F0\\.5
13,1,Grammatical Error Correction,Unrestricted,2018-07,CNN Seq2Seq + Fluency Boost,61.34,100.0,61.34,1.0,61.34,1.0,ito:ITO_00141,Natural Language Processing,F0\\.5
14,1,Grammatical Error Detection,JFLEG,2018-11,BiLSTM-JOINT (trained on FCE),52.52,100.0,52.52,1.0,52.52,0.86,ito:ITO_00141,Natural Language Processing,F0\\.5
0,1,AMR Parsing,LDC2014T12,2016-08,Imitation learning,70.0,95.5,70.0,0.95,73.3,0.95,ito:ITO_00141,Natural Language Processing,F1\\ Newswire
1,1,AMR Parsing,LDC2014T12,2016-11,Incremental joint model ,71.0,96.86,1.0,0.01,73.3,0.97,ito:ITO_00141,Natural Language Processing,F1\\ Newswire
2,1,AMR Parsing,LDC2014T12,2018-10,Transition-based+improved aligner+ensemble,73.3,100.0,2.3,0.03,73.3,1.0,ito:ITO_00141,Natural Language Processing,F1\\ Newswire
3,1,AMR Parsing,LDC2014T12:,2016-08,Imitation learning ,0.7,93.33,0.7,0.93,0.75,0.01,ito:ITO_00141,Natural Language Processing,F1\\ Newswire
4,1,AMR Parsing,LDC2014T12:,2016-11,Incremental joint model,0.71,94.67,0.0,0.0,0.75,0.01,ito:ITO_00141,Natural Language Processing,F1\\ Newswire
5,1,AMR Parsing,LDC2014T12:,2018-10,Transition-based+improved aligner+ensemble,0.73,97.33,0.0,0.0,0.75,0.01,ito:ITO_00141,Natural Language Processing,F1\\ Newswire
6,1,AMR Parsing,LDC2014T12:,2019-05,Sequence-to-Graph Transduction,0.75,100.0,0.0,0.0,0.75,0.01,ito:ITO_00141,Natural Language Processing,F1\\ Newswire
0,1,Question Answering,SQuAD1.1 dev,2016-08,Match-LSTM with Bi-Ans-Ptr (Boundary+Search+b) ,64.1,71.17,64.1,0.71,90.06,0.71,ito:ITO_00141,Natural Language Processing,EM
1,1,Question Answering,SQuAD1.1 dev,2016-11,RASOR,66.4,73.73,2.3,0.03,90.06,0.73,ito:ITO_00141,Natural Language Processing,EM
2,1,Question Answering,SQuAD1.1 dev,2016-11,BIDAF (single),67.7,75.17,1.3,0.01,90.06,0.75,ito:ITO_00141,Natural Language Processing,EM
3,1,Question Answering,SQuAD1.1 dev,2017-03,SEDT-LSTM,67.89,75.38,0.2,0.0,90.06,0.75,ito:ITO_00141,Natural Language Processing,EM
4,1,Question Answering,SQuAD1.1 dev,2017-03,FastQAExt (beam-size 5),70.3,78.06,2.4,0.03,90.06,0.78,ito:ITO_00141,Natural Language Processing,EM
5,1,Question Answering,SQuAD1.1 dev,2017-04,Ruminating Reader,70.6,78.39,0.3,0.0,90.06,0.78,ito:ITO_00141,Natural Language Processing,EM
6,1,Question Answering,SQuAD1.1 dev,2017-05,R.M-Reader (single),78.9,87.61,8.3,0.09,90.06,0.87,ito:ITO_00141,Natural Language Processing,EM
7,1,Question Answering,SQuAD1.1 dev,2018-10,BERT large (+TriviaQA),84.2,93.49,5.3,0.06,90.06,0.93,ito:ITO_00141,Natural Language Processing,EM
8,1,Question Answering,SQuAD1.1 dev,2019-06,XLNet (single model),89.7,99.6,5.5,0.06,90.06,0.99,ito:ITO_00141,Natural Language Processing,EM
9,1,Question Answering,SQuAD1.1 dev,2019-10,T5-11B,90.06,100.0,0.4,0.0,90.06,0.99,ito:ITO_00141,Natural Language Processing,EM
10,1,Question Answering,SQuAD1.1,2016-08,Match-LSTM with Ans-Ptr (Boundary),60.474,67.27,60.474,0.67,89.898,0.67,ito:ITO_00141,Natural Language Processing,EM
11,1,Question Answering,SQuAD1.1,2016-08,Match-LSTM with Ans-Ptr (Boundary) (ensemble),67.901,75.53,7.4,0.08,89.898,0.75,ito:ITO_00141,Natural Language Processing,EM
12,1,Question Answering,SQuAD1.1,2016-09,ReasoNet (ensemble),75.034,83.47,7.1,0.08,89.898,0.83,ito:ITO_00141,Natural Language Processing,EM
13,1,Question Answering,SQuAD1.1,2017-05,Reinforced Mnemonic Reader (ensemble model),82.283,91.53,7.2,0.08,89.898,0.91,ito:ITO_00141,Natural Language Processing,EM
14,1,Question Answering,SQuAD1.1,2018-10,BERT (single model),85.083,94.64,2.8,0.03,89.898,0.94,ito:ITO_00141,Natural Language Processing,EM
15,1,Question Answering,SQuAD1.1,2018-10,BERT (ensemble),87.433,97.26,2.4,0.03,89.898,0.97,ito:ITO_00141,Natural Language Processing,EM
16,1,Question Answering,SQuAD1.1,2019-06,XLNet (single model),89.898,100.0,2.5,0.03,89.898,0.99,ito:ITO_00141,Natural Language Processing,EM
17,1,Open-Domain Question Answering,SQuAD1.1,2016-11,DCN,66.2,94.57,66.2,0.95,70.0,0.73,ito:ITO_00141,Natural Language Processing,EM
18,1,Open-Domain Question Answering,SQuAD1.1,2017-03,DrQA,70.0,100.0,3.8,0.05,70.0,0.77,ito:ITO_00141,Natural Language Processing,EM
19,1,Question Answering,NewsQA,2017-03,FastQAExt,43.7,82.3,43.7,0.82,53.1,0.48,ito:ITO_00141,Natural Language Processing,EM
20,1,Question Answering,NewsQA,2018-01,AMANDA,48.4,91.15,4.7,0.09,53.1,0.53,ito:ITO_00141,Natural Language Processing,EM
21,1,Question Answering,NewsQA,2018-05,MINIMAL(Dyn),50.1,94.35,1.7,0.03,53.1,0.55,ito:ITO_00141,Natural Language Processing,EM
22,1,Question Answering,NewsQA,2018-11,DecaProp,53.1,100.0,3.0,0.06,53.1,0.59,ito:ITO_00141,Natural Language Processing,EM
23,1,Question Answering,TriviaQA,2017-05,Mnemonic Reader,46.94,69.84,46.94,0.7,67.21,0.52,ito:ITO_00141,Natural Language Processing,EM
24,1,Question Answering,TriviaQA,2017-06,Reading Twice for NLU,50.56,75.23,3.6,0.05,67.21,0.56,ito:ITO_00141,Natural Language Processing,EM
25,1,Question Answering,TriviaQA,2017-10,S-Norm,66.37,98.75,15.8,0.24,67.21,0.73,ito:ITO_00141,Natural Language Processing,EM
26,1,Question Answering,TriviaQA,2018-10,MemoReader,67.21,100.0,0.8,0.01,67.21,0.74,ito:ITO_00141,Natural Language Processing,EM
27,1,Question Answering,SQuAD2.0,2017-11,FusionNet++ (ensemble),70.3,77.61,70.3,0.78,90.578,0.78,ito:ITO_00141,Natural Language Processing,EM
28,1,Question Answering,SQuAD2.0,2017-12,SAN (ensemble model),71.316,78.73,1.0,0.01,90.578,0.79,ito:ITO_00141,Natural Language Processing,EM
29,1,Question Answering,SQuAD2.0,2018-08,Reinforced Mnemonic Reader + Answer Verifier (single model),71.767,79.23,0.5,0.01,90.578,0.79,ito:ITO_00141,Natural Language Processing,EM
30,1,Question Answering,SQuAD2.0,2018-10,BERT (single model),80.005,88.33,8.2,0.09,90.578,0.88,ito:ITO_00141,Natural Language Processing,EM
31,1,Question Answering,SQuAD2.0,2019-06,XLNet (single model),87.926,97.07,7.9,0.09,90.578,0.97,ito:ITO_00141,Natural Language Processing,EM
32,1,Question Answering,SQuAD2.0,2019-08,XLNet + SG-Net Verifier (ensemble),88.174,97.35,0.2,0.0,90.578,0.97,ito:ITO_00141,Natural Language Processing,EM
33,1,Question Answering,SQuAD2.0,2019-09,ALBERT (ensemble model),89.731,99.06,1.6,0.02,90.578,0.99,ito:ITO_00141,Natural Language Processing,EM
34,1,Question Answering,SQuAD2.0,2020-01,Retro-Reader (ensemble),90.578,100.0,0.8,0.01,90.578,1.0,ito:ITO_00141,Natural Language Processing,EM
35,1,Open-Domain Question Answering,SearchQA,2018-07,Denoising QA,58.8,100.0,58.8,1.0,58.8,0.65,ito:ITO_00141,Natural Language Processing,EM
36,1,Question Answering,SQuAD2.0 dev,2018-08,RMR + ELMo (Model-III),72.3,82.25,72.3,0.82,87.9,0.8,ito:ITO_00141,Natural Language Processing,EM
37,1,Question Answering,SQuAD2.0 dev,2018-10,BERT large,78.7,89.53,6.4,0.07,87.9,0.87,ito:ITO_00141,Natural Language Processing,EM
38,1,Question Answering,SQuAD2.0 dev,2019-06,XLNet (single model),87.9,100.0,9.2,0.1,87.9,0.97,ito:ITO_00141,Natural Language Processing,EM
39,1,Open-Domain Question Answering,DuReader,2019-07,ERNIE 2.0 Large,64.2,100.0,64.2,1.0,64.2,0.71,ito:ITO_00141,Natural Language Processing,EM
40,1,Question Answering,FQuAD,2020-02,CamemBERTQA,77.9,100.0,77.9,1.0,77.9,0.86,ito:ITO_00141,Natural Language Processing,EM
0,1,Text Generation,EMNLP2017 WMT,2016-09,SeqGAN,0.4541,72.42,0.4541,0.72,0.627,0.01,ito:ITO_00141,Natural Language Processing,BLEU\\-4
1,1,Text Generation,EMNLP2017 WMT,2017-09,LeakGAN,0.627,100.0,0.2,0.32,0.627,0.02,ito:ITO_00141,Natural Language Processing,BLEU\\-4
2,1,Text Generation,COCO Captions,2016-09,SeqGAN,0.521,66.97,0.521,0.67,0.778,0.01,ito:ITO_00141,Natural Language Processing,BLEU\\-4
3,1,Text Generation,COCO Captions,2017-05,RankGAN,0.557,71.59,0.0,0.0,0.778,0.02,ito:ITO_00141,Natural Language Processing,BLEU\\-4
4,1,Text Generation,COCO Captions,2017-09,LeakGAN,0.778,100.0,0.2,0.26,0.778,0.02,ito:ITO_00141,Natural Language Processing,BLEU\\-4
5,1,Question Answering,NarrativeQA,2016-11,BiDAF,15.69,51.56,15.69,0.52,30.43,0.43,ito:ITO_00141,Natural Language Processing,BLEU\\-4
6,1,Question Answering,NarrativeQA,2018-09,MHPGM + NOIC,21.07,69.24,5.4,0.18,30.43,0.58,ito:ITO_00141,Natural Language Processing,BLEU\\-4
7,1,Question Answering,NarrativeQA,2018-10,ConZNet,22.49,73.91,1.4,0.05,30.43,0.62,ito:ITO_00141,Natural Language Processing,BLEU\\-4
8,1,Question Answering,NarrativeQA,2018-11,DecaProp,27.61,90.73,5.1,0.17,30.43,0.76,ito:ITO_00141,Natural Language Processing,BLEU\\-4
9,1,Question Answering,NarrativeQA,2019-01,Masque (NarrativeQA + MS MARCO),30.43,100.0,2.8,0.09,30.43,0.83,ito:ITO_00141,Natural Language Processing,BLEU\\-4
10,1,Question Generation,SQuAD1.1,2017-04,NQG++,13.27,55.5,13.27,0.55,23.91,0.36,ito:ITO_00141,Natural Language Processing,BLEU\\-4
11,1,Question Generation,SQuAD1.1,2018-06,MPQG,13.91,58.18,0.6,0.03,23.91,0.38,ito:ITO_00141,Natural Language Processing,BLEU\\-4
12,1,Question Generation,SQuAD1.1,2019-05,UniLM,22.78,95.27,8.9,0.37,23.91,0.62,ito:ITO_00141,Natural Language Processing,BLEU\\-4
13,1,Question Generation,SQuAD1.1,2020-01,ProphetNet,23.91,100.0,1.1,0.05,23.91,0.66,ito:ITO_00141,Natural Language Processing,BLEU\\-4
14,1,Text Generation,DailyDialog,2018-08,AEM+Attention,2.84,100.0,2.84,1.0,2.84,0.08,ito:ITO_00141,Natural Language Processing,BLEU\\-4
15,1,Image Captioning,COCO,2019-05,"NIC (ResNet-50, CutMix)",24.9,100.0,24.9,1.0,24.9,0.68,ito:ITO_00141,Natural Language Processing,BLEU\\-4
16,1,Image Captioning,Flickr30k Captions test,2019-09,Unified VLP,30.1,100.0,30.1,1.0,30.1,0.82,ito:ITO_00141,Natural Language Processing,BLEU\\-4
17,1,Image Captioning,COCO Captions test,2019-09,Unified VLP,36.5,100.0,36.5,1.0,36.5,1.0,ito:ITO_00141,Natural Language Processing,BLEU\\-4
0,1,Text Generation,Chinese Poems,2016-09,SeqGAN,0.738,90.89,0.738,0.91,0.812,0.02,ito:ITO_00141,Natural Language Processing,BLEU\\-2
1,1,Text Generation,Chinese Poems,2017-05,RankGAN,0.812,100.0,0.1,0.12,0.812,0.02,ito:ITO_00141,Natural Language Processing,BLEU\\-2
2,1,Text Generation,EMNLP2017 WMT,2016-09,SeqGAN,0.859,89.85,0.859,0.9,0.956,0.02,ito:ITO_00141,Natural Language Processing,BLEU\\-2
3,1,Text Generation,EMNLP2017 WMT,2017-09,LeakGAN,0.956,100.0,0.1,0.1,0.956,0.02,ito:ITO_00141,Natural Language Processing,BLEU\\-2
4,1,Text Generation,COCO Captions,2016-09,SeqGAN,0.831,87.47,0.831,0.87,0.95,0.02,ito:ITO_00141,Natural Language Processing,BLEU\\-2
5,1,Text Generation,COCO Captions,2017-05,RankGAN,0.85,89.47,0.0,0.0,0.95,0.02,ito:ITO_00141,Natural Language Processing,BLEU\\-2
6,1,Text Generation,COCO Captions,2017-09,LeakGAN,0.95,100.0,0.1,0.11,0.95,0.02,ito:ITO_00141,Natural Language Processing,BLEU\\-2
7,1,Text Generation,DailyDialog,2018-08,AEM+Attention,5.69,100.0,5.69,1.0,5.69,0.12,ito:ITO_00141,Natural Language Processing,BLEU\\-2
8,1,Image Captioning,COCO,2019-05,"NIC (ResNet-50, CutMix)",46.3,100.0,46.3,1.0,46.3,1.0,ito:ITO_00141,Natural Language Processing,BLEU\\-2
0,1,Text Generation,EMNLP2017 WMT,2016-09,SeqGAN,0.6015,73.44,0.6015,0.73,0.819,0.02,ito:ITO_00141,Natural Language Processing,BLEU\\-3
1,1,Text Generation,EMNLP2017 WMT,2017-09,LeakGAN,0.819,100.0,0.2,0.24,0.819,0.02,ito:ITO_00141,Natural Language Processing,BLEU\\-3
2,1,Text Generation,COCO Captions,2016-09,SeqGAN,0.642,72.95,0.642,0.73,0.88,0.02,ito:ITO_00141,Natural Language Processing,BLEU\\-3
3,1,Text Generation,COCO Captions,2017-05,RankGAN,0.672,76.36,0.0,0.0,0.88,0.02,ito:ITO_00141,Natural Language Processing,BLEU\\-3
4,1,Text Generation,COCO Captions,2017-09,LeakGAN,0.88,100.0,0.2,0.23,0.88,0.03,ito:ITO_00141,Natural Language Processing,BLEU\\-3
5,1,Text Generation,DailyDialog,2018-08,AEM+Attention,3.78,100.0,3.78,1.0,3.78,0.11,ito:ITO_00141,Natural Language Processing,BLEU\\-3
6,1,Text Generation,CMU-SE,2018-08,STWGAN-GP,0.617,100.0,0.617,1.0,0.617,0.02,ito:ITO_00141,Natural Language Processing,BLEU\\-3
7,1,Image Captioning,COCO,2019-05,"NIC (ResNet-50, CutMix)",33.6,100.0,33.6,1.0,33.6,1.0,ito:ITO_00141,Natural Language Processing,BLEU\\-3
0,1,Text Generation,EMNLP2017 WMT,2016-09,SeqGAN,0.4498,90.32,0.4498,0.9,0.498,0.66,ito:ITO_00141,Natural Language Processing,BLEU\\-5
1,1,Text Generation,EMNLP2017 WMT,2017-05,RankGAN,0.463,92.97,0.0,0.0,0.498,0.67,ito:ITO_00141,Natural Language Processing,BLEU\\-5
2,1,Text Generation,EMNLP2017 WMT,2017-09,LeakGAN,0.498,100.0,0.0,0.0,0.498,0.73,ito:ITO_00141,Natural Language Processing,BLEU\\-5
3,1,Text Generation,COCO Captions,2016-09,SeqGAN,0.427,62.24,0.427,0.62,0.686,0.62,ito:ITO_00141,Natural Language Processing,BLEU\\-5
4,1,Text Generation,COCO Captions,2017-05,RankGAN,0.544,79.3,0.1,0.15,0.686,0.79,ito:ITO_00141,Natural Language Processing,BLEU\\-5
5,1,Text Generation,COCO Captions,2017-09,LeakGAN,0.686,100.0,0.1,0.15,0.686,1.0,ito:ITO_00141,Natural Language Processing,BLEU\\-5
0,1,Text-to-Image Generation,CUB,2016-10,GAWWN,3.62,76.21,3.62,0.76,4.75,0.07,ito:ITO_00141,Natural Language Processing,Inception\\ score
1,1,Text-to-Image Generation,CUB,2016-12,StackGAN,3.7,77.89,0.1,0.02,4.75,0.07,ito:ITO_00141,Natural Language Processing,Inception\\ score
2,1,Text-to-Image Generation,CUB,2017-10,StackGAN-v2,3.82,80.42,0.1,0.02,4.75,0.07,ito:ITO_00141,Natural Language Processing,Inception\\ score
3,1,Text-to-Image Generation,CUB,2017-11,AttnGAN,4.36,91.79,0.5,0.11,4.75,0.08,ito:ITO_00141,Natural Language Processing,Inception\\ score
4,1,Text-to-Image Generation,CUB,2019-03,MirrorGAN,4.56,96.0,0.2,0.04,4.75,0.09,ito:ITO_00141,Natural Language Processing,Inception\\ score
5,1,Text-to-Image Generation,CUB,2019-04,DM-GAN,4.75,100.0,0.2,0.04,4.75,0.09,ito:ITO_00141,Natural Language Processing,Inception\\ score
6,1,Text-to-Image Generation,COCO,2016-12,StackGAN,8.45,16.03,8.45,0.16,52.73,0.16,ito:ITO_00141,Natural Language Processing,Inception\\ score
7,1,Text-to-Image Generation,COCO,2017-11,AttnGAN,25.89,49.1,17.4,0.33,52.73,0.49,ito:ITO_00141,Natural Language Processing,Inception\\ score
8,1,Text-to-Image Generation,COCO,2019-03,MirrorGAN,26.47,50.2,0.6,0.01,52.73,0.5,ito:ITO_00141,Natural Language Processing,Inception\\ score
9,1,Text-to-Image Generation,COCO,2019-04,DM-GAN,30.49,57.82,4.0,0.08,52.73,0.58,ito:ITO_00141,Natural Language Processing,Inception\\ score
10,1,Text-to-Image Generation,COCO,2019-12,CPGAN,52.73,100.0,22.2,0.42,52.73,1.0,ito:ITO_00141,Natural Language Processing,Inception\\ score
11,1,Text-to-Image Generation,Oxford 102 Flowers,2016-12,StackGAN,3.2,98.16,3.2,0.98,3.26,0.06,ito:ITO_00141,Natural Language Processing,Inception\\ score
12,1,Text-to-Image Generation,Oxford 102 Flowers,2017-10,StackGAN-v2,3.26,100.0,0.1,0.03,3.26,0.06,ito:ITO_00141,Natural Language Processing,Inception\\ score
0,1,Text-to-Image Generation,CUB,2016-10,GAWWN,67.22,100.0,67.22,1.0,67.22,0.51,ito:ITO_00141,Natural Language Processing,FID
1,1,Text-to-Image Generation,Oxford 102 Flowers,2017-10,StackGAN-v2,48.68,88.06,48.68,0.88,55.28,0.37,ito:ITO_00141,Natural Language Processing,FID
2,1,Text-to-Image Generation,Oxford 102 Flowers,2017-10,StackGAN-v1 ,55.28,100.0,6.6,0.12,55.28,0.42,ito:ITO_00141,Natural Language Processing,FID
3,1,Text-to-Image Generation,COCO,2017-10,StackGAN-v1 ,74.05,90.76,74.05,0.91,81.59,0.57,ito:ITO_00141,Natural Language Processing,FID
4,1,Text-to-Image Generation,COCO,2017-10,StackGAN-v2,81.59,100.0,7.5,0.09,81.59,0.62,ito:ITO_00141,Natural Language Processing,FID
5,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2017-11,AttnGAN,125.98,96.13,125.98,0.96,131.05,0.96,ito:ITO_00141,Natural Language Processing,FID
6,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2019-04,DM-GAN,131.05,100.0,5.1,0.04,131.05,1.0,ito:ITO_00141,Natural Language Processing,FID
0,1,Aspect-Based Sentiment Analysis,Sentihood,2016-10,LSTM-LOC,69.3,78.84,69.3,0.79,87.9,0.79,ito:ITO_00141,Natural Language Processing,Aspect
1,1,Aspect-Based Sentiment Analysis,Sentihood,2018-04,Sentic LSTM + TA + SA,78.18,88.94,8.9,0.1,87.9,0.89,ito:ITO_00141,Natural Language Processing,Aspect
2,1,Aspect-Based Sentiment Analysis,Sentihood,2018-06,Liu et al.,78.5,89.31,0.3,0.0,87.9,0.89,ito:ITO_00141,Natural Language Processing,Aspect
3,1,Aspect-Based Sentiment Analysis,Sentihood,2019-03,BERT-pair-QA-B,87.9,100.0,9.4,0.11,87.9,1.0,ito:ITO_00141,Natural Language Processing,Aspect
0,1,Aspect-Based Sentiment Analysis,Sentihood,2016-10,LSTM-LOC,81.9,87.5,81.9,0.88,93.6,0.88,ito:ITO_00141,Natural Language Processing,Sentiment
1,1,Aspect-Based Sentiment Analysis,Sentihood,2018-04,Sentic LSTM + TA + SA,89.32,95.43,7.4,0.08,93.6,0.95,ito:ITO_00141,Natural Language Processing,Sentiment
2,1,Aspect-Based Sentiment Analysis,Sentihood,2018-06,Liu et al.,91.0,97.22,1.7,0.02,93.6,0.97,ito:ITO_00141,Natural Language Processing,Sentiment
3,1,Aspect-Based Sentiment Analysis,Sentihood,2019-03,BERT-pair-QA-B,93.3,99.68,2.3,0.02,93.6,1.0,ito:ITO_00141,Natural Language Processing,Sentiment
4,1,Aspect-Based Sentiment Analysis,Sentihood,2019-03,BERT-pair-QA-M,93.6,100.0,0.3,0.0,93.6,1.0,ito:ITO_00141,Natural Language Processing,Sentiment
0,1,Hypernym Discovery,General,2016-11,vTE,9.91,52.08,9.91,0.52,19.03,0.14,ito:ITO_00141,Natural Language Processing,P\\-at\\-5
1,1,Hypernym Discovery,General,2018-06,CRIM,19.03,100.0,9.1,0.48,19.03,0.28,ito:ITO_00141,Natural Language Processing,P\\-at\\-5
2,1,Hypernym Discovery,Music domain,2016-11,vTE,12.41,30.04,12.41,0.3,41.31,0.18,ito:ITO_00141,Natural Language Processing,P\\-at\\-5
3,1,Hypernym Discovery,Music domain,2018-06,CRIM,41.31,100.0,28.9,0.7,41.31,0.6,ito:ITO_00141,Natural Language Processing,P\\-at\\-5
4,1,Hypernym Discovery,Medical domain,2016-11,vTE,20.71,56.32,20.71,0.56,36.77,0.3,ito:ITO_00141,Natural Language Processing,P\\-at\\-5
5,1,Hypernym Discovery,Medical domain,2018-06,CRIM,36.77,100.0,16.1,0.44,36.77,0.54,ito:ITO_00141,Natural Language Processing,P\\-at\\-5
6,1,Multi-Label Text Classification,Wiki-30K,2019-05,LAHA,62.87,100.0,62.87,1.0,62.87,0.92,ito:ITO_00141,Natural Language Processing,P\\-at\\-5
7,1,Multi-Label Text Classification,AAPD,2019-05,LAHA,41.19,100.0,41.19,1.0,41.19,0.6,ito:ITO_00141,Natural Language Processing,P\\-at\\-5
8,1,Multi-Label Text Classification,Amazon-12K,2019-05,LAHA,63.16,100.0,63.16,1.0,63.16,0.92,ito:ITO_00141,Natural Language Processing,P\\-at\\-5
9,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,LAHA,25.88,100.0,25.88,1.0,25.88,0.38,ito:ITO_00141,Natural Language Processing,P\\-at\\-5
10,1,Multi-Label Text Classification,EUR-Lex,2019-05,LAHA,50.71,73.81,50.71,0.74,68.7,0.74,ito:ITO_00141,Natural Language Processing,P\\-at\\-5
11,1,Multi-Label Text Classification,EUR-Lex,2019-06,bert-base,68.7,100.0,18.0,0.26,68.7,1.0,ito:ITO_00141,Natural Language Processing,P\\-at\\-5
12,1,Text Classification,RCV1,2019-06,NLP-Cap,56.33,100.0,56.33,1.0,56.33,0.82,ito:ITO_00141,Natural Language Processing,P\\-at\\-5
0,1,AMR Parsing,LDC2014T12:,2016-11,Incremental joint model,0.66,94.29,0.66,0.94,0.7,0.01,ito:ITO_00141,Natural Language Processing,F1\\ Full
1,1,AMR Parsing,LDC2014T12:,2018-10,Transition-based+improved aligner+ensemble,0.68,97.14,0.0,0.0,0.7,0.01,ito:ITO_00141,Natural Language Processing,F1\\ Full
2,1,AMR Parsing,LDC2014T12:,2019-05,Sequence-to-Graph Transduction,0.7,100.0,0.0,0.0,0.7,0.01,ito:ITO_00141,Natural Language Processing,F1\\ Full
3,1,AMR Parsing,LDC2014T12,2016-11,Incremental joint model ,66.0,94.02,66.0,0.94,70.2,0.94,ito:ITO_00141,Natural Language Processing,F1\\ Full
4,1,AMR Parsing,LDC2014T12,2018-10,Transition-based+improved aligner+ensemble,68.4,97.44,2.4,0.03,70.2,0.97,ito:ITO_00141,Natural Language Processing,F1\\ Full
5,1,AMR Parsing,LDC2014T12,2019-05,Two-stage Sequence-to-Graph Transducer,70.2,100.0,1.8,0.03,70.2,1.0,ito:ITO_00141,Natural Language Processing,F1\\ Full
0,1,Question Answering,NarrativeQA,2016-11,BiDAF,15.68,60.01,15.68,0.6,26.13,0.35,ito:ITO_00141,Natural Language Processing,METEOR
1,1,Question Answering,NarrativeQA,2018-09,MHPGM + NOIC,19.03,72.83,3.4,0.13,26.13,0.42,ito:ITO_00141,Natural Language Processing,METEOR
2,1,Question Answering,NarrativeQA,2018-10,ConZNet,19.24,73.63,0.2,0.01,26.13,0.42,ito:ITO_00141,Natural Language Processing,METEOR
3,1,Question Answering,NarrativeQA,2018-11,DecaProp,21.8,83.43,2.6,0.1,26.13,0.48,ito:ITO_00141,Natural Language Processing,METEOR
4,1,Question Answering,NarrativeQA,2019-01,Masque (NarrativeQA + MS MARCO),26.13,100.0,4.3,0.16,26.13,0.58,ito:ITO_00141,Natural Language Processing,METEOR
5,1,Data-to-Text Generation,E2E NLG Challenge,2017-12,Gong,44.69,98.68,44.69,0.99,45.29,0.99,ito:ITO_00141,Natural Language Processing,METEOR
6,1,Data-to-Text Generation,E2E NLG Challenge,2018-04,Sys1-Primary,45.17,99.74,0.5,0.01,45.29,1.0,ito:ITO_00141,Natural Language Processing,METEOR
7,1,Data-to-Text Generation,E2E NLG Challenge,2018-11,TUDA,45.29,100.0,0.1,0.0,45.29,1.0,ito:ITO_00141,Natural Language Processing,METEOR
8,1,Paper generation,ACL Title and Abstract Dataset,2018-05,Writing-editing Network,14.0,100.0,14,1.0,14,0.31,ito:ITO_00141,Natural Language Processing,METEOR
9,1,Table-to-Text Generation,Wikipedia Person and Animal Dataset,2018-09,KB-to-Language Generation Model,42.0,100.0,42,1.0,42,0.93,ito:ITO_00141,Natural Language Processing,METEOR
10,1,KB-to-Language Generation,Wikipedia Person and Animal Dataset,2018-09,KB-to-Language Generation Model,23.4,100.0,23.4,1.0,23.4,0.52,ito:ITO_00141,Natural Language Processing,METEOR
11,1,Image Captioning,COCO,2019-05,"NIC (ResNet-50, CutMix)",23.1,100.0,23.1,1.0,23.1,0.51,ito:ITO_00141,Natural Language Processing,METEOR
12,1,Image Captioning,Flickr30k Captions test,2019-09,Unified VLP,23.0,100.0,23,1.0,23,0.51,ito:ITO_00141,Natural Language Processing,METEOR
13,1,Image Captioning,COCO Captions test,2019-09,Unified VLP,28.4,100.0,28.4,1.0,28.4,0.63,ito:ITO_00141,Natural Language Processing,METEOR
0,1,Question Answering,MS MARCO,2016-11,BiDaF Baseline,23.96,45.9,23.96,0.46,52.2,0.4,ito:ITO_00141,Natural Language Processing,Rouge\\-L
1,1,Question Answering,MS MARCO,2018-05,VNET,51.63,98.91,27.7,0.53,52.2,0.86,ito:ITO_00141,Natural Language Processing,Rouge\\-L
2,1,Question Answering,MS MARCO,2018-11,Deep Cascade QA,52.01,99.64,0.4,0.01,52.2,0.87,ito:ITO_00141,Natural Language Processing,Rouge\\-L
3,1,Question Answering,MS MARCO,2019-01,Masque Q&A Style,52.2,100.0,0.2,0.0,52.2,0.87,ito:ITO_00141,Natural Language Processing,Rouge\\-L
4,1,Question Answering,NarrativeQA,2016-11,BiDAF,36.74,61.37,36.74,0.61,59.87,0.61,ito:ITO_00141,Natural Language Processing,Rouge\\-L
5,1,Question Answering,NarrativeQA,2018-09,MHPGM + NOIC,44.16,73.76,7.4,0.12,59.87,0.74,ito:ITO_00141,Natural Language Processing,Rouge\\-L
6,1,Question Answering,NarrativeQA,2018-10,ConZNet,46.67,77.95,2.5,0.04,59.87,0.78,ito:ITO_00141,Natural Language Processing,Rouge\\-L
7,1,Question Answering,NarrativeQA,2019-01,Masque (NarrativeQA + MS MARCO),59.87,100.0,13.2,0.22,59.87,1.0,ito:ITO_00141,Natural Language Processing,Rouge\\-L
0,1,Visual Question Answering,VQA v2 test-std,2016-12,Prior,25.98,35.83,25.98,0.36,72.5,0.36,ito:ITO_00141,Natural Language Processing,overall
1,1,Visual Question Answering,VQA v2 test-std,2016-12,"MCB [11, 12]",62.27,85.89,36.3,0.5,72.5,0.86,ito:ITO_00141,Natural Language Processing,overall
2,1,Visual Question Answering,VQA v2 test-std,2017-05,MUTAN,67.4,92.97,5.1,0.07,72.5,0.93,ito:ITO_00141,Natural Language Processing,overall
3,1,Visual Question Answering,VQA v2 test-std,2017-07,Up-Down,70.34,97.02,2.9,0.04,72.5,0.97,ito:ITO_00141,Natural Language Processing,overall
4,1,Visual Question Answering,VQA v2 test-std,2018-05,BAN+Glove+Counter,70.4,97.1,0.1,0.0,72.5,0.97,ito:ITO_00141,Natural Language Processing,overall
5,1,Visual Question Answering,VQA v2 test-std,2019-06,MCANed-6,70.9,97.79,0.5,0.01,72.5,0.98,ito:ITO_00141,Natural Language Processing,overall
6,1,Visual Question Answering,VQA v2 test-std,2019-08,VisualBERT,71.0,97.93,0.1,0.0,72.5,0.98,ito:ITO_00141,Natural Language Processing,overall
7,1,Visual Question Answering,VQA v2 test-std,2019-08,LXMERT,72.5,100.0,1.5,0.02,72.5,1.0,ito:ITO_00141,Natural Language Processing,overall
8,1,Visual Question Answering,VizWiz 2018,2019-04,Pythia v0.3 ,54.72,98.77,54.72,0.99,55.4,0.75,ito:ITO_00141,Natural Language Processing,overall
9,1,Visual Question Answering,VizWiz 2018,2019-08,"LXR955, No Ensemble",55.4,100.0,0.7,0.01,55.4,0.76,ito:ITO_00141,Natural Language Processing,overall
0,1,Dialog Generation,Amazon-5,2017-01,mm,5.0,100.0,5,1.0,5,1.0,ito:ITO_00141,Natural Language Processing,1\\ in\\ 10\\ R\\-at\\-2
0,1,Optical Character Recognition,FSNS,2017-02,STREET,27.54,100.0,27.54,1.0,27.54,1.0,ito:ITO_00141,Natural Language Processing,Sequence\\ error
0,1,Text Generation,Yahoo Questions,2017-02,CNN-VAE,63.9,100.0,63.9,1.0,63.9,1.0,ito:ITO_00141,Natural Language Processing,Perplexity
1,1,Code Generation,Android Repos,2018-05,Entity Type Model,2.65,100.0,2.65,1.0,2.65,0.04,ito:ITO_00141,Natural Language Processing,Perplexity
0,1,Text Generation,Yahoo Questions,2017-02,CNN-VAE,10.0,100.0,10.0,1.0,10.0,1.0,ito:ITO_00141,Natural Language Processing,KL
0,1,Text Generation,Yahoo Questions,2017-02,CNN-VAE,332.1,100.0,332.1,1.0,332.1,1.0,ito:ITO_00141,Natural Language Processing,NLL
0,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,58.1,100.0,58.1,1.0,58.1,1.0,ito:ITO_00141,Natural Language Processing,NDCG\\ \\(x\\ 100\\)
0,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,58.8,84.85,58.8,0.85,69.3,0.85,ito:ITO_00141,Natural Language Processing,MRR\\ \\(x\\ 100\\)
1,1,Visual Dialog,Visual Dialog v1.0 test-std,2018-09,CorefNMN (ResNet-152),61.5,88.74,2.7,0.04,69.3,0.89,ito:ITO_00141,Natural Language Processing,MRR\\ \\(x\\ 100\\)
2,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,DAN,63.2,91.2,1.7,0.02,69.3,0.91,ito:ITO_00141,Natural Language Processing,MRR\\ \\(x\\ 100\\)
3,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,HACAN,64.22,92.67,1.0,0.01,69.3,0.93,ito:ITO_00141,Natural Language Processing,MRR\\ \\(x\\ 100\\)
4,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-04,5xFGA (F-RCNNx101),69.3,100.0,5.1,0.07,69.3,1.0,ito:ITO_00141,Natural Language Processing,MRR\\ \\(x\\ 100\\)
0,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,4.4,100.0,4.4,1.0,4.4,1.0,ito:ITO_00141,Natural Language Processing,Mean
0,1,Sentiment Analysis,SemEval 2017 Task 4-A,2017-04,LSTMs+CNNs ensemble with multiple conv. ops,0.685,100.0,0.685,1.0,0.685,0.76,ito:ITO_00141,Natural Language Processing,Average\\ Recall
1,1,Sentiment Analysis,ASTD,2019-08,CNN-LSTM,0.62,100.0,0.62,1.0,0.62,0.69,ito:ITO_00141,Natural Language Processing,Average\\ Recall
2,1,Sentiment Analysis,ArSAS,2019-08,CNN-LSTM,0.9,100.0,0.9,1.0,0.9,1.0,ito:ITO_00141,Natural Language Processing,Average\\ Recall
0,1,Sentiment Analysis,SemEval,2017-04,LSTMs+CNNs ensemble with multiple conv. ops ,0.685,100.0,0.685,1.0,0.685,0.7,ito:ITO_00141,Natural Language Processing,F1\\-score
1,1,Humor Detection,200k Short Texts for Humor Detection,2019-06,XLNet Large Cased,0.92,93.78,0.92,0.94,0.981,0.94,ito:ITO_00141,Natural Language Processing,F1\\-score
2,1,Humor Detection,200k Short Texts for Humor Detection,2020-04,ColBERT,0.981,100.0,0.1,0.1,0.981,1.0,ito:ITO_00141,Natural Language Processing,F1\\-score
0,1,Semantic Textual Similarity,SentEval,2017-05,InferSent,86.3,98.29,86.3,0.98,87.8,0.98,ito:ITO_00141,Natural Language Processing,SICK\\-E
1,1,Semantic Textual Similarity,SentEval,2018-03,GenSen,87.8,100.0,1.5,0.02,87.8,1.0,ito:ITO_00141,Natural Language Processing,SICK\\-E
0,1,Semantic Textual Similarity,SentEval,2017-05,InferSent,0.884,99.55,0.884,1.0,0.888,1.0,ito:ITO_00141,Natural Language Processing,SICK\\-R
1,1,Semantic Textual Similarity,SentEval,2018-03,GenSen,0.888,100.0,0.0,0.0,0.888,1.0,ito:ITO_00141,Natural Language Processing,SICK\\-R
0,1,Code Generation,100 sleep nights of 8 caregivers,2017-05,anv,10.0,100.0,10,1.0,10,1.0,ito:ITO_00141,Natural Language Processing,14\\ gestures\\ accuracy
1,1,Visual Question Answering,100 sleep nights of 8 caregivers,2018-10,TallyQA,10.0,100.0,10,1.0,10,1.0,ito:ITO_00141,Natural Language Processing,14\\ gestures\\ accuracy
2,1,Factual Visual Question Answering,100 sleep nights of 8 caregivers,2019-11,TallyQA,10.0,100.0,10,1.0,10,1.0,ito:ITO_00141,Natural Language Processing,14\\ gestures\\ accuracy
0,1,Abstract Anaphora Resolution,The ARRAU Corpus,2017-06,MR-LSTM,43.83,100.0,43.83,1.0,43.83,1.0,ito:ITO_00141,Natural Language Processing,Average\\ Precision
1,1,Relationship extraction using distant supervision,New York Times Corpus,2018-08,BGRU-SET,0.39,100.0,0.39,1.0,0.39,0.01,ito:ITO_00141,Natural Language Processing,Average\\ Precision
0,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,bc-LSTM+Att,56.19,87.55,56.19,0.88,64.18,0.88,ito:ITO_00141,Natural Language Processing,Weighted\\-F1
1,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,ICON,58.54,91.21,2.4,0.04,64.18,0.91,ito:ITO_00141,Natural Language Processing,Weighted\\-F1
2,1,Emotion Recognition in Conversation,IEMOCAP,2018-11,DialogueRNN,62.75,97.77,4.2,0.07,64.18,0.98,ito:ITO_00141,Natural Language Processing,Weighted\\-F1
3,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,DialogueGCN,64.18,100.0,1.4,0.02,64.18,1.0,ito:ITO_00141,Natural Language Processing,Weighted\\-F1
4,1,Emotion Recognition in Conversation,MELD,2017-07,bc-LSTM+Att,56.44,97.01,56.44,0.97,58.18,0.88,ito:ITO_00141,Natural Language Processing,Weighted\\-F1
5,1,Emotion Recognition in Conversation,MELD,2018-11,DialogueRNN,57.03,98.02,0.6,0.01,58.18,0.89,ito:ITO_00141,Natural Language Processing,Weighted\\-F1
6,1,Emotion Recognition in Conversation,MELD,2019-08,DialogueGCN,58.1,99.86,1.1,0.02,58.18,0.91,ito:ITO_00141,Natural Language Processing,Weighted\\-F1
7,1,Emotion Recognition in Conversation,MELD,2019-09,KET,58.18,100.0,0.1,0.0,58.18,0.91,ito:ITO_00141,Natural Language Processing,Weighted\\-F1
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,bc-LSTM+Att,0.189,98.44,0.189,0.98,0.192,0.98,ito:ITO_00141,Natural Language Processing,MAE\\ \\(Valence\\)
1,1,Emotion Recognition in Conversation,SEMAINE,2018-06,CMN,0.192,100.0,0.0,0.0,0.192,1.0,ito:ITO_00141,Natural Language Processing,MAE\\ \\(Valence\\)
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,bc-LSTM+Att,0.213,100.0,0.213,1.0,0.213,1.0,ito:ITO_00141,Natural Language Processing,MAE\\ \\(Arousal\\)
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,bc-LSTM+Att,0.19,97.44,0.19,0.97,0.195,0.97,ito:ITO_00141,Natural Language Processing,MAE\\ \\(Expectancy\\)
1,1,Emotion Recognition in Conversation,SEMAINE,2018-06,CMN,0.195,100.0,0.0,0.0,0.195,1.0,ito:ITO_00141,Natural Language Processing,MAE\\ \\(Expectancy\\)
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,bc-LSTM+Att,8.67,99.2,8.67,0.99,8.74,0.99,ito:ITO_00141,Natural Language Processing,MAE\\ \\(Power\\)
1,1,Emotion Recognition in Conversation,SEMAINE,2018-06,CMN,8.74,100.0,0.1,0.01,8.74,1.0,ito:ITO_00141,Natural Language Processing,MAE\\ \\(Power\\)
0,1,Multimodal Emotion Recognition,IEMOCAP,2017-07,bc-LSTM ,0.741,96.86,0.741,0.97,0.765,0.93,ito:ITO_00141,Natural Language Processing,UA
1,1,Multimodal Emotion Recognition,IEMOCAP,2018-06,CHFusion (A+T+V),0.765,100.0,0.0,0.0,0.765,0.96,ito:ITO_00141,Natural Language Processing,UA
2,1,Speech Emotion Recognition,IEMOCAP,2018-02,CNN+LSTM,0.8,100.0,0.8,1.0,0.8,1.0,ito:ITO_00141,Natural Language Processing,UA
0,1,Fake News Detection,FNC-1,2017-07,3rd place at FNC-1,81.72,98.36,81.72,0.98,83.08,0.98,ito:ITO_00141,Natural Language Processing,Weighted\\ Accuracy
1,1,Fake News Detection,FNC-1,2017-12,Bhatt et al,83.08,100.0,1.4,0.02,83.08,1.0,ito:ITO_00141,Natural Language Processing,Weighted\\ Accuracy
0,1,Fake News Detection,FNC-1,2017-07,3rd place at FNC-1,97.9,99.86,97.9,1.0,98.04,1.0,ito:ITO_00141,Natural Language Processing,Per\\-class\\ Accuracy\\ \\(Unrelated\\)
1,1,Fake News Detection,FNC-1,2017-12,Bhatt et al,98.04,100.0,0.1,0.0,98.04,1.0,ito:ITO_00141,Natural Language Processing,Per\\-class\\ Accuracy\\ \\(Unrelated\\)
0,1,Fake News Detection,FNC-1,2017-07,3rd place at FNC-1,44.04,85.78,44.04,0.86,51.34,0.86,ito:ITO_00141,Natural Language Processing,Per\\-class\\ Accuracy\\ \\(Agree\\)
1,1,Fake News Detection,FNC-1,2017-12,"Baseline based on word2vec + hand-crafted features (Bhatt et al., 2017)",50.7,98.75,6.7,0.13,51.34,0.99,ito:ITO_00141,Natural Language Processing,Per\\-class\\ Accuracy\\ \\(Agree\\)
2,1,Fake News Detection,FNC-1,2018-11,"Bi-LSTM (max-pooling, attention)",51.34,100.0,0.6,0.01,51.34,1.0,ito:ITO_00141,Natural Language Processing,Per\\-class\\ Accuracy\\ \\(Agree\\)
0,1,Fake News Detection,FNC-1,2017-07,3rd place at FNC-1,6.6,63.89,6.6,0.64,10.33,0.64,ito:ITO_00141,Natural Language Processing,Per\\-class\\ Accuracy\\ \\(Disagree\\)
1,1,Fake News Detection,FNC-1,2017-12,"Baseline based on word2vec + hand-crafted features (Bhatt et al., 2017)",9.61,93.03,3.0,0.29,10.33,0.93,ito:ITO_00141,Natural Language Processing,Per\\-class\\ Accuracy\\ \\(Disagree\\)
2,1,Fake News Detection,FNC-1,2018-11,"Bi-LSTM (max-pooling, attention)",10.33,100.0,0.7,0.07,10.33,1.0,ito:ITO_00141,Natural Language Processing,Per\\-class\\ Accuracy\\ \\(Disagree\\)
0,1,Fake News Detection,FNC-1,2017-07,3rd place at FNC-1,81.38,94.98,81.38,0.95,85.68,0.95,ito:ITO_00141,Natural Language Processing,Per\\-class\\ Accuracy\\ \\(Discuss\\)
1,1,Fake News Detection,FNC-1,2017-12,Bhatt et al,85.68,100.0,4.3,0.05,85.68,1.0,ito:ITO_00141,Natural Language Processing,Per\\-class\\ Accuracy\\ \\(Discuss\\)
0,1,Visual Question Answering,GQA Test2019,2017-07,BottomUp,78.71,84.54,78.71,0.85,93.1,0.85,ito:ITO_00141,Natural Language Processing,Consistency
1,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Single Model",89.59,96.23,10.9,0.12,93.1,0.96,ito:ITO_00141,Natural Language Processing,Consistency
2,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Ensemble",93.1,100.0,3.5,0.04,93.1,1.0,ito:ITO_00141,Natural Language Processing,Consistency
0,1,Visual Question Answering,GQA Test2019,2017-07,BottomUp,66.64,83.52,66.64,0.84,79.79,0.84,ito:ITO_00141,Natural Language Processing,Binary
1,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Single Model",77.16,96.7,10.5,0.13,79.79,0.97,ito:ITO_00141,Natural Language Processing,Binary
2,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Ensemble",79.79,100.0,2.6,0.03,79.79,1.0,ito:ITO_00141,Natural Language Processing,Binary
0,1,Visual Question Answering,GQA Test2019,2017-07,BottomUp,34.83,73.11,34.83,0.73,47.64,0.73,ito:ITO_00141,Natural Language Processing,Open
1,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Single Model",45.47,95.45,10.6,0.22,47.64,0.95,ito:ITO_00141,Natural Language Processing,Open
2,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Ensemble",47.64,100.0,2.2,0.05,47.64,1.0,ito:ITO_00141,Natural Language Processing,Open
0,1,Visual Question Answering,GQA Test2019,2017-07,BottomUp,84.57,99.25,84.57,0.99,85.21,0.99,ito:ITO_00141,Natural Language Processing,Plausibility
1,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Ensemble",85.21,100.0,0.6,0.01,85.21,1.0,ito:ITO_00141,Natural Language Processing,Plausibility
0,1,Visual Question Answering,GQA Test2019,2017-07,BottomUp,96.18,99.81,96.18,1.0,96.36,1.0,ito:ITO_00141,Natural Language Processing,Validity
1,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Single Model",96.35,99.99,0.2,0.0,96.36,1.0,ito:ITO_00141,Natural Language Processing,Validity
2,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Ensemble",96.36,100.0,0.0,0.0,96.36,1.0,ito:ITO_00141,Natural Language Processing,Validity
0,1,Visual Question Answering,GQA Test2019,2017-07,BottomUp,5.98,93.15,5.98,0.93,6.42,0.93,ito:ITO_00141,Natural Language Processing,Distribution
1,1,Visual Question Answering,GQA Test2019,2019-08,"LXR955, Ensemble",6.42,100.0,0.4,0.06,6.42,1.0,ito:ITO_00141,Natural Language Processing,Distribution
0,1,Code Generation,WikiSQL,2017-08,"Seq2SQL (Zhong et al., 2017)",59.4,66.59,59.4,0.67,89.2,0.67,ito:ITO_00141,Natural Language Processing,Execution\\ Accuracy
1,1,Code Generation,WikiSQL,2018-03,"PT-MAML (Huang et al., 2018)",68.0,76.23,8.6,0.1,89.2,0.76,ito:ITO_00141,Natural Language Processing,Execution\\ Accuracy
2,1,Code Generation,WikiSQL,2018-04,"STAMP+RL (Sun et al., 2018)+",74.6,83.63,6.6,0.07,89.2,0.84,ito:ITO_00141,Natural Language Processing,Execution\\ Accuracy
3,1,Code Generation,WikiSQL,2018-04,"TypeSQL+TC (Yu et al., 2018)+",82.6,92.6,8.0,0.09,89.2,0.93,ito:ITO_00141,Natural Language Processing,Execution\\ Accuracy
4,1,Code Generation,WikiSQL,2019-10,NL2SQL-RULE,89.2,100.0,6.6,0.07,89.2,1.0,ito:ITO_00141,Natural Language Processing,Execution\\ Accuracy
0,1,Code Generation,WikiSQL,2017-08,"Seq2SQL (Zhong et al., 2017)",48.3,57.71,48.3,0.58,83.7,0.58,ito:ITO_00141,Natural Language Processing,Exact\\ Match\\ Accuracy
1,1,Code Generation,WikiSQL,2018-03,"PT-MAML (Huang et al., 2018)",62.8,75.03,14.5,0.17,83.7,0.75,ito:ITO_00141,Natural Language Processing,Exact\\ Match\\ Accuracy
2,1,Code Generation,WikiSQL,2018-10,Tranx,68.6,81.96,5.8,0.07,83.7,0.82,ito:ITO_00141,Natural Language Processing,Exact\\ Match\\ Accuracy
3,1,Code Generation,WikiSQL,2019-10,NL2SQL-RULE,83.7,100.0,15.1,0.18,83.7,1.0,ito:ITO_00141,Natural Language Processing,Exact\\ Match\\ Accuracy
0,1,Relation Extraction,Wikipedia-Wikidata relations,2017-09,ContextAtt,0.159,100.0,0.159,1.0,0.159,1.0,ito:ITO_00141,Natural Language Processing,Error\\ rate
0,1,Temporal Information Extraction,TempEval-3,2017-09,Ning et al.,67.2,100.0,67.2,1.0,67.2,1.0,ito:ITO_00141,Natural Language Processing,Temporal\\ awareness
0,1,Word Sense Disambiguation,Supervised:,2017-09,Bi-LSTM<sub>att+LEX</sub>,72.0,90.34,72.0,0.9,79.7,0.9,ito:ITO_00141,Natural Language Processing,Senseval\\ 2
1,1,Word Sense Disambiguation,Supervised:,2018-05,GAS<sub>ext</sub>,72.2,90.59,0.2,0.0,79.7,0.91,ito:ITO_00141,Natural Language Processing,Senseval\\ 2
2,1,Word Sense Disambiguation,Supervised:,2018-11,"SemCor+WNGT, vocabulary reduced, ensemble",75.15,94.29,3.0,0.04,79.7,0.94,ito:ITO_00141,Natural Language Processing,Senseval\\ 2
3,1,Word Sense Disambiguation,Supervised:,2019-05,"SemCor+WNGC, hypernyms",79.7,100.0,4.5,0.06,79.7,1.0,ito:ITO_00141,Natural Language Processing,Senseval\\ 2
0,1,Word Sense Disambiguation,Supervised:,2017-09,Bi-LSTM<sub>att+LEX</sub>,69.4,89.2,69.4,0.89,77.8,0.89,ito:ITO_00141,Natural Language Processing,Senseval\\ 3
1,1,Word Sense Disambiguation,Supervised:,2018-02,ELMo,69.6,89.46,0.2,0.0,77.8,0.89,ito:ITO_00141,Natural Language Processing,Senseval\\ 3
2,1,Word Sense Disambiguation,Supervised:,2018-05,GAS<sub>ext</sub>,70.5,90.62,0.9,0.01,77.8,0.91,ito:ITO_00141,Natural Language Processing,Senseval\\ 3
3,1,Word Sense Disambiguation,Supervised:,2019-05,"SemCor+WNGC, hypernyms",77.8,100.0,7.3,0.09,77.8,1.0,ito:ITO_00141,Natural Language Processing,Senseval\\ 3
0,1,Word Sense Disambiguation,Supervised:,2017-09,Bi-LSTM<sub>att+LEX</sub>,66.4,84.37,66.4,0.84,78.7,0.84,ito:ITO_00141,Natural Language Processing,SemEval\\ 2013
1,1,Word Sense Disambiguation,Supervised:,2017-09,Bi-LSTM<sub>att+LEX+POS</sub>,66.9,85.01,0.5,0.01,78.7,0.85,ito:ITO_00141,Natural Language Processing,SemEval\\ 2013
2,1,Word Sense Disambiguation,Supervised:,2018-05,GAS<sub>ext</sub>,67.2,85.39,0.3,0.0,78.7,0.85,ito:ITO_00141,Natural Language Processing,SemEval\\ 2013
3,1,Word Sense Disambiguation,Supervised:,2018-11,"SemCor+WNGT, vocabulary reduced, ensemble",72.63,92.29,5.4,0.07,78.7,0.92,ito:ITO_00141,Natural Language Processing,SemEval\\ 2013
4,1,Word Sense Disambiguation,Supervised:,2019-05,"SemCor+WNGC, hypernyms",78.7,100.0,6.1,0.08,78.7,1.0,ito:ITO_00141,Natural Language Processing,SemEval\\ 2013
5,1,Word Sense Disambiguation,Knowledge-based:,2018-01,WSD-TM,65.3,100.0,65.3,1.0,65.3,0.83,ito:ITO_00141,Natural Language Processing,SemEval\\ 2013
0,1,Word Sense Disambiguation,Supervised:,2017-09,Bi-LSTM<sub>att+LEX</sub>,72.4,87.65,72.4,0.88,82.6,0.88,ito:ITO_00141,Natural Language Processing,SemEval\\ 2015
1,1,Word Sense Disambiguation,Supervised:,2018-05,GAS<sub>ext</sub>,72.6,87.89,0.2,0.0,82.6,0.88,ito:ITO_00141,Natural Language Processing,SemEval\\ 2015
2,1,Word Sense Disambiguation,Supervised:,2018-11,"SemCor+WNGT, vocabulary reduced, ensemble",74.46,90.15,1.9,0.02,82.6,0.9,ito:ITO_00141,Natural Language Processing,SemEval\\ 2015
3,1,Word Sense Disambiguation,Supervised:,2019-05,"SemCor+WNGC, hypernyms",82.6,100.0,8.1,0.1,82.6,1.0,ito:ITO_00141,Natural Language Processing,SemEval\\ 2015
4,1,Word Sense Disambiguation,Knowledge-based:,2018-01,WSD-TM,69.6,100.0,69.6,1.0,69.6,0.84,ito:ITO_00141,Natural Language Processing,SemEval\\ 2015
0,1,Named Entity Recognition,Long-tail emerging entities,2017-09,SpinningBytes,39.33,97.74,39.33,0.98,40.24,0.98,ito:ITO_00141,Natural Language Processing,F1\\ \\(surface\\ form\\)
1,1,Named Entity Recognition,Long-tail emerging entities,2018-06,Aguilar et al.,40.24,100.0,0.9,0.02,40.24,1.0,ito:ITO_00141,Natural Language Processing,F1\\ \\(surface\\ form\\)
0,1,Machine Translation,20NEWS,2017-09,tensorflow/tensor2tensor,5.0,100.0,5,1.0,5,0.06,ito:ITO_00141,Natural Language Processing,1\\-of\\-100\\ Accuracy
1,1,Conversational Response Selection,DSTC7 Ubuntu,2018-12,Sequential Inference Models,60.8,85.39,60.8,0.85,71.2,0.72,ito:ITO_00141,Natural Language Processing,1\\-of\\-100\\ Accuracy
2,1,Conversational Response Selection,DSTC7 Ubuntu,2019-01,Sequential Attention-based Network,64.5,90.59,3.7,0.05,71.2,0.77,ito:ITO_00141,Natural Language Processing,1\\-of\\-100\\ Accuracy
3,1,Conversational Response Selection,DSTC7 Ubuntu,2019-04,Bi-encoder (v2),70.9,99.58,6.4,0.09,71.2,0.84,ito:ITO_00141,Natural Language Processing,1\\-of\\-100\\ Accuracy
4,1,Conversational Response Selection,DSTC7 Ubuntu,2019-11,Multi-context ConveRT,71.2,100.0,0.3,0.0,71.2,0.84,ito:ITO_00141,Natural Language Processing,1\\-of\\-100\\ Accuracy
5,1,Conversational Response Selection,PolyAI AmazonQA,2019-04,PolyAI Encoder,71.3,84.58,71.3,0.85,84.3,0.85,ito:ITO_00141,Natural Language Processing,1\\-of\\-100\\ Accuracy
6,1,Conversational Response Selection,PolyAI AmazonQA,2019-11,ConveRT,84.3,100.0,13.0,0.15,84.3,1.0,ito:ITO_00141,Natural Language Processing,1\\-of\\-100\\ Accuracy
7,1,Conversational Response Selection,PolyAI Reddit,2019-04,PolyAI Encoder,61.3,85.38,61.3,0.85,71.8,0.73,ito:ITO_00141,Natural Language Processing,1\\-of\\-100\\ Accuracy
8,1,Conversational Response Selection,PolyAI Reddit,2019-11,Multi-context ConveRT,71.8,100.0,10.5,0.15,71.8,0.85,ito:ITO_00141,Natural Language Processing,1\\-of\\-100\\ Accuracy
9,1,Conversational Response Selection,PolyAI OpenSubtitles,2019-04,PolyAI Encoder,30.6,100.0,30.6,1.0,30.6,0.36,ito:ITO_00141,Natural Language Processing,1\\-of\\-100\\ Accuracy
0,1,Question Answering,WikiHop,2017-10,BiDAF,42.9,60.76,42.9,0.61,70.6,0.61,ito:ITO_00141,Natural Language Processing,Test
1,1,Question Answering,WikiHop,2018-04,Coref-GRU,59.3,83.99,16.4,0.23,70.6,0.84,ito:ITO_00141,Natural Language Processing,Test
2,1,Question Answering,WikiHop,2018-09,MHQA,65.4,92.63,6.1,0.09,70.6,0.93,ito:ITO_00141,Natural Language Processing,Test
3,1,Question Answering,WikiHop,2019-01,CFC,70.6,100.0,5.2,0.07,70.6,1.0,ito:ITO_00141,Natural Language Processing,Test
4,1,Table-based Fact Verification,TabFact,2019-09,Table-BERT-Horizontal-T+F-Template,65.12,100.0,65.12,1.0,65.12,0.92,ito:ITO_00141,Natural Language Processing,Test
0,1,Fine-Grained Opinion Analysis,MPQA,2017-11,FS-MTL,83.8,98.69,83.8,0.99,84.91,0.99,ito:ITO_00141,Natural Language Processing,Holder\\ Binary\\ F1
1,1,Fine-Grained Opinion Analysis,MPQA,2019-06,SRL-SAWR,84.91,100.0,1.1,0.01,84.91,1.0,ito:ITO_00141,Natural Language Processing,Holder\\ Binary\\ F1
0,1,Fine-Grained Opinion Analysis,MPQA,2017-11,FS-MTL,72.06,98.32,72.06,0.98,73.29,0.98,ito:ITO_00141,Natural Language Processing,Target\\ Binary\\ F1
1,1,Fine-Grained Opinion Analysis,MPQA,2019-06,SRL-SAWR,73.29,100.0,1.2,0.02,73.29,1.0,ito:ITO_00141,Natural Language Processing,Target\\ Binary\\ F1
0,1,Constituency Grammar Induction,PTB,2017-11,PRPN (tuned),47.3,84.92,47.3,0.85,55.7,0.85,ito:ITO_00141,Natural Language Processing,Mean\\ F1\\ \\(WSJ\\)
1,1,Constituency Grammar Induction,PTB,2018-08,DMV + invertible projector,47.9,86.0,0.6,0.01,55.7,0.86,ito:ITO_00141,Natural Language Processing,Mean\\ F1\\ \\(WSJ\\)
2,1,Constituency Grammar Induction,PTB,2018-10,ON-LSTM (tuned),48.1,86.36,0.2,0.0,55.7,0.86,ito:ITO_00141,Natural Language Processing,Mean\\ F1\\ \\(WSJ\\)
3,1,Constituency Grammar Induction,PTB,2019-06,DIORA (+PP),55.7,100.0,7.6,0.14,55.7,1.0,ito:ITO_00141,Natural Language Processing,Mean\\ F1\\ \\(WSJ\\)
0,1,Constituency Grammar Induction,PTB,2017-11,PRPN (tuned),47.9,79.7,47.9,0.8,60.1,0.8,ito:ITO_00141,Natural Language Processing,Max\\ F1\\ \\(WSJ\\)
1,1,Constituency Grammar Induction,PTB,2018-10,ON-LSTM (tuned),50.0,83.19,2.1,0.03,60.1,0.83,ito:ITO_00141,Natural Language Processing,Max\\ F1\\ \\(WSJ\\)
2,1,Constituency Grammar Induction,PTB,2019-04,URNNG,52.4,87.19,2.4,0.04,60.1,0.87,ito:ITO_00141,Natural Language Processing,Max\\ F1\\ \\(WSJ\\)
3,1,Constituency Grammar Induction,PTB,2019-06,DIORA (+PP),56.2,93.51,3.8,0.06,60.1,0.94,ito:ITO_00141,Natural Language Processing,Max\\ F1\\ \\(WSJ\\)
4,1,Constituency Grammar Induction,PTB,2019-06,Compound PCFG,60.1,100.0,3.9,0.06,60.1,1.0,ito:ITO_00141,Natural Language Processing,Max\\ F1\\ \\(WSJ\\)
0,1,Chunking,CoNLL 2000,2017-11,Adversarial Training,95.25,98.48,95.25,0.98,96.72,0.98,ito:ITO_00141,Natural Language Processing,Exact\\ Span\\ F1
1,1,Chunking,CoNLL 2000,2018-08,Flair,96.72,100.0,1.5,0.02,96.72,1.0,ito:ITO_00141,Natural Language Processing,Exact\\ Span\\ F1
2,1,Scientific Concept Extraction,STM-corpus,2020-01,SciBERT (full data),65.5,98.64,65.5,0.99,66.4,0.68,ito:ITO_00141,Natural Language Processing,Exact\\ Span\\ F1
3,1,Scientific Concept Extraction,STM-corpus,2020-01,SciBERT (active learning),66.4,100.0,0.9,0.01,66.4,0.69,ito:ITO_00141,Natural Language Processing,Exact\\ Span\\ F1
0,1,Ad-Hoc Information Retrieval,TREC Robust04,2017-11,DRMM,0.431,80.1,0.431,0.8,0.5381,0.01,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-20
1,1,Ad-Hoc Information Retrieval,TREC Robust04,2018-09,POSIT-DRMM-MV,0.464,86.23,0.0,0.0,0.5381,0.01,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-20
2,1,Ad-Hoc Information Retrieval,TREC Robust04,2019-04,CEDR-KNRM,0.5381,100.0,0.1,0.19,0.5381,0.02,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-20
3,1,Document Ranking,ClueWeb09-B,2019-06,XLNet,31.1,100.0,31.1,1.0,31.1,1.0,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-20
0,1,Ad-Hoc Information Retrieval,TREC Robust04,2017-11,DRMM,0.382,81.85,0.382,0.82,0.4667,0.82,ito:ITO_00141,Natural Language Processing,P\\-at\\-20
1,1,Ad-Hoc Information Retrieval,TREC Robust04,2018-09,POSIT-DRMM-MV,0.389,83.35,0.0,0.0,0.4667,0.83,ito:ITO_00141,Natural Language Processing,P\\-at\\-20
2,1,Ad-Hoc Information Retrieval,TREC Robust04,2018-10,SNRM-PRF,0.3948,84.59,0.0,0.0,0.4667,0.85,ito:ITO_00141,Natural Language Processing,P\\-at\\-20
3,1,Ad-Hoc Information Retrieval,TREC Robust04,2018-10,NPRF-DRMM,0.4064,87.08,0.0,0.0,0.4667,0.87,ito:ITO_00141,Natural Language Processing,P\\-at\\-20
4,1,Ad-Hoc Information Retrieval,TREC Robust04,2019-03,BERT FT(Microblog),0.4287,91.86,0.0,0.0,0.4667,0.92,ito:ITO_00141,Natural Language Processing,P\\-at\\-20
5,1,Ad-Hoc Information Retrieval,TREC Robust04,2019-04,CEDR-KNRM,0.4667,100.0,0.0,0.0,0.4667,1.0,ito:ITO_00141,Natural Language Processing,P\\-at\\-20
0,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2017-11,AttnGAN,0.512,94.12,0.512,0.94,0.544,0.94,ito:ITO_00141,Natural Language Processing,LPIPS
1,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2019-04,DM-GAN,0.544,100.0,0.0,0.0,0.544,1.0,ito:ITO_00141,Natural Language Processing,LPIPS
0,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2017-11,AttnGAN,13.0,79.27,13.0,0.79,16.4,0.79,ito:ITO_00141,Natural Language Processing,Acc
1,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2019-04,DM-GAN,16.4,100.0,3.4,0.21,16.4,1.0,ito:ITO_00141,Natural Language Processing,Acc
0,1,Text-to-Image Generation,COCO,2017-11,AttnGAN,25.88,72.19,25.88,0.72,35.85,0.72,ito:ITO_00141,Natural Language Processing,SOA\\-C
1,1,Text-to-Image Generation,COCO,2019-04,DM-GAN,33.44,93.28,7.6,0.21,35.85,0.93,ito:ITO_00141,Natural Language Processing,SOA\\-C
2,1,Text-to-Image Generation,COCO,2019-10,OP-GAN,35.85,100.0,2.4,0.07,35.85,1.0,ito:ITO_00141,Natural Language Processing,SOA\\-C
0,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2017-11,AttnGAN,11.9,70.41,11.9,0.7,16.9,0.7,ito:ITO_00141,Natural Language Processing,Real
1,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2019-04,DM-GAN,16.9,100.0,5.0,0.3,16.9,1.0,ito:ITO_00141,Natural Language Processing,Real
0,1,Data-to-Text Generation,E2E NLG Challenge,2017-12,Gong,8.3453,95.59,8.3453,0.96,8.73,0.96,ito:ITO_00141,Natural Language Processing,NIST
1,1,Data-to-Text Generation,E2E NLG Challenge,2018-04,Sys1-Primary,8.5105,97.49,0.2,0.02,8.73,0.97,ito:ITO_00141,Natural Language Processing,NIST
2,1,Data-to-Text Generation,E2E NLG Challenge,2018-05,Slug,8.613,98.66,0.1,0.01,8.73,0.99,ito:ITO_00141,Natural Language Processing,NIST
3,1,Data-to-Text Generation,E2E NLG Challenge,2019-04,S_1^R,8.73,100.0,0.1,0.01,8.73,1.0,ito:ITO_00141,Natural Language Processing,NIST
0,1,Data-to-Text Generation,E2E NLG Challenge,2017-12,Gong,2.2721,95.87,2.2721,0.96,2.37,0.02,ito:ITO_00141,Natural Language Processing,CIDEr
1,1,Data-to-Text Generation,E2E NLG Challenge,2019-04,S_1^R,2.37,100.0,0.1,0.04,2.37,0.02,ito:ITO_00141,Natural Language Processing,CIDEr
2,1,Image Captioning,COCO,2019-05,"NIC (ResNet-50, CutMix)",77.6,100.0,77.6,1.0,77.6,0.66,ito:ITO_00141,Natural Language Processing,CIDEr
3,1,Image Captioning,Flickr30k Captions test,2019-09,Unified VLP,67.4,100.0,67.4,1.0,67.4,0.58,ito:ITO_00141,Natural Language Processing,CIDEr
4,1,Image Captioning,COCO Captions test,2019-09,Unified VLP,116.9,100.0,116.9,1.0,116.9,1.0,ito:ITO_00141,Natural Language Processing,CIDEr
5,1,Text Generation,CommonGen,2019-11,UniLM,14.92,100.0,14.92,1.0,14.92,0.13,ito:ITO_00141,Natural Language Processing,CIDEr
0,1,Word Sense Disambiguation,Knowledge-based:,2018-01,WSD-TM,66.9,100.0,66.9,1.0,66.9,1.0,ito:ITO_00141,Natural Language Processing,All
0,1,Grammatical Error Correction,_Restricted_,2018-01,CNN Seq2Seq,57.47,93.45,57.47,0.93,61.5,0.92,ito:ITO_00141,Natural Language Processing,GLEU
1,1,Grammatical Error Correction,_Restricted_,2018-06,SMT + BiGRU,61.5,100.0,4.0,0.07,61.5,0.99,ito:ITO_00141,Natural Language Processing,GLEU
2,1,Grammatical Error Correction,Unrestricted,2018-07,CNN Seq2Seq + Fluency Boost and inference,62.37,100.0,62.37,1.0,62.37,1.0,ito:ITO_00141,Natural Language Processing,GLEU
3,1,Grammatical Error Correction,JFLEG,2019-03,Copy-augmented Model (4 Ensemble +Denoising Autoencoder),61.0,100.0,61,1.0,61,0.98,ito:ITO_00141,Natural Language Processing,GLEU
0,1,Word Sense Disambiguation,Supervised:,2018-02,ELMo,62.2,84.74,62.2,0.85,73.4,0.85,ito:ITO_00141,Natural Language Processing,SemEval\\ 2007
1,1,Word Sense Disambiguation,Supervised:,2018-11,"SemCor+WNGT, vocabulary reduced, ensemble",66.81,91.02,4.6,0.06,73.4,0.91,ito:ITO_00141,Natural Language Processing,SemEval\\ 2007
2,1,Word Sense Disambiguation,Supervised:,2019-05,"SemCor+WNGC, hypernyms",73.4,100.0,6.6,0.09,73.4,1.0,ito:ITO_00141,Natural Language Processing,SemEval\\ 2007
0,1,Question Answering,RACE,2018-03,BiAttention MRU,60.2,100.0,60.2,1.0,60.2,1.0,ito:ITO_00141,Natural Language Processing,RACE\\-m
0,1,Question Answering,RACE,2018-03,BiAttention MRU,50.3,100.0,50.3,1.0,50.3,1.0,ito:ITO_00141,Natural Language Processing,RACE\\-h
0,1,Question Answering,RACE,2018-03,BiAttention MRU,53.3,100.0,53.3,1.0,53.3,1.0,ito:ITO_00141,Natural Language Processing,RACE
0,1,Natural Language Inference,MultiNLI,2018-03,GenSen,71.4,77.61,71.4,0.78,92.0,0.78,ito:ITO_00141,Natural Language Processing,Matched
1,1,Natural Language Inference,MultiNLI,2018-04,Multi-task BiLSTM + Attn,72.2,78.48,0.8,0.01,92.0,0.78,ito:ITO_00141,Natural Language Processing,Matched
2,1,Natural Language Inference,MultiNLI,2018-06,Finetuned Transformer LM,82.1,89.24,9.9,0.11,92.0,0.89,ito:ITO_00141,Natural Language Processing,Matched
3,1,Natural Language Inference,MultiNLI,2019-01,MT-DNN,86.7,94.24,4.6,0.05,92.0,0.94,ito:ITO_00141,Natural Language Processing,Matched
4,1,Natural Language Inference,MultiNLI,2019-06,XLNet (single model),90.8,98.7,4.1,0.04,92.0,0.99,ito:ITO_00141,Natural Language Processing,Matched
5,1,Natural Language Inference,MultiNLI,2019-09,ALBERT,91.3,99.24,0.5,0.01,92.0,0.99,ito:ITO_00141,Natural Language Processing,Matched
6,1,Natural Language Inference,MultiNLI,2019-10,T5-11B,92.0,100.0,0.7,0.01,92.0,1.0,ito:ITO_00141,Natural Language Processing,Matched
7,1,Natural Language Inference,MultiNLI Dev,2019-09,TinyBERT (M=6;d'=768;d'i=3072),84.5,100.0,84.5,1.0,84.5,0.92,ito:ITO_00141,Natural Language Processing,Matched
0,1,Natural Language Inference,MultiNLI,2018-03,GenSen,71.3,77.75,71.3,0.78,91.7,0.78,ito:ITO_00141,Natural Language Processing,Mismatched
1,1,Natural Language Inference,MultiNLI,2018-04,Multi-task BiLSTM + Attn,72.1,78.63,0.8,0.01,91.7,0.79,ito:ITO_00141,Natural Language Processing,Mismatched
2,1,Natural Language Inference,MultiNLI,2018-06,Finetuned Transformer LM,81.4,88.77,9.3,0.1,91.7,0.89,ito:ITO_00141,Natural Language Processing,Mismatched
3,1,Natural Language Inference,MultiNLI,2019-01,MT-DNN,86.0,93.78,4.6,0.05,91.7,0.94,ito:ITO_00141,Natural Language Processing,Mismatched
4,1,Natural Language Inference,MultiNLI,2019-07,RoBERTa,90.2,98.36,4.2,0.05,91.7,0.98,ito:ITO_00141,Natural Language Processing,Mismatched
5,1,Natural Language Inference,MultiNLI,2019-10,T5-11B,91.7,100.0,1.5,0.02,91.7,1.0,ito:ITO_00141,Natural Language Processing,Mismatched
6,1,Natural Language Inference,MultiNLI Dev,2019-09,TinyBERT (M=6;d'=768;d'i=3072),84.5,100.0,84.5,1.0,84.5,0.92,ito:ITO_00141,Natural Language Processing,Mismatched
0,1,Relation Extraction,ADE Corpus,2018-04,multi-head,74.58,96.62,74.58,0.97,77.19,0.97,ito:ITO_00141,Natural Language Processing,RE\\+\\ Macro\\ F1
1,1,Relation Extraction,ADE Corpus,2018-08,multi-head + AT,75.52,97.84,0.9,0.01,77.19,0.98,ito:ITO_00141,Natural Language Processing,RE\\+\\ Macro\\ F1
2,1,Relation Extraction,ADE Corpus,2019-05,Relation-Metric,77.19,100.0,1.7,0.02,77.19,1.0,ito:ITO_00141,Natural Language Processing,RE\\+\\ Macro\\ F1
3,1,Relation Extraction,CoNLL04,2018-04,multi-head,62.04,96.34,62.04,0.96,64.4,0.8,ito:ITO_00141,Natural Language Processing,RE\\+\\ Macro\\ F1
4,1,Relation Extraction,CoNLL04,2018-12,Biaffine attention,64.4,100.0,2.4,0.04,64.4,0.83,ito:ITO_00141,Natural Language Processing,RE\\+\\ Macro\\ F1
0,1,Relation Extraction,CoNLL04,2018-04,multi-head,83.9,97.33,83.9,0.97,86.2,0.96,ito:ITO_00141,Natural Language Processing,NER\\ Macro\\ F1
1,1,Relation Extraction,CoNLL04,2018-12,Biaffine attention,86.2,100.0,2.3,0.03,86.2,0.99,ito:ITO_00141,Natural Language Processing,NER\\ Macro\\ F1
2,1,Relation Extraction,ADE Corpus,2018-04,multi-head,86.4,99.29,86.4,0.99,87.02,0.99,ito:ITO_00141,Natural Language Processing,NER\\ Macro\\ F1
3,1,Relation Extraction,ADE Corpus,2018-08,multi-head + AT,86.73,99.67,0.3,0.0,87.02,1.0,ito:ITO_00141,Natural Language Processing,NER\\ Macro\\ F1
4,1,Relation Extraction,ADE Corpus,2019-05,Relation-Metric,87.02,100.0,0.3,0.0,87.02,1.0,ito:ITO_00141,Natural Language Processing,NER\\ Macro\\ F1
0,1,Text Classification,LOCAL DATASET,2018-05,RMDL (15 RDLs,90.79,100.0,90.79,1.0,90.79,1.0,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(%\\)
0,1,Meeting Summarization,300W,2018-05,abc,10.0,100.0,10,1.0,10,1.0,ito:ITO_00141,Natural Language Processing,10%
0,1,Entity Typing,Freebase FIGER,2018-06,TextEnt-full,94.8,100.0,94.8,1.0,94.8,1.0,ito:ITO_00141,Natural Language Processing,BEP
1,1,Question-Answer-Generation,Question-Answer-Generation,2018-06,TextEnt-full,94.8,100.0,94.8,1.0,94.8,1.0,ito:ITO_00141,Natural Language Processing,BEP
0,1,Text Classification,20NEWS,2018-06,TextEnt-full,83.9,97.33,83.9,0.97,86.2,0.91,ito:ITO_00141,Natural Language Processing,F\\-measure
1,1,Text Classification,20NEWS,2019-09,NABoE-full,86.2,100.0,2.3,0.03,86.2,0.94,ito:ITO_00141,Natural Language Processing,F\\-measure
2,1,Text Classification,R8,2018-06,TextEnt-full,91.0,99.24,91.0,0.99,91.7,0.99,ito:ITO_00141,Natural Language Processing,F\\-measure
3,1,Text Classification,R8,2019-09,NABoE-full,91.7,100.0,0.7,0.01,91.7,1.0,ito:ITO_00141,Natural Language Processing,F\\-measure
0,1,Entity Typing,Freebase FIGER,2018-06,TextEnt-full,85.7,100.0,85.7,1.0,85.7,0.97,ito:ITO_00141,Natural Language Processing,Micro\\ F1
1,1,Question-Answer-Generation,Question-Answer-Generation,2018-06,TextEnt-full,85.7,100.0,85.7,1.0,85.7,0.97,ito:ITO_00141,Natural Language Processing,Micro\\ F1
2,1,Entity Linking,FIGER,2019-05,ERNIE,73.39,100.0,73.39,1.0,73.39,0.83,ito:ITO_00141,Natural Language Processing,Micro\\ F1
3,1,Multi-Label Text Classification,EUR-Lex,2019-06,bert-base,73.2,100.0,73.2,1.0,73.2,0.83,ito:ITO_00141,Natural Language Processing,Micro\\ F1
4,1,Text Classification,RCV1,2019-08,HiLAP (bow-CNN),83.3,94.12,83.3,0.94,88.5,0.94,ito:ITO_00141,Natural Language Processing,Micro\\ F1
5,1,Text Classification,RCV1,2020-02,MAGNET,88.5,100.0,5.2,0.06,88.5,1.0,ito:ITO_00141,Natural Language Processing,Micro\\ F1
6,1,Node Classification,BlogCatalog,2019-12,DAOR,33.05,100.0,33.05,1.0,33.05,0.37,ito:ITO_00141,Natural Language Processing,Micro\\ F1
7,1,Spoken language identification,Spoken language identification,2019-12,DAOR,33.05,100.0,33.05,1.0,33.05,0.37,ito:ITO_00141,Natural Language Processing,Micro\\ F1
0,1,Entity Typing,Freebase FIGER,2018-06,TextEnt-full,84.2,100.0,84.2,1.0,84.2,1.0,ito:ITO_00141,Natural Language Processing,Macro\\ F1
1,1,Question-Answer-Generation,Question-Answer-Generation,2018-06,TextEnt-full,84.2,100.0,84.2,1.0,84.2,1.0,ito:ITO_00141,Natural Language Processing,Macro\\ F1
2,1,Entity Linking,FIGER,2019-05,ERNIE,76.51,100.0,76.51,1.0,76.51,0.91,ito:ITO_00141,Natural Language Processing,Macro\\ F1
3,1,Text Classification,RCV1,2019-08,HiLAP (bow-CNN),60.1,100.0,60.1,1.0,60.1,0.71,ito:ITO_00141,Natural Language Processing,Macro\\ F1
4,1,Node Classification,BlogCatalog,2019-12,DAOR,17.25,100.0,17.25,1.0,17.25,0.2,ito:ITO_00141,Natural Language Processing,Macro\\ F1
5,1,Spoken language identification,Spoken language identification,2019-12,DAOR,17.25,100.0,17.25,1.0,17.25,0.2,ito:ITO_00141,Natural Language Processing,Macro\\ F1
0,1,Paraphrase Identification,2017_test set,2018-06,CNN,50.0,100.0,50,1.0,50,1.0,ito:ITO_00141,Natural Language Processing,10\\ fold\\ Cross\\ validation
0,1,Multimodal Sentiment Analysis,CMU-MOSEI,2018-07,Graph-MFN,0.71,100.0,0.71,1.0,0.71,1.0,ito:ITO_00141,Natural Language Processing,MAE
0,1,Visual Question Answering,VQA-CP,2018-08,HAN,28.65,55.04,28.65,0.55,52.05,0.55,ito:ITO_00141,Natural Language Processing,Score
1,1,Visual Question Answering,VQA-CP,2019-02,MuRel,39.54,75.97,10.9,0.21,52.05,0.76,ito:ITO_00141,Natural Language Processing,Score
2,1,Visual Question Answering,VQA-CP,2019-05,UpDn+SCR (VQA-X),49.45,95.0,9.9,0.19,52.05,0.95,ito:ITO_00141,Natural Language Processing,Score
3,1,Visual Question Answering,VQA-CP,2019-09,Learned-Mixin +H,52.05,100.0,2.6,0.05,52.05,1.0,ito:ITO_00141,Natural Language Processing,Score
0,1,Question Answering,CoQA,2018-08,DrQA + seq2seq with copy attention (single model),67.0,81.21,67.0,0.81,82.5,0.81,ito:ITO_00141,Natural Language Processing,In\\-domain
1,1,Question Answering,CoQA,2018-09,BiDAF++ (single model),69.4,84.12,2.4,0.03,82.5,0.84,ito:ITO_00141,Natural Language Processing,In\\-domain
2,1,Question Answering,CoQA,2018-10,FlowQA (single model),76.3,92.48,6.9,0.08,82.5,0.92,ito:ITO_00141,Natural Language Processing,In\\-domain
3,1,Question Answering,CoQA,2018-10,BERT Large Augmented (single model),82.5,100.0,6.2,0.08,82.5,1.0,ito:ITO_00141,Natural Language Processing,In\\-domain
0,1,Question Answering,CoQA,2018-08,DrQA + seq2seq with copy attention (single model),65.1,80.27,65.1,0.8,81.1,0.8,ito:ITO_00141,Natural Language Processing,Overall
1,1,Question Answering,CoQA,2018-09,BiDAF++ (single model),67.8,83.6,2.7,0.03,81.1,0.84,ito:ITO_00141,Natural Language Processing,Overall
2,1,Question Answering,CoQA,2018-10,FlowQA (single model),75.0,92.48,7.2,0.09,81.1,0.92,ito:ITO_00141,Natural Language Processing,Overall
3,1,Question Answering,CoQA,2018-10,BERT Large Augmented (single model),81.1,100.0,6.1,0.08,81.1,1.0,ito:ITO_00141,Natural Language Processing,Overall
0,1,Question Answering,CoQA,2018-08,DrQA + seq2seq with copy attention (single model),60.4,77.84,60.4,0.78,77.6,0.78,ito:ITO_00141,Natural Language Processing,Out\\-of\\-domain
1,1,Question Answering,CoQA,2018-09,BiDAF++ (single model),63.8,82.22,3.4,0.04,77.6,0.82,ito:ITO_00141,Natural Language Processing,Out\\-of\\-domain
2,1,Question Answering,CoQA,2018-10,FlowQA (single model),71.8,92.53,8.0,0.1,77.6,0.93,ito:ITO_00141,Natural Language Processing,Out\\-of\\-domain
3,1,Question Answering,CoQA,2018-10,BERT Large Augmented (single model),77.6,100.0,5.8,0.07,77.6,1.0,ito:ITO_00141,Natural Language Processing,Out\\-of\\-domain
0,1,Entity Linking,AIDA-CoNLL,2018-08,base model + att + global ,82.6,100.0,82.6,1.0,82.6,1.0,ito:ITO_00141,Natural Language Processing,Micro\\-F1\\ strong
0,1,Entity Linking,AIDA-CoNLL,2018-08,base model + att + global ,82.4,100.0,82.4,1.0,82.4,1.0,ito:ITO_00141,Natural Language Processing,Macro\\-F1\\ strong
0,1,Machine Translation,WMT2014 English-German,2018-08,Noisy back-translation,33.8,100.0,33.8,1.0,33.8,0.77,ito:ITO_00141,Natural Language Processing,SacreBLEU
1,1,Machine Translation,WMT2014 English-French,2018-08,Transformer Big + BT,43.8,100.0,43.8,1.0,43.8,1.0,ito:ITO_00141,Natural Language Processing,SacreBLEU
2,1,Machine Translation,WMT2019 English-German,2019-07,Facebook-FAIR (ensemble),42.7,100.0,42.7,1.0,42.7,0.97,ito:ITO_00141,Natural Language Processing,SacreBLEU
0,1,Constituency Grammar Induction,PTB,2018-08,DMV + invertible projector,60.2,88.92,60.2,0.89,67.7,0.89,ito:ITO_00141,Natural Language Processing,Mean\\ F1\\ \\(WSJ10\\)
1,1,Constituency Grammar Induction,PTB,2018-10,ON-LSTM,65.1,96.16,4.9,0.07,67.7,0.96,ito:ITO_00141,Natural Language Processing,Mean\\ F1\\ \\(WSJ10\\)
2,1,Constituency Grammar Induction,PTB,2019-06,DIORA,67.7,100.0,2.6,0.04,67.7,1.0,ito:ITO_00141,Natural Language Processing,Mean\\ F1\\ \\(WSJ10\\)
0,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),54.7,94.98,54.7,0.95,57.59,0.92,ito:ITO_00141,Natural Language Processing,NDCG
1,1,Visual Dialog,VisDial v1.0 test-std,2019-02,DAN,57.59,100.0,2.9,0.05,57.59,0.97,ito:ITO_00141,Natural Language Processing,NDCG
2,1,Visual Dialog,Visual Dialog v1.0,2019-02,HACAN,57.17,96.29,57.17,0.96,59.37,0.96,ito:ITO_00141,Natural Language Processing,NDCG
3,1,Visual Dialog,Visual Dialog v1.0,2019-02,DAN,57.59,97.0,0.4,0.01,59.37,0.97,ito:ITO_00141,Natural Language Processing,NDCG
4,1,Visual Dialog,Visual Dialog v1.0,2020-04,MVAN,59.37,100.0,1.8,0.03,59.37,1.0,ito:ITO_00141,Natural Language Processing,NDCG
0,1,Question Answering,QuAC,2018-10,FlowQA (single model),5.8,100.0,5.8,1.0,5.8,1.0,ito:ITO_00141,Natural Language Processing,HEQD
0,1,Question Answering,QuAC,2018-10,FlowQA (single model),59.6,100.0,59.6,1.0,59.6,1.0,ito:ITO_00141,Natural Language Processing,HEQQ
0,1,Multimodal Emotion Recognition,IEMOCAP,2018-10,Multimodal Dual Recurrent Encoder (MDRE) / (A+T),0.718,100.0,0.718,1.0,0.718,1.0,ito:ITO_00141,Natural Language Processing,WAP
1,1,Speech Emotion Recognition,IEMOCAP,2018-10,Multimodal Dual Recurrent Encoder (MDRE) / (A+T),0.718,100.0,0.718,1.0,0.718,1.0,ito:ITO_00141,Natural Language Processing,WAP
0,1,Constituency Grammar Induction,PTB,2018-10,ON-LSTM,66.8,97.52,66.8,0.98,68.5,0.98,ito:ITO_00141,Natural Language Processing,Max\\ F1\\ \\(WSJ10\\)
1,1,Constituency Grammar Induction,PTB,2019-06,DIORA,68.5,100.0,1.7,0.02,68.5,1.0,ito:ITO_00141,Natural Language Processing,Max\\ F1\\ \\(WSJ10\\)
0,1,Click-Through Rate Prediction,Avazu,2018-10,AutoInt,0.3823,100.0,0.3823,1.0,0.3823,1.0,ito:ITO_00141,Natural Language Processing,LogLoss
1,1,Logical Reasoning Reading Comprehension,Logical Reasoning Reading Comprehension,2018-10,AutoInt,0.3823,100.0,0.3823,1.0,0.3823,1.0,ito:ITO_00141,Natural Language Processing,LogLoss
0,1,Information Retrieval,TREC-PM,2018-11,hpipubcommon,0.5605,100.0,0.5605,1.0,0.5605,1.0,ito:ITO_00141,Natural Language Processing,infNDCG
0,1,Phrase Grounding,Flickr30k,2018-11,COCO_ELMo_PNASNet,69.19,100.0,69.19,1.0,69.19,1.0,ito:ITO_00141,Natural Language Processing,Pointing\\ Game\\ Accuracy
1,1,Phrase Grounding,ReferIt,2018-11,VG_BiLSTM_VGG,62.76,100.0,62.76,1.0,62.76,0.91,ito:ITO_00141,Natural Language Processing,Pointing\\ Game\\ Accuracy
2,1,Phrase Grounding,Visual Genome,2018-11,VG_ELMo_PNASNet,55.16,100.0,55.16,1.0,55.16,0.8,ito:ITO_00141,Natural Language Processing,Pointing\\ Game\\ Accuracy
0,1,Intent Detection,SNIPS,2018-12,Capsule-NLU,91.8,99.53,91.8,1.0,92.23,1.0,ito:ITO_00141,Natural Language Processing,Slot\\ F1\\ Score
1,1,Intent Detection,SNIPS,2019-06,SF-ID,92.23,100.0,0.4,0.0,92.23,1.0,ito:ITO_00141,Natural Language Processing,Slot\\ F1\\ Score
0,1,Intent Detection,SNIPS,2018-12,Capsule-NLU,97.7,100.0,97.7,1.0,97.7,1.0,ito:ITO_00141,Natural Language Processing,Intent\\ Accuracy
0,1,Question Answering,Natural Questions,2019-01,BERT-joint,66.2,100.0,66.2,1.0,66.2,1.0,ito:ITO_00141,Natural Language Processing,F1\\ \\(Long\\)
0,1,Question Answering,Natural Questions,2019-01,BERT-joint,52.1,100.0,52.1,1.0,52.1,1.0,ito:ITO_00141,Natural Language Processing,F1\\ \\(Short\\)
0,1,Language Modelling,The Pile,2019-02,GPT-2 (Zero-Shot),1.2253,100.0,1.2253,1.0,1.2253,1.0,ito:ITO_00141,Natural Language Processing,Bits\\ per\\ byte
0,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,HAN,93.99,100.0,93.99,1.0,93.99,1.0,ito:ITO_00141,Natural Language Processing,Micro\\-F1\\ \\(80%\\ training\\ data\\)
0,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,HAN,92.24,100.0,92.24,1.0,92.24,1.0,ito:ITO_00141,Natural Language Processing,Macro\\-F1\\ \\(20%\\ training\\ data\\)
0,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,HAN,93.7,97.12,93.7,0.97,96.48,0.97,ito:ITO_00141,Natural Language Processing,Macro\\-F1\\ \\(60%\\ training\\ data\\)
1,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-12,NLAH (2ndprox),96.48,100.0,2.8,0.03,96.48,1.0,ito:ITO_00141,Natural Language Processing,Macro\\-F1\\ \\(60%\\ training\\ data\\)
0,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,HAN,93.08,99.61,93.08,1.0,93.44,1.0,ito:ITO_00141,Natural Language Processing,Macro\\-F1\\ \\(80%\\ training\\ data\\)
1,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,ESim,93.44,100.0,0.4,0.0,93.44,1.0,ito:ITO_00141,Natural Language Processing,Macro\\-F1\\ \\(80%\\ training\\ data\\)
0,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,HAN,93.11,100.0,93.11,1.0,93.11,1.0,ito:ITO_00141,Natural Language Processing,Micro\\-F1\\ \\(20%\\ training\\ data\\)
0,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Subtask 4,2019-03,BERT-pair-QA-B,89.9,100.0,89.9,1.0,89.9,1.0,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(3\\-way\\)
0,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Subtask 4,2019-03,BERT-pair-QA-B,85.9,100.0,85.9,1.0,85.9,1.0,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(4\\-way\\)
0,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Subtask 4,2019-03,BERT-pair-QA-B,95.6,100.0,95.6,1.0,95.6,1.0,ito:ITO_00141,Natural Language Processing,Binary\\ Accuracy
0,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 1,2019-04,BERT-PT,84.26,100.0,84.26,1.0,84.26,0.98,ito:ITO_00141,Natural Language Processing,Laptop\\ \\(F1\\)
1,1,Aspect Extraction,SemEval 2014 Task 4 Sub Task 2,2020-01,BAT,85.57,100.0,85.57,1.0,85.57,1.0,ito:ITO_00141,Natural Language Processing,Laptop\\ \\(F1\\)
0,1,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 1,2019-04,BERT-PT,77.97,100.0,77.97,1.0,77.97,0.96,ito:ITO_00141,Natural Language Processing,Restaurant\\ \\(F1\\)
1,1,Aspect Extraction,SemEval 2014 Task 4 Sub Task 2,2020-01,BAT,81.5,100.0,81.5,1.0,81.5,1.0,ito:ITO_00141,Natural Language Processing,Restaurant\\ \\(F1\\)
0,1,Text-To-Speech Synthesis,CMUDict 0.7b,2019-04,Token-Level Ensemble Distillation,4.6,100.0,4.6,1.0,4.6,1.0,ito:ITO_00141,Natural Language Processing,Phoneme\\ Error\\ Rate
0,1,Text-To-Speech Synthesis,CMUDict 0.7b,2019-04,Token-Level Ensemble Distillation,19.88,100.0,19.88,1.0,19.88,1.0,ito:ITO_00141,Natural Language Processing,Word\\ Error\\ Rate\\ \\(WER\\)
1,1,Arabic Text Diacritization,Tashkeela,2019-04,Shakkala,0.1119,100.0,0.1119,1.0,0.1119,0.01,ito:ITO_00141,Natural Language Processing,Word\\ Error\\ Rate\\ \\(WER\\)
0,1,Text Classification,IMDb,2019-04,KD-LSTMreg,53.7,100.0,53.7,1.0,53.7,1.0,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(10\\ classes\\)
0,1,Passage Re-Ranking,TREC-PM,2019-04,BERT + Doc2query,36.5,100.0,36.5,1.0,36.5,1.0,ito:ITO_00141,Natural Language Processing,mAP
0,1,Arabic Text Diacritization,Tashkeela,2019-04,Shakkala,0.0373,100.0,0.0373,1.0,0.0373,1.0,ito:ITO_00141,Natural Language Processing,Diacritic\\ Error\\ Rate
1,1,EEG Emotion Recognition,EEG Emotion Recognition,2019-04,Shakkala,0.0373,100.0,0.0373,1.0,0.0373,1.0,ito:ITO_00141,Natural Language Processing,Diacritic\\ Error\\ Rate
0,1,Synthetic Data Generation,UCI Epileptic Seizure Recognition,2019-05,GAN,0.87,94.57,0.87,0.95,0.92,0.95,ito:ITO_00141,Natural Language Processing,AUROC
1,1,Synthetic Data Generation,UCI Epileptic Seizure Recognition,2020-01,corGAN,0.92,100.0,0.1,0.11,0.92,1.0,ito:ITO_00141,Natural Language Processing,AUROC
2,1,Emotion-Cause Pair Extraction,Emotion-Cause Pair Extraction,2019-05,GAN,0.87,94.57,0.87,0.95,0.92,0.95,ito:ITO_00141,Natural Language Processing,AUROC
3,1,Emotion-Cause Pair Extraction,Emotion-Cause Pair Extraction,2020-01,corGAN,0.92,100.0,0.1,0.11,0.92,1.0,ito:ITO_00141,Natural Language Processing,AUROC
0,1,Question Answering,HotpotQA,2019-05,DFGN,59.82,72.07,59.82,0.72,83.0,0.72,ito:ITO_00141,Natural Language Processing,Joint\\ F1
1,1,Question Answering,HotpotQA,2019-07,SpanBERT,83.0,100.0,23.2,0.28,83.0,1.0,ito:ITO_00141,Natural Language Processing,Joint\\ F1
0,1,AMR Parsing,LDC2017T10,2019-05,Sequence-to-Graph Transduction,76.3,100.0,76.3,1.0,76.3,1.0,ito:ITO_00141,Natural Language Processing,Smatch
0,1,Text-To-Speech Synthesis,LJSpeech,2019-05,Merlin,2.4,62.5,2.4,0.62,3.84,0.62,ito:ITO_00141,Natural Language Processing,Audio\\ Quality\\ MOS
1,1,Text-To-Speech Synthesis,LJSpeech,2019-05,FastSpeech (Mel + WaveGlow),3.84,100.0,1.4,0.36,3.84,1.0,ito:ITO_00141,Natural Language Processing,Audio\\ Quality\\ MOS
0,1,Text-To-Speech Synthesis,LJSpeech,2019-05,FastSpeech,270.0,100.0,270,1.0,270,1.0,ito:ITO_00141,Natural Language Processing,Speedup
0,1,Text-To-Speech Synthesis,LJSpeech,2019-05,FastSpeech,3.84,100.0,3.84,1.0,3.84,1.0,ito:ITO_00141,Natural Language Processing,MOS
0,1,Multi-Label Text Classification,Wiki-30K,2019-05,LAHA,67.82,100.0,67.82,1.0,67.82,0.73,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-5
1,1,Multi-Label Text Classification,AAPD,2019-05,LAHA,83.7,100.0,83.7,1.0,83.7,0.9,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-5
2,1,Multi-Label Text Classification,EUR-Lex,2019-05,LAHA,59.28,72.03,59.28,0.72,82.3,0.64,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-5
3,1,Multi-Label Text Classification,EUR-Lex,2019-06,bert-base,82.3,100.0,23.0,0.28,82.3,0.88,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-5
4,1,Multi-Label Text Classification,Amazon-12K,2019-05,LAHA,87.57,100.0,87.57,1.0,87.57,0.94,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-5
5,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,LAHA,54.65,100.0,54.65,1.0,54.65,0.59,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-5
6,1,Text Classification,RCV1,2019-06,NLP-Cap,93.11,100.0,93.11,1.0,93.11,1.0,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-5
0,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,LAHA,51.7,100.0,51.7,1.0,51.7,0.56,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-3
1,1,Multi-Label Text Classification,Wiki-30K,2019-05,LAHA,75.64,100.0,75.64,1.0,75.64,0.82,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-3
2,1,Multi-Label Text Classification,EUR-Lex,2019-05,LAHA,64.89,91.25,64.89,0.91,71.11,0.7,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-3
3,1,Multi-Label Text Classification,EUR-Lex,2019-06,NLP-Cap,71.11,100.0,6.2,0.09,71.11,0.77,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-3
4,1,Multi-Label Text Classification,Amazon-12K,2019-05,LAHA,89.13,100.0,89.13,1.0,89.13,0.96,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-3
5,1,Multi-Label Text Classification,AAPD,2019-05,LAHA,80.11,100.0,80.11,1.0,80.11,0.87,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-3
6,1,Text Classification,RCV1,2019-06,NLP-Cap,92.47,100.0,92.47,1.0,92.47,1.0,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-3
0,1,Multi-Label Text Classification,Amazon-12K,2019-05,LAHA,79.16,100.0,79.16,1.0,79.16,0.97,ito:ITO_00141,Natural Language Processing,P\\-at\\-3
1,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,LAHA,34.6,100.0,34.6,1.0,34.6,0.43,ito:ITO_00141,Natural Language Processing,P\\-at\\-3
2,1,Multi-Label Text Classification,Wiki-30K,2019-05,LAHA,73.14,100.0,73.14,1.0,73.14,0.9,ito:ITO_00141,Natural Language Processing,P\\-at\\-3
3,1,Multi-Label Text Classification,AAPD,2019-05,LAHA,60.72,100.0,60.72,1.0,60.72,0.75,ito:ITO_00141,Natural Language Processing,P\\-at\\-3
4,1,Multi-Label Text Classification,EUR-Lex,2019-05,LAHA,61.48,93.89,61.48,0.94,65.48,0.76,ito:ITO_00141,Natural Language Processing,P\\-at\\-3
5,1,Multi-Label Text Classification,EUR-Lex,2019-06,NLP-Cap,65.48,100.0,4.0,0.06,65.48,0.81,ito:ITO_00141,Natural Language Processing,P\\-at\\-3
6,1,Text Classification,RCV1,2019-06,NLP-Cap,81.27,100.0,81.27,1.0,81.27,1.0,ito:ITO_00141,Natural Language Processing,P\\-at\\-3
0,1,Fake News Detection,Grover-Mega,2019-05,Grover-Mega,92.0,100.0,92.0,1.0,92.0,1.0,ito:ITO_00141,Natural Language Processing,Unpaired\\ Accuracy
0,1,Multi-Label Text Classification,EUR-Lex,2019-06,bert-base,79.6,100.0,79.6,1.0,79.6,1.0,ito:ITO_00141,Natural Language Processing,RP\\-at\\-5
0,1,Multi-Label Text Classification,EUR-Lex,2019-06,NLP-Cap,80.2,100.0,80.2,1.0,80.2,0.83,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-1
1,1,Text Classification,RCV1,2019-06,NLP-Cap,97.05,100.0,97.05,1.0,97.05,1.0,ito:ITO_00141,Natural Language Processing,nDCG\\-at\\-1
0,1,Relation Extraction,DocRED,2019-06,DocRED-LSTM,43.6,80.12,43.6,0.8,54.42,0.8,ito:ITO_00141,Natural Language Processing,Ign\\ F1
1,1,Relation Extraction,DocRED,2019-06,DocRED-Context-Aware,43.93,80.72,0.3,0.01,54.42,0.81,ito:ITO_00141,Natural Language Processing,Ign\\ F1
2,1,Relation Extraction,DocRED,2019-06,DocRED-BiLSTM,44.73,82.19,0.8,0.01,54.42,0.82,ito:ITO_00141,Natural Language Processing,Ign\\ F1
3,1,Relation Extraction,DocRED,2019-09,Two-Step+BERT-base,54.42,100.0,9.7,0.18,54.42,1.0,ito:ITO_00141,Natural Language Processing,Ign\\ F1
0,1,Aspect Term Extraction and Sentiment Classification,SemEval,2019-06,IMN-BERT,70.72,100.0,70.72,1.0,70.72,1.0,ito:ITO_00141,Natural Language Processing,Restaurant\\ 2014\\ \\(F1\\)
0,1,Aspect Term Extraction and Sentiment Classification,SemEval,2019-06,IMN-BERT,61.73,100.0,61.73,1.0,61.73,1.0,ito:ITO_00141,Natural Language Processing,Laptop\\ 2014\\ \\(F1\\)
0,1,Aspect Term Extraction and Sentiment Classification,SemEval,2019-06,IMN-BERT,60.22,100.0,60.22,1.0,60.22,1.0,ito:ITO_00141,Natural Language Processing,Restaurant\\ 2015\\ \\(F1\\)
0,1,Natural Language Inference,ANLI test,2019-06,XLNet (Large),70.3,97.1,70.3,0.97,72.4,0.97,ito:ITO_00141,Natural Language Processing,A1
1,1,Natural Language Inference,ANLI test,2019-07,RoBERTa (Large),72.4,100.0,2.1,0.03,72.4,1.0,ito:ITO_00141,Natural Language Processing,A1
0,1,Natural Language Inference,ANLI test,2019-06,XLNet (Large),50.9,100.0,50.9,1.0,50.9,1.0,ito:ITO_00141,Natural Language Processing,A2
0,1,Natural Language Inference,ANLI test,2019-06,XLNet (Large),49.4,100.0,49.4,1.0,49.4,1.0,ito:ITO_00141,Natural Language Processing,A3
0,1,Document Ranking,ClueWeb09-B,2019-06,XLNet,20.28,100.0,20.28,1.0,20.28,1.0,ito:ITO_00141,Natural Language Processing,ERR\\-at\\-20
0,1,Reading Comprehension,RACE,2019-06,XLNet,84.0,93.33,84.0,0.93,90.0,0.93,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(High\\)
1,1,Reading Comprehension,RACE,2019-09,Megatron-BERT,88.6,98.44,4.6,0.05,90.0,0.98,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(High\\)
2,1,Reading Comprehension,RACE,2019-09,Megatron-BERT (ensemble),90.0,100.0,1.4,0.02,90.0,1.0,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(High\\)
0,1,Reading Comprehension,RACE,2019-06,XLNet,88.6,95.17,88.6,0.95,93.1,0.95,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(Middle\\)
1,1,Reading Comprehension,RACE,2019-09,Megatron-BERT,91.8,98.6,3.2,0.03,93.1,0.99,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(Middle\\)
2,1,Reading Comprehension,RACE,2019-09,Megatron-BERT (ensemble),93.1,100.0,1.3,0.01,93.1,1.0,ito:ITO_00141,Natural Language Processing,Accuracy\\ \\(Middle\\)
0,1,Coreference Resolution,GAP,2019-08,ProBERT,92.5,100.0,92.5,1.0,92.5,1.0,ito:ITO_00141,Natural Language Processing,Overall\\ F1
0,1,Coreference Resolution,GAP,2019-08,ProBERT,94.0,100.0,94,1.0,94,1.0,ito:ITO_00141,Natural Language Processing,Masculine\\ F1\\ \\(M\\)
0,1,Coreference Resolution,GAP,2019-08,ProBERT,91.1,100.0,91.1,1.0,91.1,1.0,ito:ITO_00141,Natural Language Processing,Feminine\\ F1\\ \\(F\\)
0,1,Coreference Resolution,GAP,2019-08,ProBERT,0.97,100.0,0.97,1.0,0.97,1.0,ito:ITO_00141,Natural Language Processing,Bias\\ \\(F/M\\)
0,1,Visual Question Answering,VizWiz 2018,2019-08,"LXR955, No Ensemble",74.0,100.0,74,1.0,74,1.0,ito:ITO_00141,Natural Language Processing,yes/no
0,1,Visual Question Answering,VizWiz 2018,2019-08,"LXR955, No Ensemble",24.76,100.0,24.76,1.0,24.76,1.0,ito:ITO_00141,Natural Language Processing,number
0,1,Visual Question Answering,VizWiz 2018,2019-08,"LXR955, No Ensemble",39.0,100.0,39,1.0,39,1.0,ito:ITO_00141,Natural Language Processing,other
0,1,Visual Question Answering,VizWiz 2018,2019-08,"LXR955, No Ensemble",82.26,100.0,82.26,1.0,82.26,1.0,ito:ITO_00141,Natural Language Processing,unanswerable
0,1,Sentiment Analysis,FiQA,2019-08,FinBERT,0.55,100.0,0.55,1.0,0.55,1.0,ito:ITO_00141,Natural Language Processing,R\\^2
0,1,Table-based Fact Verification,TabFact,2019-09,Table-BERT-Horizontal-T+F-Template,66.1,100.0,66.1,1.0,66.1,1.0,ito:ITO_00141,Natural Language Processing,Val
0,1,Image Captioning,Flickr30k Captions test,2019-09,Unified VLP,17.0,100.0,17,1.0,17,0.8,ito:ITO_00141,Natural Language Processing,SPICE
1,1,Image Captioning,COCO Captions test,2019-09,Unified VLP,21.2,100.0,21.2,1.0,21.2,1.0,ito:ITO_00141,Natural Language Processing,SPICE
0,1,Emotion Recognition in Conversation,EmoryNLP,2019-09,KET,34.39,100.0,34.39,1.0,34.39,1.0,ito:ITO_00141,Natural Language Processing,Weighted\\ Macro\\-F1
0,1,Question Answering,MultiRC,2019-10,T5-11B,88.2,100.0,88.2,1.0,88.2,1.0,ito:ITO_00141,Natural Language Processing,F1a
0,1,Machine Translation,IWSLT2017 Arabic-English,2019-10,Transformer base + BPE-Dropout,33.0,100.0,33,1.0,33,0.83,ito:ITO_00141,Natural Language Processing,Cased\\ sacreBLEU
1,1,Machine Translation,IWSLT2017 French-English,2019-10,Transformer base + BPE-Dropout,38.6,100.0,38.6,1.0,38.6,0.97,ito:ITO_00141,Natural Language Processing,Cased\\ sacreBLEU
2,1,Machine Translation,IWSLT2017 English-Arabic,2019-10,Transformer base + BPE-Dropout,15.2,100.0,15.2,1.0,15.2,0.38,ito:ITO_00141,Natural Language Processing,Cased\\ sacreBLEU
3,1,Machine Translation,IWSLT2017 English-French,2019-10,Transformer base + BPE-Dropout,39.83,100.0,39.83,1.0,39.83,1.0,ito:ITO_00141,Natural Language Processing,Cased\\ sacreBLEU
0,1,Part-Of-Speech Tagging,French GSD,2019-11,CamemBERT,98.19,100.0,98.19,1.0,98.19,0.99,ito:ITO_00141,Natural Language Processing,UPOS
1,1,Part-Of-Speech Tagging,Sequoia Treebank,2019-11,CamemBERT,99.21,100.0,99.21,1.0,99.21,1.0,ito:ITO_00141,Natural Language Processing,UPOS
2,1,Part-Of-Speech Tagging,Spoken Corpus,2019-11,CamemBERT,96.68,100.0,96.68,1.0,96.68,0.97,ito:ITO_00141,Natural Language Processing,UPOS
3,1,Part-Of-Speech Tagging,ParTUT,2019-11,CamemBERT,97.63,100.0,97.63,1.0,97.63,0.98,ito:ITO_00141,Natural Language Processing,UPOS
0,1,Sparse Learning,ImageNet,2019-11,Resnet-50: 80% Sparse,77.1,100.0,77.1,1.0,77.1,1.0,ito:ITO_00141,Natural Language Processing,Top\\-1\\ Accuracy
1,1,Chinese Spelling Error Correction,Chinese Spelling Error Correction,2019-11,Resnet-50: 80% Sparse,77.1,100.0,77.1,1.0,77.1,1.0,ito:ITO_00141,Natural Language Processing,Top\\-1\\ Accuracy
0,1,Aspect Extraction,SemEval 2014 Task 4 Sub Task 2,2020-01,BAT,83.54,100.0,83.54,1.0,83.54,1.0,ito:ITO_00141,Natural Language Processing,Mean\\ F1\\ \\(Laptop\\ \\+\\ Restaurant\\)
0,1,Bias Detection,StereoSet,2020-04,GPT-2 (small),72.97,100.0,72.97,1.0,72.97,1.0,ito:ITO_00141,Natural Language Processing,ICAT\\ Score
1,1,AMR Parsing,AMR Parsing,2020-04,GPT-2 (small),72.97,100.0,72.97,1.0,72.97,1.0,ito:ITO_00141,Natural Language Processing,ICAT\\ Score
0,1,Question Answering,SCDE,2020-04,bert-large-uncased + APN,0.661,100.0,0.661,1.0,0.661,1.0,ito:ITO_00141,Natural Language Processing,DE
0,1,Question Answering,SCDE,2020-04,bert-large-uncased + APN,0.299,100.0,0.299,1.0,0.299,1.0,ito:ITO_00141,Natural Language Processing,PA
0,1,Question Answering,SCDE,2020-04,bert-large-uncased + APN,0.717,100.0,0.717,1.0,0.717,1.0,ito:ITO_00141,Natural Language Processing,BA
0,1,Speech Recognition,TIMIT,2013-03,Bi-LSTM + skip connections w/ CTC,17.7,86.76,17.7,0.87,20.4,0.26,ito:ITO_00145,Audio process,Percentage\\ error
1,1,Speech Recognition,TIMIT,2017-04,"Soft Monotonic Attention (ours, offline)",20.1,98.53,2.4,0.12,20.4,0.3,ito:ITO_00145,Audio process,Percentage\\ error
2,1,Speech Recognition,TIMIT,2019-07,LAS multitask with indicators sampling,20.4,100.0,0.3,0.01,20.4,0.3,ito:ITO_00145,Audio process,Percentage\\ error
3,1,Speech Recognition,swb_hub_500 WER fullSWBCH,2014-06,DNN + Dropout,19.1,100.0,19.1,1.0,19.1,0.28,ito:ITO_00145,Audio process,Percentage\\ error
4,1,Noisy Speech Recognition,CHiME real,2014-12,CNN + Bi-RNN + CTC (speech to letters),67.94,100.0,67.94,1.0,67.94,1.0,ito:ITO_00145,Audio process,Percentage\\ error
5,1,Noisy Speech Recognition,CHiME clean,2014-12,CNN + Bi-RNN + CTC (speech to letters),6.3,100.0,6.3,1.0,6.3,0.09,ito:ITO_00145,Audio process,Percentage\\ error
6,1,Accented Speech Recognition,VoxForge Indian,2014-12,Deep Speech,45.35,100.0,45.35,1.0,45.35,0.67,ito:ITO_00145,Audio process,Percentage\\ error
7,1,Accented Speech Recognition,VoxForge European,2014-12,Deep Speech,31.2,100.0,31.2,1.0,31.2,0.46,ito:ITO_00145,Audio process,Percentage\\ error
8,1,Accented Speech Recognition,VoxForge Commonwealth,2014-12,Deep Speech,28.46,100.0,28.46,1.0,28.46,0.42,ito:ITO_00145,Audio process,Percentage\\ error
9,1,Accented Speech Recognition,VoxForge American-Canadian,2014-12,Deep Speech,15.01,100.0,15.01,1.0,15.01,0.22,ito:ITO_00145,Audio process,Percentage\\ error
10,1,Speech Recognition,WSJ eval92,2015-04,TC-DNN-BLSTM-DNN,3.5,97.22,3.5,0.97,3.6,0.05,ito:ITO_00145,Audio process,Percentage\\ error
11,1,Speech Recognition,WSJ eval92,2015-12,Deep Speech 2,3.6,100.0,0.1,0.03,3.6,0.05,ito:ITO_00145,Audio process,Percentage\\ error
12,1,Speech Recognition,LibriSpeech test-clean,2015-12,Deep Speech 2,5.33,25.58,5.33,0.26,20.84,0.08,ito:ITO_00145,Audio process,Percentage\\ error
13,1,Speech Recognition,LibriSpeech test-clean,2017-12,CTC + policy learning,5.42,26.01,0.1,0.0,20.84,0.08,ito:ITO_00145,Audio process,Percentage\\ error
14,1,Speech Recognition,LibriSpeech test-clean,2018-05,Snips,6.4,30.71,1.0,0.05,20.84,0.09,ito:ITO_00145,Audio process,Percentage\\ error
15,1,Speech Recognition,LibriSpeech test-clean,2020-02,Local Prior Matching (Large Model),20.84,100.0,14.4,0.69,20.84,0.31,ito:ITO_00145,Audio process,Percentage\\ error
16,1,Speech Recognition,WSJ eval93,2015-12,Deep Speech 2,4.98,73.24,4.98,0.73,6.8,0.07,ito:ITO_00145,Audio process,Percentage\\ error
17,1,Speech Recognition,WSJ eval93,2018-12,Convolutional Speech Recognition,6.8,100.0,1.8,0.26,6.8,0.1,ito:ITO_00145,Audio process,Percentage\\ error
0,1,Node Classification,BlogCatalog,2014-03,DeepWalk,22.5,26.5,22.5,0.27,84.9,0.23,ito:ITO_00145,Audio process,Accuracy
1,1,Node Classification,BlogCatalog,2017-04,Struc2vec,22.8,26.86,0.3,0.0,84.9,0.23,ito:ITO_00145,Audio process,Accuracy
2,1,Node Classification,BlogCatalog,2017-11,GraphGAN,23.2,27.33,0.4,0.0,84.9,0.23,ito:ITO_00145,Audio process,Accuracy
3,1,Node Classification,BlogCatalog,2019-06,DEMO-Net(weight),84.9,100.0,61.7,0.73,84.9,0.85,ito:ITO_00145,Audio process,Accuracy
4,1,Spoken language identification,Spoken language identification,2014-03,DeepWalk,22.5,26.5,22.5,0.27,84.9,0.23,ito:ITO_00145,Audio process,Accuracy
5,1,Spoken language identification,Spoken language identification,2017-04,Struc2vec,22.8,26.86,0.3,0.0,84.9,0.23,ito:ITO_00145,Audio process,Accuracy
6,1,Spoken language identification,Spoken language identification,2017-11,GraphGAN,23.2,27.33,0.4,0.0,84.9,0.23,ito:ITO_00145,Audio process,Accuracy
7,1,Spoken language identification,Spoken language identification,2019-06,DEMO-Net(weight),84.9,100.0,61.7,0.73,84.9,0.85,ito:ITO_00145,Audio process,Accuracy
8,1,Synthetic-to-Real Translation,Syn2Real-C,2015-05,DANN,57.4,71.93,57.4,0.72,79.8,0.58,ito:ITO_00145,Audio process,Accuracy
9,1,Synthetic-to-Real Translation,Syn2Real-C,2017-11,ADR,74.8,93.73,17.4,0.22,79.8,0.75,ito:ITO_00145,Audio process,Accuracy
10,1,Synthetic-to-Real Translation,Syn2Real-C,2019-11,DADA,79.8,100.0,5.0,0.06,79.8,0.8,ito:ITO_00145,Audio process,Accuracy
11,1,Speaker-Specific Lip to Speech Synthesis,Speaker-Specific Lip to Speech Synthesis,2015-09,GCN-FP,71.7,87.52,71.7,0.88,81.92,0.72,ito:ITO_00145,Audio process,Accuracy
12,1,Speaker-Specific Lip to Speech Synthesis,Speaker-Specific Lip to Speech Synthesis,2015-11,DCNN,76.7,93.63,5.0,0.06,81.92,0.77,ito:ITO_00145,Audio process,Accuracy
13,1,Speaker-Specific Lip to Speech Synthesis,Speaker-Specific Lip to Speech Synthesis,2019-01,AdaLanczosNet,77.7,94.85,1.0,0.01,81.92,0.78,ito:ITO_00145,Audio process,Accuracy
14,1,Speaker-Specific Lip to Speech Synthesis,Speaker-Specific Lip to Speech Synthesis,2019-06,Truncated Krylov,81.92,100.0,4.2,0.05,81.92,0.82,ito:ITO_00145,Audio process,Accuracy
15,1,Constrained Lip-synchronization,Constrained Lip-synchronization,2015-09,GCN-FP,70.3,91.05,70.3,0.91,77.21,0.71,ito:ITO_00145,Audio process,Accuracy
16,1,Constrained Lip-synchronization,Constrained Lip-synchronization,2015-11,DCNN,73.1,94.68,2.8,0.04,77.21,0.74,ito:ITO_00145,Audio process,Accuracy
17,1,Constrained Lip-synchronization,Constrained Lip-synchronization,2019-01,LanczosNet,73.4,95.07,0.3,0.0,77.21,0.74,ito:ITO_00145,Audio process,Accuracy
18,1,Constrained Lip-synchronization,Constrained Lip-synchronization,2019-06,Truncated Krylov,77.21,100.0,3.8,0.05,77.21,0.78,ito:ITO_00145,Audio process,Accuracy
19,1,Lip to Speech Synthesis,Lip to Speech Synthesis,2015-09,GCN-FP,54.3,78.66,54.3,0.79,69.03,0.55,ito:ITO_00145,Audio process,Accuracy
20,1,Lip to Speech Synthesis,Lip to Speech Synthesis,2015-11,DCNN,62.2,90.11,7.9,0.11,69.03,0.63,ito:ITO_00145,Audio process,Accuracy
21,1,Lip to Speech Synthesis,Lip to Speech Synthesis,2019-01,AdaLanczosNet,63.3,91.7,1.1,0.02,69.03,0.64,ito:ITO_00145,Audio process,Accuracy
22,1,Lip to Speech Synthesis,Lip to Speech Synthesis,2019-06,Snowball (linear),65.85,95.39,2.5,0.04,69.03,0.66,ito:ITO_00145,Audio process,Accuracy
23,1,Lip to Speech Synthesis,Lip to Speech Synthesis,2019-06,Truncated Krylov,69.03,100.0,3.2,0.05,69.03,0.7,ito:ITO_00145,Audio process,Accuracy
24,1,Unsupervised MNIST,MNIST,2015-11,Adversarial AE,95.9,96.58,95.9,0.97,99.3,0.97,ito:ITO_00145,Audio process,Accuracy
25,1,Unsupervised MNIST,MNIST,2018-03,Bidirectional InfoGAN,96.61,97.29,0.7,0.01,99.3,0.97,ito:ITO_00145,Audio process,Accuracy
26,1,Unsupervised MNIST,MNIST,2018-07,IIC,99.3,100.0,2.7,0.03,99.3,1.0,ito:ITO_00145,Audio process,Accuracy
27,1,Dialog Act Classification,Switchboard corpus,2016-03,CNN[[Lee and Dernoncourt2016]],73.1,89.91,73.1,0.9,81.3,0.74,ito:ITO_00145,Audio process,Accuracy
28,1,Dialog Act Classification,Switchboard corpus,2017-09,Bi-LSTM-CRF,79.2,97.42,6.1,0.08,81.3,0.8,ito:ITO_00145,Audio process,Accuracy
29,1,Dialog Act Classification,Switchboard corpus,2017-11,CRF-ASN,81.3,100.0,2.1,0.03,81.3,0.82,ito:ITO_00145,Audio process,Accuracy
30,1,Surgical Skills Evaluation,JIGSAWS,2016-06,Bidir. LSTM,0.833,85.0,0.833,0.85,0.98,0.01,ito:ITO_00145,Audio process,Accuracy
31,1,Surgical Skills Evaluation,JIGSAWS,2018-06,CNN,0.98,100.0,0.1,0.1,0.98,0.01,ito:ITO_00145,Audio process,Accuracy
32,1,Zero-Shot Text-to-Image Generation,Zero-Shot Text-to-Image Generation,2016-06,Bidir. LSTM,0.833,85.0,0.833,0.85,0.98,0.01,ito:ITO_00145,Audio process,Accuracy
33,1,Zero-Shot Text-to-Image Generation,Zero-Shot Text-to-Image Generation,2018-06,CNN,0.98,100.0,0.1,0.1,0.98,0.01,ito:ITO_00145,Audio process,Accuracy
34,1,Surgical Skills Evaluation,MISTIC-SIL,2016-06,Bidir. LSTM,0.895,100.0,0.895,1.0,0.895,0.01,ito:ITO_00145,Audio process,Accuracy
35,1,Handwritten Word Generation,Handwritten Word Generation,2016-06,Bidir. LSTM,0.895,100.0,0.895,1.0,0.895,0.01,ito:ITO_00145,Audio process,Accuracy
36,1,Node Classification,AIFB,2017-03,R-GCN,95.83,100.0,95.83,1.0,95.83,0.97,ito:ITO_00145,Audio process,Accuracy
37,1,Unconstrained Lip-synchronization,Unconstrained Lip-synchronization,2017-03,R-GCN,95.83,100.0,95.83,1.0,95.83,0.97,ito:ITO_00145,Audio process,Accuracy
38,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,bc-LSTM+Att,56.32,86.31,56.32,0.86,65.25,0.57,ito:ITO_00145,Audio process,Accuracy
39,1,Emotion Recognition in Conversation,IEMOCAP,2018-06,CMN,56.56,86.68,0.2,0.0,65.25,0.57,ito:ITO_00145,Audio process,Accuracy
40,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,ICON,59.09,90.56,2.5,0.04,65.25,0.6,ito:ITO_00145,Audio process,Accuracy
41,1,Emotion Recognition in Conversation,IEMOCAP,2018-11,DialogueRNN,63.4,97.16,4.3,0.07,65.25,0.64,ito:ITO_00145,Audio process,Accuracy
42,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,DialogueGCN,65.25,100.0,1.9,0.03,65.25,0.66,ito:ITO_00145,Audio process,Accuracy
43,1,Emotion Recognition in Conversation,MELD,2017-07,bc-LSTM+Att,57.5,96.57,57.5,0.97,59.54,0.58,ito:ITO_00145,Audio process,Accuracy
44,1,Emotion Recognition in Conversation,MELD,2018-11,DialogueRNN,59.54,100.0,2.0,0.03,59.54,0.6,ito:ITO_00145,Audio process,Accuracy
45,1,Multimodal Emotion Recognition,Monologue,2017-07,bc-LSTM,74.1,100.0,74.1,1.0,74.1,0.75,ito:ITO_00145,Audio process,Accuracy
46,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2017-07,CRN,68.8,82.99,68.8,0.83,82.9,0.69,ito:ITO_00145,Audio process,Accuracy
47,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2017-11,pix2pixHD,69.2,83.47,0.4,0.0,82.9,0.7,ito:ITO_00145,Audio process,Accuracy
48,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2019-03,SPADE,79.9,96.38,10.7,0.13,82.9,0.8,ito:ITO_00145,Audio process,Accuracy
49,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2019-10,CC-FPSE,82.9,100.0,3.0,0.04,82.9,0.83,ito:ITO_00145,Audio process,Accuracy
50,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2017-07,CRN,68.6,82.75,68.6,0.83,82.9,0.69,ito:ITO_00145,Audio process,Accuracy
51,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2017-11,pix2pixHD,71.6,86.37,3.0,0.04,82.9,0.72,ito:ITO_00145,Audio process,Accuracy
52,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2018-04,SIMS,74.7,90.11,3.1,0.04,82.9,0.75,ito:ITO_00145,Audio process,Accuracy
53,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2019-03,SPADE,82.9,100.0,8.2,0.1,82.9,0.83,ito:ITO_00145,Audio process,Accuracy
54,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2017-07,CRN,40.4,57.14,40.4,0.57,70.7,0.41,ito:ITO_00145,Audio process,Accuracy
55,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2017-11,pix2pixHD,45.8,64.78,5.4,0.08,70.7,0.46,ito:ITO_00145,Audio process,Accuracy
56,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2019-03,SPADE,67.9,96.04,22.1,0.31,70.7,0.68,ito:ITO_00145,Audio process,Accuracy
57,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2019-10,CC-FPSE,70.7,100.0,2.8,0.04,70.7,0.71,ito:ITO_00145,Audio process,Accuracy
58,1,Text-To-Speech Synthesis,LJSpeech,2018-06,tacotron,12.0,100.0,12,1.0,12,0.12,ito:ITO_00145,Audio process,Accuracy
59,1,Emotion Recognition,MPED,2019-05,BiHDM,40.34,100.0,40.34,1.0,40.34,0.41,ito:ITO_00145,Audio process,Accuracy
60,1,Emotion Recognition,SEED-IV,2019-07,RGNN,79.37,100.0,79.37,1.0,79.37,0.8,ito:ITO_00145,Audio process,Accuracy
61,1,Prosody Prediction,Helsinki Prosody Corpus,2019-08,BERT,83.2,100.0,83.2,1.0,83.2,0.84,ito:ITO_00145,Audio process,Accuracy
62,1,Node Classification,Coauthor CS,2019-09,GraphMix,91.83,96.87,91.83,0.97,94.8,0.92,ito:ITO_00145,Audio process,Accuracy
63,1,Node Classification,Coauthor CS,2019-10,GCN (PPR Diffusion),93.01,98.11,1.2,0.01,94.8,0.94,ito:ITO_00145,Audio process,Accuracy
64,1,Node Classification,Coauthor CS,2020-02,GCN-LPA,94.8,100.0,1.8,0.02,94.8,0.95,ito:ITO_00145,Audio process,Accuracy
65,1,Face Age Editing,Face Age Editing,2019-09,GraphMix,91.83,96.87,91.83,0.97,94.8,0.92,ito:ITO_00145,Audio process,Accuracy
66,1,Face Age Editing,Face Age Editing,2019-10,GCN (PPR Diffusion),93.01,98.11,1.2,0.01,94.8,0.94,ito:ITO_00145,Audio process,Accuracy
67,1,Face Age Editing,Face Age Editing,2020-02,GCN-LPA,94.8,100.0,1.8,0.02,94.8,0.95,ito:ITO_00145,Audio process,Accuracy
68,1,Node Classification,AMZ Comp,2019-10,GCN (Heat Diffusion),86.77,100.0,86.77,1.0,86.77,0.87,ito:ITO_00145,Audio process,Accuracy
69,1,End-To-End Dialogue Modelling,End-To-End Dialogue Modelling,2019-10,GCN (Heat Diffusion),86.77,100.0,86.77,1.0,86.77,0.87,ito:ITO_00145,Audio process,Accuracy
0,1,Node Classification,BlogCatalog,2014-03,DeepWalk,0.214,69.19,0.214,0.69,0.3093,0.0,ito:ITO_00145,Audio process,Macro\\-F1
1,1,Node Classification,BlogCatalog,2015-10,GraRep,0.3093,100.0,0.1,0.32,0.3093,0.0,ito:ITO_00145,Audio process,Macro\\-F1
2,1,Spoken language identification,Spoken language identification,2014-03,DeepWalk,0.214,69.19,0.214,0.69,0.3093,0.0,ito:ITO_00145,Audio process,Macro\\-F1
3,1,Spoken language identification,Spoken language identification,2015-10,GraRep,0.3093,100.0,0.1,0.32,0.3093,0.0,ito:ITO_00145,Audio process,Macro\\-F1
4,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,bc-LSTM+Att,54.84,86.46,54.84,0.86,63.43,0.86,ito:ITO_00145,Audio process,Macro\\-F1
5,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,ICON,56.52,89.11,1.7,0.03,63.43,0.89,ito:ITO_00145,Audio process,Macro\\-F1
6,1,Emotion Recognition in Conversation,IEMOCAP,2018-11,DialogueRNN,60.66,95.63,4.1,0.06,63.43,0.96,ito:ITO_00145,Audio process,Macro\\-F1
7,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,DialogueGCN,63.43,100.0,2.8,0.04,63.43,1.0,ito:ITO_00145,Audio process,Macro\\-F1
0,1,Dialog Generation,Persona-Chat,2014-09,Seq2Seq + Attention,16.18,81.84,16.18,0.82,19.77,0.82,ito:ITO_00145,Audio process,Avg\\ F1
1,1,Dialog Generation,Persona-Chat,2020-04,P^2 Bot,19.77,100.0,3.6,0.18,19.77,1.0,ito:ITO_00145,Audio process,Avg\\ F1
0,1,Image-to-Image Translation,GTAV-to-Cityscapes Labels,2014-09,VGG16 60.3,41.3,85.15,41.3,0.85,48.5,0.63,ito:ITO_00145,Audio process,mIoU
1,1,Image-to-Image Translation,GTAV-to-Cityscapes Labels,2015-12,ResNet101 65.1,48.5,100.0,7.2,0.15,48.5,0.74,ito:ITO_00145,Audio process,mIoU
2,1,Image-to-Image Translation,SYNTHIA Fall-to-Winter,2016-12,FCNs in the wild,59.6,94.15,59.6,0.94,63.3,0.91,ito:ITO_00145,Audio process,mIoU
3,1,Image-to-Image Translation,SYNTHIA Fall-to-Winter,2017-11,CyCADA,63.3,100.0,3.7,0.06,63.3,0.97,ito:ITO_00145,Audio process,mIoU
4,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2016-12,FCNs in the wild,20.2,37.9,20.2,0.38,53.3,0.31,ito:ITO_00145,Audio process,mIoU
5,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2017-07,CDA,29.0,54.41,8.8,0.17,53.3,0.44,ito:ITO_00145,Audio process,mIoU
6,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2018-02,Multi-level Adaptation,46.7,87.62,17.7,0.33,53.3,0.71,ito:ITO_00145,Audio process,mIoU
7,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2018-11,ADVENT,48.0,90.06,1.3,0.02,53.3,0.73,ito:ITO_00145,Audio process,mIoU
8,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-03,SWD,48.1,90.24,0.1,0.0,53.3,0.73,ito:ITO_00145,Audio process,mIoU
9,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-08,PyCDA (ResNet-101),53.3,100.0,5.2,0.1,53.3,0.81,ito:ITO_00145,Audio process,mIoU
10,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2016-12,FCNs in the wild,27.1,53.98,27.1,0.54,50.2,0.41,ito:ITO_00145,Audio process,mIoU
11,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2017-07,CDA,28.9,57.57,1.8,0.04,50.2,0.44,ito:ITO_00145,Audio process,mIoU
12,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2017-11,CyCADA pixel+feat,39.5,78.69,10.6,0.21,50.2,0.6,ito:ITO_00145,Audio process,mIoU
13,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2018-02,Multi-level Adaptation,42.4,84.46,2.9,0.06,50.2,0.65,ito:ITO_00145,Audio process,mIoU
14,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2018-08,Domain adaptation (ResNet-101),43.2,86.06,0.8,0.02,50.2,0.66,ito:ITO_00145,Audio process,mIoU
15,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2018-10,CBST-SP (ResNet-38),46.2,92.03,3.0,0.06,50.2,0.71,ito:ITO_00145,Audio process,mIoU
16,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2018-10,"CBST-SP (ResNet-38, MST)",47.0,93.63,0.8,0.02,50.2,0.72,ito:ITO_00145,Audio process,mIoU
17,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2019-04,BDL (ResNet-101),48.5,96.61,1.5,0.03,50.2,0.74,ito:ITO_00145,Audio process,mIoU
18,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2019-08,MRKLD-SP-MST (ResNet-38),49.8,99.2,1.3,0.03,50.2,0.76,ito:ITO_00145,Audio process,mIoU
19,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2019-10,CAG-UDA,50.2,100.0,0.4,0.01,50.2,0.77,ito:ITO_00145,Audio process,mIoU
20,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2017-07,CRN,22.4,51.26,22.4,0.51,43.7,0.34,ito:ITO_00145,Audio process,mIoU
21,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2019-03,SPADE,38.5,88.1,16.1,0.37,43.7,0.59,ito:ITO_00145,Audio process,mIoU
22,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2019-10,CC-FPSE,43.7,100.0,5.2,0.12,43.7,0.67,ito:ITO_00145,Audio process,mIoU
23,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2017-07,CRN,52.4,80.0,52.4,0.8,65.5,0.8,ito:ITO_00145,Audio process,mIoU
24,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2017-11,pix2pixHD,58.3,89.01,5.9,0.09,65.5,0.89,ito:ITO_00145,Audio process,mIoU
25,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2019-03,SPADE,62.3,95.11,4.0,0.06,65.5,0.95,ito:ITO_00145,Audio process,mIoU
26,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2019-10,CC-FPSE,65.5,100.0,3.2,0.05,65.5,1.0,ito:ITO_00145,Audio process,mIoU
27,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2017-07,CRN,23.7,56.97,23.7,0.57,41.6,0.36,ito:ITO_00145,Audio process,mIoU
28,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2019-03,SPADE,37.4,89.9,13.7,0.33,41.6,0.57,ito:ITO_00145,Audio process,mIoU
29,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2019-10,CC-FPSE,41.6,100.0,4.2,0.1,41.6,0.64,ito:ITO_00145,Audio process,mIoU
30,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2017-07,CRN,16.5,53.57,16.5,0.54,30.8,0.25,ito:ITO_00145,Audio process,mIoU
31,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2017-11,pix2pixHD,17.4,56.49,0.9,0.03,30.8,0.27,ito:ITO_00145,Audio process,mIoU
32,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2019-03,SPADE,30.8,100.0,13.4,0.44,30.8,0.47,ito:ITO_00145,Audio process,mIoU
0,1,Unsupervised Image-To-Image Translation,SVNH-to-MNIST,2014-09,DANN,73.6,81.42,73.6,0.81,90.4,0.81,ito:ITO_00145,Audio process,Classification\\ Accuracy
1,1,Unsupervised Image-To-Image Translation,SVNH-to-MNIST,2016-11,DTN,84.4,93.36,10.8,0.12,90.4,0.93,ito:ITO_00145,Audio process,Classification\\ Accuracy
2,1,Unsupervised Image-To-Image Translation,SVNH-to-MNIST,2017-11,CyCADA pixel+feat,90.4,100.0,6.0,0.07,90.4,1.0,ito:ITO_00145,Audio process,Classification\\ Accuracy
0,1,Image Generation,CIFAR-10,2014-10,NICE,4.5,100.0,4.5,1.0,4.5,1.0,ito:ITO_00145,Audio process,Model\\ Entropy
0,1,Image Generation,CIFAR-10,2014-10,NICE,4.5,100.0,4.5,1.0,4.5,1.0,ito:ITO_00145,Audio process,bits/dimension
1,1,Image Generation,MNIST,2018-11,i-ResNet,1.06,100.0,1.06,1.0,1.06,0.24,ito:ITO_00145,Audio process,bits/dimension
0,1,Image Generation,CIFAR-10,2014-10,NICE,4.5,100.0,4.5,1.0,4.5,1.0,ito:ITO_00145,Audio process,NLL\\ Test
1,1,Image Generation,ImageNet 64x64,2019-02,Flow++,3.69,98.4,3.69,0.98,3.75,0.82,ito:ITO_00145,Audio process,NLL\\ Test
2,1,Image Generation,ImageNet 64x64,2019-02,MaCow (Unf),3.75,100.0,0.1,0.03,3.75,0.83,ito:ITO_00145,Audio process,NLL\\ Test
0,1,Speech Recognition,WSJ eval92,2015-04,TC-DNN-BLSTM-DNN,3.5,50.72,3.5,0.51,6.9,0.09,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
1,1,Speech Recognition,WSJ eval92,2015-12,Deep Speech 2,3.6,52.17,0.1,0.01,6.9,0.09,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
2,1,Speech Recognition,WSJ eval92,2019-04,Jasper 10x3,6.9,100.0,3.3,0.48,6.9,0.18,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
3,1,Speech Recognition,LibriSpeech test-clean,2015-12,Deep Speech 2,5.33,74.13,5.33,0.74,7.19,0.14,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
4,1,Speech Recognition,LibriSpeech test-clean,2017-12,CTC + policy learning,5.42,75.38,0.1,0.01,7.19,0.14,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
5,1,Speech Recognition,LibriSpeech test-clean,2018-05,Snips,6.4,89.01,1.0,0.14,7.19,0.17,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
6,1,Speech Recognition,LibriSpeech test-clean,2020-02,Local Prior Matching (Large Model),7.19,100.0,0.8,0.11,7.19,0.19,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
7,1,Speech Recognition,LibriSpeech test-other,2015-12,Deep Speech 2,13.25,63.58,13.25,0.64,20.84,0.35,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
8,1,Speech Recognition,LibriSpeech test-other,2018-05,Snips,16.5,79.17,3.2,0.15,20.84,0.43,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
9,1,Speech Recognition,LibriSpeech test-other,2020-02,Local Prior Matching (Large Model),20.84,100.0,4.3,0.21,20.84,0.55,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
10,1,Speech Recognition,WSJ eval93,2015-12,Deep Speech 2,4.98,73.24,4.98,0.73,6.8,0.13,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
11,1,Speech Recognition,WSJ eval93,2018-12,Convolutional Speech Recognition,6.8,100.0,1.8,0.26,6.8,0.18,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
12,1,Distant Speech Recognition,CHiME-4 real 6ch,2018-03,HMM-TDNN(LFMMI) + LSTMLM + NN-GEV,2.74,100.0,2.74,1.0,2.74,0.07,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
13,1,Distant Speech Recognition,DIRHA English WSJ,2018-11,Li-GRU,23.9,62.57,23.9,0.63,38.2,0.63,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
14,1,Distant Speech Recognition,DIRHA English WSJ,2018-11,SincNet-Raw waveform,38.2,100.0,14.3,0.37,38.2,1.0,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
15,1,Text-To-Speech Synthesis,CMUDict 0.7b,2019-04,Token-Level Ensemble Distillation,19.88,100.0,19.88,1.0,19.88,0.52,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
16,1,Speech Recognition,AISHELL-1,2019-09,CTC/Att,6.7,100.0,6.7,1.0,6.7,0.18,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
17,1,Speech Recognition,Hub5'00 CallHome,2019-09,Espresso,19.1,100.0,19.1,1.0,19.1,0.5,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
18,1,Speech Recognition,Hub5'00 SwitchBoard,2019-09,Espresso,9.2,100.0,9.2,1.0,9.2,0.24,ito:ITO_00145,Audio process,Word\\ Error\\ Rate\\ \\(WER\\)
0,1,Speech Recognition,2017_test set,2015-08,1,2.0,100.0,2,1.0,2,1.0,ito:ITO_00145,Audio process,1\\ in\\ 2\\ R\\-at\\-1
0,1,Acoustic Novelty Detection,A3Lab PASCAL CHiME,2015-08,BLSTM-DAE,93.4,98.94,93.4,0.99,94.4,0.99,ito:ITO_00145,Audio process,F1
1,1,Acoustic Novelty Detection,A3Lab PASCAL CHiME,2015-10,NP-BLSTM-DAE,94.4,100.0,1.0,0.01,94.4,1.0,ito:ITO_00145,Audio process,F1
2,1,Attribute Value Extraction,Attribute Value Extraction,2015-08,BLSTM-DAE,93.4,98.94,93.4,0.99,94.4,0.99,ito:ITO_00145,Audio process,F1
3,1,Attribute Value Extraction,Attribute Value Extraction,2015-10,NP-BLSTM-DAE,94.4,100.0,1.0,0.01,94.4,1.0,ito:ITO_00145,Audio process,F1
4,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,bc-LSTM+Att,56.19,87.55,56.19,0.88,64.18,0.6,ito:ITO_00145,Audio process,F1
5,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,ICON,58.54,91.21,2.4,0.04,64.18,0.62,ito:ITO_00145,Audio process,F1
6,1,Emotion Recognition in Conversation,IEMOCAP,2019-05,DialogueRNN,62.75,97.77,4.2,0.07,64.18,0.66,ito:ITO_00145,Audio process,F1
7,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,DialogueGCN,64.18,100.0,1.4,0.02,64.18,0.68,ito:ITO_00145,Audio process,F1
8,1,Multimodal Emotion Recognition,IEMOCAP,2018-06,CHFusion (A+T+V),0.768,100.0,0.768,1.0,0.768,0.01,ito:ITO_00145,Audio process,F1
9,1,Speech Emotion Recognition,IEMOCAP,2019-04,Ensemble (Random Forests + Gradient Boosted Trees + Multi Layer Perceptron + Multinomial Naive Bayes + Logistic Regression) / (A+T),0.718,100.0,0.718,1.0,0.718,0.01,ito:ITO_00145,Audio process,F1
0,1,Speech Separation,wsj0-2mix,2015-08,Deep Clustering ++,10.8,57.45,10.8,0.57,18.8,0.57,ito:ITO_00145,Audio process,SI\\-SDRi
1,1,Speech Separation,wsj0-2mix,2018-04,Chimera++,11.5,61.17,0.7,0.04,18.8,0.61,ito:ITO_00145,Audio process,SI\\-SDRi
2,1,Speech Separation,wsj0-2mix,2018-09,TasNet v2,13.2,70.21,1.7,0.09,18.8,0.7,ito:ITO_00145,Audio process,SI\\-SDRi
3,1,Speech Separation,wsj0-2mix,2018-09,Conv-TasNet,15.3,81.38,2.1,0.11,18.8,0.81,ito:ITO_00145,Audio process,SI\\-SDRi
4,1,Speech Separation,wsj0-2mix,2019-04,DeepCASA,17.7,94.15,2.4,0.13,18.8,0.94,ito:ITO_00145,Audio process,SI\\-SDRi
5,1,Speech Separation,wsj0-2mix,2019-10,Dual-path RNN,18.8,100.0,1.1,0.06,18.8,1.0,ito:ITO_00145,Audio process,SI\\-SDRi
0,1,Speech Separation,wsj0-2mix,2015-08,Deep Clustering ++,10.8,52.94,10.8,0.53,20.4,0.53,ito:ITO_00145,Audio process,SI\\-SDR
1,1,Speech Separation,wsj0-2mix,2018-04,Chimera++,11.5,56.37,0.7,0.03,20.4,0.56,ito:ITO_00145,Audio process,SI\\-SDR
2,1,Speech Separation,wsj0-2mix,2018-09,TasNet v2,13.2,64.71,1.7,0.08,20.4,0.65,ito:ITO_00145,Audio process,SI\\-SDR
3,1,Speech Separation,wsj0-2mix,2018-09,Conv-TasNet,15.3,75.0,2.1,0.1,20.4,0.75,ito:ITO_00145,Audio process,SI\\-SDR
4,1,Speech Separation,wsj0-2mix,2019-04,DeepCASA,17.7,86.76,2.4,0.12,20.4,0.87,ito:ITO_00145,Audio process,SI\\-SDR
5,1,Speech Separation,wsj0-2mix,2019-10,Dual-path RNN,18.8,92.16,1.1,0.05,20.4,0.92,ito:ITO_00145,Audio process,SI\\-SDR
6,1,Speech Separation,wsj0-2mix,2020-02,Wavesplit,20.4,100.0,1.6,0.08,20.4,1.0,ito:ITO_00145,Audio process,SI\\-SDR
0,1,Conditional Image Generation,CIFAR-10,2015-11,DCGAN,6.58,68.68,6.58,0.69,9.58,0.04,ito:ITO_00145,Audio process,Inception\\ score
1,1,Conditional Image Generation,CIFAR-10,2016-06,Improved GAN,8.09,84.45,1.5,0.16,9.58,0.05,ito:ITO_00145,Audio process,Inception\\ score
2,1,Conditional Image Generation,CIFAR-10,2016-10,AC-GAN,8.25,86.12,0.2,0.02,9.58,0.05,ito:ITO_00145,Audio process,Inception\\ score
3,1,Conditional Image Generation,CIFAR-10,2016-12,SGAN,8.59,89.67,0.3,0.03,9.58,0.05,ito:ITO_00145,Audio process,Inception\\ score
4,1,Conditional Image Generation,CIFAR-10,2017-03,WGAN-GP,8.67,90.5,0.1,0.01,9.58,0.05,ito:ITO_00145,Audio process,Inception\\ score
5,1,Conditional Image Generation,CIFAR-10,2017-09,Splitting GAN,8.87,92.59,0.2,0.02,9.58,0.05,ito:ITO_00145,Audio process,Inception\\ score
6,1,Conditional Image Generation,CIFAR-10,2018-09,BigGAN,9.22,96.24,0.4,0.04,9.58,0.06,ito:ITO_00145,Audio process,Inception\\ score
7,1,Conditional Image Generation,CIFAR-10,2019-12,MHingeGAN,9.58,100.0,0.4,0.04,9.58,0.06,ito:ITO_00145,Audio process,Inception\\ score
8,1,Image Generation,CIFAR-10,2016-06,ALI,5.34,57.92,5.34,0.58,9.22,0.03,ito:ITO_00145,Audio process,Inception\\ score
9,1,Image Generation,CIFAR-10,2016-06,Improved GAN,6.86,74.4,1.5,0.16,9.22,0.04,ito:ITO_00145,Audio process,Inception\\ score
10,1,Image Generation,CIFAR-10,2017-02,CEGAN-Ent-VI,7.07,76.68,0.2,0.02,9.22,0.04,ito:ITO_00145,Audio process,Inception\\ score
11,1,Image Generation,CIFAR-10,2017-03,LR-GAN,7.17,77.77,0.1,0.01,9.22,0.04,ito:ITO_00145,Audio process,Inception\\ score
12,1,Image Generation,CIFAR-10,2017-03,WGAN-GP,7.86,85.25,0.7,0.08,9.22,0.05,ito:ITO_00145,Audio process,Inception\\ score
13,1,Image Generation,CIFAR-10,2017-09,Splitting GAN,7.9,85.68,0.0,0.0,9.22,0.05,ito:ITO_00145,Audio process,Inception\\ score
14,1,Image Generation,CIFAR-10,2017-10,PGGAN,8.8,95.44,0.9,0.1,9.22,0.05,ito:ITO_00145,Audio process,Inception\\ score
15,1,Image Generation,CIFAR-10,2018-09,BigGAN,9.22,100.0,0.4,0.04,9.22,0.06,ito:ITO_00145,Audio process,Inception\\ score
16,1,Image Generation,Stanford Dogs,2016-06,InfoGAN,43.16,91.99,43.16,0.92,46.92,0.26,ito:ITO_00145,Audio process,Inception\\ score
17,1,Image Generation,Stanford Dogs,2018-11,FineGAN,46.92,100.0,3.8,0.08,46.92,0.28,ito:ITO_00145,Audio process,Inception\\ score
18,1,Image Generation,Stanford Cars,2016-06,InfoGAN,28.62,87.74,28.62,0.88,32.62,0.17,ito:ITO_00145,Audio process,Inception\\ score
19,1,Image Generation,Stanford Cars,2018-11,FineGAN,32.62,100.0,4.0,0.12,32.62,0.2,ito:ITO_00145,Audio process,Inception\\ score
20,1,Image Generation,CUB 128 x 128,2016-06,InfoGAN,47.32,90.08,47.32,0.9,52.53,0.28,ito:ITO_00145,Audio process,Inception\\ score
21,1,Image Generation,CUB 128 x 128,2018-11,FineGAN,52.53,100.0,5.2,0.1,52.53,0.32,ito:ITO_00145,Audio process,Inception\\ score
22,1,Text-to-Image Generation,CUB,2016-10,GAWWN,3.62,76.21,3.62,0.76,4.75,0.02,ito:ITO_00145,Audio process,Inception\\ score
23,1,Text-to-Image Generation,CUB,2016-12,StackGAN,3.7,77.89,0.1,0.02,4.75,0.02,ito:ITO_00145,Audio process,Inception\\ score
24,1,Text-to-Image Generation,CUB,2017-10,StackGAN-v2,3.82,80.42,0.1,0.02,4.75,0.02,ito:ITO_00145,Audio process,Inception\\ score
25,1,Text-to-Image Generation,CUB,2017-11,AttnGAN,4.36,91.79,0.5,0.11,4.75,0.03,ito:ITO_00145,Audio process,Inception\\ score
26,1,Text-to-Image Generation,CUB,2019-03,MirrorGAN,4.56,96.0,0.2,0.04,4.75,0.03,ito:ITO_00145,Audio process,Inception\\ score
27,1,Text-to-Image Generation,CUB,2019-04,DM-GAN,4.75,100.0,0.2,0.04,4.75,0.03,ito:ITO_00145,Audio process,Inception\\ score
28,1,Conditional Image Generation,ImageNet 128x128,2016-10,AC-GAN,28.5,17.12,28.5,0.17,166.5,0.17,ito:ITO_00145,Audio process,Inception\\ score
29,1,Conditional Image Generation,ImageNet 128x128,2018-02,Projection Discriminator,36.8,22.1,8.3,0.05,166.5,0.22,ito:ITO_00145,Audio process,Inception\\ score
30,1,Conditional Image Generation,ImageNet 128x128,2018-05,SAGAN,52.52,31.54,15.7,0.09,166.5,0.32,ito:ITO_00145,Audio process,Inception\\ score
31,1,Conditional Image Generation,ImageNet 128x128,2018-09,BigGAN-deep,124.5,74.77,72.0,0.43,166.5,0.75,ito:ITO_00145,Audio process,Inception\\ score
32,1,Conditional Image Generation,ImageNet 128x128,2018-09,BigGAN-deep,166.5,100.0,42.0,0.25,166.5,1.0,ito:ITO_00145,Audio process,Inception\\ score
33,1,Text-to-Image Generation,COCO,2016-12,StackGAN,8.45,16.03,8.45,0.16,52.73,0.05,ito:ITO_00145,Audio process,Inception\\ score
34,1,Text-to-Image Generation,COCO,2017-11,AttnGAN,25.89,49.1,17.4,0.33,52.73,0.16,ito:ITO_00145,Audio process,Inception\\ score
35,1,Text-to-Image Generation,COCO,2019-03,MirrorGAN,26.47,50.2,0.6,0.01,52.73,0.16,ito:ITO_00145,Audio process,Inception\\ score
36,1,Text-to-Image Generation,COCO,2019-04,DM-GAN,30.49,57.82,4.0,0.08,52.73,0.18,ito:ITO_00145,Audio process,Inception\\ score
37,1,Text-to-Image Generation,COCO,2019-12,CPGAN,52.73,100.0,22.2,0.42,52.73,0.32,ito:ITO_00145,Audio process,Inception\\ score
38,1,Text-to-Image Generation,Oxford 102 Flowers,2016-12,StackGAN,3.2,98.16,3.2,0.98,3.26,0.02,ito:ITO_00145,Audio process,Inception\\ score
39,1,Text-to-Image Generation,Oxford 102 Flowers,2017-10,StackGAN-v2,3.26,100.0,0.1,0.03,3.26,0.02,ito:ITO_00145,Audio process,Inception\\ score
40,1,Image Generation,STL-10,2017-09,D2GAN,7.98,85.44,7.98,0.85,9.34,0.05,ito:ITO_00145,Audio process,Inception\\ score
41,1,Image Generation,STL-10,2018-02,SN-GAN,9.1,97.43,1.1,0.12,9.34,0.05,ito:ITO_00145,Audio process,Inception\\ score
42,1,Image Generation,STL-10,2018-12,Improving MMD GAN,9.34,100.0,0.2,0.02,9.34,0.06,ito:ITO_00145,Audio process,Inception\\ score
0,1,Image Generation,Binarized MNIST,2016-01,PixelCNN,81.3,100.0,81.3,1.0,81.3,1.0,ito:ITO_00145,Audio process,nats
0,1,Image Generation,ImageNet 32x32,2016-01,PixelRNN,3.86,90.19,3.86,0.9,4.28,0.9,ito:ITO_00145,Audio process,bpd
1,1,Image Generation,ImageNet 32x32,2016-05,"Real NVP (Dinh et al., 2017)",4.28,100.0,0.4,0.09,4.28,1.0,ito:ITO_00145,Audio process,bpd
2,1,Image Generation,CelebA 256x256,2018-07,"Glow (Kingma and Dhariwal, 2018)",1.03,100.0,1.03,1.0,1.03,0.24,ito:ITO_00145,Audio process,bpd
3,1,Image Generation,MNIST,2018-11,i-ResNet,1.06,100.0,1.06,1.0,1.06,0.25,ito:ITO_00145,Audio process,bpd
4,1,Image Generation,ImageNet 64x64,2019-02,Flow++,3.69,98.4,3.69,0.98,3.75,0.86,ito:ITO_00145,Audio process,bpd
5,1,Image Generation,ImageNet 64x64,2019-02,MaCow (Unf),3.75,100.0,0.1,0.03,3.75,0.88,ito:ITO_00145,Audio process,bpd
0,1,Visual Dialog,VisDial v0.9 val,2016-05,HieCoAtt-QI,57.88,83.98,57.88,0.84,68.92,0.84,ito:ITO_00145,Audio process,MRR
1,1,Visual Dialog,VisDial v0.9 val,2017-09,AMEM Seo et al. (2017),62.27,90.35,4.4,0.06,68.92,0.9,ito:ITO_00145,Audio process,MRR
2,1,Visual Dialog,VisDial v0.9 val,2017-11,CoAtt Wu et al. (2018),63.98,92.83,1.7,0.02,68.92,0.92,ito:ITO_00145,Audio process,MRR
3,1,Visual Dialog,VisDial v0.9 val,2018-09,CorefNMN (ResNet-152),64.1,93.01,0.1,0.0,68.92,0.92,ito:ITO_00145,Audio process,MRR
4,1,Visual Dialog,VisDial v0.9 val,2019-02,DAN,66.38,96.31,2.3,0.03,68.92,0.96,ito:ITO_00145,Audio process,MRR
5,1,Visual Dialog,VisDial v0.9 val,2019-04,9xFGA (VGG),68.92,100.0,2.5,0.04,68.92,0.99,ito:ITO_00145,Audio process,MRR
6,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),61.5,88.74,61.5,0.89,69.3,0.89,ito:ITO_00145,Audio process,MRR
7,1,Visual Dialog,VisDial v1.0 test-std,2019-02,DAN,63.2,91.2,1.7,0.02,69.3,0.91,ito:ITO_00145,Audio process,MRR
8,1,Visual Dialog,VisDial v1.0 test-std,2019-04,5xFGA (F-RCNNx101),69.3,100.0,6.1,0.09,69.3,1.0,ito:ITO_00145,Audio process,MRR
9,1,Visual Dialog,Visual Dialog v1.0,2019-02,HACAN,64.22,99.04,64.22,0.99,64.84,0.93,ito:ITO_00145,Audio process,MRR
10,1,Visual Dialog,Visual Dialog v1.0,2020-04,MVAN,64.84,100.0,0.6,0.01,64.84,0.94,ito:ITO_00145,Audio process,MRR
0,1,Visual Dialog,VisDial v0.9 val,2016-05,HieCoAtt-QI,74.49,86.36,74.49,0.86,86.26,0.86,ito:ITO_00145,Audio process,R\\-at\\-5
1,1,Visual Dialog,VisDial v0.9 val,2017-09,AMEM Seo et al. (2017),78.66,91.19,4.2,0.05,86.26,0.91,ito:ITO_00145,Audio process,R\\-at\\-5
2,1,Visual Dialog,VisDial v0.9 val,2017-11,CoAtt Wu et al. (2018),80.71,93.57,2.0,0.02,86.26,0.93,ito:ITO_00145,Audio process,R\\-at\\-5
3,1,Visual Dialog,VisDial v0.9 val,2019-02,DAN,82.42,95.55,1.7,0.02,86.26,0.95,ito:ITO_00145,Audio process,R\\-at\\-5
4,1,Visual Dialog,VisDial v0.9 val,2019-02,HACAN,83.03,96.26,0.6,0.01,86.26,0.96,ito:ITO_00145,Audio process,R\\-at\\-5
5,1,Visual Dialog,VisDial v0.9 val,2019-04,9xFGA (VGG),86.26,100.0,3.2,0.04,86.26,0.99,ito:ITO_00145,Audio process,R\\-at\\-5
6,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,76.88,88.64,76.88,0.89,86.73,0.89,ito:ITO_00145,Audio process,R\\-at\\-5
7,1,Visual Dialog,Visual Dialog v1.0 test-std,2018-09,CorefNMN (ResNet-152),78.1,90.05,1.2,0.01,86.73,0.9,ito:ITO_00145,Audio process,R\\-at\\-5
8,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,DAN,79.75,91.95,1.7,0.02,86.73,0.92,ito:ITO_00145,Audio process,R\\-at\\-5
9,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,HACAN,80.63,92.97,0.9,0.01,86.73,0.93,ito:ITO_00145,Audio process,R\\-at\\-5
10,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-04,5xFGA (F-RCNNx101),86.73,100.0,6.1,0.07,86.73,1.0,ito:ITO_00145,Audio process,R\\-at\\-5
11,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),78.1,90.05,78.1,0.9,86.73,0.9,ito:ITO_00145,Audio process,R\\-at\\-5
12,1,Visual Dialog,VisDial v1.0 test-std,2019-02,DAN,79.75,91.95,1.7,0.02,86.73,0.92,ito:ITO_00145,Audio process,R\\-at\\-5
13,1,Visual Dialog,VisDial v1.0 test-std,2019-04,5xFGA (F-RCNNx101),86.73,100.0,7.0,0.08,86.73,1.0,ito:ITO_00145,Audio process,R\\-at\\-5
0,1,Visual Dialog,VisDial v0.9 val,2016-05,HieCoAtt-QI,43.51,78.88,43.51,0.79,55.16,0.78,ito:ITO_00145,Audio process,R\\-at\\-1
1,1,Visual Dialog,VisDial v0.9 val,2017-09,AMEM Seo et al. (2017),48.53,87.98,5.0,0.09,55.16,0.87,ito:ITO_00145,Audio process,R\\-at\\-1
2,1,Visual Dialog,VisDial v0.9 val,2017-11,CoAtt Wu et al. (2018),50.29,91.17,1.8,0.03,55.16,0.9,ito:ITO_00145,Audio process,R\\-at\\-1
3,1,Visual Dialog,VisDial v0.9 val,2018-09,CorefNMN (ResNet-152),50.92,92.31,0.6,0.01,55.16,0.92,ito:ITO_00145,Audio process,R\\-at\\-1
4,1,Visual Dialog,VisDial v0.9 val,2019-02,DAN,53.33,96.68,2.4,0.04,55.16,0.96,ito:ITO_00145,Audio process,R\\-at\\-1
5,1,Visual Dialog,VisDial v0.9 val,2019-02,HACAN,54.76,99.27,1.4,0.03,55.16,0.98,ito:ITO_00145,Audio process,R\\-at\\-1
6,1,Visual Dialog,VisDial v0.9 val,2019-04,9xFGA (VGG),55.16,100.0,0.4,0.01,55.16,0.99,ito:ITO_00145,Audio process,R\\-at\\-1
7,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,44.15,79.34,44.15,0.79,55.65,0.79,ito:ITO_00145,Audio process,R\\-at\\-1
8,1,Visual Dialog,Visual Dialog v1.0 test-std,2018-09,CorefNMN (ResNet-152),47.55,85.44,3.4,0.06,55.65,0.85,ito:ITO_00145,Audio process,R\\-at\\-1
9,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,DAN,49.63,89.18,2.1,0.04,55.65,0.89,ito:ITO_00145,Audio process,R\\-at\\-1
10,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,HACAN,50.88,91.43,1.2,0.02,55.65,0.91,ito:ITO_00145,Audio process,R\\-at\\-1
11,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-04,5xFGA (F-RCNNx101),55.65,100.0,4.8,0.09,55.65,1.0,ito:ITO_00145,Audio process,R\\-at\\-1
12,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),47.55,85.44,47.55,0.85,55.65,0.85,ito:ITO_00145,Audio process,R\\-at\\-1
13,1,Visual Dialog,VisDial v1.0 test-std,2019-02,DAN,49.63,89.18,2.1,0.04,55.65,0.89,ito:ITO_00145,Audio process,R\\-at\\-1
14,1,Visual Dialog,VisDial v1.0 test-std,2019-04,5xFGA (F-RCNNx101),55.65,100.0,6.0,0.11,55.65,1.0,ito:ITO_00145,Audio process,R\\-at\\-1
0,1,Visual Dialog,VisDial v0.9 val,2016-05,HieCoAtt-QI,83.96,90.33,83.96,0.9,92.95,0.89,ito:ITO_00145,Audio process,R\\-at\\-10
1,1,Visual Dialog,VisDial v0.9 val,2017-09,AMEM Seo et al. (2017),87.43,94.06,3.5,0.04,92.95,0.93,ito:ITO_00145,Audio process,R\\-at\\-10
2,1,Visual Dialog,VisDial v0.9 val,2017-11,CoAtt Wu et al. (2018),88.81,95.55,1.4,0.02,92.95,0.94,ito:ITO_00145,Audio process,R\\-at\\-10
3,1,Visual Dialog,VisDial v0.9 val,2019-02,DAN,90.38,97.24,1.6,0.02,92.95,0.96,ito:ITO_00145,Audio process,R\\-at\\-10
4,1,Visual Dialog,VisDial v0.9 val,2019-02,HACAN,90.68,97.56,0.3,0.0,92.95,0.96,ito:ITO_00145,Audio process,R\\-at\\-10
5,1,Visual Dialog,VisDial v0.9 val,2019-04,9xFGA (VGG),92.95,100.0,2.3,0.02,92.95,0.99,ito:ITO_00145,Audio process,R\\-at\\-10
6,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,86.88,92.38,86.88,0.92,94.05,0.92,ito:ITO_00145,Audio process,R\\-at\\-10
7,1,Visual Dialog,Visual Dialog v1.0 test-std,2018-09,CorefNMN (ResNet-152),88.8,94.42,1.9,0.02,94.05,0.94,ito:ITO_00145,Audio process,R\\-at\\-10
8,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,DAN,89.35,95.0,0.5,0.01,94.05,0.95,ito:ITO_00145,Audio process,R\\-at\\-10
9,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,HACAN,89.45,95.11,0.1,0.0,94.05,0.95,ito:ITO_00145,Audio process,R\\-at\\-10
10,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-04,5xFGA (F-RCNNx101),94.05,100.0,4.6,0.05,94.05,1.0,ito:ITO_00145,Audio process,R\\-at\\-10
11,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),88.8,94.42,88.8,0.94,94.05,0.94,ito:ITO_00145,Audio process,R\\-at\\-10
12,1,Visual Dialog,VisDial v1.0 test-std,2019-02,DAN,89.35,95.0,0.5,0.01,94.05,0.95,ito:ITO_00145,Audio process,R\\-at\\-10
13,1,Visual Dialog,VisDial v1.0 test-std,2019-04,5xFGA (F-RCNNx101),94.05,100.0,4.7,0.05,94.05,1.0,ito:ITO_00145,Audio process,R\\-at\\-10
0,1,Visual Dialog,VisDial v0.9 val,2016-05,HieCoAtt-QI,5.84,100.0,5.84,1.0,5.84,1.0,ito:ITO_00145,Audio process,Mean\\ Rank
1,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),4.4,100.0,4.4,1.0,4.4,0.75,ito:ITO_00145,Audio process,Mean\\ Rank
2,1,Visual Dialog,Visual Dialog v1.0,2019-02,HACAN,4.2,97.67,4.2,0.98,4.3,0.72,ito:ITO_00145,Audio process,Mean\\ Rank
3,1,Visual Dialog,Visual Dialog v1.0,2019-02,DAN,4.3,100.0,0.1,0.02,4.3,0.74,ito:ITO_00145,Audio process,Mean\\ Rank
0,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-06,BiGAN,0.07,21.88,0.07,0.22,0.32,0.22,ito:ITO_00145,Audio process,Class\\ IOU
1,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-06,CoGAN,0.08,25.0,0.0,0.0,0.32,0.25,ito:ITO_00145,Audio process,Class\\ IOU
2,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-11,pix2pix,0.32,100.0,0.2,0.62,0.32,1.0,ito:ITO_00145,Audio process,Class\\ IOU
3,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,BiGAN,0.02,11.11,0.02,0.11,0.18,0.06,ito:ITO_00145,Audio process,Class\\ IOU
4,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,CoGAN,0.06,33.33,0.0,0.0,0.18,0.19,ito:ITO_00145,Audio process,Class\\ IOU
5,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-11,pix2pix,0.18,100.0,0.1,0.56,0.18,0.56,ito:ITO_00145,Audio process,Class\\ IOU
6,1,Image-to-Image Translation,Aerial-to-Map,2016-11,cGAN,0.26,100.0,0.26,1.0,0.26,0.81,ito:ITO_00145,Audio process,Class\\ IOU
0,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-06,BiGAN,13.0,32.5,13,0.32,40,0.28,ito:ITO_00145,Audio process,Per\\-class\\ Accuracy
1,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-11,pix2pix,40.0,100.0,27,0.68,40,0.87,ito:ITO_00145,Audio process,Per\\-class\\ Accuracy
2,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,BiGAN,6.0,24.0,6,0.24,25,0.13,ito:ITO_00145,Audio process,Per\\-class\\ Accuracy
3,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,CoGAN,10.0,40.0,4,0.16,25,0.22,ito:ITO_00145,Audio process,Per\\-class\\ Accuracy
4,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-11,pix2pix,25.0,100.0,15,0.6,25,0.54,ito:ITO_00145,Audio process,Per\\-class\\ Accuracy
5,1,Image-to-Image Translation,Aerial-to-Map,2016-11,cGAN,46.0,100.0,46,1.0,46,1.0,ito:ITO_00145,Audio process,Per\\-class\\ Accuracy
0,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,BiGAN,19.0,23.09,19.0,0.23,82.3,0.21,ito:ITO_00145,Audio process,Per\\-pixel\\ Accuracy
1,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,CoGAN,40.0,48.6,21.0,0.26,82.3,0.43,ito:ITO_00145,Audio process,Per\\-pixel\\ Accuracy
2,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-11,pix2pix,71.0,86.27,31.0,0.38,82.3,0.77,ito:ITO_00145,Audio process,Per\\-pixel\\ Accuracy
3,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2017-07,CRN,77.1,93.68,6.1,0.07,82.3,0.84,ito:ITO_00145,Audio process,Per\\-pixel\\ Accuracy
4,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2017-11,pix2pixHD,81.4,98.91,4.3,0.05,82.3,0.88,ito:ITO_00145,Audio process,Per\\-pixel\\ Accuracy
5,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2019-03,SPADE,81.9,99.51,0.5,0.01,82.3,0.89,ito:ITO_00145,Audio process,Per\\-pixel\\ Accuracy
6,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2019-10,CC-FPSE,82.3,100.0,0.4,0.0,82.3,0.89,ito:ITO_00145,Audio process,Per\\-pixel\\ Accuracy
7,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-06,BiGAN,41.0,48.24,41,0.48,85,0.45,ito:ITO_00145,Audio process,Per\\-pixel\\ Accuracy
8,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-06,CoGAN,45.0,52.94,4,0.05,85,0.49,ito:ITO_00145,Audio process,Per\\-pixel\\ Accuracy
9,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-11,pix2pix,85.0,100.0,40,0.47,85,0.92,ito:ITO_00145,Audio process,Per\\-pixel\\ Accuracy
10,1,Image-to-Image Translation,Aerial-to-Map,2016-11,cGAN,70.0,100.0,70,1.0,70,0.76,ito:ITO_00145,Audio process,Per\\-pixel\\ Accuracy
11,1,Image-to-Image Translation,SYNTHIA Fall-to-Winter,2017-11,CyCADA,92.1,100.0,92.1,1.0,92.1,1.0,ito:ITO_00145,Audio process,Per\\-pixel\\ Accuracy
12,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2017-11,CyCADA pixel+feat,82.3,100.0,82.3,1.0,82.3,0.89,ito:ITO_00145,Audio process,Per\\-pixel\\ Accuracy
0,1,Dialog State Tracking,Wizard-of-Oz,2016-06,Neural belief tracker,84.4,94.94,84.4,0.95,88.9,0.95,ito:ITO_00145,Audio process,Joint
1,1,Dialog State Tracking,Wizard-of-Oz,2018-05,Zhong et al.,88.1,99.1,3.7,0.04,88.9,0.99,ito:ITO_00145,Audio process,Joint
2,1,Dialog State Tracking,Wizard-of-Oz,2018-10,StateNet,88.9,100.0,0.8,0.01,88.9,1.0,ito:ITO_00145,Audio process,Joint
3,1,Dialog State Tracking,Second dialogue state tracking challenge,2016-06,Neural belief tracker,73.4,97.22,73.4,0.97,75.5,0.83,ito:ITO_00145,Audio process,Joint
4,1,Dialog State Tracking,Second dialogue state tracking challenge,2018-05,Zhong et al.,74.5,98.68,1.1,0.01,75.5,0.84,ito:ITO_00145,Audio process,Joint
5,1,Dialog State Tracking,Second dialogue state tracking challenge,2018-10,StateNet,75.5,100.0,1.0,0.01,75.5,0.85,ito:ITO_00145,Audio process,Joint
0,1,Dialog State Tracking,Second dialogue state tracking challenge,2016-06,Neural belief tracker,90.0,100.0,90,1.0,90,1.0,ito:ITO_00145,Audio process,Area
0,1,Dialog State Tracking,Second dialogue state tracking challenge,2016-06,Neural belief tracker,84.0,100.0,84,1.0,84,1.0,ito:ITO_00145,Audio process,Food
0,1,Dialog State Tracking,Second dialogue state tracking challenge,2016-06,Neural belief tracker,94.0,100.0,94,1.0,94,1.0,ito:ITO_00145,Audio process,Price
0,1,Dialog State Tracking,Wizard-of-Oz,2016-06,Neural belief tracker,96.5,99.38,96.5,0.99,97.1,0.99,ito:ITO_00145,Audio process,Request
1,1,Dialog State Tracking,Wizard-of-Oz,2018-05,Zhong et al.,97.1,100.0,0.6,0.01,97.1,1.0,ito:ITO_00145,Audio process,Request
2,1,Dialog State Tracking,Second dialogue state tracking challenge,2016-06,Neural belief tracker,96.5,98.97,96.5,0.99,97.5,0.99,ito:ITO_00145,Audio process,Request
3,1,Dialog State Tracking,Second dialogue state tracking challenge,2018-05,Zhong et al.,97.5,100.0,1.0,0.01,97.5,1.0,ito:ITO_00145,Audio process,Request
0,1,Image Generation,CUB 128 x 128,2016-06,InfoGAN,13.2,37.81,13.2,0.38,34.91,0.08,ito:ITO_00145,Audio process,FID
1,1,Image Generation,CUB 128 x 128,2017-03,LR-GAN,34.91,100.0,21.7,0.62,34.91,0.22,ito:ITO_00145,Audio process,FID
2,1,Image Generation,Stanford Cars,2016-06,InfoGAN,17.63,19.85,17.63,0.2,88.8,0.11,ito:ITO_00145,Audio process,FID
3,1,Image Generation,Stanford Cars,2017-03,LR-GAN,88.8,100.0,71.2,0.8,88.8,0.57,ito:ITO_00145,Audio process,FID
4,1,Image Generation,Stanford Dogs,2016-06,InfoGAN,29.34,53.43,29.34,0.53,54.91,0.19,ito:ITO_00145,Audio process,FID
5,1,Image Generation,Stanford Dogs,2017-03,LR-GAN,54.91,100.0,25.6,0.47,54.91,0.35,ito:ITO_00145,Audio process,FID
6,1,Text-to-Image Generation,CUB,2016-10,GAWWN,67.22,100.0,67.22,1.0,67.22,0.43,ito:ITO_00145,Audio process,FID
7,1,Fundus to Angiography Generation,Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients,2016-11,pix2pix,48.6,100.0,48.6,1.0,48.6,0.31,ito:ITO_00145,Audio process,FID
8,1,Image Generation,CIFAR-10,2017-03,WGAN-GP,29.3,56.13,29.3,0.56,52.202,0.19,ito:ITO_00145,Audio process,FID
9,1,Image Generation,CIFAR-10,2019-05,GLF+perceptual loss (ours),44.6,85.44,15.3,0.29,52.202,0.29,ito:ITO_00145,Audio process,FID
10,1,Image Generation,CIFAR-10,2019-06,Residual Flow,46.37,88.83,1.8,0.03,52.202,0.3,ito:ITO_00145,Audio process,FID
11,1,Image Generation,CIFAR-10,2019-10,PresGAN,52.202,100.0,5.8,0.11,52.202,0.34,ito:ITO_00145,Audio process,FID
12,1,Image Generation,CAT 256x256,2017-03,WGAN-GP,155.46,100.0,155.46,1.0,155.46,1.0,ito:ITO_00145,Audio process,FID
13,1,Image Generation,LSUN Bedroom 64 x 64,2017-06,WGAN-GP + TT Update Rule,9.5,83.33,9.5,0.83,11.4,0.06,ito:ITO_00145,Audio process,FID
14,1,Image Generation,LSUN Bedroom 64 x 64,2018-02,FOGAN,11.4,100.0,1.9,0.17,11.4,0.07,ito:ITO_00145,Audio process,FID
15,1,Image Generation,LSUN Bedroom 256 x 256,2017-06,WGAN-GP + TT Update Rule,9.5,26.68,9.5,0.27,35.61,0.06,ito:ITO_00145,Audio process,FID
16,1,Image Generation,LSUN Bedroom 256 x 256,2017-10,StackGAN-v2,35.61,100.0,26.1,0.73,35.61,0.23,ito:ITO_00145,Audio process,FID
17,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2017-07,CRN,70.4,63.14,70.4,0.63,111.5,0.45,ito:ITO_00145,Audio process,FID
18,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2017-11,pix2pixHD,111.5,100.0,41.1,0.37,111.5,0.72,ito:ITO_00145,Audio process,FID
19,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2017-07,CRN,99.0,100.0,99.0,1.0,99.0,0.64,ito:ITO_00145,Audio process,FID
20,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2017-07,CRN,104.7,100.0,104.7,1.0,104.7,0.67,ito:ITO_00145,Audio process,FID
21,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2017-07,CRN,73.3,89.61,73.3,0.9,81.8,0.47,ito:ITO_00145,Audio process,FID
22,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2017-11,pix2pixHD,81.8,100.0,8.5,0.1,81.8,0.53,ito:ITO_00145,Audio process,FID
23,1,Text-to-Image Generation,COCO,2017-10,StackGAN-v1 ,74.05,90.76,74.05,0.91,81.59,0.48,ito:ITO_00145,Audio process,FID
24,1,Text-to-Image Generation,COCO,2017-10,StackGAN-v2,81.59,100.0,7.5,0.09,81.59,0.52,ito:ITO_00145,Audio process,FID
25,1,Text-to-Image Generation,Oxford 102 Flowers,2017-10,StackGAN-v2,48.68,88.06,48.68,0.88,55.28,0.31,ito:ITO_00145,Audio process,FID
26,1,Text-to-Image Generation,Oxford 102 Flowers,2017-10,StackGAN-v1 ,55.28,100.0,6.6,0.12,55.28,0.36,ito:ITO_00145,Audio process,FID
27,1,Image Generation,FFHQ,2017-10,PGGAN,8.04,100.0,8.04,1.0,8.04,0.05,ito:ITO_00145,Audio process,FID
28,1,Image Generation,CelebA-HQ 1024x1024,2017-10,PGGAN,7.3,76.92,7.3,0.77,9.49,0.05,ito:ITO_00145,Audio process,FID
29,1,Image Generation,CelebA-HQ 1024x1024,2019-03,COCO-GAN,9.49,100.0,2.2,0.23,9.49,0.06,ito:ITO_00145,Audio process,FID
30,1,Image Generation,LSUN Cat 256 x 256,2017-10,PGGAN,37.52,100.0,37.52,1.0,37.52,0.24,ito:ITO_00145,Audio process,FID
31,1,Image Generation,LSUN Churches 256 x 256,2017-10,PGGAN,6.42,100.0,6.42,1.0,6.42,0.04,ito:ITO_00145,Audio process,FID
32,1,Image Generation,CelebA-HQ 256x256,2017-10,PGGAN,8.03,11.65,8.03,0.12,68.93,0.05,ito:ITO_00145,Audio process,FID
33,1,Image Generation,CelebA-HQ 256x256,2018-07,GLOW,68.93,100.0,60.9,0.88,68.93,0.44,ito:ITO_00145,Audio process,FID
34,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2017-11,AttnGAN,125.98,96.13,125.98,0.96,131.05,0.81,ito:ITO_00145,Audio process,FID
35,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2019-04,DM-GAN,131.05,100.0,5.1,0.04,131.05,0.84,ito:ITO_00145,Audio process,FID
36,1,Conditional Image Generation,ImageNet 128x128,2018-02,Projection Discriminator,27.62,100.0,27.62,1.0,27.62,0.18,ito:ITO_00145,Audio process,FID
37,1,Conditional Image Generation,CIFAR-10,2018-02,Projection Discriminator,17.5,100.0,17.5,1.0,17.5,0.11,ito:ITO_00145,Audio process,FID
38,1,Image Generation,STL-10,2018-02,SN-GAN,40.1,85.79,40.1,0.86,46.74,0.26,ito:ITO_00145,Audio process,FID
39,1,Image Generation,STL-10,2019-05,ProbGAN,46.74,100.0,6.6,0.14,46.74,0.3,ito:ITO_00145,Audio process,FID
40,1,Layout-to-Image Generation,COCO-Stuff 64x64,2018-04,SG2Im,67.96,100.0,67.96,1.0,67.96,0.44,ito:ITO_00145,Audio process,FID
41,1,Layout-to-Image Generation,Visual Genome 64x64,2018-04,SG2Im,74.61,100.0,74.61,1.0,74.61,0.48,ito:ITO_00145,Audio process,FID
42,1,Multimodal Unsupervised Image-To-Image Translation,AFHQ,2018-04,MUNIT,41.5,43.41,41.5,0.43,95.6,0.27,ito:ITO_00145,Audio process,FID
43,1,Multimodal Unsupervised Image-To-Image Translation,AFHQ,2018-08,DRIT,95.6,100.0,54.1,0.57,95.6,0.61,ito:ITO_00145,Audio process,FID
44,1,Multimodal Unsupervised Image-To-Image Translation,CelebA-HQ,2018-04,MUNIT,31.4,60.27,31.4,0.6,52.1,0.2,ito:ITO_00145,Audio process,FID
45,1,Multimodal Unsupervised Image-To-Image Translation,CelebA-HQ,2018-08,DRIT,52.1,100.0,20.7,0.4,52.1,0.34,ito:ITO_00145,Audio process,FID
46,1,Image Generation,ImageNet 128x128,2018-09,BigGAN,14.88,33.92,14.88,0.34,43.87,0.1,ito:ITO_00145,Audio process,FID
47,1,Image Generation,ImageNet 128x128,2018-11,SS-GAN (sBN),43.87,100.0,29.0,0.66,43.87,0.28,ito:ITO_00145,Audio process,FID
48,1,Image Generation,ImageNet 256x256,2018-09,BigGAN-deep,8.1,100.0,8.1,1.0,8.1,0.05,ito:ITO_00145,Audio process,FID
49,1,Image Generation,CelebA-HQ 128x128,2018-11,SS-GAN (sBN),24.36,100.0,24.36,1.0,24.36,0.16,ito:ITO_00145,Audio process,FID
50,1,Image Generation,Oxford 102 Flowers 256 x 256,2019-03,MSG-StyleGAN,19.6,100.0,19.6,1.0,19.6,0.13,ito:ITO_00145,Audio process,FID
51,1,Image Generation,Indian Celebs 256 x 256,2019-03,MSG-StyleGAN,28.44,100.0,28.44,1.0,28.44,0.18,ito:ITO_00145,Audio process,FID
52,1,Image Generation,CelebA-HQ 64x64,2019-03,COCO-GAN,4.0,100.0,4,1.0,4,0.03,ito:ITO_00145,Audio process,FID
53,1,Talking Head Generation,VoxCeleb2,2019-05,Few-shot Adversarial Model,48.5,100.0,48.5,1.0,48.5,0.31,ito:ITO_00145,Audio process,FID
54,1,Talking Head Generation,VoxCeleb1,2019-05,Few-shot Adversarial Model,29.5,100.0,29.5,1.0,29.5,0.19,ito:ITO_00145,Audio process,FID
55,1,Talking Head Generation,VoxCeleb1,2019-05,Few-shot Adversarial Model,38.0,100.0,38,1.0,38,0.24,ito:ITO_00145,Audio process,FID
56,1,Talking Head Generation,VoxCeleb2,2019-05,Few-shot Adversarial Model,30.6,100.0,30.6,1.0,30.6,0.2,ito:ITO_00145,Audio process,FID
57,1,Talking Head Generation,VoxCeleb1,2019-05,Few-shot Adversarial Model,43.0,100.0,43,1.0,43,0.28,ito:ITO_00145,Audio process,FID
58,1,Talking Head Generation,VoxCeleb2,2019-05,Few-shot Adversarial Model,42.2,100.0,42.2,1.0,42.2,0.27,ito:ITO_00145,Audio process,FID
59,1,Image Generation,MNIST,2019-05,GLF+perceptual loss (ours),5.8,13.8,5.8,0.14,42.019,0.04,ito:ITO_00145,Audio process,FID
60,1,Image Generation,MNIST,2019-10,PresGAN,42.019,100.0,36.2,0.86,42.019,0.27,ito:ITO_00145,Audio process,FID
61,1,Image Generation,Fashion-MNIST,2019-05,GLF+perceptual loss (ours),10.3,100.0,10.3,1.0,10.3,0.07,ito:ITO_00145,Audio process,FID
62,1,Image Generation,CelebA 256x256,2019-05,GLF+perceptual loss (ours),41.8,100.0,41.8,1.0,41.8,0.27,ito:ITO_00145,Audio process,FID
63,1,Image Generation,ImageNet 64x64,2019-07,BigBiGAN,15.82,100.0,15.82,1.0,15.82,0.1,ito:ITO_00145,Audio process,FID
64,1,Layout-to-Image Generation,COCO-Stuff 128x128,2019-08,LostGAN,29.65,49.83,29.65,0.5,59.5,0.19,ito:ITO_00145,Audio process,FID
65,1,Layout-to-Image Generation,COCO-Stuff 128x128,2019-09,SOARISG,59.5,100.0,29.8,0.5,59.5,0.38,ito:ITO_00145,Audio process,FID
66,1,Layout-to-Image Generation,Visual Genome 128x128,2019-08,LostGAN,29.36,100.0,29.36,1.0,29.36,0.19,ito:ITO_00145,Audio process,FID
67,1,Image Generation,CelebA 128 x 128,2019-10,PresGAN,29.115,100.0,29.115,1.0,29.115,0.19,ito:ITO_00145,Audio process,FID
68,1,Image Generation,Stacked MNIST,2019-10,PresGAN,23.965,100.0,23.965,1.0,23.965,0.15,ito:ITO_00145,Audio process,FID
69,1,Pose Transfer,Deep-Fashion,2019-10,bFT,12.266,100.0,12.266,1.0,12.266,0.08,ito:ITO_00145,Audio process,FID
70,1,Image Generation,CIFAR-100,2019-11,MSGAN,19.74,100.0,19.74,1.0,19.74,0.13,ito:ITO_00145,Audio process,FID
71,1,Image Generation,ImageNet 32x32,2019-11,MSGAN,12.3,100.0,12.3,1.0,12.3,0.08,ito:ITO_00145,Audio process,FID
72,1,Image Generation,ADE-Indoor,2019-11,SB-GAN,85.27,100.0,85.27,1.0,85.27,0.55,ito:ITO_00145,Audio process,FID
73,1,Image Generation,Cityscapes-25K 256x512,2019-11,SB-GAN,62.97,100.0,62.97,1.0,62.97,0.41,ito:ITO_00145,Audio process,FID
74,1,Image Generation,Cityscapes-5K 256x512,2019-11,SB-GAN,65.49,100.0,65.49,1.0,65.49,0.42,ito:ITO_00145,Audio process,FID
75,1,Image-to-Image Translation,ADE-Indoor Labels-to-Photo,2019-11,SB-GAN,48.15,100.0,48.15,1.0,48.15,0.31,ito:ITO_00145,Audio process,FID
76,1,Image Generation,LSUN Car 256 x 256,2019-12,StyleGAN2,2.32,100.0,2.32,1.0,2.32,0.01,ito:ITO_00145,Audio process,FID
77,1,Image Generation,LSUN Car 512 x 384,2019-12,StyleGAN2,2.32,100.0,2.32,1.0,2.32,0.01,ito:ITO_00145,Audio process,FID
78,1,Image Generation,LSUN Horse 256 x 256,2019-12,StyleGAN2,3.43,100.0,3.43,1.0,3.43,0.02,ito:ITO_00145,Audio process,FID
79,1,Image-to-Image Translation,CelebA-HQ,2019-12,StarGAN v2,18.0,100.0,18.0,1.0,18.0,0.12,ito:ITO_00145,Audio process,FID
80,1,Image-to-Image Translation,AFHQ,2019-12,StarGAN v2,24.4,100.0,24.4,1.0,24.4,0.16,ito:ITO_00145,Audio process,FID
81,1,Image-to-Image Translation,Deep-Fashion,2020-04,CoCosNet,14.4,100.0,14.4,1.0,14.4,0.09,ito:ITO_00145,Audio process,FID
0,1,Image Generation,ImageNet 64x64,2016-06,"Gated PixelCNN (van den Oord et al., [2016c])",3.57,93.7,3.57,0.94,3.81,0.94,ito:ITO_00145,Audio process,Bits\\ per\\ byte
1,1,Image Generation,ImageNet 64x64,2017-03,Parallel Multiscale,3.7,97.11,0.1,0.03,3.81,0.97,ito:ITO_00145,Audio process,Bits\\ per\\ byte
2,1,Image Generation,ImageNet 64x64,2018-07,GLOW,3.81,100.0,0.1,0.03,3.81,1.0,ito:ITO_00145,Audio process,Bits\\ per\\ byte
3,1,Audio Generation,"Classical music, 5 seconds at 12 kHz",2018-04,Sparse Transformer 152M (strided),1.97,100.0,1.97,1.0,1.97,0.52,ito:ITO_00145,Audio process,Bits\\ per\\ byte
0,1,Image Generation,ImageNet 64x64,2016-06,"Gated PixelCNN (van den Oord et al., [2016c])",3.57,93.7,3.57,0.94,3.81,0.94,ito:ITO_00145,Audio process,Bits\\ per\\ dim
1,1,Image Generation,ImageNet 64x64,2017-03,Parallel Multiscale,3.7,97.11,0.1,0.03,3.81,0.97,ito:ITO_00145,Audio process,Bits\\ per\\ dim
2,1,Image Generation,ImageNet 64x64,2018-07,"Glow (Kingma and Dhariwal, 2018)",3.81,100.0,0.1,0.03,3.81,1.0,ito:ITO_00145,Audio process,Bits\\ per\\ dim
0,1,Surgical Skills Evaluation,MISTIC-SIL,2016-06,Bidir. LSTM,19.5,100.0,19.5,1.0,19.5,1.0,ito:ITO_00145,Audio process,Edit\\ Distance
1,1,Handwritten Word Generation,Handwritten Word Generation,2016-06,Bidir. LSTM,19.5,100.0,19.5,1.0,19.5,1.0,ito:ITO_00145,Audio process,Edit\\ Distance
2,1,Surgical Skills Evaluation,JIGSAWS,2016-06,Bidir. LSTM,14.6,100.0,14.6,1.0,14.6,0.75,ito:ITO_00145,Audio process,Edit\\ Distance
3,1,Zero-Shot Text-to-Image Generation,Zero-Shot Text-to-Image Generation,2016-06,Bidir. LSTM,14.6,100.0,14.6,1.0,14.6,0.75,ito:ITO_00145,Audio process,Edit\\ Distance
0,1,Environmental Sound Classification,UrbanSound8k,2016-08,SB-CNN aug,79.0,100.0,79.0,1.0,79.0,1.0,ito:ITO_00145,Audio process,Accuracy\\ \\(10\\-fold\\)
0,1,Speech Synthesis,North American English,2016-09,HMM-driven concatenative,3.86,85.29,3.86,0.85,4.526,0.85,ito:ITO_00145,Audio process,Mean\\ Opinion\\ Score
1,1,Speech Synthesis,North American English,2016-09,WaveNet (L+F),4.21,93.02,0.4,0.09,4.526,0.93,ito:ITO_00145,Audio process,Mean\\ Opinion\\ Score
2,1,Speech Synthesis,North American English,2017-12,Tacotron 2,4.526,100.0,0.3,0.07,4.526,1.0,ito:ITO_00145,Audio process,Mean\\ Opinion\\ Score
3,1,Speech Synthesis,Mandarin Chinese,2016-09,WaveNet (L+F),4.08,100.0,4.08,1.0,4.08,0.9,ito:ITO_00145,Audio process,Mean\\ Opinion\\ Score
0,1,Image-to-Image Translation,RaFD,2016-10,DIA,4.1,50.81,4.1,0.51,8.07,0.51,ito:ITO_00145,Audio process,Classification\\ Error
1,1,Image-to-Image Translation,RaFD,2016-11,IcGAN,8.07,100.0,4.0,0.5,8.07,1.0,ito:ITO_00145,Audio process,Classification\\ Error
0,1,Cross-View Image-to-Image Translation,cvusa,2016-11,Pix2pix,0.3923,73.11,0.3923,0.73,0.5366,0.41,ito:ITO_00145,Audio process,SSIM
1,1,Cross-View Image-to-Image Translation,cvusa,2016-12,CrossNet,0.4147,77.28,0.0,0.0,0.5366,0.43,ito:ITO_00145,Audio process,SSIM
2,1,Cross-View Image-to-Image Translation,cvusa,2018-03,X-Fork,0.4356,81.18,0.0,0.0,0.5366,0.45,ito:ITO_00145,Audio process,SSIM
3,1,Cross-View Image-to-Image Translation,cvusa,2019-04,SelectionGAN,0.5323,99.2,0.1,0.19,0.5366,0.55,ito:ITO_00145,Audio process,SSIM
4,1,Cross-View Image-to-Image Translation,cvusa,2019-12,UniGAN,0.5366,100.0,0.0,0.0,0.5366,0.56,ito:ITO_00145,Audio process,SSIM
5,1,Cross-View Image-to-Image Translation,Ego2Top,2016-11,Pix2pix,0.2213,36.74,0.2213,0.37,0.6024,0.23,ito:ITO_00145,Audio process,SSIM
6,1,Cross-View Image-to-Image Translation,Ego2Top,2018-03,X-Fork,0.274,45.48,0.1,0.17,0.6024,0.29,ito:ITO_00145,Audio process,SSIM
7,1,Cross-View Image-to-Image Translation,Ego2Top,2019-04,SelectionGAN,0.6024,100.0,0.3,0.5,0.6024,0.63,ito:ITO_00145,Audio process,SSIM
8,1,Pose Transfer,Deep-Fashion,2017-05,PG Squared,0.762,98.58,0.762,0.99,0.773,0.79,ito:ITO_00145,Audio process,SSIM
9,1,Pose Transfer,Deep-Fashion,2019-04,Progressive Pose Attention,0.773,100.0,0.0,0.0,0.773,0.81,ito:ITO_00145,Audio process,SSIM
10,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,0.311,100.0,0.311,1.0,0.311,0.32,ito:ITO_00145,Audio process,SSIM
11,1,Talking Face Generation,LRW,2019-10,LipGAN,0.96,100.0,0.96,1.0,0.96,1.0,ito:ITO_00145,Audio process,SSIM
12,1,Facial Inpainting,FFHQ,2020-02,DMFN,0.8985,100.0,0.8985,1.0,0.8985,0.94,ito:ITO_00145,Audio process,SSIM
0,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2016-12,FCNs in the wild,20.2,37.9,20.2,0.38,53.3,0.38,ito:ITO_00145,Audio process,mIoU\\ \\(13\\ classes\\)
1,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2017-07,CDA,29.0,54.41,8.8,0.17,53.3,0.54,ito:ITO_00145,Audio process,mIoU\\ \\(13\\ classes\\)
2,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2018-11,ADVENT,48.0,90.06,19.0,0.36,53.3,0.9,ito:ITO_00145,Audio process,mIoU\\ \\(13\\ classes\\)
3,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-03,SWD,48.1,90.24,0.1,0.0,53.3,0.9,ito:ITO_00145,Audio process,mIoU\\ \\(13\\ classes\\)
4,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-04,DADA (ResNet-101),49.8,93.43,1.7,0.03,53.3,0.93,ito:ITO_00145,Audio process,mIoU\\ \\(13\\ classes\\)
5,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-04,Bidirectional Learning (ResNet-101),51.4,96.44,1.6,0.03,53.3,0.96,ito:ITO_00145,Audio process,mIoU\\ \\(13\\ classes\\)
6,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-08,PyCDA (ResNet-101),53.3,100.0,1.9,0.04,53.3,1.0,ito:ITO_00145,Audio process,mIoU\\ \\(13\\ classes\\)
0,1,Dialog Generation,Amazon-5,2017-01,mm,5.0,100.0,5,1.0,5,1.0,ito:ITO_00145,Audio process,1\\ in\\ 10\\ R\\-at\\-2
0,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2017-03,UNIT,0.023,13.14,0.023,0.13,0.175,0.13,ito:ITO_00145,Audio process,Diversity
1,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2017-11,BicycleGAN,0.14,80.0,0.1,0.57,0.175,0.8,ito:ITO_00145,Audio process,Diversity
2,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2018-04,MUNIT,0.175,100.0,0.0,0.0,0.175,1.0,ito:ITO_00145,Audio process,Diversity
3,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,2017-03,UNIT,0.011,10.09,0.011,0.1,0.109,0.06,ito:ITO_00145,Audio process,Diversity
4,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,2017-11,BicycleGAN,0.104,95.41,0.1,0.92,0.109,0.59,ito:ITO_00145,Audio process,Diversity
5,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,2018-04,MUNIT,0.109,100.0,0.0,0.0,0.109,0.62,ito:ITO_00145,Audio process,Diversity
0,1,Unsupervised Image-To-Image Translation,Freiburg Forest Dataset,2017-03,UNIT,9.42,43.51,9.42,0.44,21.65,0.34,ito:ITO_00145,Audio process,PSNR
1,1,Unsupervised Image-To-Image Translation,Freiburg Forest Dataset,2017-03,cycGAN,18.57,85.77,9.2,0.42,21.65,0.67,ito:ITO_00145,Audio process,PSNR
2,1,Unsupervised Image-To-Image Translation,Freiburg Forest Dataset,2017-11,In2I,21.65,100.0,3.1,0.14,21.65,0.78,ito:ITO_00145,Audio process,PSNR
3,1,Multimodal Unsupervised Image-To-Image Translation,EPFL NIR-VIS,2017-03,UNIT,15.33,66.33,15.33,0.66,23.11,0.55,ito:ITO_00145,Audio process,PSNR
4,1,Multimodal Unsupervised Image-To-Image Translation,EPFL NIR-VIS,2017-03,cycGAN,17.38,75.21,2.0,0.09,23.11,0.62,ito:ITO_00145,Audio process,PSNR
5,1,Multimodal Unsupervised Image-To-Image Translation,EPFL NIR-VIS,2017-11,In2I,23.11,100.0,5.7,0.25,23.11,0.83,ito:ITO_00145,Audio process,PSNR
6,1,Facial Inpainting,VggFace2,2018-12,SymmFCNet (Full),27.81,100.0,27.81,1.0,27.81,1.0,ito:ITO_00145,Audio process,PSNR
7,1,Facial Inpainting,WebFace,2018-12,SymmFCNet (Full),27.22,100.0,27.22,1.0,27.22,0.98,ito:ITO_00145,Audio process,PSNR
8,1,Cross-View Image-to-Image Translation,cvusa,2019-12,UniGAN,22.8223,100.0,22.8223,1.0,22.8223,0.82,ito:ITO_00145,Audio process,PSNR
9,1,Facial Inpainting,FFHQ,2020-02,DMFN,26.49,100.0,26.49,1.0,26.49,0.95,ito:ITO_00145,Audio process,PSNR
0,1,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,2017-03,UNIT,0.826,78.67,0.826,0.79,1.05,0.01,ito:ITO_00145,Audio process,IS
1,1,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,2018-04,MUNIT,1.05,100.0,0.2,0.19,1.05,0.01,ito:ITO_00145,Audio process,IS
2,1,Pose Transfer,Deep-Fashion,2017-05,PG Squared,3.09,89.85,3.09,0.9,3.439,0.02,ito:ITO_00145,Audio process,IS
3,1,Pose Transfer,Deep-Fashion,2017-12,Disentangled PG,3.228,93.86,0.1,0.03,3.439,0.03,ito:ITO_00145,Audio process,IS
4,1,Pose Transfer,Deep-Fashion,2017-12,Deformable GAN,3.439,100.0,0.2,0.06,3.439,0.03,ito:ITO_00145,Audio process,IS
5,1,Image Generation,ImageNet 128x128,2018-09,BigGAN-deep,124.5,100.0,124.5,1.0,124.5,1.0,ito:ITO_00145,Audio process,IS
6,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,3.323,100.0,3.323,1.0,3.323,0.03,ito:ITO_00145,Audio process,IS
0,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,2017-03,UNIT,37.4,65.96,37.4,0.66,56.7,0.66,ito:ITO_00145,Audio process,Quality
1,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,2017-11,BicycleGAN,56.7,100.0,19.3,0.34,56.7,1.0,ito:ITO_00145,Audio process,Quality
2,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2017-03,UNIT,37.3,72.85,37.3,0.73,51.2,0.66,ito:ITO_00145,Audio process,Quality
3,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2017-03,CycleGAN,40.8,79.69,3.5,0.07,51.2,0.72,ito:ITO_00145,Audio process,Quality
4,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2017-11,BicycleGAN,51.2,100.0,10.4,0.2,51.2,0.9,ito:ITO_00145,Audio process,Quality
0,1,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,2017-03,UNIT,0.115,11.07,0.115,0.11,1.039,0.11,ito:ITO_00145,Audio process,CIS
1,1,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,2018-04,MUNIT,1.039,100.0,0.9,0.87,1.039,1.0,ito:ITO_00145,Audio process,CIS
0,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,58.1,100.0,58.1,1.0,58.1,1.0,ito:ITO_00145,Audio process,NDCG\\ \\(x\\ 100\\)
0,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,58.8,84.85,58.8,0.85,69.3,0.85,ito:ITO_00145,Audio process,MRR\\ \\(x\\ 100\\)
1,1,Visual Dialog,Visual Dialog v1.0 test-std,2018-09,CorefNMN (ResNet-152),61.5,88.74,2.7,0.04,69.3,0.89,ito:ITO_00145,Audio process,MRR\\ \\(x\\ 100\\)
2,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,DAN,63.2,91.2,1.7,0.02,69.3,0.91,ito:ITO_00145,Audio process,MRR\\ \\(x\\ 100\\)
3,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-02,HACAN,64.22,92.67,1.0,0.01,69.3,0.93,ito:ITO_00145,Audio process,MRR\\ \\(x\\ 100\\)
4,1,Visual Dialog,Visual Dialog v1.0 test-std,2019-04,5xFGA (F-RCNNx101),69.3,100.0,5.1,0.07,69.3,1.0,ito:ITO_00145,Audio process,MRR\\ \\(x\\ 100\\)
0,1,Visual Dialog,Visual Dialog v1.0 test-std,2017-04,NMN,4.4,100.0,4.4,1.0,4.4,1.0,ito:ITO_00145,Audio process,Mean
0,1,Emotion Recognition in Conversation,IEMOCAP,2017-07,bc-LSTM+Att,56.19,87.55,56.19,0.88,64.18,0.88,ito:ITO_00145,Audio process,Weighted\\-F1
1,1,Emotion Recognition in Conversation,IEMOCAP,2018-10,ICON,58.54,91.21,2.4,0.04,64.18,0.91,ito:ITO_00145,Audio process,Weighted\\-F1
2,1,Emotion Recognition in Conversation,IEMOCAP,2018-11,DialogueRNN,62.75,97.77,4.2,0.07,64.18,0.98,ito:ITO_00145,Audio process,Weighted\\-F1
3,1,Emotion Recognition in Conversation,IEMOCAP,2019-08,DialogueGCN,64.18,100.0,1.4,0.02,64.18,1.0,ito:ITO_00145,Audio process,Weighted\\-F1
4,1,Emotion Recognition in Conversation,MELD,2017-07,bc-LSTM+Att,56.44,97.01,56.44,0.97,58.18,0.88,ito:ITO_00145,Audio process,Weighted\\-F1
5,1,Emotion Recognition in Conversation,MELD,2018-11,DialogueRNN,57.03,98.02,0.6,0.01,58.18,0.89,ito:ITO_00145,Audio process,Weighted\\-F1
6,1,Emotion Recognition in Conversation,MELD,2019-08,DialogueGCN,58.1,99.86,1.1,0.02,58.18,0.91,ito:ITO_00145,Audio process,Weighted\\-F1
7,1,Emotion Recognition in Conversation,MELD,2019-09,KET,58.18,100.0,0.1,0.0,58.18,0.91,ito:ITO_00145,Audio process,Weighted\\-F1
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,bc-LSTM+Att,0.189,98.44,0.189,0.98,0.192,0.98,ito:ITO_00145,Audio process,MAE\\ \\(Valence\\)
1,1,Emotion Recognition in Conversation,SEMAINE,2018-06,CMN,0.192,100.0,0.0,0.0,0.192,1.0,ito:ITO_00145,Audio process,MAE\\ \\(Valence\\)
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,bc-LSTM+Att,0.213,100.0,0.213,1.0,0.213,1.0,ito:ITO_00145,Audio process,MAE\\ \\(Arousal\\)
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,bc-LSTM+Att,0.19,97.44,0.19,0.97,0.195,0.97,ito:ITO_00145,Audio process,MAE\\ \\(Expectancy\\)
1,1,Emotion Recognition in Conversation,SEMAINE,2018-06,CMN,0.195,100.0,0.0,0.0,0.195,1.0,ito:ITO_00145,Audio process,MAE\\ \\(Expectancy\\)
0,1,Emotion Recognition in Conversation,SEMAINE,2017-07,bc-LSTM+Att,8.67,99.2,8.67,0.99,8.74,0.99,ito:ITO_00145,Audio process,MAE\\ \\(Power\\)
1,1,Emotion Recognition in Conversation,SEMAINE,2018-06,CMN,8.74,100.0,0.1,0.01,8.74,1.0,ito:ITO_00145,Audio process,MAE\\ \\(Power\\)
0,1,Multimodal Emotion Recognition,IEMOCAP,2017-07,bc-LSTM ,0.741,96.86,0.741,0.97,0.765,0.93,ito:ITO_00145,Audio process,UA
1,1,Multimodal Emotion Recognition,IEMOCAP,2018-06,CHFusion (A+T+V),0.765,100.0,0.0,0.0,0.765,0.96,ito:ITO_00145,Audio process,UA
2,1,Speech Emotion Recognition,IEMOCAP,2018-02,CNN+LSTM,0.8,100.0,0.8,1.0,0.8,1.0,ito:ITO_00145,Audio process,UA
0,1,Audio Super-Resolution,Piano,2017-08,U-Net,3.4,100.0,3.4,1.0,3.4,1.0,ito:ITO_00145,Audio process,Log\\-Spectral\\ Distance
1,1,Audio Super-Resolution,VCTK Multi-Speaker,2017-08,U-Net,3.1,100.0,3.1,1.0,3.1,0.91,ito:ITO_00145,Audio process,Log\\-Spectral\\ Distance
0,1,3D Absolute Human Pose Estimation,Human3.6M,2017-10,Fang,60.4,100.0,60.4,1.0,60.4,1.0,ito:ITO_00145,Audio process,MPJPE
1,1,3D Absolute Human Pose Estimation,Total Capture,2020-03,GeoFuse,24.6,100.0,24.6,1.0,24.6,0.41,ito:ITO_00145,Audio process,MPJPE
0,1,Image-to-Image Translation,SYNTHIA Fall-to-Winter,2017-11,CyCADA,85.7,100.0,85.7,1.0,85.7,1.0,ito:ITO_00145,Audio process,fwIOU
1,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2017-11,CyCADA pixel+feat,72.4,100.0,72.4,1.0,72.4,0.84,ito:ITO_00145,Audio process,fwIOU
0,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2017-11,AttnGAN,0.512,94.12,0.512,0.94,0.544,0.94,ito:ITO_00145,Audio process,LPIPS
1,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2019-04,DM-GAN,0.544,100.0,0.0,0.0,0.544,1.0,ito:ITO_00145,Audio process,LPIPS
2,1,Pose Transfer,Deep-Fashion,2017-12,Deformable GAN,0.233,100.0,0.233,1.0,0.233,0.43,ito:ITO_00145,Audio process,LPIPS
3,1,Image-to-Image Translation,CelebA-HQ,2019-12,StarGAN v2,0.428,100.0,0.428,1.0,0.428,0.79,ito:ITO_00145,Audio process,LPIPS
4,1,Image-to-Image Translation,AFHQ,2019-12,StarGAN v2,0.524,100.0,0.524,1.0,0.524,0.96,ito:ITO_00145,Audio process,LPIPS
5,1,Facial Inpainting,FFHQ,2020-02,DMFN,0.0457,100.0,0.0457,1.0,0.0457,0.08,ito:ITO_00145,Audio process,LPIPS
0,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2017-11,AttnGAN,13.0,79.27,13.0,0.79,16.4,0.79,ito:ITO_00145,Audio process,Acc
1,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2019-04,DM-GAN,16.4,100.0,3.4,0.21,16.4,1.0,ito:ITO_00145,Audio process,Acc
0,1,Text-to-Image Generation,COCO,2017-11,AttnGAN,25.88,72.19,25.88,0.72,35.85,0.72,ito:ITO_00145,Audio process,SOA\\-C
1,1,Text-to-Image Generation,COCO,2019-04,DM-GAN,33.44,93.28,7.6,0.21,35.85,0.93,ito:ITO_00145,Audio process,SOA\\-C
2,1,Text-to-Image Generation,COCO,2019-10,OP-GAN,35.85,100.0,2.4,0.07,35.85,1.0,ito:ITO_00145,Audio process,SOA\\-C
0,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2017-11,AttnGAN,11.9,70.41,11.9,0.7,16.9,0.7,ito:ITO_00145,Audio process,Real
1,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2019-04,DM-GAN,16.9,100.0,5.0,0.3,16.9,1.0,ito:ITO_00145,Audio process,Real
0,1,Fundus to Angiography Generation,Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients,2017-11,pix2pixHD,0.00258,100.0,0.00258,1.0,0.00258,0.0,ito:ITO_00145,Audio process,Kernel\\ Inception\\ Distance
1,1,Image-to-Image Translation,portrait2photo,2019-07,U-GAT-IT,1.69,100.0,1.69,1.0,1.69,0.15,ito:ITO_00145,Audio process,Kernel\\ Inception\\ Distance
2,1,Image-to-Image Translation,cat2dog,2019-07,U-GAT-IT,7.07,100.0,7.07,1.0,7.07,0.61,ito:ITO_00145,Audio process,Kernel\\ Inception\\ Distance
3,1,Image-to-Image Translation,zebra2horse,2019-07,U-GAT-IT,7.47,100.0,7.47,1.0,7.47,0.64,ito:ITO_00145,Audio process,Kernel\\ Inception\\ Distance
4,1,Image-to-Image Translation,anime-to-selfie,2019-07,U-GAT-IT,11.52,100.0,11.52,1.0,11.52,0.99,ito:ITO_00145,Audio process,Kernel\\ Inception\\ Distance
5,1,Image-to-Image Translation,horse2zebra,2019-07,U-GAT-IT,7.06,100.0,7.06,1.0,7.06,0.61,ito:ITO_00145,Audio process,Kernel\\ Inception\\ Distance
6,1,Image-to-Image Translation,vangogh2photo,2019-07,U-GAT-IT,5.61,100.0,5.61,1.0,5.61,0.48,ito:ITO_00145,Audio process,Kernel\\ Inception\\ Distance
7,1,Image-to-Image Translation,selfie-to-anime,2019-07,U-GAT-IT,11.61,100.0,11.61,1.0,11.61,1.0,ito:ITO_00145,Audio process,Kernel\\ Inception\\ Distance
8,1,Image-to-Image Translation,photo2portrait,2019-07,U-GAT-IT,1.79,100.0,1.79,1.0,1.79,0.15,ito:ITO_00145,Audio process,Kernel\\ Inception\\ Distance
9,1,Image-to-Image Translation,photo2vangogh,2019-07,U-GAT-IT,4.28,100.0,4.28,1.0,4.28,0.37,ito:ITO_00145,Audio process,Kernel\\ Inception\\ Distance
10,1,Image-to-Image Translation,dog2cat,2019-07,U-GAT-IT,8.15,100.0,8.15,1.0,8.15,0.7,ito:ITO_00145,Audio process,Kernel\\ Inception\\ Distance
0,1,Pose Transfer,Deep-Fashion,2017-12,Deformable GAN,30.07,100.0,30.07,1.0,30.07,1.0,ito:ITO_00145,Audio process,Retrieval\\ Top10\\ Recall
0,1,Image Inpainting,Places2 val,2018-01,ContextAttention,8.6,100.0,8.6,1.0,8.6,1.0,ito:ITO_00145,Audio process,rect\\ mask\\ l1\\ error
0,1,Image Inpainting,Places2 val,2018-01,ContextAttention,2.1,100.0,2.1,1.0,2.1,1.0,ito:ITO_00145,Audio process,rect\\ mask\\ l2\\ err
0,1,Image Inpainting,Places2 val,2018-01,ContextAttention,17.2,100.0,17.2,1.0,17.2,1.0,ito:ITO_00145,Audio process,free\\-form\\ mask\\ l1\\ err
0,1,Image Inpainting,Places2 val,2018-01,ContextAttention,4.7,100.0,4.7,1.0,4.7,1.0,ito:ITO_00145,Audio process,free\\-form\\ mask\\ l2\\ err
0,1,Image-to-Image Translation,Cityscapes-to-Foggy Cityscapes,2018-03,FRCNN in the wild,27.6,74.8,27.6,0.75,36.9,0.75,ito:ITO_00145,Audio process,mAP
1,1,Image-to-Image Translation,Cityscapes-to-Foggy Cityscapes,2019-05,Diversify & Match,34.6,93.77,7.0,0.19,36.9,0.94,ito:ITO_00145,Audio process,mAP
2,1,Image-to-Image Translation,Cityscapes-to-Foggy Cityscapes,2019-10,Progressive Domain Adaptation,36.9,100.0,2.3,0.06,36.9,1.0,ito:ITO_00145,Audio process,mAP
0,1,Layout-to-Image Generation,Visual Genome 64x64,2018-04,SG2Im,6.3,67.74,6.3,0.68,9.3,0.24,ito:ITO_00145,Audio process,Inception\\ Score
1,1,Layout-to-Image Generation,Visual Genome 64x64,2018-11,Layout2Im,8.1,87.1,1.8,0.19,9.3,0.31,ito:ITO_00145,Audio process,Inception\\ Score
2,1,Layout-to-Image Generation,Visual Genome 64x64,2019-08,LostGAN,8.7,93.55,0.6,0.06,9.3,0.34,ito:ITO_00145,Audio process,Inception\\ Score
3,1,Layout-to-Image Generation,Visual Genome 64x64,2020-03,OC-GAN,9.3,100.0,0.6,0.06,9.3,0.36,ito:ITO_00145,Audio process,Inception\\ Score
4,1,Layout-to-Image Generation,COCO-Stuff 64x64,2018-04,SG2Im,7.3,67.59,7.3,0.68,10.8,0.28,ito:ITO_00145,Audio process,Inception\\ Score
5,1,Layout-to-Image Generation,COCO-Stuff 64x64,2018-11,Layout2Im,9.1,84.26,1.8,0.17,10.8,0.35,ito:ITO_00145,Audio process,Inception\\ Score
6,1,Layout-to-Image Generation,COCO-Stuff 64x64,2019-08,LostGAN,9.8,90.74,0.7,0.06,10.8,0.38,ito:ITO_00145,Audio process,Inception\\ Score
7,1,Layout-to-Image Generation,COCO-Stuff 64x64,2019-09,SOARISG,10.3,95.37,0.5,0.05,10.8,0.4,ito:ITO_00145,Audio process,Inception\\ Score
8,1,Layout-to-Image Generation,COCO-Stuff 64x64,2020-03,OC-GAN,10.8,100.0,0.5,0.05,10.8,0.42,ito:ITO_00145,Audio process,Inception\\ Score
9,1,Image Generation,ImageNet 64x64,2019-07,BigBiGAN,19.4,74.73,19.4,0.75,25.96,0.75,ito:ITO_00145,Audio process,Inception\\ Score
10,1,Image Generation,ImageNet 64x64,2020-04,FQ-GAN,25.96,100.0,6.6,0.25,25.96,1.0,ito:ITO_00145,Audio process,Inception\\ Score
11,1,Layout-to-Image Generation,COCO-Stuff 128x128,2019-08,LostGAN,13.8,94.52,13.8,0.95,14.6,0.53,ito:ITO_00145,Audio process,Inception\\ Score
12,1,Layout-to-Image Generation,COCO-Stuff 128x128,2020-03,OC-GAN,14.6,100.0,0.8,0.05,14.6,0.56,ito:ITO_00145,Audio process,Inception\\ Score
13,1,Layout-to-Image Generation,Visual Genome 128x128,2019-08,LostGAN,11.1,90.24,11.1,0.9,12.3,0.43,ito:ITO_00145,Audio process,Inception\\ Score
14,1,Layout-to-Image Generation,Visual Genome 128x128,2020-03,OC-GAN,12.3,100.0,1.2,0.1,12.3,0.47,ito:ITO_00145,Audio process,Inception\\ Score
0,1,Visual Dialog,VisDial v1.0 test-std,2018-09,CorefNMN Kottur et al. (2018),54.7,94.98,54.7,0.95,57.59,0.92,ito:ITO_00145,Audio process,NDCG
1,1,Visual Dialog,VisDial v1.0 test-std,2019-02,DAN,57.59,100.0,2.9,0.05,57.59,0.97,ito:ITO_00145,Audio process,NDCG
2,1,Visual Dialog,Visual Dialog v1.0,2019-02,HACAN,57.17,96.29,57.17,0.96,59.37,0.96,ito:ITO_00145,Audio process,NDCG
3,1,Visual Dialog,Visual Dialog v1.0,2019-02,DAN,57.59,97.0,0.4,0.01,59.37,0.97,ito:ITO_00145,Audio process,NDCG
4,1,Visual Dialog,Visual Dialog v1.0,2020-04,MVAN,59.37,100.0,1.8,0.03,59.37,1.0,ito:ITO_00145,Audio process,NDCG
0,1,Music Modeling,JSB Chorales,2018-09,Music Transformer,0.335,100.0,0.335,1.0,0.335,1.0,ito:ITO_00145,Audio process,NLL
1,1,person reposing,person reposing,2018-09,Music Transformer,0.335,100.0,0.335,1.0,0.335,1.0,ito:ITO_00145,Audio process,NLL
0,1,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,2018-09,CLAN,47.8,88.85,47.8,0.89,53.8,0.89,ito:ITO_00145,Audio process,MIoU\\ \\(13\\ classes\\)
1,1,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,2019-10,CAG-UDA,52.6,97.77,4.8,0.09,53.8,0.98,ito:ITO_00145,Audio process,MIoU\\ \\(13\\ classes\\)
2,1,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,2019-12,MRNet(ResNet-101),53.8,100.0,1.2,0.02,53.8,1.0,ito:ITO_00145,Audio process,MIoU\\ \\(13\\ classes\\)
0,1,Multimodal Emotion Recognition,IEMOCAP,2018-10,Multimodal Dual Recurrent Encoder (MDRE) / (A+T),0.718,100.0,0.718,1.0,0.718,1.0,ito:ITO_00145,Audio process,WAP
1,1,Speech Emotion Recognition,IEMOCAP,2018-10,Multimodal Dual Recurrent Encoder (MDRE) / (A+T),0.718,100.0,0.718,1.0,0.718,1.0,ito:ITO_00145,Audio process,WAP
0,1,Audio Source Separation,AudioSet,2019-04,Co-Separation,4.26,100.0,4.26,1.0,4.26,1.0,ito:ITO_00145,Audio process,SDR
0,1,Image Generation,LSUN Bedroom,2018-12,StyleGAN,2.65,100.0,2.65,1.0,2.65,1.0,ito:ITO_00145,Audio process,FID\\-50k
0,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,HAN,93.11,100.0,93.11,1.0,93.11,1.0,ito:ITO_00145,Audio process,Micro\\-F1\\ \\(20%\\ training\\ data\\)
0,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,HAN,93.99,100.0,93.99,1.0,93.99,1.0,ito:ITO_00145,Audio process,Micro\\-F1\\ \\(80%\\ training\\ data\\)
0,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,HAN,93.08,99.61,93.08,1.0,93.44,1.0,ito:ITO_00145,Audio process,Macro\\-F1\\ \\(80%\\ training\\ data\\)
1,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,ESim,93.44,100.0,0.4,0.0,93.44,1.0,ito:ITO_00145,Audio process,Macro\\-F1\\ \\(80%\\ training\\ data\\)
0,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,HAN,92.24,100.0,92.24,1.0,92.24,1.0,ito:ITO_00145,Audio process,Macro\\-F1\\ \\(20%\\ training\\ data\\)
0,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-03,HAN,93.7,97.12,93.7,0.97,96.48,0.97,ito:ITO_00145,Audio process,Macro\\-F1\\ \\(60%\\ training\\ data\\)
1,1,Interactive Evaluation of Dialog,Interactive Evaluation of Dialog,2019-12,NLAH (2ndprox),96.48,100.0,2.8,0.03,96.48,1.0,ito:ITO_00145,Audio process,Macro\\-F1\\ \\(60%\\ training\\ data\\)
0,1,Emotion Recognition in Conversation,EC,2019-03,HRLCE + BERT,0.7709,99.28,0.7709,0.99,0.7765,0.01,ito:ITO_00145,Audio process,Micro\\-F1
1,1,Emotion Recognition in Conversation,EC,2019-04,NELEC,0.7765,100.0,0.0,0.0,0.7765,0.01,ito:ITO_00145,Audio process,Micro\\-F1
2,1,Emotion Recognition in Conversation,DailyDialog,2019-09,KET,53.37,100.0,53.37,1.0,53.37,1.0,ito:ITO_00145,Audio process,Micro\\-F1
0,1,Speech Recognition,Hub5'00 SwitchBoard,2019-04,Jasper DR 10x5,16.2,100.0,16.2,1.0,16.2,1.0,ito:ITO_00145,Audio process,CallHome
0,1,Speech Recognition,Hub5'00 SwitchBoard,2019-04,Jasper DR 10x5,7.8,100.0,7.8,1.0,7.8,1.0,ito:ITO_00145,Audio process,SwitchBoard
0,1,Text-To-Speech Synthesis,CMUDict 0.7b,2019-04,Token-Level Ensemble Distillation,4.6,100.0,4.6,1.0,4.6,1.0,ito:ITO_00145,Audio process,Phoneme\\ Error\\ Rate
0,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,0.94,100.0,0.94,1.0,0.94,0.98,ito:ITO_00145,Audio process,PCKh
1,1,Pose Transfer,Deep-Fashion,2019-04,Progressive Pose Attention,0.96,100.0,0.96,1.0,0.96,1.0,ito:ITO_00145,Audio process,PCKh
0,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,0.811,100.0,0.811,1.0,0.811,1.0,ito:ITO_00145,Audio process,mask\\-SSIM
0,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,0.74,100.0,0.74,1.0,0.74,0.76,ito:ITO_00145,Audio process,DS
1,1,Pose Transfer,Deep-Fashion,2019-04,Progressive Pose Attention,0.976,100.0,0.976,1.0,0.976,1.0,ito:ITO_00145,Audio process,DS
0,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,3.773,100.0,3.773,1.0,3.773,1.0,ito:ITO_00145,Audio process,mask\\-IS
0,1,Audio Source Separation,AudioSet,2019-04,Co-Separation,13.0,100.0,13,1.0,13,1.0,ito:ITO_00145,Audio process,SAR
0,1,Audio Source Separation,AudioSet,2019-04,Co-Separation,7.07,100.0,7.07,1.0,7.07,1.0,ito:ITO_00145,Audio process,SIR
0,1,Audio Denoising,AV-Bench,2019-04,Co-Separation,14.5,100.0,14.5,1.0,14.5,1.0,ito:ITO_00145,Audio process,NSDR
1,1,Audio Denoising,AV-Bench,2019-04,Co-Separation,11.9,100.0,11.9,1.0,11.9,0.82,ito:ITO_00145,Audio process,NSDR
2,1,Audio Denoising,AV-Bench,2019-04,Co-Separation,8.53,100.0,8.53,1.0,8.53,0.59,ito:ITO_00145,Audio process,NSDR
0,1,Direction of Arrival Estimation,SOFA,2019-04,reg-cartesian,9.68,100.0,9.68,1.0,9.68,1.0,ito:ITO_00145,Audio process,Angular\\ Error
0,1,Arabic Text Diacritization,Tashkeela,2019-04,Shakkala,0.0373,100.0,0.0373,1.0,0.0373,1.0,ito:ITO_00145,Audio process,Diacritic\\ Error\\ Rate
1,1,EEG Emotion Recognition,EEG Emotion Recognition,2019-04,Shakkala,0.0373,100.0,0.0373,1.0,0.0373,1.0,ito:ITO_00145,Audio process,Diacritic\\ Error\\ Rate
0,1,Synthetic Data Generation,UCI Epileptic Seizure Recognition,2019-05,GAN,0.87,94.57,0.87,0.95,0.92,0.95,ito:ITO_00145,Audio process,AUROC
1,1,Synthetic Data Generation,UCI Epileptic Seizure Recognition,2020-01,corGAN,0.92,100.0,0.1,0.11,0.92,1.0,ito:ITO_00145,Audio process,AUROC
2,1,Emotion-Cause Pair Extraction,Emotion-Cause Pair Extraction,2019-05,GAN,0.87,94.57,0.87,0.95,0.92,0.95,ito:ITO_00145,Audio process,AUROC
3,1,Emotion-Cause Pair Extraction,Emotion-Cause Pair Extraction,2020-01,corGAN,0.92,100.0,0.1,0.11,0.92,1.0,ito:ITO_00145,Audio process,AUROC
0,1,Text-To-Speech Synthesis,LJSpeech,2019-05,Merlin,2.4,62.5,2.4,0.62,3.84,0.62,ito:ITO_00145,Audio process,Audio\\ Quality\\ MOS
1,1,Text-To-Speech Synthesis,LJSpeech,2019-05,FastSpeech (Mel + WaveGlow),3.84,100.0,1.4,0.36,3.84,1.0,ito:ITO_00145,Audio process,Audio\\ Quality\\ MOS
0,1,Text-To-Speech Synthesis,LJSpeech,2019-05,FastSpeech,270.0,100.0,270,1.0,270,1.0,ito:ITO_00145,Audio process,Speedup
0,1,Text-To-Speech Synthesis,LJSpeech,2019-05,FastSpeech,3.84,100.0,3.84,1.0,3.84,1.0,ito:ITO_00145,Audio process,MOS
0,1,Image Inpainting,Paris StreetView,2019-05,Coherent Semantic Attention for Image Inpainting,23.1,100.0,23.1,1.0,23.1,1.0,ito:ITO_00145,Audio process,40\\-50%\\ Mask\\ PSNR
0,1,Image Inpainting,Paris StreetView,2019-05,Coherent Semantic Attention for Image Inpainting,32.67,100.0,32.67,1.0,32.67,1.0,ito:ITO_00145,Audio process,10\\-20%\\ Mask\\ PSNR
0,1,Image Inpainting,Paris StreetView,2019-05,Coherent Semantic Attention for Image Inpainting,30.32,100.0,30.32,1.0,30.32,1.0,ito:ITO_00145,Audio process,20\\-30%\\ Mask\\ PSNR
0,1,Image Inpainting,Paris StreetView,2019-05,Coherent Semantic Attention for Image Inpainting,24.85,100.0,24.85,1.0,24.85,1.0,ito:ITO_00145,Audio process,30\\-40%\\ Mask\\ PSNR
0,1,Image Generation,ImageNet 64x64,2019-07,BigBiGAN,47.51,100.0,47.51,1.0,47.51,1.0,ito:ITO_00145,Audio process,Cls
0,1,3D Absolute Human Pose Estimation,Human3.6M,2019-07,RootNet,120.0,100.0,120,1.0,120,1.0,ito:ITO_00145,Audio process,MRPE
0,1,Layout-to-Image Generation,COCO-Stuff 128x128,2019-08,LostGAN,20.03,59.86,20.03,0.6,33.46,0.6,ito:ITO_00145,Audio process,SceneFID
1,1,Layout-to-Image Generation,COCO-Stuff 128x128,2019-09,SOARISG,33.46,100.0,13.4,0.4,33.46,1.0,ito:ITO_00145,Audio process,SceneFID
2,1,Layout-to-Image Generation,Visual Genome 128x128,2019-08,LostGAN,13.17,100.0,13.17,1.0,13.17,0.39,ito:ITO_00145,Audio process,SceneFID
0,1,Speech Recognition,Hub5'00 SwitchBoard,2019-09,Espresso,9.2,100.0,9.2,1.0,9.2,1.0,ito:ITO_00145,Audio process,Eval2000
0,1,Emotion Recognition in Conversation,EmoryNLP,2019-09,KET,34.39,100.0,34.39,1.0,34.39,1.0,ito:ITO_00145,Audio process,Weighted\\ Macro\\-F1
0,1,Talking Face Generation,LRW,2019-10,LipGAN,0.6,100.0,0.6,1.0,0.6,1.0,ito:ITO_00145,Audio process,LMD
0,1,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,2019-10,CAG-UDA,44.5,95.7,44.5,0.96,46.5,0.96,ito:ITO_00145,Audio process,MIoU\\ \\(16\\ classes\\)
1,1,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,2019-12,MRNet(ResNet-101),46.5,100.0,2.0,0.04,46.5,1.0,ito:ITO_00145,Audio process,MIoU\\ \\(16\\ classes\\)
0,1,Cross-View Image-to-Image Translation,cvusa,2019-12,UniGAN,2.6,100.0,2.6,1.0,2.6,1.0,ito:ITO_00145,Audio process,KL
0,1,Cross-View Image-to-Image Translation,cvusa,2019-12,UniGAN,19.8276,100.0,19.8276,1.0,19.8276,1.0,ito:ITO_00145,Audio process,SD
0,1,Node Classification,BlogCatalog,2019-12,DAOR,33.05,100.0,33.05,1.0,33.05,1.0,ito:ITO_00145,Audio process,Micro\\ F1
1,1,Spoken language identification,Spoken language identification,2019-12,DAOR,33.05,100.0,33.05,1.0,33.05,1.0,ito:ITO_00145,Audio process,Micro\\ F1
0,1,Node Classification,BlogCatalog,2019-12,DAOR,17.25,100.0,17.25,1.0,17.25,1.0,ito:ITO_00145,Audio process,Macro\\ F1
1,1,Spoken language identification,Spoken language identification,2019-12,DAOR,17.25,100.0,17.25,1.0,17.25,1.0,ito:ITO_00145,Audio process,Macro\\ F1
0,1,Sparse Learning,ImageNet32,2020-03,Resnet18,93.63,100.0,93.63,1.0,93.63,1.0,ito:ITO_00145,Audio process,Sparsity
1,1,Speech Extraction,Speech Extraction,2020-03,Resnet18,93.63,100.0,93.63,1.0,93.63,1.0,ito:ITO_00145,Audio process,Sparsity
0,1,Citation Intent Classification,ACL-ARC,2013-06,SVM,41.0,60.38,41.0,0.6,67.9,0.44,ito:ITO_00310,Adversarial process,F1
1,1,Citation Intent Classification,ACL-ARC,2016-06,BiLSTM-Attention,51.8,76.29,10.8,0.16,67.9,0.56,ito:ITO_00310,Adversarial process,F1
2,1,Citation Intent Classification,ACL-ARC,2018-01,Feature-rich Random Forest,53.0,78.06,1.2,0.02,67.9,0.57,ito:ITO_00310,Adversarial process,F1
3,1,Citation Intent Classification,ACL-ARC,2018-02,BiLSTM-Attention + ELMo,54.6,80.41,1.6,0.02,67.9,0.59,ito:ITO_00310,Adversarial process,F1
4,1,Citation Intent Classification,ACL-ARC,2019-03,SciBERT,65.8,96.91,11.2,0.16,67.9,0.71,ito:ITO_00310,Adversarial process,F1
5,1,Citation Intent Classification,ACL-ARC,2019-04,Structural-scaffolds,67.9,100.0,2.1,0.03,67.9,0.73,ito:ITO_00310,Adversarial process,F1
6,1,Sentence Classification,SciCite,2018-01,Feature-Rich Random Forest,79.6,93.76,79.6,0.94,84.9,0.86,ito:ITO_00310,Adversarial process,F1
7,1,Sentence Classification,SciCite,2018-10,BERT,84.4,99.41,4.8,0.06,84.9,0.91,ito:ITO_00310,Adversarial process,F1
8,1,Sentence Classification,SciCite,2019-03,SciBERT,84.9,100.0,0.5,0.01,84.9,0.92,ito:ITO_00310,Adversarial process,F1
9,1,Sentence Classification,ACL-ARC,2018-01,Random Forest,53.0,74.67,53.0,0.75,70.98,0.57,ito:ITO_00310,Adversarial process,F1
10,1,Sentence Classification,ACL-ARC,2019-03,SciBERT (Base Vocab),65.79,92.69,12.8,0.18,70.98,0.71,ito:ITO_00310,Adversarial process,F1
11,1,Sentence Classification,ACL-ARC,2019-03,SciBERT,70.98,100.0,5.2,0.07,70.98,0.77,ito:ITO_00310,Adversarial process,F1
12,1,Citation Intent Classification,SciCite,2018-01,Feature-Rich Random Forest,79.6,93.66,79.6,0.94,84.99,0.86,ito:ITO_00310,Adversarial process,F1
13,1,Citation Intent Classification,SciCite,2019-03,SciBERT,84.99,100.0,5.4,0.06,84.99,0.92,ito:ITO_00310,Adversarial process,F1
14,1,Sentence Classification,PubMed 20k RCT,2018-08,Hierarchical Neural Networks,92.6,100.0,92.6,1.0,92.6,1.0,ito:ITO_00310,Adversarial process,F1
15,1,Document Classification,Reuters-21578,2019-02,VLAWE,89.3,99.33,89.3,0.99,89.9,0.96,ito:ITO_00310,Adversarial process,F1
16,1,Document Classification,Reuters-21578,2020-02,MAGNET,89.9,100.0,0.6,0.01,89.9,0.97,ito:ITO_00310,Adversarial process,F1
17,1,Sentence Classification,Paper Field,2019-03,SciBERT (SciVocab),64.07,97.5,64.07,0.98,65.71,0.69,ito:ITO_00310,Adversarial process,F1
18,1,Sentence Classification,Paper Field,2019-03,SciBERT (SciVocab),65.71,100.0,1.6,0.02,65.71,0.71,ito:ITO_00310,Adversarial process,F1
19,1,Sentence Classification,ScienceCite,2019-03,SciBERT (SciVocab),84.99,100.0,84.99,1.0,84.99,0.92,ito:ITO_00310,Adversarial process,F1
20,1,Document Classification,AAPD,2019-04,KD-LSTMreg,72.9,100.0,72.9,1.0,72.9,0.79,ito:ITO_00310,Adversarial process,F1
21,1,Multi-Label Text Classification,AAPD,2020-02,MAGNET,69.6,100.0,69.6,1.0,69.6,0.75,ito:ITO_00310,Adversarial process,F1
0,1,Document Classification,Cora,2014-03,DeepWalk,67.2,80.48,67.2,0.8,83.5,0.67,ito:ITO_00310,Adversarial process,Accuracy
1,1,Document Classification,Cora,2016-03,Planetoid*,75.7,90.66,8.5,0.1,83.5,0.76,ito:ITO_00310,Adversarial process,Accuracy
2,1,Document Classification,Cora,2016-09,Graph-CNN,81.5,97.6,5.8,0.07,83.5,0.82,ito:ITO_00310,Adversarial process,Accuracy
3,1,Document Classification,Cora,2016-11,MoNet,81.7,97.84,0.2,0.0,83.5,0.82,ito:ITO_00310,Adversarial process,Accuracy
4,1,Document Classification,Cora,2017-10,GAT,83.0,99.4,1.3,0.02,83.5,0.83,ito:ITO_00310,Adversarial process,Accuracy
5,1,Document Classification,Cora,2018-08,LGCN,83.3,99.76,0.3,0.0,83.5,0.84,ito:ITO_00310,Adversarial process,Accuracy
6,1,Document Classification,Cora,2019-04,ACNet,83.5,100.0,0.2,0.0,83.5,0.84,ito:ITO_00310,Adversarial process,Accuracy
7,1,Text Classification,IMDb,2014-05,Paragraph Vectors Le & Mikolov (2014),92.58,95.64,92.58,0.96,96.8,0.93,ito:ITO_00310,Adversarial process,Accuracy
8,1,Text Classification,IMDb,2019-01,HAHNN (CNN),95.17,98.32,2.6,0.03,96.8,0.96,ito:ITO_00310,Adversarial process,Accuracy
9,1,Text Classification,IMDb,2019-04,BERT Finetune + UDA,95.8,98.97,0.6,0.01,96.8,0.96,ito:ITO_00310,Adversarial process,Accuracy
10,1,Text Classification,IMDb,2019-06,XLNet,96.8,100.0,1.0,0.01,96.8,0.97,ito:ITO_00310,Adversarial process,Accuracy
11,1,Document Classification,Reuters En-De,2014-10,BilBOWA,86.5,100.0,86.5,1.0,86.5,0.87,ito:ITO_00310,Adversarial process,Accuracy
12,1,Document Classification,Reuters De-En,2014-10,BilBOWA,75.0,100.0,75,1.0,75,0.75,ito:ITO_00310,Adversarial process,Accuracy
13,1,Text Classification,RCV1,2016-02,One-hot CNN+ Johnson & Zhang ([2016b]),94.13,100.0,94.13,1.0,94.13,0.95,ito:ITO_00310,Adversarial process,Accuracy
14,1,Text Classification,Yahoo! Answers,2016-07,FastText,72.3,93.15,72.3,0.93,77.62,0.73,ito:ITO_00310,Adversarial process,Accuracy
15,1,Text Classification,Yahoo! Answers,2018-05,SWEM-concat,73.53,94.73,1.2,0.02,77.62,0.74,ito:ITO_00310,Adversarial process,Accuracy
16,1,Text Classification,Yahoo! Answers,2018-07,DRNN,76.26,98.25,2.7,0.03,77.62,0.77,ito:ITO_00310,Adversarial process,Accuracy
17,1,Text Classification,Yahoo! Answers,2019-05,BERT-ITPT-FiT,77.62,100.0,1.4,0.02,77.62,0.78,ito:ITO_00310,Adversarial process,Accuracy
18,1,Text Classification,Ohsumed,2017-07,CNN+Lowercased,36.2,52.85,36.2,0.53,68.5,0.36,ito:ITO_00310,Adversarial process,Accuracy
19,1,Text Classification,Ohsumed,2018-09,Text GCN,68.36,99.8,32.2,0.47,68.5,0.69,ito:ITO_00310,Adversarial process,Accuracy
20,1,Text Classification,Ohsumed,2019-02,SGCN,68.5,100.0,0.1,0.0,68.5,0.69,ito:ITO_00310,Adversarial process,Accuracy
21,1,Document Classification,WOS-46985,2017-09,HDLTex,76.58,92.91,76.58,0.93,82.42,0.77,ito:ITO_00310,Adversarial process,Accuracy
22,1,Document Classification,WOS-46985,2018-05,RMDL (30 RDLs),82.42,100.0,5.8,0.07,82.42,0.83,ito:ITO_00310,Adversarial process,Accuracy
23,1,Document Classification,WOS-11967,2017-09,HDLTex,86.07,93.97,86.07,0.94,91.59,0.86,ito:ITO_00310,Adversarial process,Accuracy
24,1,Document Classification,WOS-11967,2018-05,RMDL (30 RDLs),91.59,100.0,5.5,0.06,91.59,0.92,ito:ITO_00310,Adversarial process,Accuracy
25,1,Document Classification,WOS-5736,2017-09,HDLTex,90.93,97.18,90.93,0.97,93.57,0.91,ito:ITO_00310,Adversarial process,Accuracy
26,1,Document Classification,WOS-5736,2018-05,RMDL (30 RDLs),93.57,100.0,2.6,0.03,93.57,0.94,ito:ITO_00310,Adversarial process,Accuracy
27,1,Text Classification,20NEWS,2018-05,RMDL (15 RDLs),87.91,99.33,87.91,0.99,88.5,0.88,ito:ITO_00310,Adversarial process,Accuracy
28,1,Text Classification,20NEWS,2019-02,SGC,88.5,100.0,0.6,0.01,88.5,0.89,ito:ITO_00310,Adversarial process,Accuracy
29,1,Document Classification,Reuters-21578,2018-05,RMDL (30 RDLs),90.69,93.07,90.69,0.93,97.44,0.91,ito:ITO_00310,Adversarial process,Accuracy
30,1,Document Classification,Reuters-21578,2019-04,ApproxRepSet,97.17,99.72,6.5,0.07,97.44,0.98,ito:ITO_00310,Adversarial process,Accuracy
31,1,Document Classification,Reuters-21578,2019-08,MPAD-path,97.44,100.0,0.3,0.0,97.44,0.98,ito:ITO_00310,Adversarial process,Accuracy
32,1,Text Classification,R8,2018-06,TextEnt-full,96.7,98.77,96.7,0.99,97.9,0.97,ito:ITO_00310,Adversarial process,Accuracy
33,1,Text Classification,R8,2018-09,Text GCN,97.07,99.15,0.4,0.0,97.9,0.97,ito:ITO_00310,Adversarial process,Accuracy
34,1,Text Classification,R8,2019-02,SGC,97.2,99.28,0.1,0.0,97.9,0.98,ito:ITO_00310,Adversarial process,Accuracy
35,1,Text Classification,R8,2019-06,GraphStar,97.4,99.49,0.2,0.0,97.9,0.98,ito:ITO_00310,Adversarial process,Accuracy
36,1,Text Classification,R8,2019-09,NABoE-full,97.9,100.0,0.5,0.01,97.9,0.98,ito:ITO_00310,Adversarial process,Accuracy
37,1,Text Classification,R52,2018-09,Text GCN,93.56,98.48,93.56,0.98,95.0,0.94,ito:ITO_00310,Adversarial process,Accuracy
38,1,Text Classification,R52,2019-02,SGC,94.0,98.95,0.4,0.0,95.0,0.94,ito:ITO_00310,Adversarial process,Accuracy
39,1,Text Classification,R52,2019-06,GraphStar,95.0,100.0,1.0,0.01,95.0,0.95,ito:ITO_00310,Adversarial process,Accuracy
40,1,Text Classification,Sogou News,2018-10,CCCapsNet,97.25,99.16,97.25,0.99,98.07,0.98,ito:ITO_00310,Adversarial process,Accuracy
41,1,Text Classification,Sogou News,2019-05,BERT-ITPT-FiT,98.07,100.0,0.8,0.01,98.07,0.98,ito:ITO_00310,Adversarial process,Accuracy
42,1,Adversarial Defense,ImageNet,2018-12,Feature Denoising,49.5,100.0,49.5,1.0,49.5,0.5,ito:ITO_00310,Adversarial process,Accuracy
43,1,Adversarial Defense,CAAD 2018,2018-12,Feature Denoising,50.6,100.0,50.6,1.0,50.6,0.51,ito:ITO_00310,Adversarial process,Accuracy
44,1,Text Classification,Yelp-5,2019-01,HAHNN (CNN),73.28,100.0,73.28,1.0,73.28,0.74,ito:ITO_00310,Adversarial process,Accuracy
45,1,Adversarial Defense,CIFAR-10,2019-04,"PCL (against PGD, white box)",46.7,100.0,46.7,1.0,46.7,0.47,ito:ITO_00310,Adversarial process,Accuracy
46,1,Document Classification,Amazon,2019-04,ApproxRepSet,94.31,100.0,94.31,1.0,94.31,0.95,ito:ITO_00310,Adversarial process,Accuracy
47,1,Document Classification,Recipe,2019-04,ApproxRepSet,59.06,100.0,59.06,1.0,59.06,0.59,ito:ITO_00310,Adversarial process,Accuracy
48,1,Document Classification,BBCSport,2019-04,ApproxRepSet,95.73,96.12,95.73,0.96,99.59,0.96,ito:ITO_00310,Adversarial process,Accuracy
49,1,Document Classification,BBCSport,2019-08,MPAD-path,99.59,100.0,3.9,0.04,99.59,1.0,ito:ITO_00310,Adversarial process,Accuracy
50,1,Document Classification,Classic,2019-04,ApproxRepSet,96.24,99.37,96.24,0.99,96.85,0.97,ito:ITO_00310,Adversarial process,Accuracy
51,1,Document Classification,Classic,2019-12,REL-RWMD k-NN,96.85,100.0,0.6,0.01,96.85,0.97,ito:ITO_00310,Adversarial process,Accuracy
52,1,Document Classification,Twitter,2019-04,ApproxRepSet,72.6,100.0,72.6,1.0,72.6,0.73,ito:ITO_00310,Adversarial process,Accuracy
53,1,Document Classification,Yelp-14,2019-04,KD-LSTMreg,69.4,100.0,69.4,1.0,69.4,0.7,ito:ITO_00310,Adversarial process,Accuracy
54,1,Text Classification,Yelp-2,2019-04,BERT Finetune + UDA,97.95,99.31,97.95,0.99,98.63,0.98,ito:ITO_00310,Adversarial process,Accuracy
55,1,Text Classification,Yelp-2,2019-05,BERT-ITPT-FiT,98.08,99.44,0.1,0.0,98.63,0.98,ito:ITO_00310,Adversarial process,Accuracy
56,1,Text Classification,Yelp-2,2019-06,XLNet,98.63,100.0,0.5,0.01,98.63,0.99,ito:ITO_00310,Adversarial process,Accuracy
57,1,Document Classification,IMDb-M,2019-06,LSTM-reg (single model),52.8,100.0,52.8,1.0,52.8,0.53,ito:ITO_00310,Adversarial process,Accuracy
58,1,Document Classification,MPQA,2019-08,MPAD-path,89.81,100.0,89.81,1.0,89.81,0.9,ito:ITO_00310,Adversarial process,Accuracy
0,1,Text Classification,IMDb,2014-05,Paragraph Vectors Le & Mikolov (2014),92.58,95.64,92.58,0.96,96.8,0.96,ito:ITO_00310,Adversarial process,Accuracy\\ \\(2\\ classes\\)
1,1,Text Classification,IMDb,2019-01,HAHNN (CNN),95.17,98.32,2.6,0.03,96.8,0.98,ito:ITO_00310,Adversarial process,Accuracy\\ \\(2\\ classes\\)
2,1,Text Classification,IMDb,2019-05,BERT-ITPT-FiT,95.63,98.79,0.5,0.01,96.8,0.99,ito:ITO_00310,Adversarial process,Accuracy\\ \\(2\\ classes\\)
3,1,Text Classification,IMDb,2019-06,XLNet,96.8,100.0,1.2,0.01,96.8,1.0,ito:ITO_00310,Adversarial process,Accuracy\\ \\(2\\ classes\\)
0,1,Text Classification,TREC-6,2015-04,TBCNN,4.0,41.67,4.0,0.42,9.6,0.11,ito:ITO_00310,Adversarial process,Error
1,1,Text Classification,TREC-6,2015-11,C-LSTM,5.4,56.25,1.4,0.15,9.6,0.15,ito:ITO_00310,Adversarial process,Error
2,1,Text Classification,TREC-6,2017-02,GRU-RNN-GLOVE,7.0,72.92,1.6,0.17,9.6,0.19,ito:ITO_00310,Adversarial process,Error
3,1,Text Classification,TREC-6,2018-03,Capsule-B,7.2,75.0,0.2,0.02,9.6,0.19,ito:ITO_00310,Adversarial process,Error
4,1,Text Classification,TREC-6,2018-05,byte mLSTM7,9.6,100.0,2.4,0.25,9.6,0.26,ito:ITO_00310,Adversarial process,Error
5,1,Text Classification,DBpedia,2015-09,Char-level CNN,1.55,55.96,1.55,0.56,2.77,0.04,ito:ITO_00310,Adversarial process,Error
6,1,Text Classification,DBpedia,2018-05,Seq2CNN(50),2.77,100.0,1.2,0.43,2.77,0.07,ito:ITO_00310,Adversarial process,Error
7,1,Text Classification,AG News,2015-09,Char-level CNN,9.51,67.93,9.51,0.68,14.0,0.26,ito:ITO_00310,Adversarial process,Error
8,1,Text Classification,AG News,2018-05,Seq2CNN with GWS(50),9.64,68.86,0.1,0.01,14.0,0.26,ito:ITO_00310,Adversarial process,Error
9,1,Text Classification,AG News,2018-08,ToWE-SG,14.0,100.0,4.4,0.31,14.0,0.38,ito:ITO_00310,Adversarial process,Error
10,1,Text Classification,TREC-50,2016-12,Rules,2.8,100.0,2.8,1.0,2.8,0.08,ito:ITO_00310,Adversarial process,Error
11,1,Text Classification,Amazon-5,2019-04,BERT Finetune + UDA,37.12,100.0,37.12,1.0,37.12,1.0,ito:ITO_00310,Adversarial process,Error
12,1,Text Classification,Amazon-2,2019-04,BERT Finetune + UDA,3.5,89.74,3.5,0.9,3.9,0.09,ito:ITO_00310,Adversarial process,Error
13,1,Text Classification,Amazon-2,2019-09,ULMFiT (Small data),3.9,100.0,0.4,0.1,3.9,0.11,ito:ITO_00310,Adversarial process,Error
0,1,Topic modeling,20 Newsgroups,2015-11,NVDM,836.0,100.0,836,1.0,836,1.0,ito:ITO_00310,Adversarial process,Test\\ perplexity
0,1,Entity Disambiguation,WNED-WIKI,2017-04,Glonal,77.5,86.98,77.5,0.87,89.1,0.86,ito:ITO_00310,Adversarial process,Micro\\-F1
1,1,Entity Disambiguation,WNED-WIKI,2019-09,confidence-order,89.1,100.0,11.6,0.13,89.1,0.99,ito:ITO_00310,Adversarial process,Micro\\-F1
2,1,Adversarial Attack Detection,Adversarial Attack Detection,2017-04,Glonal,77.5,86.98,77.5,0.87,89.1,0.86,ito:ITO_00310,Adversarial process,Micro\\-F1
3,1,Adversarial Attack Detection,Adversarial Attack Detection,2019-09,confidence-order,89.1,100.0,11.6,0.13,89.1,0.99,ito:ITO_00310,Adversarial process,Micro\\-F1
4,1,Multi-Label Text Classification,RCV1-v2,2020-02,MAGNET,88.5,100.0,88.5,1.0,88.5,0.98,ito:ITO_00310,Adversarial process,Micro\\-F1
5,1,Multi-Label Text Classification,Slashdot,2020-02,MAGNET,56.8,100.0,56.8,1.0,56.8,0.63,ito:ITO_00310,Adversarial process,Micro\\-F1
6,1,Multi-Label Text Classification,Reuters-21578,2020-02,MAGNET,89.9,100.0,89.9,1.0,89.9,1.0,ito:ITO_00310,Adversarial process,Micro\\-F1
0,1,Text Classification,LOCAL DATASET,2018-05,RMDL (15 RDLs,90.79,100.0,90.79,1.0,90.79,1.0,ito:ITO_00310,Adversarial process,Accuracy\\ \\(%\\)
0,1,Text Classification,R8,2018-06,TextEnt-full,91.0,99.24,91.0,0.99,91.7,0.99,ito:ITO_00310,Adversarial process,F\\-measure
1,1,Text Classification,R8,2019-09,NABoE-full,91.7,100.0,0.7,0.01,91.7,1.0,ito:ITO_00310,Adversarial process,F\\-measure
2,1,Text Classification,20NEWS,2018-06,TextEnt-full,83.9,97.33,83.9,0.97,86.2,0.91,ito:ITO_00310,Adversarial process,F\\-measure
3,1,Text Classification,20NEWS,2019-09,NABoE-full,86.2,100.0,2.3,0.03,86.2,0.94,ito:ITO_00310,Adversarial process,F\\-measure
0,1,Emotion Classification,SemEval 2018 Task 1E-c,2018-12,Transformer (finetune),56.1,100.0,56.1,1.0,56.1,1.0,ito:ITO_00310,Adversarial process,Macro\\-F1
0,1,Adversarial Attack,1B Words,2019-02,xyz,0.9,100.0,0.9,1.0,0.9,1.0,ito:ITO_00310,Adversarial process,14\\ gestures\\ accuracy
0,1,Text Classification,IMDb,2019-04,KD-LSTMreg,53.7,100.0,53.7,1.0,53.7,1.0,ito:ITO_00310,Adversarial process,Accuracy\\ \\(10\\ classes\\)
0,1,Multi-Label Text Classification,EUR-Lex,2019-05,LAHA,59.28,72.03,59.28,0.72,82.3,0.64,ito:ITO_00310,Adversarial process,nDCG\\-at\\-5
1,1,Multi-Label Text Classification,EUR-Lex,2019-06,bert-base,82.3,100.0,23.0,0.28,82.3,0.88,ito:ITO_00310,Adversarial process,nDCG\\-at\\-5
2,1,Multi-Label Text Classification,Amazon-12K,2019-05,LAHA,87.57,100.0,87.57,1.0,87.57,0.94,ito:ITO_00310,Adversarial process,nDCG\\-at\\-5
3,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,LAHA,54.65,100.0,54.65,1.0,54.65,0.59,ito:ITO_00310,Adversarial process,nDCG\\-at\\-5
4,1,Multi-Label Text Classification,Wiki-30K,2019-05,LAHA,67.82,100.0,67.82,1.0,67.82,0.73,ito:ITO_00310,Adversarial process,nDCG\\-at\\-5
5,1,Multi-Label Text Classification,AAPD,2019-05,LAHA,83.7,100.0,83.7,1.0,83.7,0.9,ito:ITO_00310,Adversarial process,nDCG\\-at\\-5
6,1,Text Classification,RCV1,2019-06,NLP-Cap,93.11,100.0,93.11,1.0,93.11,1.0,ito:ITO_00310,Adversarial process,nDCG\\-at\\-5
0,1,Multi-Label Text Classification,EUR-Lex,2019-05,LAHA,64.89,91.25,64.89,0.91,71.11,0.7,ito:ITO_00310,Adversarial process,nDCG\\-at\\-3
1,1,Multi-Label Text Classification,EUR-Lex,2019-06,NLP-Cap,71.11,100.0,6.2,0.09,71.11,0.77,ito:ITO_00310,Adversarial process,nDCG\\-at\\-3
2,1,Multi-Label Text Classification,Amazon-12K,2019-05,LAHA,89.13,100.0,89.13,1.0,89.13,0.96,ito:ITO_00310,Adversarial process,nDCG\\-at\\-3
3,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,LAHA,51.7,100.0,51.7,1.0,51.7,0.56,ito:ITO_00310,Adversarial process,nDCG\\-at\\-3
4,1,Multi-Label Text Classification,Wiki-30K,2019-05,LAHA,75.64,100.0,75.64,1.0,75.64,0.82,ito:ITO_00310,Adversarial process,nDCG\\-at\\-3
5,1,Multi-Label Text Classification,AAPD,2019-05,LAHA,80.11,100.0,80.11,1.0,80.11,0.87,ito:ITO_00310,Adversarial process,nDCG\\-at\\-3
6,1,Text Classification,RCV1,2019-06,NLP-Cap,92.47,100.0,92.47,1.0,92.47,1.0,ito:ITO_00310,Adversarial process,nDCG\\-at\\-3
0,1,Multi-Label Text Classification,EUR-Lex,2019-05,LAHA,74.95,93.45,74.95,0.93,80.2,0.77,ito:ITO_00310,Adversarial process,P\\-at\\-1
1,1,Multi-Label Text Classification,EUR-Lex,2019-06,NLP-Cap,80.2,100.0,5.2,0.06,80.2,0.83,ito:ITO_00310,Adversarial process,P\\-at\\-1
2,1,Multi-Label Text Classification,Amazon-12K,2019-05,LAHA,94.87,100.0,94.87,1.0,94.87,0.98,ito:ITO_00310,Adversarial process,P\\-at\\-1
3,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,LAHA,54.38,100.0,54.38,1.0,54.38,0.56,ito:ITO_00310,Adversarial process,P\\-at\\-1
4,1,Multi-Label Text Classification,Wiki-30K,2019-05,LAHA,84.18,100.0,84.18,1.0,84.18,0.87,ito:ITO_00310,Adversarial process,P\\-at\\-1
5,1,Multi-Label Text Classification,AAPD,2019-05,LAHA,84.48,100.0,84.48,1.0,84.48,0.87,ito:ITO_00310,Adversarial process,P\\-at\\-1
6,1,Text Classification,RCV1,2019-06,NLP-Cap,97.05,100.0,97.05,1.0,97.05,1.0,ito:ITO_00310,Adversarial process,P\\-at\\-1
0,1,Multi-Label Text Classification,EUR-Lex,2019-05,LAHA,50.71,73.81,50.71,0.74,68.7,0.74,ito:ITO_00310,Adversarial process,P\\-at\\-5
1,1,Multi-Label Text Classification,EUR-Lex,2019-06,bert-base,68.7,100.0,18.0,0.26,68.7,1.0,ito:ITO_00310,Adversarial process,P\\-at\\-5
2,1,Multi-Label Text Classification,Wiki-30K,2019-05,LAHA,62.87,100.0,62.87,1.0,62.87,0.92,ito:ITO_00310,Adversarial process,P\\-at\\-5
3,1,Multi-Label Text Classification,Amazon-12K,2019-05,LAHA,63.16,100.0,63.16,1.0,63.16,0.92,ito:ITO_00310,Adversarial process,P\\-at\\-5
4,1,Multi-Label Text Classification,AAPD,2019-05,LAHA,41.19,100.0,41.19,1.0,41.19,0.6,ito:ITO_00310,Adversarial process,P\\-at\\-5
5,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,LAHA,25.88,100.0,25.88,1.0,25.88,0.38,ito:ITO_00310,Adversarial process,P\\-at\\-5
6,1,Text Classification,RCV1,2019-06,NLP-Cap,56.33,100.0,56.33,1.0,56.33,0.82,ito:ITO_00310,Adversarial process,P\\-at\\-5
0,1,Multi-Label Text Classification,EUR-Lex,2019-05,LAHA,61.48,93.89,61.48,0.94,65.48,0.76,ito:ITO_00310,Adversarial process,P\\-at\\-3
1,1,Multi-Label Text Classification,EUR-Lex,2019-06,NLP-Cap,65.48,100.0,4.0,0.06,65.48,0.81,ito:ITO_00310,Adversarial process,P\\-at\\-3
2,1,Multi-Label Text Classification,Amazon-12K,2019-05,LAHA,79.16,100.0,79.16,1.0,79.16,0.97,ito:ITO_00310,Adversarial process,P\\-at\\-3
3,1,Multi-Label Text Classification,Kan-Shan Cup,2019-05,LAHA,34.6,100.0,34.6,1.0,34.6,0.43,ito:ITO_00310,Adversarial process,P\\-at\\-3
4,1,Multi-Label Text Classification,Wiki-30K,2019-05,LAHA,73.14,100.0,73.14,1.0,73.14,0.9,ito:ITO_00310,Adversarial process,P\\-at\\-3
5,1,Multi-Label Text Classification,AAPD,2019-05,LAHA,60.72,100.0,60.72,1.0,60.72,0.75,ito:ITO_00310,Adversarial process,P\\-at\\-3
6,1,Text Classification,RCV1,2019-06,NLP-Cap,81.27,100.0,81.27,1.0,81.27,1.0,ito:ITO_00310,Adversarial process,P\\-at\\-3
0,1,Multi-Label Text Classification,EUR-Lex,2019-06,bert-base,79.6,100.0,79.6,1.0,79.6,1.0,ito:ITO_00310,Adversarial process,RP\\-at\\-5
0,1,Multi-Label Text Classification,EUR-Lex,2019-06,bert-base,73.2,100.0,73.2,1.0,73.2,0.83,ito:ITO_00310,Adversarial process,Micro\\ F1
1,1,Text Classification,RCV1,2019-08,HiLAP (bow-CNN),83.3,94.12,83.3,0.94,88.5,0.94,ito:ITO_00310,Adversarial process,Micro\\ F1
2,1,Text Classification,RCV1,2020-02,MAGNET,88.5,100.0,5.2,0.06,88.5,1.0,ito:ITO_00310,Adversarial process,Micro\\ F1
0,1,Text Classification,RCV1,2019-06,NLP-Cap,97.05,100.0,97.05,1.0,97.05,1.0,ito:ITO_00310,Adversarial process,nDCG\\-at\\-1
1,1,Multi-Label Text Classification,EUR-Lex,2019-06,NLP-Cap,80.2,100.0,80.2,1.0,80.2,0.83,ito:ITO_00310,Adversarial process,nDCG\\-at\\-1
0,1,Pulmonary Embolism Detection,PE-CAD FPRED,2019-08,ModelGenesis,88.04,100.0,88.04,1.0,88.04,1.0,ito:ITO_00310,Adversarial process,AUC
1,1,Provable Adversarial Defense,Provable Adversarial Defense,2019-08,ModelGenesis,88.04,100.0,88.04,1.0,88.04,1.0,ito:ITO_00310,Adversarial process,AUC
0,1,Topic Models,20NEWS,2019-08,Bayesian SMM,851.0,100.0,851,1.0,851,1.0,ito:ITO_00310,Adversarial process,PPL
0,1,Text Classification,RCV1,2019-08,HiLAP (bow-CNN),60.1,100.0,60.1,1.0,60.1,1.0,ito:ITO_00310,Adversarial process,Macro\\ F1
0,1,Text Classification,20NEWS,2019-11,SCDV-MS,86.2,100.0,86.2,1.0,86.2,1.0,ito:ITO_00310,Adversarial process,Precision
0,1,Text Classification,20NEWS,2019-11,SCDV-MS,86.18,100.0,86.18,1.0,86.18,1.0,ito:ITO_00310,Adversarial process,Recall
0,1,SQL-to-Text,WikiSQL,2015-11,GGS-NN,35.53,91.17,35.53,0.91,38.97,0.91,ito:ITO_00485,Computer code process,BLEU\\-4
1,1,SQL-to-Text,WikiSQL,2018-04,Graph2Seq-PGE,38.97,100.0,3.4,0.09,38.97,1.0,ito:ITO_00485,Computer code process,BLEU\\-4
0,1,Dimensionality Reduction,1B Words,2016-03,fst,1000000000.0,100.0,1000000000,1.0,1000000000,1.0,ito:ITO_00485,Computer code process,14\\ gestures\\ accuracy
1,1,Code Generation,100 sleep nights of 8 caregivers,2017-05,anv,10.0,100.0,10,1.0,10,0.0,ito:ITO_00485,Computer code process,14\\ gestures\\ accuracy
0,1,Code Generation,Django,2016-03,"lpn (Ling et al., 2016)",62.3,84.53,62.3,0.85,73.7,0.69,ito:ITO_00485,Computer code process,Accuracy
1,1,Code Generation,Django,2018-10,Tranx,73.7,100.0,11.4,0.15,73.7,0.81,ito:ITO_00485,Computer code process,Accuracy
2,1,Feature Selection,MNIST,2019-01,CAE,90.6,100.0,90.6,1.0,90.6,1.0,ito:ITO_00485,Computer code process,Accuracy
3,1,Feature Selection,ISOLET,2019-01,CAE,68.5,100.0,68.5,1.0,68.5,0.76,ito:ITO_00485,Computer code process,Accuracy
4,1,Feature Selection,Fashion-MNIST,2019-01,CAE,67.7,100.0,67.7,1.0,67.7,0.75,ito:ITO_00485,Computer code process,Accuracy
5,1,Feature Selection,Mice Protein,2019-01,CAE,13.4,100.0,13.4,1.0,13.4,0.15,ito:ITO_00485,Computer code process,Accuracy
6,1,Feature Selection,Activity,2019-01,CAE,42.0,100.0,42,1.0,42,0.46,ito:ITO_00485,Computer code process,Accuracy
7,1,Feature Selection,Coil-20,2019-01,CAE,58.6,100.0,58.6,1.0,58.6,0.65,ito:ITO_00485,Computer code process,Accuracy
0,1,Code Generation,WikiSQL,2017-08,"Seq2SQL (Zhong et al., 2017)",59.4,66.59,59.4,0.67,89.2,0.67,ito:ITO_00485,Computer code process,Execution\\ Accuracy
1,1,Code Generation,WikiSQL,2018-03,"PT-MAML (Huang et al., 2018)",68.0,76.23,8.6,0.1,89.2,0.76,ito:ITO_00485,Computer code process,Execution\\ Accuracy
2,1,Code Generation,WikiSQL,2018-04,"STAMP+RL (Sun et al., 2018)+",74.6,83.63,6.6,0.07,89.2,0.84,ito:ITO_00485,Computer code process,Execution\\ Accuracy
3,1,Code Generation,WikiSQL,2018-04,"TypeSQL+TC (Yu et al., 2018)+",82.6,92.6,8.0,0.09,89.2,0.93,ito:ITO_00485,Computer code process,Execution\\ Accuracy
4,1,Code Generation,WikiSQL,2019-10,NL2SQL-RULE,89.2,100.0,6.6,0.07,89.2,1.0,ito:ITO_00485,Computer code process,Execution\\ Accuracy
0,1,Code Generation,WikiSQL,2017-08,"Seq2SQL (Zhong et al., 2017)",48.3,57.71,48.3,0.58,83.7,0.58,ito:ITO_00485,Computer code process,Exact\\ Match\\ Accuracy
1,1,Code Generation,WikiSQL,2018-03,"PT-MAML (Huang et al., 2018)",62.8,75.03,14.5,0.17,83.7,0.75,ito:ITO_00485,Computer code process,Exact\\ Match\\ Accuracy
2,1,Code Generation,WikiSQL,2018-10,Tranx,68.6,81.96,5.8,0.07,83.7,0.82,ito:ITO_00485,Computer code process,Exact\\ Match\\ Accuracy
3,1,Code Generation,WikiSQL,2019-10,NL2SQL-RULE,83.7,100.0,15.1,0.18,83.7,1.0,ito:ITO_00485,Computer code process,Exact\\ Match\\ Accuracy
0,1,Text-To-SQL,WikiSQL,2017-11,SQLNet (Seq2set+CA+WE),71.9,78.15,71.9,0.78,92.0,0.78,ito:ITO_00485,Computer code process,Accuracy\\ \\(anywhere\\)
1,1,Text-To-SQL,WikiSQL,2019-10,NL2SQL-BERT,92.0,100.0,20.1,0.22,92.0,1.0,ito:ITO_00485,Computer code process,Accuracy\\ \\(anywhere\\)
0,1,Text-To-SQL,WikiSQL,2017-11,SQLNet (Seq2set+CA+WE),90.3,93.09,90.3,0.93,97.0,0.93,ito:ITO_00485,Computer code process,Accuracy\\ \\(agg\\)
1,1,Text-To-SQL,WikiSQL,2019-10,NL2SQL-BERT,97.0,100.0,6.7,0.07,97.0,1.0,ito:ITO_00485,Computer code process,Accuracy\\ \\(agg\\)
0,1,Text-To-SQL,WikiSQL,2017-11,SQLNet (Seq2set+CA+WE),90.9,93.71,90.9,0.94,97.0,0.94,ito:ITO_00485,Computer code process,Accuracy\\ \\(sel\\)
1,1,Text-To-SQL,WikiSQL,2019-10,NL2SQL-BERT,97.0,100.0,6.1,0.06,97.0,1.0,ito:ITO_00485,Computer code process,Accuracy\\ \\(sel\\)
0,1,Code Generation,Android Repos,2018-05,Entity Type Model,2.65,100.0,2.65,1.0,2.65,1.0,ito:ITO_00485,Computer code process,Perplexity
0,1,Code Generation,CoNaLa,2018-10,TranX,24.3,100.0,24.3,1.0,24.3,1.0,ito:ITO_00485,Computer code process,BLEU
1,1,Code Generation,CoNaLa-Ext,2018-10,TranX,18.85,100.0,18.85,1.0,18.85,0.78,ito:ITO_00485,Computer code process,BLEU
0,1,Feature Selection,Zoo,2019-05,Zoo,100.0,100.0,100,1.0,100,1.0,ito:ITO_00485,Computer code process,Accuracy\\(10\\-fold\\)
1,1,Feature Selection,Glass identification,2019-05,Glass,75.0,100.0,75,1.0,75,0.75,ito:ITO_00485,Computer code process,Accuracy\\(10\\-fold\\)
0,1,Type prediction,Py150,2020-03,DFSud,98.7,100.0,98.7,1.0,98.7,1.0,ito:ITO_00485,Computer code process,MRR
1,1,Value prediction,Py150,2020-03,DFSud,73.6,100.0,73.6,1.0,73.6,0.75,ito:ITO_00485,Computer code process,MRR
0,1,Common Sense Reasoning,Event2Mind,2018-05,BiRNN 100d,4.22,95.91,4.22,0.96,4.4,0.05,ito:ITO_00506,Reasoning,Test
1,1,Common Sense Reasoning,Event2Mind,2018-05,ConvNet,4.4,100.0,0.2,0.05,4.4,0.05,ito:ITO_00506,Reasoning,Test
2,1,Common Sense Reasoning,SWAG,2018-08,ESIM + ELMo,59.2,68.6,59.2,0.69,86.3,0.69,ito:ITO_00506,Reasoning,Test
3,1,Common Sense Reasoning,SWAG,2018-10,BERT Large,86.3,100.0,27.1,0.31,86.3,1.0,ito:ITO_00506,Reasoning,Test
0,1,Common Sense Reasoning,Event2Mind,2018-05,BiRNN 100d,4.25,95.72,4.25,0.96,4.44,0.05,ito:ITO_00506,Reasoning,Dev
1,1,Common Sense Reasoning,Event2Mind,2018-05,ConvNet,4.44,100.0,0.2,0.05,4.44,0.05,ito:ITO_00506,Reasoning,Dev
2,1,Common Sense Reasoning,SWAG,2018-08,ESIM + ELMo,59.1,68.24,59.1,0.68,86.6,0.68,ito:ITO_00506,Reasoning,Dev
3,1,Common Sense Reasoning,SWAG,2018-10,BERT Base,81.6,94.23,22.5,0.26,86.6,0.94,ito:ITO_00506,Reasoning,Dev
4,1,Common Sense Reasoning,SWAG,2018-10,BERT Large,86.6,100.0,5.0,0.06,86.6,1.0,ito:ITO_00506,Reasoning,Dev
0,1,Common Sense Reasoning,Winograd Schema Challenge,2018-06,Word-LM-partial,62.6,88.54,62.6,0.89,70.7,0.89,ito:ITO_00506,Reasoning,Score
1,1,Common Sense Reasoning,Winograd Schema Challenge,2019-02,GPT-2,70.7,100.0,8.1,0.11,70.7,1.0,ito:ITO_00506,Reasoning,Score
0,1,Common Sense Reasoning,Visual Dialog  v0.9,2018-09,NMN [kottur2018visual],80.1,98.89,80.1,0.99,81.0,0.99,ito:ITO_00506,Reasoning,1\\ in\\ 10\\ R\\-at\\-5
1,1,Common Sense Reasoning,Visual Dialog  v0.9,2019-09,PDUN,81.0,100.0,0.9,0.01,81.0,1.0,ito:ITO_00506,Reasoning,1\\ in\\ 10\\ R\\-at\\-5
0,1,Common Sense Reasoning,Visual Dialog  v0.9,2018-09,NMN [kottur2018visual],88.8,98.12,88.8,0.98,90.5,0.96,ito:ITO_00506,Reasoning,Recall\\-at\\-10
1,1,Common Sense Reasoning,Visual Dialog  v0.9,2019-09,PDUN,90.5,100.0,1.7,0.02,90.5,0.98,ito:ITO_00506,Reasoning,Recall\\-at\\-10
2,1,Common Sense Reasoning,Visual Dialog v1.0,2018-09,NMN [kottur2018visual],88.8,95.9,88.8,0.96,92.6,0.96,ito:ITO_00506,Reasoning,Recall\\-at\\-10
3,1,Common Sense Reasoning,Visual Dialog v1.0,2019-09,PDUN,92.6,100.0,3.8,0.04,92.6,1.0,ito:ITO_00506,Reasoning,Recall\\-at\\-10
0,1,Common Sense Reasoning,CommonsenseQA,2018-11,BERT-LARGE,55.9,86.4,55.9,0.86,64.7,0.7,ito:ITO_00506,Reasoning,Accuracy
1,1,Common Sense Reasoning,CommonsenseQA,2019-06,CAGE-reasoning,64.7,100.0,8.8,0.14,64.7,0.81,ito:ITO_00506,Reasoning,Accuracy
2,1,Common Sense Reasoning,CODAH,2019-04,BERT Large,69.6,100.0,69.6,1.0,69.6,0.88,ito:ITO_00506,Reasoning,Accuracy
3,1,Visual Reasoning,NLVR2 Dev,2019-08,VisualBERT,66.7,89.05,66.7,0.89,74.9,0.84,ito:ITO_00506,Reasoning,Accuracy
4,1,Visual Reasoning,NLVR2 Dev,2019-08,LXMERT (Pre-train + scratch),74.9,100.0,8.2,0.11,74.9,0.94,ito:ITO_00506,Reasoning,Accuracy
5,1,Visual Reasoning,NLVR2 Test,2019-08,LXMERT,76.2,95.85,76.2,0.96,79.5,0.96,ito:ITO_00506,Reasoning,Accuracy
6,1,Visual Reasoning,NLVR2 Test,2019-09,UNITER (Large),79.5,100.0,3.3,0.04,79.5,1.0,ito:ITO_00506,Reasoning,Accuracy
0,1,Visual Reasoning,NLVR,2019-08,VisualBERT,67.4,100.0,67.4,1.0,67.4,1.0,ito:ITO_00506,Reasoning,Accuracy\\ \\(Dev\\)
0,1,Visual Reasoning,NLVR,2019-08,VisualBERT,67.0,100.0,67,1.0,67,1.0,ito:ITO_00506,Reasoning,Accuracy\\ \\(Test\\-P\\)
0,1,Visual Reasoning,NLVR,2019-08,VisualBERT,67.3,100.0,67.3,1.0,67.3,1.0,ito:ITO_00506,Reasoning,Accuracy\\ \\(Test\\-U\\)
0,1,Common Sense Reasoning,CrowdSource QA,2020-02,BERT,0.046,100.0,0.046,1.0,0.046,1.0,ito:ITO_00506,Reasoning,MSE
0,1,Knowledge Graphs,FB15k,2017-02,COMPLEX,0.587,100.0,0.587,1.0,0.587,1.0,ito:ITO_00528,Knowledge base process,MRR
1,1,Knowledge graph process,FB15k,2017-02,COMPLEX,0.587,100.0,0.587,1.0,0.587,1.0,ito:ITO_00528,Knowledge base process,MRR
2,1,Knowledge Graph Completion,FB15k-237,2019-05,KBAT,0.518,100.0,0.518,1.0,0.518,0.88,ito:ITO_00528,Knowledge base process,MRR
0,1,Open Knowledge Graph Canonicalization,Noun Phrase Canonicalization,2019-02,CESI,99.9,100.0,99.9,1.0,99.9,1.0,ito:ITO_00528,Knowledge base process,ReVerb45k
0,1,Open Knowledge Graph Canonicalization,Noun Phrase Canonicalization,2019-02,CESI,99.8,100.0,99.8,1.0,99.8,1.0,ito:ITO_00528,Knowledge base process,Ambiguous\\ dataset
0,1,Open Knowledge Graph Canonicalization,Noun Phrase Canonicalization,2019-02,CESI,98.2,100.0,98.2,1.0,98.2,1.0,ito:ITO_00528,Knowledge base process,Base\\ Dataset
0,1,Knowledge Graph Completion,MovieLens 1M,2019-02,KTUP (soft),48.9,100.0,48.9,1.0,48.9,0.78,ito:ITO_00528,Knowledge base process,Hits\\-at\\-10
1,1,Knowledge Graph Completion,DBbook2014,2019-02,KTUP (soft),60.75,100.0,60.75,1.0,60.75,0.97,ito:ITO_00528,Knowledge base process,Hits\\-at\\-10
2,1,Knowledge Graph Completion,WN18RR,2019-05,KBAT,0.581,100.0,0.581,1.0,0.581,0.01,ito:ITO_00528,Knowledge base process,Hits\\-at\\-10
3,1,Knowledge Graph Completion,FB15k-237,2019-05,KBAT,0.626,1.0,0.626,0.01,62.6,0.01,ito:ITO_00528,Knowledge base process,Hits\\-at\\-10
4,1,Knowledge Graph Completion,FB15k-237,2019-06,KBGAT,62.6,100.0,62.0,0.99,62.6,1.0,ito:ITO_00528,Knowledge base process,Hits\\-at\\-10
0,1,Knowledge Graph Completion,MovieLens 1M,2019-02,KTUP (soft),527.0,100.0,527,1.0,527,1.0,ito:ITO_00528,Knowledge base process,Mean\\ Rank
1,1,Knowledge Graph Completion,DBbook2014,2019-02,KTUP (soft),499.0,100.0,499,1.0,499,0.95,ito:ITO_00528,Knowledge base process,Mean\\ Rank
0,1,Knowledge Graph Completion,WN18RR,2019-05,KBAT,0.361,100.0,0.361,1.0,0.361,0.01,ito:ITO_00528,Knowledge base process,Hits\\-at\\-1
1,1,Knowledge Graph Completion,FB15k-237,2019-05,KBAT,0.46,1.0,0.46,0.01,46.0,0.01,ito:ITO_00528,Knowledge base process,Hits\\-at\\-1
2,1,Knowledge Graph Completion,FB15k-237,2019-06,KBAT,46.0,100.0,45.5,0.99,46.0,1.0,ito:ITO_00528,Knowledge base process,Hits\\-at\\-1
0,1,Knowledge Graph Completion,WN18RR,2019-05,KBAT,0.483,93.6,0.483,0.94,0.516,0.01,ito:ITO_00528,Knowledge base process,Hits\\-at\\-3
1,1,Knowledge Graph Completion,WN18RR,2019-11,HAKE,0.516,100.0,0.0,0.0,0.516,0.01,ito:ITO_00528,Knowledge base process,Hits\\-at\\-3
2,1,Knowledge Graph Completion,FB15k-237,2019-05,KBAT,0.54,1.0,0.54,0.01,54.0,0.01,ito:ITO_00528,Knowledge base process,Hits\\-at\\-3
3,1,Knowledge Graph Completion,FB15k-237,2019-06,KBGAT,54.0,100.0,53.5,0.99,54.0,1.0,ito:ITO_00528,Knowledge base process,Hits\\-at\\-3
0,1,Knowledge Graph Completion,FB15k-237,2019-05,KBAT,0.21,100.0,0.21,1.0,0.21,1.0,ito:ITO_00528,Knowledge base process,MR
0,1,Sparse Learning,CINIC-10,2020-03,Resnet18,92.43,100.0,92.43,1.0,92.43,1.0,ito:ITO_00528,Knowledge base process,Sparsity
1,1,Inductive knowledge graph completion,Inductive knowledge graph completion,2020-03,Resnet18,92.43,100.0,92.43,1.0,92.43,1.0,ito:ITO_00528,Knowledge base process,Sparsity
0,1,3D Human Pose Estimation,HumanEva-I,2010-03,TGP,48.7,100.0,48.7,1.0,48.7,1.0,ito:ITO_00600,Robotics process,Mean\\ Reconstruction\\ Error\\ \\(mm\\)
0,1,Skeleton Based Action Recognition,UWA3D,2012-07,HOJ3D,17.7,21.74,17.7,0.22,81.4,0.18,ito:ITO_00600,Robotics process,Accuracy
1,1,Skeleton Based Action Recognition,UWA3D,2017-08,ESV (Synthesized + Pre-trained),73.8,90.66,56.1,0.69,81.4,0.74,ito:ITO_00600,Robotics process,Accuracy
2,1,Skeleton Based Action Recognition,UWA3D,2018-04,VA-fusion (aug.),81.4,100.0,7.6,0.09,81.4,0.82,ito:ITO_00600,Robotics process,Accuracy
3,1,Skeleton Based Action Recognition,CAD-120,2012-10,KGS,86.0,96.3,86.0,0.96,89.3,0.86,ito:ITO_00600,Robotics process,Accuracy
4,1,Skeleton Based Action Recognition,CAD-120,2013-02,All Features (w ground truth),89.3,100.0,3.3,0.04,89.3,0.89,ito:ITO_00600,Robotics process,Accuracy
5,1,Hand Gesture Recognition,Cambridge,2013-03,Sanin et al. [sanin2013spatio],93.0,94.68,93.0,0.95,98.23,0.93,ito:ITO_00600,Robotics process,Accuracy
6,1,Hand Gesture Recognition,Cambridge,2019-01,Key Frames + Feature Fusion,98.23,100.0,5.2,0.05,98.23,0.98,ito:ITO_00600,Robotics process,Accuracy
7,1,Hand Gesture Recognition,VIVA Hand Gestures Dataset,2014-06,Two Stream CNNs,68.0,79.0,68.0,0.79,86.08,0.68,ito:ITO_00600,Robotics process,Accuracy
8,1,Hand Gesture Recognition,VIVA Hand Gestures Dataset,2017-05,I3D,83.1,96.54,15.1,0.18,86.08,0.83,ito:ITO_00600,Robotics process,Accuracy
9,1,Hand Gesture Recognition,VIVA Hand Gestures Dataset,2018-12,MTUT,86.08,100.0,3.0,0.03,86.08,0.86,ito:ITO_00600,Robotics process,Accuracy
10,1,Skeleton Based Action Recognition,UT-Kinect,2014-06,Lie Group,97.1,98.58,97.1,0.99,98.5,0.97,ito:ITO_00600,Robotics process,Accuracy
11,1,Skeleton Based Action Recognition,UT-Kinect,2018-06,DPRL,98.5,100.0,1.4,0.01,98.5,0.99,ito:ITO_00600,Robotics process,Accuracy
12,1,Skeleton Based Action Recognition,Florence 3D,2014-06,Lie Group,90.9,91.73,90.9,0.92,99.1,0.91,ito:ITO_00600,Robotics process,Accuracy
13,1,Skeleton Based Action Recognition,Florence 3D,2016-06,Rolling Rotations (FTP),91.4,92.23,0.5,0.01,99.1,0.92,ito:ITO_00600,Robotics process,Accuracy
14,1,Skeleton Based Action Recognition,Florence 3D,2018-02,Deep STGC_K,99.1,100.0,7.7,0.08,99.1,0.99,ito:ITO_00600,Robotics process,Accuracy
15,1,Synthetic-to-Real Translation,Syn2Real-C,2015-05,DANN,57.4,71.93,57.4,0.72,79.8,0.58,ito:ITO_00600,Robotics process,Accuracy
16,1,Synthetic-to-Real Translation,Syn2Real-C,2017-11,ADR,74.8,93.73,17.4,0.22,79.8,0.75,ito:ITO_00600,Robotics process,Accuracy
17,1,Synthetic-to-Real Translation,Syn2Real-C,2019-11,DADA,79.8,100.0,5.0,0.06,79.8,0.8,ito:ITO_00600,Robotics process,Accuracy
18,1,Constrained Lip-synchronization,Constrained Lip-synchronization,2015-09,GCN-FP,70.3,91.05,70.3,0.91,77.21,0.7,ito:ITO_00600,Robotics process,Accuracy
19,1,Constrained Lip-synchronization,Constrained Lip-synchronization,2015-11,DCNN,73.1,94.68,2.8,0.04,77.21,0.73,ito:ITO_00600,Robotics process,Accuracy
20,1,Constrained Lip-synchronization,Constrained Lip-synchronization,2019-01,LanczosNet,73.4,95.07,0.3,0.0,77.21,0.74,ito:ITO_00600,Robotics process,Accuracy
21,1,Constrained Lip-synchronization,Constrained Lip-synchronization,2019-06,Truncated Krylov,77.21,100.0,3.8,0.05,77.21,0.77,ito:ITO_00600,Robotics process,Accuracy
22,1,3D Object Classification,ModelNet10,2016-04,ORION,93.8,100.0,93.8,1.0,93.8,0.94,ito:ITO_00600,Robotics process,Accuracy
23,1,Surgical Skills Evaluation,MISTIC-SIL,2016-06,Bidir. LSTM,0.895,100.0,0.895,1.0,0.895,0.01,ito:ITO_00600,Robotics process,Accuracy
24,1,Handwritten Word Generation,Handwritten Word Generation,2016-06,Bidir. LSTM,0.895,100.0,0.895,1.0,0.895,0.01,ito:ITO_00600,Robotics process,Accuracy
25,1,Surgical Skills Evaluation,JIGSAWS,2016-06,Bidir. LSTM,0.833,85.0,0.833,0.85,0.98,0.01,ito:ITO_00600,Robotics process,Accuracy
26,1,Surgical Skills Evaluation,JIGSAWS,2018-06,CNN,0.98,100.0,0.1,0.1,0.98,0.01,ito:ITO_00600,Robotics process,Accuracy
27,1,Zero-Shot Text-to-Image Generation,Zero-Shot Text-to-Image Generation,2016-06,Bidir. LSTM,0.833,85.0,0.833,0.85,0.98,0.01,ito:ITO_00600,Robotics process,Accuracy
28,1,Zero-Shot Text-to-Image Generation,Zero-Shot Text-to-Image Generation,2018-06,CNN,0.98,100.0,0.1,0.1,0.98,0.01,ito:ITO_00600,Robotics process,Accuracy
29,1,Skeleton Based Action Recognition,SBU,2016-06,ChebyNet,96.0,96.95,96.0,0.97,99.02,0.96,ito:ITO_00600,Robotics process,Accuracy
30,1,Skeleton Based Action Recognition,SBU,2017-03,Joint Line Distance,99.02,100.0,3.0,0.03,99.02,0.99,ito:ITO_00600,Robotics process,Accuracy
31,1,Node Classification,Wiki-Vote,2016-09,"GCN (Kipf and Welling, 2017)",32.9,32.97,32.9,0.33,99.8,0.33,ito:ITO_00600,Robotics process,Accuracy
32,1,Node Classification,Wiki-Vote,2016-09,"GCN_cheby (Kipf and Welling, 2017)",49.5,49.6,16.6,0.17,99.8,0.5,ito:ITO_00600,Robotics process,Accuracy
33,1,Node Classification,Wiki-Vote,2017-10,"GAT (Velickovic et al., 2018)",59.4,59.52,9.9,0.1,99.8,0.6,ito:ITO_00600,Robotics process,Accuracy
34,1,Node Classification,Wiki-Vote,2019-06,DEMO-Net(weight),99.8,100.0,40.4,0.4,99.8,1.0,ito:ITO_00600,Robotics process,Accuracy
35,1,Transparent Object Depth Estimation,Transparent Object Depth Estimation,2016-09,"GCN (Kipf and Welling, 2017)",32.9,32.97,32.9,0.33,99.8,0.33,ito:ITO_00600,Robotics process,Accuracy
36,1,Transparent Object Depth Estimation,Transparent Object Depth Estimation,2016-09,"GCN_cheby (Kipf and Welling, 2017)",49.5,49.6,16.6,0.17,99.8,0.5,ito:ITO_00600,Robotics process,Accuracy
37,1,Transparent Object Depth Estimation,Transparent Object Depth Estimation,2017-10,"GAT (Velickovic et al., 2018)",59.4,59.52,9.9,0.1,99.8,0.6,ito:ITO_00600,Robotics process,Accuracy
38,1,Transparent Object Depth Estimation,Transparent Object Depth Estimation,2019-06,DEMO-Net(weight),99.8,100.0,40.4,0.4,99.8,1.0,ito:ITO_00600,Robotics process,Accuracy
39,1,Skeleton Based Action Recognition,SYSU 3D,2016-12,Dynamic Skeletons,75.5,86.88,75.5,0.87,86.9,0.76,ito:ITO_00600,Robotics process,Accuracy
40,1,Skeleton Based Action Recognition,SYSU 3D,2017-03,VA-LSTM,77.5,89.18,2.0,0.02,86.9,0.78,ito:ITO_00600,Robotics process,Accuracy
41,1,Skeleton Based Action Recognition,SYSU 3D,2018-04,VA-fusion (aug.),86.7,99.77,9.2,0.11,86.9,0.87,ito:ITO_00600,Robotics process,Accuracy
42,1,Skeleton Based Action Recognition,SYSU 3D,2019-04,SGN,86.9,100.0,0.2,0.0,86.9,0.87,ito:ITO_00600,Robotics process,Accuracy
43,1,Hand Gesture Recognition,ChaLearn val,2017-01,Wang et al.,39.23,68.34,39.23,0.68,57.4,0.39,ito:ITO_00600,Robotics process,Accuracy
44,1,Hand Gesture Recognition,ChaLearn val,2018-04,8-MFFs-3f1c (5 crop),57.4,100.0,18.2,0.32,57.4,0.58,ito:ITO_00600,Robotics process,Accuracy
45,1,Node Classification,AIFB,2017-03,R-GCN,95.83,100.0,95.83,1.0,95.83,0.96,ito:ITO_00600,Robotics process,Accuracy
46,1,Unconstrained Lip-synchronization,Unconstrained Lip-synchronization,2017-03,R-GCN,95.83,100.0,95.83,1.0,95.83,0.96,ito:ITO_00600,Robotics process,Accuracy
47,1,3D Object Classification,ModelNet40,2017-04,ECC (12 votes),83.2,100.0,83.2,1.0,83.2,0.83,ito:ITO_00600,Robotics process,Accuracy
48,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2017-04,Res-TCN,20.3,52.59,20.3,0.53,38.6,0.2,ito:ITO_00600,Robotics process,Accuracy
49,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2018-01,ST-GCN,30.7,79.53,10.4,0.27,38.6,0.31,ito:ITO_00600,Robotics process,Accuracy
50,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2018-05,2s-AGCN,36.1,93.52,5.4,0.14,38.6,0.36,ito:ITO_00600,Robotics process,Accuracy
51,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2018-11,SLnL-rFA,36.6,94.82,0.5,0.01,38.6,0.37,ito:ITO_00600,Robotics process,Accuracy
52,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-06,DGNN,36.9,95.6,0.3,0.01,38.6,0.37,ito:ITO_00600,Robotics process,Accuracy
53,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-11,GCN-NAS,37.1,96.11,0.2,0.01,38.6,0.37,ito:ITO_00600,Robotics process,Accuracy
54,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2019-12,MS-AAGCN,37.8,97.93,0.7,0.02,38.6,0.38,ito:ITO_00600,Robotics process,Accuracy
55,1,Skeleton Based Action Recognition,Kinetics-Skeleton dataset,2020-03,2s-AGCN+TEM,38.6,100.0,0.8,0.02,38.6,0.39,ito:ITO_00600,Robotics process,Accuracy
56,1,Hand Gesture Recognition,EgoGesture,2017-05,I3D,92.78,98.67,92.78,0.99,94.03,0.93,ito:ITO_00600,Robotics process,Accuracy
57,1,Hand Gesture Recognition,EgoGesture,2018-12,MTUT,93.87,99.83,1.1,0.01,94.03,0.94,ito:ITO_00600,Robotics process,Accuracy
58,1,Hand Gesture Recognition,EgoGesture,2019-01,ResNeXt-101,94.03,100.0,0.2,0.0,94.03,0.94,ito:ITO_00600,Robotics process,Accuracy
59,1,Semantic Segmentation,S3DIS,2017-06,PointNet++,91.9,100.0,91.9,1.0,91.9,0.92,ito:ITO_00600,Robotics process,Accuracy
60,1,Hand Gesture Recognition,SmartWatch,2017-07,F-BGRU,97.4,100.0,97.4,1.0,97.4,0.98,ito:ITO_00600,Robotics process,Accuracy
61,1,Hand Gesture Recognition,MGB,2017-07,F-BLSTM,98.04,100.0,98.04,1.0,98.04,0.98,ito:ITO_00600,Robotics process,Accuracy
62,1,Hand Gesture Recognition,BUAA,2017-07,F-BGRU,99.25,100.0,99.25,1.0,99.25,0.99,ito:ITO_00600,Robotics process,Accuracy
63,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2017-07,CRN,40.4,57.14,40.4,0.57,70.7,0.4,ito:ITO_00600,Robotics process,Accuracy
64,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2017-11,pix2pixHD,45.8,64.78,5.4,0.08,70.7,0.46,ito:ITO_00600,Robotics process,Accuracy
65,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2019-03,SPADE,67.9,96.04,22.1,0.31,70.7,0.68,ito:ITO_00600,Robotics process,Accuracy
66,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2019-10,CC-FPSE,70.7,100.0,2.8,0.04,70.7,0.71,ito:ITO_00600,Robotics process,Accuracy
67,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2017-07,CRN,68.6,82.75,68.6,0.83,82.9,0.69,ito:ITO_00600,Robotics process,Accuracy
68,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2017-11,pix2pixHD,71.6,86.37,3.0,0.04,82.9,0.72,ito:ITO_00600,Robotics process,Accuracy
69,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2018-04,SIMS,74.7,90.11,3.1,0.04,82.9,0.75,ito:ITO_00600,Robotics process,Accuracy
70,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2019-03,SPADE,82.9,100.0,8.2,0.1,82.9,0.83,ito:ITO_00600,Robotics process,Accuracy
71,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2017-07,CRN,68.8,82.99,68.8,0.83,82.9,0.69,ito:ITO_00600,Robotics process,Accuracy
72,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2017-11,pix2pixHD,69.2,83.47,0.4,0.0,82.9,0.69,ito:ITO_00600,Robotics process,Accuracy
73,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2019-03,SPADE,79.9,96.38,10.7,0.13,82.9,0.8,ito:ITO_00600,Robotics process,Accuracy
74,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2019-10,CC-FPSE,82.9,100.0,3.0,0.04,82.9,0.83,ito:ITO_00600,Robotics process,Accuracy
75,1,Skeleton Based Action Recognition,N-UCLA,2018-02,Glimpse Clouds,87.6,94.7,87.6,0.95,92.5,0.88,ito:ITO_00600,Robotics process,Accuracy
76,1,Skeleton Based Action Recognition,N-UCLA,2018-04,VA-fusion (aug.),88.1,95.24,0.5,0.01,92.5,0.88,ito:ITO_00600,Robotics process,Accuracy
77,1,Skeleton Based Action Recognition,N-UCLA,2018-12,Action Machine,92.3,99.78,4.2,0.05,92.5,0.92,ito:ITO_00600,Robotics process,Accuracy
78,1,Skeleton Based Action Recognition,N-UCLA,2019-04,SGN,92.5,100.0,0.2,0.0,92.5,0.93,ito:ITO_00600,Robotics process,Accuracy
79,1,Hand Gesture Recognition,NVGesture,2018-04,8-MFFs-3f1c,84.7,97.43,84.7,0.97,86.93,0.85,ito:ITO_00600,Robotics process,Accuracy
80,1,Hand Gesture Recognition,NVGesture,2018-12,MTUT,86.93,100.0,2.2,0.03,86.93,0.87,ito:ITO_00600,Robotics process,Accuracy
81,1,Hand Gesture Recognition,ChaLean test,2018-04,8-MFFs-3f1c,56.7,100.0,56.7,1.0,56.7,0.57,ito:ITO_00600,Robotics process,Accuracy
82,1,Unsupervised Semantic Segmentation,Potsdam-3,2018-07,IIC,45.4,100.0,45.4,1.0,45.4,0.45,ito:ITO_00600,Robotics process,Accuracy
83,1,Unsupervised Semantic Segmentation,COCO-Stuff-15,2018-07,IIC,27.7,100.0,27.7,1.0,27.7,0.28,ito:ITO_00600,Robotics process,Accuracy
84,1,Unsupervised Semantic Segmentation,Potsdam,2018-07,IIC,65.1,100.0,65.1,1.0,65.1,0.65,ito:ITO_00600,Robotics process,Accuracy
85,1,Unsupervised Semantic Segmentation,COCO-Stuff-3,2018-07,IIC,72.3,100.0,72.3,1.0,72.3,0.72,ito:ITO_00600,Robotics process,Accuracy
86,1,Hand Gesture Recognition,Northwestern University,2019-01,Key Frames + Feature Fusion,96.89,100.0,96.89,1.0,96.89,0.97,ito:ITO_00600,Robotics process,Accuracy
87,1,Skeleton Based Action Recognition,MSR Action3D,2019-06,HDM-BG,86.1,100.0,86.1,1.0,86.1,0.86,ito:ITO_00600,Robotics process,Accuracy
88,1,Skeleton Based Action Recognition,UPenn Action,2019-06,HDM-BG,93.4,94.06,93.4,0.94,99.3,0.94,ito:ITO_00600,Robotics process,Accuracy
89,1,Skeleton Based Action Recognition,UPenn Action,2020-01,UniPose-LSTM,99.3,100.0,5.9,0.06,99.3,0.99,ito:ITO_00600,Robotics process,Accuracy
90,1,Hand Gesture Recognition,DHG-28,2019-07,DG-STA,88.0,100.0,88,1.0,88,0.88,ito:ITO_00600,Robotics process,Accuracy
91,1,Hand Gesture Recognition,DHG-14,2019-07,DG-STA,91.9,100.0,91.9,1.0,91.9,0.92,ito:ITO_00600,Robotics process,Accuracy
92,1,Node Classification,Coauthor CS,2019-09,GraphMix,91.83,96.87,91.83,0.97,94.8,0.92,ito:ITO_00600,Robotics process,Accuracy
93,1,Node Classification,Coauthor CS,2019-10,GCN (PPR Diffusion),93.01,98.11,1.2,0.01,94.8,0.93,ito:ITO_00600,Robotics process,Accuracy
94,1,Node Classification,Coauthor CS,2020-02,GCN-LPA,94.8,100.0,1.8,0.02,94.8,0.95,ito:ITO_00600,Robotics process,Accuracy
95,1,Face Age Editing,Face Age Editing,2019-09,GraphMix,91.83,96.87,91.83,0.97,94.8,0.92,ito:ITO_00600,Robotics process,Accuracy
96,1,Face Age Editing,Face Age Editing,2019-10,GCN (PPR Diffusion),93.01,98.11,1.2,0.01,94.8,0.93,ito:ITO_00600,Robotics process,Accuracy
97,1,Face Age Editing,Face Age Editing,2020-02,GCN-LPA,94.8,100.0,1.8,0.02,94.8,0.95,ito:ITO_00600,Robotics process,Accuracy
0,1,Robotic Grasping,Cornell Grasp Dataset,2013-01,Fast Search,60.5,61.92,60.5,0.62,97.7,0.62,ito:ITO_00600,Robotics process,5\\ fold\\ cross\\ validation
1,1,Robotic Grasping,Cornell Grasp Dataset,2014-12,"AlexNet, MultiGrasp",88.0,90.07,27.5,0.28,97.7,0.9,ito:ITO_00600,Robotics process,5\\ fold\\ cross\\ validation
2,1,Robotic Grasping,Cornell Grasp Dataset,2016-11,Multi-Modal Grasp Predictor,89.21,91.31,1.2,0.01,97.7,0.91,ito:ITO_00600,Robotics process,5\\ fold\\ cross\\ validation
3,1,Robotic Grasping,Cornell Grasp Dataset,2018-10,ResNet50 multi-grasp predictor,96.0,98.26,6.8,0.07,97.7,0.98,ito:ITO_00600,Robotics process,5\\ fold\\ cross\\ validation
4,1,Robotic Grasping,Cornell Grasp Dataset,2019-09,GR-ConvNet,97.7,100.0,1.7,0.02,97.7,1.0,ito:ITO_00600,Robotics process,5\\ fold\\ cross\\ validation
0,1,3D Human Pose Estimation,Human3.6M,2013-12,LinKDE,162.14,100.0,162.14,1.0,162.14,1.0,ito:ITO_00600,Robotics process,Average\\ MPJPE\\ \\(mm\\)
1,1,Monocular 3D Human Pose Estimation,Human3.6M,2015-11,Sparseness Meets Deepness,113.0,98.18,113.0,0.98,115.1,0.7,ito:ITO_00600,Robotics process,Average\\ MPJPE\\ \\(mm\\)
2,1,Monocular 3D Human Pose Estimation,Human3.6M,2018-05,Ordinal Depth Supervision,115.1,100.0,2.1,0.02,115.1,0.71,ito:ITO_00600,Robotics process,Average\\ MPJPE\\ \\(mm\\)
3,1,3D Human Pose Estimation,Total Capture,2016-01,Tri-CPM,99.0,92.52,99.0,0.93,107.0,0.61,ito:ITO_00600,Robotics process,Average\\ MPJPE\\ \\(mm\\)
4,1,3D Human Pose Estimation,Total Capture,2017-09,PVH,107.0,100.0,8.0,0.07,107.0,0.66,ito:ITO_00600,Robotics process,Average\\ MPJPE\\ \\(mm\\)
5,1,Weakly-supervised 3D Human Pose Estimation,Human3.6M,2017-01,Tome et al.,88.4,74.66,88.4,0.75,118.4,0.55,ito:ITO_00600,Robotics process,Average\\ MPJPE\\ \\(mm\\)
6,1,Weakly-supervised 3D Human Pose Estimation,Human3.6M,2017-04,Pavlakos et al.,118.4,100.0,30.0,0.25,118.4,0.73,ito:ITO_00600,Robotics process,Average\\ MPJPE\\ \\(mm\\)
0,1,Latent Variable Models,200k Short Texts for Humor Detection,2014-01,meto,0.987,100.0,0.987,1.0,0.987,0.03,ito:ITO_00600,Robotics process,10\\-20%\\ Mask\\ PSNR
1,1,Grasp Contact Prediction,Grasp Contact Prediction,2014-01,meto,0.987,100.0,0.987,1.0,0.987,0.03,ito:ITO_00600,Robotics process,10\\-20%\\ Mask\\ PSNR
2,1,Image Inpainting,Paris StreetView,2019-05,Coherent Semantic Attention for Image Inpainting,32.67,100.0,32.67,1.0,32.67,1.0,ito:ITO_00600,Robotics process,10\\-20%\\ Mask\\ PSNR
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,60.0,78.95,60,0.79,76,0.79,ito:ITO_00600,Robotics process,Accuracy\\ \\(CS\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-04,Res-TCN,63.0,82.89,3,0.04,76,0.83,ito:ITO_00600,Robotics process,Accuracy\\ \\(CS\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2018-01,ST-GCN,71.0,93.42,8,0.11,76,0.93,ito:ITO_00600,Robotics process,Accuracy\\ \\(CS\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,76.0,100.0,5,0.07,76,1.0,ito:ITO_00600,Robotics process,Accuracy\\ \\(CS\\)
0,1,Semantic Segmentation,PASCAL VOC 2012 test,2014-07,SDS,51.6,57.98,51.6,0.58,89.0,0.56,ito:ITO_00600,Robotics process,Mean\\ IoU
1,1,Semantic Segmentation,PASCAL VOC 2012 test,2014-11,FCN (VGG-16),62.2,69.89,10.6,0.12,89.0,0.68,ito:ITO_00600,Robotics process,Mean\\ IoU
2,1,Semantic Segmentation,PASCAL VOC 2012 test,2014-12,DeepLab-MSc-CRF-LargeFOV (VGG-16),71.6,80.45,9.4,0.11,89.0,0.78,ito:ITO_00600,Robotics process,Mean\\ IoU
3,1,Semantic Segmentation,PASCAL VOC 2012 test,2015-02,CRF-RNN,74.7,83.93,3.1,0.03,89.0,0.81,ito:ITO_00600,Robotics process,Mean\\ IoU
4,1,Semantic Segmentation,PASCAL VOC 2012 test,2016-03,CentraleSupelec Deep G-CRF,80.2,90.11,5.5,0.06,89.0,0.87,ito:ITO_00600,Robotics process,Mean\\ IoU
5,1,Semantic Segmentation,PASCAL VOC 2012 test,2016-11,Multipath-RefineNet,84.2,94.61,4.0,0.04,89.0,0.91,ito:ITO_00600,Robotics process,Mean\\ IoU
6,1,Semantic Segmentation,PASCAL VOC 2012 test,2016-11,ResNet-38 MS COCO,84.9,95.39,0.7,0.01,89.0,0.92,ito:ITO_00600,Robotics process,Mean\\ IoU
7,1,Semantic Segmentation,PASCAL VOC 2012 test,2016-12,PSPNet,85.4,95.96,0.5,0.01,89.0,0.93,ito:ITO_00600,Robotics process,Mean\\ IoU
8,1,Semantic Segmentation,PASCAL VOC 2012 test,2017-06,DeepLabv3-JFT,86.9,97.64,1.5,0.02,89.0,0.94,ito:ITO_00600,Robotics process,Mean\\ IoU
9,1,Semantic Segmentation,PASCAL VOC 2012 test,2018-02,DeepLabv3+ (Xception-65-JFT),89.0,100.0,2.1,0.02,89.0,0.97,ito:ITO_00600,Robotics process,Mean\\ IoU
10,1,Semantic Segmentation,SkyScapes-Lane,2014-11,FCN8s (ResNet-50),13.74,26.98,13.74,0.27,50.93,0.15,ito:ITO_00600,Robotics process,Mean\\ IoU
11,1,Semantic Segmentation,SkyScapes-Lane,2019-10,SkyScapesNet-Lane,50.93,100.0,37.2,0.73,50.93,0.55,ito:ITO_00600,Robotics process,Mean\\ IoU
12,1,Semantic Segmentation,SkyScapes-Dense,2014-11,FCN8s (ResNet-50),33.06,82.38,33.06,0.82,40.13,0.36,ito:ITO_00600,Robotics process,Mean\\ IoU
13,1,Semantic Segmentation,SkyScapes-Dense,2018-02,DeepLabv3+,38.2,95.19,5.1,0.13,40.13,0.41,ito:ITO_00600,Robotics process,Mean\\ IoU
14,1,Semantic Segmentation,SkyScapes-Dense,2019-10,SkyScapesNet-Dense,40.13,100.0,1.9,0.05,40.13,0.44,ito:ITO_00600,Robotics process,Mean\\ IoU
15,1,Semantic Segmentation,CamVid,2014-12,DeepLab-MSc-CRF-LargeFOV,61.6,75.4,61.6,0.75,81.7,0.67,ito:ITO_00600,Robotics process,Mean\\ IoU
16,1,Semantic Segmentation,CamVid,2015-11,Dilated Convolutions,65.3,79.93,3.7,0.05,81.7,0.71,ito:ITO_00600,Robotics process,Mean\\ IoU
17,1,Semantic Segmentation,CamVid,2016-11,FC-DenseNet103,66.9,81.88,1.6,0.02,81.7,0.73,ito:ITO_00600,Robotics process,Mean\\ IoU
18,1,Semantic Segmentation,CamVid,2016-12,PSPNet,69.1,84.58,2.2,0.03,81.7,0.75,ito:ITO_00600,Robotics process,Mean\\ IoU
19,1,Semantic Segmentation,CamVid,2018-12,DeepLabV3Plus + SDCNetAug,81.7,100.0,12.6,0.15,81.7,0.89,ito:ITO_00600,Robotics process,Mean\\ IoU
20,1,Scene Segmentation,SUN-RGBD,2014-12,DeepLab-LargeFOV,32.08,95.82,32.08,0.96,33.48,0.35,ito:ITO_00600,Robotics process,Mean\\ IoU
21,1,Scene Segmentation,SUN-RGBD,2019-08,Index Network,33.48,100.0,1.4,0.04,33.48,0.36,ito:ITO_00600,Robotics process,Mean\\ IoU
22,1,Semantic Segmentation,PASCAL VOC 2011,2016-11,DLDL-8s+CRF,67.6,100.0,67.6,1.0,67.6,0.73,ito:ITO_00600,Robotics process,Mean\\ IoU
23,1,Semantic Segmentation,PASCAL VOC 2012,2016-11,DLDL-8s+CRF,67.1,100.0,67.1,1.0,67.1,0.73,ito:ITO_00600,Robotics process,Mean\\ IoU
24,1,Semantic Segmentation,NYU Depth v2,2016-11,RefineNet (ResNet-101),40.6,91.44,40.6,0.91,44.4,0.44,ito:ITO_00600,Robotics process,Mean\\ IoU
25,1,Semantic Segmentation,NYU Depth v2,2019-08,Asymmetric ALNN,44.4,100.0,3.8,0.09,44.4,0.48,ito:ITO_00600,Robotics process,Mean\\ IoU
26,1,Semantic Segmentation,S3DIS,2016-12,PointNet,47.6,67.42,47.6,0.67,70.6,0.52,ito:ITO_00600,Robotics process,Mean\\ IoU
27,1,Semantic Segmentation,S3DIS,2017-11,SPG,62.1,87.96,14.5,0.21,70.6,0.67,ito:ITO_00600,Robotics process,Mean\\ IoU
28,1,Semantic Segmentation,S3DIS,2018-12,PointCNN,65.4,92.63,3.3,0.05,70.6,0.71,ito:ITO_00600,Robotics process,Mean\\ IoU
29,1,Semantic Segmentation,S3DIS,2019-04,ConvPoint,68.2,96.6,2.8,0.04,70.6,0.74,ito:ITO_00600,Robotics process,Mean\\ IoU
30,1,Semantic Segmentation,S3DIS,2019-04,KPConv,70.6,100.0,2.4,0.03,70.6,0.77,ito:ITO_00600,Robotics process,Mean\\ IoU
31,1,Semantic Segmentation,ShapeNet,2017-06,PointNet++,84.6,98.6,84.6,0.99,85.8,0.92,ito:ITO_00600,Robotics process,Mean\\ IoU
32,1,Semantic Segmentation,ShapeNet,2017-11,SGPN,85.8,100.0,1.2,0.01,85.8,0.93,ito:ITO_00600,Robotics process,Mean\\ IoU
33,1,Semantic Segmentation,PASCAL VOC 2007,2017-07,DeepLabv3 (ImageNet+300M),81.3,97.95,81.3,0.98,83.0,0.88,ito:ITO_00600,Robotics process,Mean\\ IoU
34,1,Semantic Segmentation,PASCAL VOC 2007,2019-09,GALDNet,83.0,100.0,1.7,0.02,83.0,0.9,ito:ITO_00600,Robotics process,Mean\\ IoU
35,1,Scene Segmentation,NYU Depth v2,2017-07,Dilated FCN-2s RGB,32.3,100.0,32.3,1.0,32.3,0.35,ito:ITO_00600,Robotics process,Mean\\ IoU
36,1,Semantic Segmentation,ScanNetV2,2018-08,SSMA,57.7,100.0,57.7,1.0,57.7,0.63,ito:ITO_00600,Robotics process,Mean\\ IoU
37,1,Semantic Segmentation,SUN-RGBD,2018-08,SSMA,45.73,100.0,45.73,1.0,45.73,0.5,ito:ITO_00600,Robotics process,Mean\\ IoU
38,1,Semantic Segmentation,Freiburg Forest,2018-08,SSMA,84.18,100.0,84.18,1.0,84.18,0.91,ito:ITO_00600,Robotics process,Mean\\ IoU
39,1,Semantic Segmentation,SYNTHIA-CVPR’16,2018-08,SSMA,92.1,100.0,92.1,1.0,92.1,1.0,ito:ITO_00600,Robotics process,Mean\\ IoU
40,1,Weakly-Supervised Semantic Segmentation,PASCAL VOC 2012 val,2019-04,IRNet (ResNet-50),63.5,100.0,63.5,1.0,63.5,0.69,ito:ITO_00600,Robotics process,Mean\\ IoU
41,1,Weakly-Supervised Semantic Segmentation,PASCAL VOC 2012 test,2019-04,IRNet (ResNet-50),64.8,100.0,64.8,1.0,64.8,0.7,ito:ITO_00600,Robotics process,Mean\\ IoU
42,1,Semantic Segmentation,S3DIS Area5,2019-04,KPConv,67.1,100.0,67.1,1.0,67.1,0.73,ito:ITO_00600,Robotics process,Mean\\ IoU
0,1,Face Anti-Spoofing,CASIA-MFSD,2014-08,Multi-Scale,4.92,100.0,4.92,1.0,4.92,1.0,ito:ITO_00600,Robotics process,EER
1,1,Face Anti-Spoofing,Replay-Attack,2014-08,Multi-Scale,2.14,100.0,2.14,1.0,2.14,0.43,ito:ITO_00600,Robotics process,EER
0,1,Image-to-Image Translation,GTAV-to-Cityscapes Labels,2014-09,VGG16 60.3,41.3,85.15,41.3,0.85,48.5,0.46,ito:ITO_00600,Robotics process,mIoU
1,1,Image-to-Image Translation,GTAV-to-Cityscapes Labels,2015-12,ResNet101 65.1,48.5,100.0,7.2,0.15,48.5,0.54,ito:ITO_00600,Robotics process,mIoU
2,1,Semantic Segmentation,COCO-Stuff test,2014-11,FCN (VGG-16),22.7,56.05,22.7,0.56,40.5,0.25,ito:ITO_00600,Robotics process,mIoU
3,1,Semantic Segmentation,COCO-Stuff test,2015-09,DAG-RNN (VGG-16),31.2,77.04,8.5,0.21,40.5,0.35,ito:ITO_00600,Robotics process,mIoU
4,1,Semantic Segmentation,COCO-Stuff test,2016-11,RefineNet (ResNet-101),33.6,82.96,2.4,0.06,40.5,0.37,ito:ITO_00600,Robotics process,mIoU
5,1,Semantic Segmentation,COCO-Stuff test,2018-06,CCL (ResNet-101),35.7,88.15,2.1,0.05,40.5,0.4,ito:ITO_00600,Robotics process,mIoU
6,1,Semantic Segmentation,COCO-Stuff test,2018-09,DANet (ResNet-101),39.7,98.02,4.0,0.1,40.5,0.44,ito:ITO_00600,Robotics process,mIoU
7,1,Semantic Segmentation,COCO-Stuff test,2019-09,OCR (HRNetV2-W48),40.5,100.0,0.8,0.02,40.5,0.45,ito:ITO_00600,Robotics process,mIoU
8,1,Semantic Segmentation,PASCAL Context,2014-11,FCN-8s,37.8,64.18,37.8,0.64,58.9,0.42,ito:ITO_00600,Robotics process,mIoU
9,1,Semantic Segmentation,PASCAL Context,2015-02,CRF-RNN,39.3,66.72,1.5,0.03,58.9,0.44,ito:ITO_00600,Robotics process,mIoU
10,1,Semantic Segmentation,PASCAL Context,2015-03,BoxSup,40.5,68.76,1.2,0.02,58.9,0.45,ito:ITO_00600,Robotics process,mIoU
11,1,Semantic Segmentation,PASCAL Context,2015-04,Piecewise,43.3,73.51,2.8,0.05,58.9,0.48,ito:ITO_00600,Robotics process,mIoU
12,1,Semantic Segmentation,PASCAL Context,2016-05,VeryDeep,44.5,75.55,1.2,0.02,58.9,0.49,ito:ITO_00600,Robotics process,mIoU
13,1,Semantic Segmentation,PASCAL Context,2016-06,DeepLabV2,45.7,77.59,1.2,0.02,58.9,0.51,ito:ITO_00600,Robotics process,mIoU
14,1,Semantic Segmentation,PASCAL Context,2016-11,RefineNet,47.3,80.31,1.6,0.03,58.9,0.52,ito:ITO_00600,Robotics process,mIoU
15,1,Semantic Segmentation,PASCAL Context,2016-11,ResNet-38,48.1,81.66,0.8,0.01,58.9,0.53,ito:ITO_00600,Robotics process,mIoU
16,1,Semantic Segmentation,PASCAL Context,2018-03,EncNet (ResNet-101),51.7,87.78,3.6,0.06,58.9,0.57,ito:ITO_00600,Robotics process,mIoU
17,1,Semantic Segmentation,PASCAL Context,2018-09,DANet (ResNet-101),52.6,89.3,0.9,0.02,58.9,0.58,ito:ITO_00600,Robotics process,mIoU
18,1,Semantic Segmentation,PASCAL Context,2019-03,Joint Pyramid Upsampling + EncNet,53.1,90.15,0.5,0.01,58.9,0.59,ito:ITO_00600,Robotics process,mIoU
19,1,Semantic Segmentation,PASCAL Context,2019-06,CFNet (ResNet-101),54.0,91.68,0.9,0.02,58.9,0.6,ito:ITO_00600,Robotics process,mIoU
20,1,Semantic Segmentation,PASCAL Context,2019-09,OCR (HRNetV2-W48),56.2,95.42,2.2,0.04,58.9,0.62,ito:ITO_00600,Robotics process,mIoU
21,1,Semantic Segmentation,PASCAL Context,2020-04,ResNeSt-269,58.9,100.0,2.7,0.05,58.9,0.65,ito:ITO_00600,Robotics process,mIoU
22,1,Real-Time Semantic Segmentation,Cityscapes test,2014-12,DeepLab,63.1,83.14,63.1,0.83,75.9,0.7,ito:ITO_00600,Robotics process,mIoU
23,1,Real-Time Semantic Segmentation,Cityscapes test,2015-11,Dilation10,67.1,88.41,4.0,0.05,75.9,0.74,ito:ITO_00600,Robotics process,mIoU
24,1,Real-Time Semantic Segmentation,Cityscapes test,2016-11,FRRN,71.8,94.6,4.7,0.06,75.9,0.8,ito:ITO_00600,Robotics process,mIoU
25,1,Real-Time Semantic Segmentation,Cityscapes test,2018-08,BiSeNet(ResNet-18),74.7,98.42,2.9,0.04,75.9,0.83,ito:ITO_00600,Robotics process,mIoU
26,1,Real-Time Semantic Segmentation,Cityscapes test,2018-11,ShelfNet18,74.8,98.55,0.1,0.0,75.9,0.83,ito:ITO_00600,Robotics process,mIoU
27,1,Real-Time Semantic Segmentation,Cityscapes test,2019-03,SwiftNetRN-18,75.5,99.47,0.7,0.01,75.9,0.84,ito:ITO_00600,Robotics process,mIoU
28,1,Real-Time Semantic Segmentation,Cityscapes test,2019-09,U-HarDNet-70,75.9,100.0,0.4,0.01,75.9,0.84,ito:ITO_00600,Robotics process,mIoU
29,1,Real-Time Semantic Segmentation,CamVid,2014-12,DeepLab,61.6,78.47,61.6,0.78,78.5,0.68,ito:ITO_00600,Robotics process,mIoU
30,1,Real-Time Semantic Segmentation,CamVid,2015-11,Dilation10,65.3,83.18,3.7,0.05,78.5,0.72,ito:ITO_00600,Robotics process,mIoU
31,1,Real-Time Semantic Segmentation,CamVid,2016-12,PSPNet,69.1,88.03,3.8,0.05,78.5,0.77,ito:ITO_00600,Robotics process,mIoU
32,1,Real-Time Semantic Segmentation,CamVid,2020-04,TD2-PSP50,76.0,96.82,6.9,0.09,78.5,0.84,ito:ITO_00600,Robotics process,mIoU
33,1,Real-Time Semantic Segmentation,CamVid,2020-04,BiSeNet V2(Cityscapes-Pretrained),76.7,97.71,0.7,0.01,78.5,0.85,ito:ITO_00600,Robotics process,mIoU
34,1,Real-Time Semantic Segmentation,CamVid,2020-04,BiSeNet V2-Large(Cityscapes-Pretrained),78.5,100.0,1.8,0.02,78.5,0.87,ito:ITO_00600,Robotics process,mIoU
35,1,Semantic Segmentation,Kvasir-Instrument,2015-05,UNet,0.8578,100.0,0.8578,1.0,0.8578,0.01,ito:ITO_00600,Robotics process,mIoU
36,1,Semantic Segmentation,Cityscapes val,2015-12,Dilated-ResNet (Dilated-ResNet-101),75.7,91.54,75.7,0.92,82.7,0.84,ito:ITO_00600,Robotics process,mIoU
37,1,Semantic Segmentation,Cityscapes val,2016-12,PSPNet (Dilated-ResNet-101),79.7,96.37,4.0,0.05,82.7,0.88,ito:ITO_00600,Robotics process,mIoU
38,1,Semantic Segmentation,Cityscapes val,2019-01,Auto-DeepLab-L,80.33,97.13,0.6,0.01,82.7,0.89,ito:ITO_00600,Robotics process,mIoU
39,1,Semantic Segmentation,Cityscapes val,2019-08,HRNetV2 (HRNetV2-W48),81.1,98.07,0.8,0.01,82.7,0.9,ito:ITO_00600,Robotics process,mIoU
40,1,Semantic Segmentation,Cityscapes val,2019-11,Panoptic-DeepLab,81.5,98.55,0.4,0.0,82.7,0.9,ito:ITO_00600,Robotics process,mIoU
41,1,Semantic Segmentation,Cityscapes val,2020-04,ResNeSt200,82.7,100.0,1.2,0.01,82.7,0.92,ito:ITO_00600,Robotics process,mIoU
42,1,Semantic Segmentation,Semantic3D,2016-03,TMLC-MSR,54.2,70.03,54.2,0.7,77.4,0.6,ito:ITO_00600,Robotics process,mIoU
43,1,Semantic Segmentation,Semantic3D,2017-04,SnapNet_,59.1,76.36,4.9,0.06,77.4,0.65,ito:ITO_00600,Robotics process,mIoU
44,1,Semantic Segmentation,Semantic3D,2017-10,SEGCloud,61.3,79.2,2.2,0.03,77.4,0.68,ito:ITO_00600,Robotics process,mIoU
45,1,Semantic Segmentation,Semantic3D,2017-11,SPGraph,73.2,94.57,11.9,0.15,77.4,0.81,ito:ITO_00600,Robotics process,mIoU
46,1,Semantic Segmentation,Semantic3D,2017-11,SPG,76.2,98.45,3.0,0.04,77.4,0.84,ito:ITO_00600,Robotics process,mIoU
47,1,Semantic Segmentation,Semantic3D,2019-11,RandLA-Net,77.4,100.0,1.2,0.02,77.4,0.86,ito:ITO_00600,Robotics process,mIoU
48,1,Semantic Segmentation,PASCAL VOC 2012 val,2016-06,DeepLab-CRF (ResNet-101),77.69,90.55,77.69,0.91,85.8,0.86,ito:ITO_00600,Robotics process,mIoU
49,1,Semantic Segmentation,PASCAL VOC 2012 val,2017-03,ResNet-GCN,81.0,94.41,3.3,0.04,85.8,0.9,ito:ITO_00600,Robotics process,mIoU
50,1,Semantic Segmentation,PASCAL VOC 2012 val,2017-06,DeepLabv3-JFT,82.7,96.39,1.7,0.02,85.8,0.92,ito:ITO_00600,Robotics process,mIoU
51,1,Semantic Segmentation,PASCAL VOC 2012 val,2018-02,DeepLabv3+ (Xception-JFT),84.56,98.55,1.9,0.02,85.8,0.94,ito:ITO_00600,Robotics process,mIoU
52,1,Semantic Segmentation,PASCAL VOC 2012 val,2018-04,ExFuse (ResNeXt-131),85.8,100.0,1.2,0.01,85.8,0.95,ito:ITO_00600,Robotics process,mIoU
53,1,Semantic Segmentation,ADE20K val,2016-11,RefineNet (ResNet-152),40.7,84.16,40.7,0.84,48.36,0.45,ito:ITO_00600,Robotics process,mIoU
54,1,Semantic Segmentation,ADE20K val,2016-12,PSPNet (ResNet-152),43.51,89.97,2.8,0.06,48.36,0.48,ito:ITO_00600,Robotics process,mIoU
55,1,Semantic Segmentation,ADE20K val,2018-03,DSSPN (ResNet-101),43.68,90.32,0.2,0.0,48.36,0.48,ito:ITO_00600,Robotics process,mIoU
56,1,Semantic Segmentation,ADE20K val,2018-03,EncNet (ResNet-101),44.65,92.33,1.0,0.02,48.36,0.49,ito:ITO_00600,Robotics process,mIoU
57,1,Semantic Segmentation,ADE20K val,2019-06,CFNet (ResNet-101),44.89,92.82,0.2,0.0,48.36,0.5,ito:ITO_00600,Robotics process,mIoU
58,1,Semantic Segmentation,ADE20K val,2019-08,Asymmetric ALNN,45.24,93.55,0.4,0.01,48.36,0.5,ito:ITO_00600,Robotics process,mIoU
59,1,Semantic Segmentation,ADE20K val,2019-09,OCR (HRNetV2-W48),45.66,94.42,0.4,0.01,48.36,0.51,ito:ITO_00600,Robotics process,mIoU
60,1,Semantic Segmentation,ADE20K val,2019-10,ACNet (ResNet-101),45.9,94.91,0.2,0.0,48.36,0.51,ito:ITO_00600,Robotics process,mIoU
61,1,Semantic Segmentation,ADE20K val,2020-03,DCNAS,47.12,97.44,1.2,0.02,48.36,0.52,ito:ITO_00600,Robotics process,mIoU
62,1,Semantic Segmentation,ADE20K val,2020-04,ResNeSt-200,48.36,100.0,1.2,0.02,48.36,0.54,ito:ITO_00600,Robotics process,mIoU
63,1,Semantic Segmentation,S3DIS Area5,2016-12,PointNet,41.1,61.25,41.1,0.61,67.1,0.46,ito:ITO_00600,Robotics process,mIoU
64,1,Semantic Segmentation,S3DIS Area5,2017-10,SegCloud,48.9,72.88,7.8,0.12,67.1,0.54,ito:ITO_00600,Robotics process,mIoU
65,1,Semantic Segmentation,S3DIS Area5,2017-11,SPG,58.04,86.5,9.1,0.14,67.1,0.64,ito:ITO_00600,Robotics process,mIoU
66,1,Semantic Segmentation,S3DIS Area5,2019-04,MinkowskiNet,65.4,97.47,7.4,0.11,67.1,0.72,ito:ITO_00600,Robotics process,mIoU
67,1,Semantic Segmentation,S3DIS Area5,2019-04,KPConv,67.1,100.0,1.7,0.03,67.1,0.74,ito:ITO_00600,Robotics process,mIoU
68,1,3D Semantic Segmentation,SemanticKITTI,2016-12,PointNet,14.6,24.83,14.6,0.25,58.8,0.16,ito:ITO_00600,Robotics process,mIoU
69,1,3D Semantic Segmentation,SemanticKITTI,2017-06,PointNet++,20.1,34.18,5.5,0.09,58.8,0.22,ito:ITO_00600,Robotics process,mIoU
70,1,3D Semantic Segmentation,SemanticKITTI,2017-10,SqueezeSeg,29.5,50.17,9.4,0.16,58.8,0.33,ito:ITO_00600,Robotics process,mIoU
71,1,3D Semantic Segmentation,SemanticKITTI,2018-07,TangentConv,35.9,61.05,6.4,0.11,58.8,0.4,ito:ITO_00600,Robotics process,mIoU
72,1,3D Semantic Segmentation,SemanticKITTI,2018-07,TagentConv,40.9,69.56,5.0,0.09,58.8,0.45,ito:ITO_00600,Robotics process,mIoU
73,1,3D Semantic Segmentation,SemanticKITTI,2019-04,KPConv,58.8,100.0,17.9,0.3,58.8,0.65,ito:ITO_00600,Robotics process,mIoU
74,1,Real-Time Semantic Segmentation,NYU Depth v2,2016-12,PSPNet101,43.2,99.31,43.2,0.99,43.5,0.48,ito:ITO_00600,Robotics process,mIoU
75,1,Real-Time Semantic Segmentation,NYU Depth v2,2020-04,TD2-PSP50,43.5,100.0,0.3,0.01,43.5,0.48,ito:ITO_00600,Robotics process,mIoU
76,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2016-12,FCNs in the wild,20.2,37.9,20.2,0.38,53.3,0.22,ito:ITO_00600,Robotics process,mIoU
77,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2017-07,CDA,29.0,54.41,8.8,0.17,53.3,0.32,ito:ITO_00600,Robotics process,mIoU
78,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2018-02,Multi-level Adaptation,46.7,87.62,17.7,0.33,53.3,0.52,ito:ITO_00600,Robotics process,mIoU
79,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2018-11,ADVENT,48.0,90.06,1.3,0.02,53.3,0.53,ito:ITO_00600,Robotics process,mIoU
80,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-03,SWD,48.1,90.24,0.1,0.0,53.3,0.53,ito:ITO_00600,Robotics process,mIoU
81,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-08,PyCDA (ResNet-101),53.3,100.0,5.2,0.1,53.3,0.59,ito:ITO_00600,Robotics process,mIoU
82,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2016-12,FCNs in the wild,27.1,53.98,27.1,0.54,50.2,0.3,ito:ITO_00600,Robotics process,mIoU
83,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2017-07,CDA,28.9,57.57,1.8,0.04,50.2,0.32,ito:ITO_00600,Robotics process,mIoU
84,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2017-11,CyCADA pixel+feat,39.5,78.69,10.6,0.21,50.2,0.44,ito:ITO_00600,Robotics process,mIoU
85,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2018-02,Multi-level Adaptation,42.4,84.46,2.9,0.06,50.2,0.47,ito:ITO_00600,Robotics process,mIoU
86,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2018-08,Domain adaptation (ResNet-101),43.2,86.06,0.8,0.02,50.2,0.48,ito:ITO_00600,Robotics process,mIoU
87,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2018-10,CBST-SP (ResNet-38),46.2,92.03,3.0,0.06,50.2,0.51,ito:ITO_00600,Robotics process,mIoU
88,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2018-10,"CBST-SP (ResNet-38, MST)",47.0,93.63,0.8,0.02,50.2,0.52,ito:ITO_00600,Robotics process,mIoU
89,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2019-04,BDL (ResNet-101),48.5,96.61,1.5,0.03,50.2,0.54,ito:ITO_00600,Robotics process,mIoU
90,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2019-08,MRKLD-SP-MST (ResNet-38),49.8,99.2,1.3,0.03,50.2,0.55,ito:ITO_00600,Robotics process,mIoU
91,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2019-10,CAG-UDA,50.2,100.0,0.4,0.01,50.2,0.56,ito:ITO_00600,Robotics process,mIoU
92,1,Image-to-Image Translation,SYNTHIA Fall-to-Winter,2016-12,FCNs in the wild,59.6,94.15,59.6,0.94,63.3,0.66,ito:ITO_00600,Robotics process,mIoU
93,1,Image-to-Image Translation,SYNTHIA Fall-to-Winter,2017-11,CyCADA,63.3,100.0,3.7,0.06,63.3,0.7,ito:ITO_00600,Robotics process,mIoU
94,1,Semantic Segmentation,LIP val,2017-03,Attention+SSL (ResNet-101),44.73,75.35,44.73,0.75,59.36,0.5,ito:ITO_00600,Robotics process,mIoU
95,1,Semantic Segmentation,LIP val,2018-04,JPPNet (ResNet-101),51.37,86.54,6.6,0.11,59.36,0.57,ito:ITO_00600,Robotics process,mIoU
96,1,Semantic Segmentation,LIP val,2018-09,CE2P (ResNet-101),53.1,89.45,1.7,0.03,59.36,0.59,ito:ITO_00600,Robotics process,mIoU
97,1,Semantic Segmentation,LIP val,2019-04,HRNetV2 (HRNetV2-W48),55.9,94.17,2.8,0.05,59.36,0.62,ito:ITO_00600,Robotics process,mIoU
98,1,Semantic Segmentation,LIP val,2019-09,OCR (HRNetV2-W48),56.65,95.43,0.8,0.01,59.36,0.63,ito:ITO_00600,Robotics process,mIoU
99,1,Semantic Segmentation,LIP val,2019-10,SCHP (ResNet-101),59.36,100.0,2.7,0.05,59.36,0.66,ito:ITO_00600,Robotics process,mIoU
100,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2017-07,CRN,22.4,51.26,22.4,0.51,43.7,0.25,ito:ITO_00600,Robotics process,mIoU
101,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2019-03,SPADE,38.5,88.1,16.1,0.37,43.7,0.43,ito:ITO_00600,Robotics process,mIoU
102,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2019-10,CC-FPSE,43.7,100.0,5.2,0.12,43.7,0.48,ito:ITO_00600,Robotics process,mIoU
103,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2017-07,CRN,23.7,56.97,23.7,0.57,41.6,0.26,ito:ITO_00600,Robotics process,mIoU
104,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2019-03,SPADE,37.4,89.9,13.7,0.33,41.6,0.41,ito:ITO_00600,Robotics process,mIoU
105,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2019-10,CC-FPSE,41.6,100.0,4.2,0.1,41.6,0.46,ito:ITO_00600,Robotics process,mIoU
106,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2017-07,CRN,16.5,53.57,16.5,0.54,30.8,0.18,ito:ITO_00600,Robotics process,mIoU
107,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2017-11,pix2pixHD,17.4,56.49,0.9,0.03,30.8,0.19,ito:ITO_00600,Robotics process,mIoU
108,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2019-03,SPADE,30.8,100.0,13.4,0.44,30.8,0.34,ito:ITO_00600,Robotics process,mIoU
109,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2017-07,CRN,52.4,80.0,52.4,0.8,65.5,0.58,ito:ITO_00600,Robotics process,mIoU
110,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2017-11,pix2pixHD,58.3,89.01,5.9,0.09,65.5,0.65,ito:ITO_00600,Robotics process,mIoU
111,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2019-03,SPADE,62.3,95.11,4.0,0.06,65.5,0.69,ito:ITO_00600,Robotics process,mIoU
112,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2019-10,CC-FPSE,65.5,100.0,3.2,0.05,65.5,0.73,ito:ITO_00600,Robotics process,mIoU
113,1,Panoptic Segmentation,Cityscapes val,2018-08,Dynamically Instantiated Network (ResNet-101),79.8,88.37,79.8,0.88,90.3,0.88,ito:ITO_00600,Robotics process,mIoU
114,1,Panoptic Segmentation,Cityscapes val,2019-11,Panoptic-DeepLab (X71),81.5,90.25,1.7,0.02,90.3,0.9,ito:ITO_00600,Robotics process,mIoU
115,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS,82.1,90.92,0.6,0.01,90.3,0.91,ito:ITO_00600,Robotics process,mIoU
116,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS (Cityscapes-fine),90.3,100.0,8.2,0.09,90.3,1.0,ito:ITO_00600,Robotics process,mIoU
117,1,Semantic Segmentation,ParisLille3D,2019-04,KPConv deform,75.9,100.0,75.9,1.0,75.9,0.84,ito:ITO_00600,Robotics process,mIoU
118,1,3D Semantic Segmentation,S3DIS,2019-07,PVCNN++,58.98,100.0,58.98,1.0,58.98,0.65,ito:ITO_00600,Robotics process,mIoU
119,1,Panoptic Segmentation,Mapillary val,2019-09,AdaptIS (ResNeXt-101),56.8,100.0,56.8,1.0,56.8,0.63,ito:ITO_00600,Robotics process,mIoU
120,1,Unsupervised Semantic Segmentation,PASCAL VOC 2012 val,2019-10,SegSort,55.86,100.0,55.86,1.0,55.86,0.62,ito:ITO_00600,Robotics process,mIoU
121,1,Real-Time Semantic Segmentation,Cityscapes val,2019-12,LiteSeg-MobileNet,67.8,100.0,67.8,1.0,67.8,0.75,ito:ITO_00600,Robotics process,mIoU
122,1,Semantic Segmentation,BDD,2019-12,FasterSeg,55.1,100.0,55.1,1.0,55.1,0.61,ito:ITO_00600,Robotics process,mIoU
123,1,Semantic Segmentation,GTAV-to-Cityscapes Labels,2019-12,MRNet,48.3,96.02,48.3,0.96,50.3,0.53,ito:ITO_00600,Robotics process,mIoU
124,1,Semantic Segmentation,GTAV-to-Cityscapes Labels,2020-03,MRNet+Rectifying Label,50.3,100.0,2.0,0.04,50.3,0.56,ito:ITO_00600,Robotics process,mIoU
125,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet-tiny,46.9,84.05,46.9,0.84,55.8,0.52,ito:ITO_00600,Robotics process,mIoU
126,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet,55.8,100.0,8.9,0.16,55.8,0.62,ito:ITO_00600,Robotics process,mIoU
127,1,Real-Time Semantic Segmentation,COCO-Stuff,2020-04,BiSeNet V2-Large,28.7,100.0,28.7,1.0,28.7,0.32,ito:ITO_00600,Robotics process,mIoU
0,1,Unsupervised Image-To-Image Translation,SVNH-to-MNIST,2014-09,DANN,73.6,81.42,73.6,0.81,90.4,0.81,ito:ITO_00600,Robotics process,Classification\\ Accuracy
1,1,Unsupervised Image-To-Image Translation,SVNH-to-MNIST,2016-11,DTN,84.4,93.36,10.8,0.12,90.4,0.93,ito:ITO_00600,Robotics process,Classification\\ Accuracy
2,1,Unsupervised Image-To-Image Translation,SVNH-to-MNIST,2017-11,CyCADA pixel+feat,90.4,100.0,6.0,0.07,90.4,1.0,ito:ITO_00600,Robotics process,Classification\\ Accuracy
3,1,3D Object Classification,ModelNet40,2018-12,3D-PointCapsNet,89.3,100.0,89.3,1.0,89.3,0.99,ito:ITO_00600,Robotics process,Classification\\ Accuracy
0,1,Image Generation,CIFAR-10,2014-10,NICE,4.5,100.0,4.5,1.0,4.5,1.0,ito:ITO_00600,Robotics process,Model\\ Entropy
0,1,Image Generation,CIFAR-10,2014-10,NICE,4.5,100.0,4.5,1.0,4.5,1.0,ito:ITO_00600,Robotics process,bits/dimension
1,1,Image Generation,MNIST,2018-11,i-ResNet,1.06,100.0,1.06,1.0,1.06,0.24,ito:ITO_00600,Robotics process,bits/dimension
0,1,Image Generation,CIFAR-10,2014-10,NICE,4.5,100.0,4.5,1.0,4.5,1.0,ito:ITO_00600,Robotics process,NLL\\ Test
1,1,Image Generation,ImageNet 64x64,2019-02,Flow++,3.69,98.4,3.69,0.98,3.75,0.82,ito:ITO_00600,Robotics process,NLL\\ Test
2,1,Image Generation,ImageNet 64x64,2019-02,MaCow (Unf),3.75,100.0,0.1,0.03,3.75,0.83,ito:ITO_00600,Robotics process,NLL\\ Test
0,1,Semantic Segmentation,ADE20K,2014-11,FCN,29.39,60.77,29.39,0.61,48.36,0.41,ito:ITO_00600,Robotics process,Validation\\ mIoU
1,1,Semantic Segmentation,ADE20K,2015-11,DilatedNet,32.31,66.81,2.9,0.06,48.36,0.45,ito:ITO_00600,Robotics process,Validation\\ mIoU
2,1,Semantic Segmentation,ADE20K,2016-11,RefineNet,40.7,84.16,8.4,0.17,48.36,0.57,ito:ITO_00600,Robotics process,Validation\\ mIoU
3,1,Semantic Segmentation,ADE20K,2016-12,PSPNet,44.94,92.93,4.2,0.09,48.36,0.63,ito:ITO_00600,Robotics process,Validation\\ mIoU
4,1,Semantic Segmentation,ADE20K,2019-11,LaU-regression-loss,45.02,93.09,0.1,0.0,48.36,0.63,ito:ITO_00600,Robotics process,Validation\\ mIoU
5,1,Semantic Segmentation,ADE20K,2020-04,CPN(ResNet-101),46.27,95.68,1.2,0.02,48.36,0.65,ito:ITO_00600,Robotics process,Validation\\ mIoU
6,1,Semantic Segmentation,ADE20K,2020-04,ResNeSt-200,48.36,100.0,2.1,0.04,48.36,0.68,ito:ITO_00600,Robotics process,Validation\\ mIoU
7,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 2% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),49.2,75.91,49.2,0.76,64.81,0.69,ito:ITO_00600,Robotics process,Validation\\ mIoU
8,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 2% labeled,2019-06,CutMix (DeepLab v2 ImageNet pre-trained),64.81,100.0,15.6,0.24,64.81,0.91,ito:ITO_00600,Robotics process,Validation\\ mIoU
9,1,Semi-Supervised Semantic Segmentation,Cityscapes 12.5% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),57.1,94.63,57.1,0.95,60.34,0.8,ito:ITO_00600,Robotics process,Validation\\ mIoU
10,1,Semi-Supervised Semantic Segmentation,Cityscapes 12.5% labeled,2019-06,"CutMix (DeepLab v2, ImageNet pre-trained)",60.34,100.0,3.2,0.05,60.34,0.85,ito:ITO_00600,Robotics process,Validation\\ mIoU
11,1,Semi-Supervised Semantic Segmentation,Cityscapes 25% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),60.5,94.72,60.5,0.95,63.87,0.85,ito:ITO_00600,Robotics process,Validation\\ mIoU
12,1,Semi-Supervised Semantic Segmentation,Cityscapes 25% labeled,2019-06,"CutMix (DeepLab v2, ImageNet pre-trained)",63.87,100.0,3.4,0.05,63.87,0.89,ito:ITO_00600,Robotics process,Validation\\ mIoU
13,1,Semi-Supervised Semantic Segmentation,Cityscapes 50% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),65.7,100.0,65.7,1.0,65.7,0.92,ito:ITO_00600,Robotics process,Validation\\ mIoU
14,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 12.5% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),64.3,90.06,64.3,0.9,71.4,0.9,ito:ITO_00600,Robotics process,Validation\\ mIoU
15,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 12.5% labeled,2019-06,CutMix (DeepLab v2 ImageNet pre-trained),67.6,94.68,3.3,0.05,71.4,0.95,ito:ITO_00600,Robotics process,Validation\\ mIoU
16,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 12.5% labeled,2019-08,s4GAN+MLMT (DeepLab v3 ImageNet pre-trained),70.4,98.6,2.8,0.04,71.4,0.99,ito:ITO_00600,Robotics process,Validation\\ mIoU
17,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 12.5% labeled,2019-08,s4GAN + MLMT (DeepLab v2 MSCOCO/ImageNet pre-trained),71.4,100.0,1.0,0.01,71.4,1.0,ito:ITO_00600,Robotics process,Validation\\ mIoU
18,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 5% labeled,2018-02,Adversarial (DeepLab v2 ImageNet pre-trained),59.1,87.95,59.1,0.88,67.2,0.83,ito:ITO_00600,Robotics process,Validation\\ mIoU
19,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 5% labeled,2019-06,CutMix (DeepLab v2 ImageNet pre-trained),66.48,98.93,7.4,0.11,67.2,0.93,ito:ITO_00600,Robotics process,Validation\\ mIoU
20,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 5% labeled,2019-08,s4GAN+MLMT (DeepLab v3 ImageNet pre-trained),66.6,99.11,0.1,0.0,67.2,0.93,ito:ITO_00600,Robotics process,Validation\\ mIoU
21,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 5% labeled,2019-08,s4GAN + MLMT (DeepLab v2 MSCOCO/ImageNet pre-trained),67.2,100.0,0.6,0.01,67.2,0.94,ito:ITO_00600,Robotics process,Validation\\ mIoU
22,1,Semi-Supervised Semantic Segmentation,Cityscapes 100 samples labeled,2019-06,"CutMix (DeepLab v2, ImageNet pre-trained)",51.2,100.0,51.2,1.0,51.2,0.72,ito:ITO_00600,Robotics process,Validation\\ mIoU
23,1,Semi-Supervised Semantic Segmentation,Pascal VOC 2012 1% labeled,2019-06,CutMix (DeepLab v2 ImageNet pre-trained),53.79,100.0,53.79,1.0,53.79,0.75,ito:ITO_00600,Robotics process,Validation\\ mIoU
24,1,Semi-Supervised Semantic Segmentation,PASCAL Context 25% labeled,2019-08,s4GAN+MLMT (DeepLab v2 ImageNet pre-trained),37.8,100.0,37.8,1.0,37.8,0.53,ito:ITO_00600,Robotics process,Validation\\ mIoU
25,1,Semi-Supervised Semantic Segmentation,Cityscapes 2% labeled,2019-08,"S4GAN (DeepLabv2 with ResNet101, MSCOCO pre-trained)",50.48,100.0,50.48,1.0,50.48,0.71,ito:ITO_00600,Robotics process,Validation\\ mIoU
26,1,Semi-Supervised Semantic Segmentation,PASCAL Context 12.5% labeled,2019-08,s4GAN+MLMT (DeepLab v2 ImageNet pre-trained),35.3,100.0,35.3,1.0,35.3,0.49,ito:ITO_00600,Robotics process,Validation\\ mIoU
27,1,Semi-Supervised Semantic Segmentation,Cityscapes 5% labeled,2019-08,"S4GAN (DeepLabv2 with ResNet101, MSCOCO pre-trained)",55.61,100.0,55.61,1.0,55.61,0.78,ito:ITO_00600,Robotics process,Validation\\ mIoU
0,1,Skeleton Based Action Recognition,J-HMDB,2014-11,Action Tubes,62.5,69.14,62.5,0.69,90.4,0.69,ito:ITO_00600,Robotics process,Accuracy\\ \\(RGB\\+pose\\)
1,1,Skeleton Based Action Recognition,J-HMDB,2016-09,MR Two-Sream R-CNN,71.1,78.65,8.6,0.1,90.4,0.79,ito:ITO_00600,Robotics process,Accuracy\\ \\(RGB\\+pose\\)
2,1,Skeleton Based Action Recognition,J-HMDB,2017-04,Chained (RGB+Flow +Pose),76.1,84.18,5.0,0.06,90.4,0.84,ito:ITO_00600,Robotics process,Accuracy\\ \\(RGB\\+pose\\)
3,1,Skeleton Based Action Recognition,J-HMDB,2017-05,I3D,84.1,93.03,8.0,0.09,90.4,0.93,ito:ITO_00600,Robotics process,Accuracy\\ \\(RGB\\+pose\\)
4,1,Skeleton Based Action Recognition,J-HMDB,2018-06,I3D + Potion,85.5,94.58,1.4,0.02,90.4,0.95,ito:ITO_00600,Robotics process,Accuracy\\ \\(RGB\\+pose\\)
5,1,Skeleton Based Action Recognition,J-HMDB,2018-06,Potion,90.4,100.0,4.9,0.05,90.4,1.0,ito:ITO_00600,Robotics process,Accuracy\\ \\(RGB\\+pose\\)
0,1,Real-Time Semantic Segmentation,Cityscapes test,2014-12,DeepLab,4000.0,100.0,4000.0,1.0,4000.0,1.0,ito:ITO_00600,Robotics process,Time\\ \\(ms\\)
1,1,Real-Time Semantic Segmentation,CamVid,2014-12,DeepLab,203.0,89.43,203.0,0.89,227.0,0.05,ito:ITO_00600,Robotics process,Time\\ \\(ms\\)
2,1,Real-Time Semantic Segmentation,CamVid,2015-11,SegNet,217.0,95.59,14.0,0.06,227.0,0.05,ito:ITO_00600,Robotics process,Time\\ \\(ms\\)
3,1,Real-Time Semantic Segmentation,CamVid,2015-11,Dilation10,227.0,100.0,10.0,0.04,227.0,0.06,ito:ITO_00600,Robotics process,Time\\ \\(ms\\)
0,1,Semantic Segmentation,Cityscapes test,2014-12,DeepLab,63.1,74.67,63.1,0.75,84.5,0.75,ito:ITO_00600,Robotics process,Mean\\ IoU\\ \\(class\\)
1,1,Semantic Segmentation,Cityscapes test,2015-04,Context,71.6,84.73,8.5,0.1,84.5,0.85,ito:ITO_00600,Robotics process,Mean\\ IoU\\ \\(class\\)
2,1,Semantic Segmentation,Cityscapes test,2016-05,LRR-4x,71.8,84.97,0.2,0.0,84.5,0.85,ito:ITO_00600,Robotics process,Mean\\ IoU\\ \\(class\\)
3,1,Semantic Segmentation,Cityscapes test,2016-11,RefineNet (ResNet-101),73.6,87.1,1.8,0.02,84.5,0.87,ito:ITO_00600,Robotics process,Mean\\ IoU\\ \\(class\\)
4,1,Semantic Segmentation,Cityscapes test,2016-11,ResNet-38,78.4,92.78,4.8,0.06,84.5,0.93,ito:ITO_00600,Robotics process,Mean\\ IoU\\ \\(class\\)
5,1,Semantic Segmentation,Cityscapes test,2016-12,"PSPNet (ResNet-101, coarse)",81.2,96.09,2.8,0.03,84.5,0.96,ito:ITO_00600,Robotics process,Mean\\ IoU\\ \\(class\\)
6,1,Semantic Segmentation,Cityscapes test,2017-06,"DeepLabv3 (ResNet-101, coarse)",81.3,96.21,0.1,0.0,84.5,0.96,ito:ITO_00600,Robotics process,Mean\\ IoU\\ \\(class\\)
7,1,Semantic Segmentation,Cityscapes test,2017-12,Mapillary,82.0,97.04,0.7,0.01,84.5,0.97,ito:ITO_00600,Robotics process,Mean\\ IoU\\ \\(class\\)
8,1,Semantic Segmentation,Cityscapes test,2018-02,DeepLabv3+ (Xception-JFT),82.1,97.16,0.1,0.0,84.5,0.97,ito:ITO_00600,Robotics process,Mean\\ IoU\\ \\(class\\)
9,1,Semantic Segmentation,Cityscapes test,2018-08,SSMA,82.3,97.4,0.2,0.0,84.5,0.97,ito:ITO_00600,Robotics process,Mean\\ IoU\\ \\(class\\)
10,1,Semantic Segmentation,Cityscapes test,2018-09,Dense Prediction Cell,82.7,97.87,0.4,0.0,84.5,0.98,ito:ITO_00600,Robotics process,Mean\\ IoU\\ \\(class\\)
11,1,Semantic Segmentation,Cityscapes test,2018-12,DeepLabV3Plus + SDCNetAug,83.5,98.82,0.8,0.01,84.5,0.99,ito:ITO_00600,Robotics process,Mean\\ IoU\\ \\(class\\)
12,1,Semantic Segmentation,Cityscapes test,2019-09,HRNetV2 + OCR +,84.5,100.0,1.0,0.01,84.5,1.0,ito:ITO_00600,Robotics process,Mean\\ IoU\\ \\(class\\)
13,1,Semantic Segmentation,KITTI Semantic Segmentation,2018-12,DeepLabV3Plus + SDCNetAug,72.8,100.0,72.8,1.0,72.8,0.86,ito:ITO_00600,Robotics process,Mean\\ IoU\\ \\(class\\)
0,1,Real-Time Semantic Segmentation,Cityscapes test,2014-12,DeepLab,0.25,0.15,0.25,0.0,163.9,0.0,ito:ITO_00600,Robotics process,Frame\\ \\(fps\\)
1,1,Real-Time Semantic Segmentation,Cityscapes test,2015-02,CRF-RNN,1.4,0.85,1.2,0.01,163.9,0.01,ito:ITO_00600,Robotics process,Frame\\ \\(fps\\)
2,1,Real-Time Semantic Segmentation,Cityscapes test,2015-11,SegNet,16.7,10.19,15.3,0.09,163.9,0.1,ito:ITO_00600,Robotics process,Frame\\ \\(fps\\)
3,1,Real-Time Semantic Segmentation,Cityscapes test,2016-06,ENet,76.9,46.92,60.2,0.37,163.9,0.47,ito:ITO_00600,Robotics process,Frame\\ \\(fps\\)
4,1,Real-Time Semantic Segmentation,Cityscapes test,2018-08,BiSeNet(Xception39),105.8,64.55,28.9,0.18,163.9,0.65,ito:ITO_00600,Robotics process,Frame\\ \\(fps\\)
5,1,Real-Time Semantic Segmentation,Cityscapes test,2020-01,FasterSeg,163.9,100.0,58.1,0.35,163.9,1.0,ito:ITO_00600,Robotics process,Frame\\ \\(fps\\)
6,1,Real-Time Semantic Segmentation,CamVid,2014-12,DeepLab,4.9,3.94,4.9,0.04,124.5,0.03,ito:ITO_00600,Robotics process,Frame\\ \\(fps\\)
7,1,Real-Time Semantic Segmentation,CamVid,2016-12,PSPNet,5.4,4.34,0.5,0.0,124.5,0.03,ito:ITO_00600,Robotics process,Frame\\ \\(fps\\)
8,1,Real-Time Semantic Segmentation,CamVid,2017-04,ICNet,27.8,22.33,22.4,0.18,124.5,0.17,ito:ITO_00600,Robotics process,Frame\\ \\(fps\\)
9,1,Real-Time Semantic Segmentation,CamVid,2020-04,BiSeNet V2-Large(Cityscapes-Pretrained),32.7,26.27,4.9,0.04,124.5,0.2,ito:ITO_00600,Robotics process,Frame\\ \\(fps\\)
10,1,Real-Time Semantic Segmentation,CamVid,2020-04,BiSeNet V2,124.5,100.0,91.8,0.74,124.5,0.76,ito:ITO_00600,Robotics process,Frame\\ \\(fps\\)
0,1,Semantic Segmentation,Kvasir-Instrument,2015-05,UNet,0.9158,100.0,0.9158,1.0,0.9158,1.0,ito:ITO_00600,Robotics process,DSC
0,1,Conditional Image Generation,CIFAR-10,2015-11,DCGAN,6.58,68.68,6.58,0.69,9.58,0.04,ito:ITO_00600,Robotics process,Inception\\ score
1,1,Conditional Image Generation,CIFAR-10,2016-06,Improved GAN,8.09,84.45,1.5,0.16,9.58,0.05,ito:ITO_00600,Robotics process,Inception\\ score
2,1,Conditional Image Generation,CIFAR-10,2016-10,AC-GAN,8.25,86.12,0.2,0.02,9.58,0.05,ito:ITO_00600,Robotics process,Inception\\ score
3,1,Conditional Image Generation,CIFAR-10,2016-12,SGAN,8.59,89.67,0.3,0.03,9.58,0.05,ito:ITO_00600,Robotics process,Inception\\ score
4,1,Conditional Image Generation,CIFAR-10,2017-03,WGAN-GP,8.67,90.5,0.1,0.01,9.58,0.05,ito:ITO_00600,Robotics process,Inception\\ score
5,1,Conditional Image Generation,CIFAR-10,2017-09,Splitting GAN,8.87,92.59,0.2,0.02,9.58,0.05,ito:ITO_00600,Robotics process,Inception\\ score
6,1,Conditional Image Generation,CIFAR-10,2018-09,BigGAN,9.22,96.24,0.4,0.04,9.58,0.06,ito:ITO_00600,Robotics process,Inception\\ score
7,1,Conditional Image Generation,CIFAR-10,2019-12,MHingeGAN,9.58,100.0,0.4,0.04,9.58,0.06,ito:ITO_00600,Robotics process,Inception\\ score
8,1,Image Generation,CIFAR-10,2016-06,ALI,5.34,57.92,5.34,0.58,9.22,0.03,ito:ITO_00600,Robotics process,Inception\\ score
9,1,Image Generation,CIFAR-10,2016-06,Improved GAN,6.86,74.4,1.5,0.16,9.22,0.04,ito:ITO_00600,Robotics process,Inception\\ score
10,1,Image Generation,CIFAR-10,2017-02,CEGAN-Ent-VI,7.07,76.68,0.2,0.02,9.22,0.04,ito:ITO_00600,Robotics process,Inception\\ score
11,1,Image Generation,CIFAR-10,2017-03,LR-GAN,7.17,77.77,0.1,0.01,9.22,0.04,ito:ITO_00600,Robotics process,Inception\\ score
12,1,Image Generation,CIFAR-10,2017-03,WGAN-GP,7.86,85.25,0.7,0.08,9.22,0.05,ito:ITO_00600,Robotics process,Inception\\ score
13,1,Image Generation,CIFAR-10,2017-09,Splitting GAN,7.9,85.68,0.0,0.0,9.22,0.05,ito:ITO_00600,Robotics process,Inception\\ score
14,1,Image Generation,CIFAR-10,2017-10,PGGAN,8.8,95.44,0.9,0.1,9.22,0.05,ito:ITO_00600,Robotics process,Inception\\ score
15,1,Image Generation,CIFAR-10,2018-09,BigGAN,9.22,100.0,0.4,0.04,9.22,0.06,ito:ITO_00600,Robotics process,Inception\\ score
16,1,Image Generation,Stanford Dogs,2016-06,InfoGAN,43.16,91.99,43.16,0.92,46.92,0.26,ito:ITO_00600,Robotics process,Inception\\ score
17,1,Image Generation,Stanford Dogs,2018-11,FineGAN,46.92,100.0,3.8,0.08,46.92,0.28,ito:ITO_00600,Robotics process,Inception\\ score
18,1,Image Generation,Stanford Cars,2016-06,InfoGAN,28.62,87.74,28.62,0.88,32.62,0.17,ito:ITO_00600,Robotics process,Inception\\ score
19,1,Image Generation,Stanford Cars,2018-11,FineGAN,32.62,100.0,4.0,0.12,32.62,0.2,ito:ITO_00600,Robotics process,Inception\\ score
20,1,Image Generation,CUB 128 x 128,2016-06,InfoGAN,47.32,90.08,47.32,0.9,52.53,0.28,ito:ITO_00600,Robotics process,Inception\\ score
21,1,Image Generation,CUB 128 x 128,2018-11,FineGAN,52.53,100.0,5.2,0.1,52.53,0.32,ito:ITO_00600,Robotics process,Inception\\ score
22,1,Text-to-Image Generation,CUB,2016-10,GAWWN,3.62,76.21,3.62,0.76,4.75,0.02,ito:ITO_00600,Robotics process,Inception\\ score
23,1,Text-to-Image Generation,CUB,2016-12,StackGAN,3.7,77.89,0.1,0.02,4.75,0.02,ito:ITO_00600,Robotics process,Inception\\ score
24,1,Text-to-Image Generation,CUB,2017-10,StackGAN-v2,3.82,80.42,0.1,0.02,4.75,0.02,ito:ITO_00600,Robotics process,Inception\\ score
25,1,Text-to-Image Generation,CUB,2017-11,AttnGAN,4.36,91.79,0.5,0.11,4.75,0.03,ito:ITO_00600,Robotics process,Inception\\ score
26,1,Text-to-Image Generation,CUB,2019-03,MirrorGAN,4.56,96.0,0.2,0.04,4.75,0.03,ito:ITO_00600,Robotics process,Inception\\ score
27,1,Text-to-Image Generation,CUB,2019-04,DM-GAN,4.75,100.0,0.2,0.04,4.75,0.03,ito:ITO_00600,Robotics process,Inception\\ score
28,1,Conditional Image Generation,ImageNet 128x128,2016-10,AC-GAN,28.5,17.12,28.5,0.17,166.5,0.17,ito:ITO_00600,Robotics process,Inception\\ score
29,1,Conditional Image Generation,ImageNet 128x128,2018-02,Projection Discriminator,36.8,22.1,8.3,0.05,166.5,0.22,ito:ITO_00600,Robotics process,Inception\\ score
30,1,Conditional Image Generation,ImageNet 128x128,2018-05,SAGAN,52.52,31.54,15.7,0.09,166.5,0.32,ito:ITO_00600,Robotics process,Inception\\ score
31,1,Conditional Image Generation,ImageNet 128x128,2018-09,BigGAN-deep,124.5,74.77,72.0,0.43,166.5,0.75,ito:ITO_00600,Robotics process,Inception\\ score
32,1,Conditional Image Generation,ImageNet 128x128,2018-09,BigGAN-deep,166.5,100.0,42.0,0.25,166.5,1.0,ito:ITO_00600,Robotics process,Inception\\ score
33,1,Text-to-Image Generation,Oxford 102 Flowers,2016-12,StackGAN,3.2,98.16,3.2,0.98,3.26,0.02,ito:ITO_00600,Robotics process,Inception\\ score
34,1,Text-to-Image Generation,Oxford 102 Flowers,2017-10,StackGAN-v2,3.26,100.0,0.1,0.03,3.26,0.02,ito:ITO_00600,Robotics process,Inception\\ score
35,1,Text-to-Image Generation,COCO,2016-12,StackGAN,8.45,16.03,8.45,0.16,52.73,0.05,ito:ITO_00600,Robotics process,Inception\\ score
36,1,Text-to-Image Generation,COCO,2017-11,AttnGAN,25.89,49.1,17.4,0.33,52.73,0.16,ito:ITO_00600,Robotics process,Inception\\ score
37,1,Text-to-Image Generation,COCO,2019-03,MirrorGAN,26.47,50.2,0.6,0.01,52.73,0.16,ito:ITO_00600,Robotics process,Inception\\ score
38,1,Text-to-Image Generation,COCO,2019-04,DM-GAN,30.49,57.82,4.0,0.08,52.73,0.18,ito:ITO_00600,Robotics process,Inception\\ score
39,1,Text-to-Image Generation,COCO,2019-12,CPGAN,52.73,100.0,22.2,0.42,52.73,0.32,ito:ITO_00600,Robotics process,Inception\\ score
40,1,Image Generation,STL-10,2017-09,D2GAN,7.98,85.44,7.98,0.85,9.34,0.05,ito:ITO_00600,Robotics process,Inception\\ score
41,1,Image Generation,STL-10,2018-02,SN-GAN,9.1,97.43,1.1,0.12,9.34,0.05,ito:ITO_00600,Robotics process,Inception\\ score
42,1,Image Generation,STL-10,2018-12,Improving MMD GAN,9.34,100.0,0.2,0.02,9.34,0.06,ito:ITO_00600,Robotics process,Inception\\ score
0,1,Face Anti-Spoofing,Replay-Attack,2015-11,YCbCr+HSV-LBP,2.9,100.0,2.9,1.0,2.9,1.0,ito:ITO_00600,Robotics process,HTER
1,1,Face Anti-Spoofing,CASIA-MFSD,2019-01,3D Synthesis (balancing sampling),1.67,100.0,1.67,1.0,1.67,0.58,ito:ITO_00600,Robotics process,HTER
0,1,Face Anti-Spoofing,MSU-MFSD,2015-11,Color LBP,10.8,100.0,10.8,1.0,10.8,1.0,ito:ITO_00600,Robotics process,Equal\\ Error\\ Rate
0,1,Semantic Segmentation,CamVid,2015-11,ReSeg,88.7,96.94,88.7,0.97,91.5,0.97,ito:ITO_00600,Robotics process,Global\\ Accuracy
1,1,Semantic Segmentation,CamVid,2016-11,FC-DenseNet103,91.5,100.0,2.8,0.03,91.5,1.0,ito:ITO_00600,Robotics process,Global\\ Accuracy
0,1,Monocular 3D Human Pose Estimation,Human3.6M,2015-11,Sparseness Meets Deepness,300.0,100.0,300,1.0,300,1.0,ito:ITO_00600,Robotics process,Frames\\ Needed
0,1,Image Generation,Binarized MNIST,2016-01,PixelCNN,81.3,100.0,81.3,1.0,81.3,1.0,ito:ITO_00600,Robotics process,nats
0,1,Image Generation,ImageNet 32x32,2016-01,PixelRNN,3.86,90.19,3.86,0.9,4.28,0.9,ito:ITO_00600,Robotics process,bpd
1,1,Image Generation,ImageNet 32x32,2016-05,"Real NVP (Dinh et al., 2017)",4.28,100.0,0.4,0.09,4.28,1.0,ito:ITO_00600,Robotics process,bpd
2,1,Image Generation,CelebA 256x256,2018-07,"Glow (Kingma and Dhariwal, 2018)",1.03,100.0,1.03,1.0,1.03,0.24,ito:ITO_00600,Robotics process,bpd
3,1,Image Generation,MNIST,2018-11,i-ResNet,1.06,100.0,1.06,1.0,1.06,0.25,ito:ITO_00600,Robotics process,bpd
4,1,Image Generation,ImageNet 64x64,2019-02,Flow++,3.69,98.4,3.69,0.98,3.75,0.86,ito:ITO_00600,Robotics process,bpd
5,1,Image Generation,ImageNet 64x64,2019-02,MaCow (Unf),3.75,100.0,0.1,0.03,3.75,0.88,ito:ITO_00600,Robotics process,bpd
0,1,3D Reconstruction,Scan2CAD,2016-03,3DMatch,10.29,32.48,10.29,0.32,31.68,0.14,ito:ITO_00600,Robotics process,Average\\ Accuracy
1,1,3D Reconstruction,Scan2CAD,2018-11,Scan2CAD,31.68,100.0,21.4,0.68,31.68,0.42,ito:ITO_00600,Robotics process,Average\\ Accuracy
2,1,Scene Segmentation,ScanNet,2016-12,PointNet++,60.2,80.27,60.2,0.8,75.0,0.8,ito:ITO_00600,Robotics process,Average\\ Accuracy
3,1,Scene Segmentation,ScanNet,2018-03,3DMV,75.0,100.0,14.8,0.2,75.0,1.0,ito:ITO_00600,Robotics process,Average\\ Accuracy
4,1,Skeleton Based Action Recognition,UAV-Human,2018-01,ST-GCN,30.25,86.83,30.25,0.87,34.84,0.4,ito:ITO_00600,Robotics process,Average\\ Accuracy
5,1,Skeleton Based Action Recognition,UAV-Human,2018-05,2S-AGCN,34.84,100.0,4.6,0.13,34.84,0.46,ito:ITO_00600,Robotics process,Average\\ Accuracy
0,1,3D Reconstruction,Data3D−R2N2,2016-04,3D-R2N2,0.56,84.72,0.56,0.85,0.661,0.01,ito:ITO_00600,Robotics process,3DIoU
1,1,3D Reconstruction,Data3D−R2N2,2016-12,PSGN,0.64,96.82,0.1,0.15,0.661,0.01,ito:ITO_00600,Robotics process,3DIoU
2,1,3D Reconstruction,Data3D−R2N2,2018-08,AttSets,0.642,97.13,0.0,0.0,0.661,0.01,ito:ITO_00600,Robotics process,3DIoU
3,1,3D Reconstruction,Data3D−R2N2,2019-01,Pix2Vox-A,0.661,100.0,0.0,0.0,0.661,0.01,ito:ITO_00600,Robotics process,3DIoU
4,1,Semantic Segmentation,ScanNet,2017-02,ScanNet,0.306,41.69,0.306,0.42,0.734,0.0,ito:ITO_00600,Robotics process,3DIoU
5,1,Semantic Segmentation,ScanNet,2017-06,PointNet++,0.339,46.19,0.0,0.0,0.734,0.0,ito:ITO_00600,Robotics process,3DIoU
6,1,Semantic Segmentation,ScanNet,2017-11,SparseConvNet,0.725,98.77,0.4,0.54,0.734,0.01,ito:ITO_00600,Robotics process,3DIoU
7,1,Semantic Segmentation,ScanNet,2019-04,MinkowskiNet,0.734,100.0,0.0,0.0,0.734,0.01,ito:ITO_00600,Robotics process,3DIoU
8,1,3D Room Layouts From A Single Rgb Panorama,Stanford 2D-3D,2018-03,LayoutNet,76.33,95.66,76.33,0.96,79.79,0.93,ito:ITO_00600,Robotics process,3DIoU
9,1,3D Room Layouts From A Single Rgb Panorama,Stanford 2D-3D,2018-11,DuLa-Net,79.36,99.46,3.0,0.04,79.79,0.97,ito:ITO_00600,Robotics process,3DIoU
10,1,3D Room Layouts From A Single Rgb Panorama,Stanford 2D-3D,2019-01,HorizonNet,79.79,100.0,0.4,0.01,79.79,0.97,ito:ITO_00600,Robotics process,3DIoU
11,1,3D Room Layouts From A Single Rgb Panorama,Realtor360,2018-03,LayoutNet,62.77,81.31,62.77,0.81,77.2,0.76,ito:ITO_00600,Robotics process,3DIoU
12,1,3D Room Layouts From A Single Rgb Panorama,Realtor360,2018-11,DuLa-Net,77.2,100.0,14.4,0.19,77.2,0.94,ito:ITO_00600,Robotics process,3DIoU
13,1,3D Room Layouts From A Single Rgb Panorama,PanoContext,2018-03,LayoutNet,74.48,90.64,74.48,0.91,82.17,0.91,ito:ITO_00600,Robotics process,3DIoU
14,1,3D Room Layouts From A Single Rgb Panorama,PanoContext,2018-11,DuLa-Net,77.42,94.22,2.9,0.04,82.17,0.94,ito:ITO_00600,Robotics process,3DIoU
15,1,3D Room Layouts From A Single Rgb Panorama,PanoContext,2019-01,HorizonNet,82.17,100.0,4.8,0.06,82.17,1.0,ito:ITO_00600,Robotics process,3DIoU
16,1,3D Room Layouts From A Single RGB Panorama,Stanford 2D-3D,2018-03,LayoutNet,76.33,95.66,76.33,0.96,79.79,0.93,ito:ITO_00600,Robotics process,3DIoU
17,1,3D Room Layouts From A Single RGB Panorama,Stanford 2D-3D,2018-11,DuLa-Net,79.36,99.46,3.0,0.04,79.79,0.97,ito:ITO_00600,Robotics process,3DIoU
18,1,3D Room Layouts From A Single RGB Panorama,Stanford 2D-3D,2019-01,HorizonNet,79.79,100.0,0.4,0.01,79.79,0.97,ito:ITO_00600,Robotics process,3DIoU
19,1,3D Room Layouts From A Single RGB Panorama,Realtor360,2018-03,LayoutNet,62.77,81.31,62.77,0.81,77.2,0.76,ito:ITO_00600,Robotics process,3DIoU
20,1,3D Room Layouts From A Single RGB Panorama,Realtor360,2018-11,DuLa-Net,77.2,100.0,14.4,0.19,77.2,0.94,ito:ITO_00600,Robotics process,3DIoU
21,1,3D Room Layouts From A Single RGB Panorama,PanoContext,2018-03,LayoutNet,74.48,90.64,74.48,0.91,82.17,0.91,ito:ITO_00600,Robotics process,3DIoU
22,1,3D Room Layouts From A Single RGB Panorama,PanoContext,2018-11,DuLa-Net,77.42,94.22,2.9,0.04,82.17,0.94,ito:ITO_00600,Robotics process,3DIoU
23,1,3D Room Layouts From A Single RGB Panorama,PanoContext,2019-01,HorizonNet,82.17,100.0,4.8,0.06,82.17,1.0,ito:ITO_00600,Robotics process,3DIoU
24,1,Scene Segmentation,ScanNet,2019-04,KPConv,68.6,100.0,68.6,1.0,68.6,0.83,ito:ITO_00600,Robotics process,3DIoU
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,13.0,44.83,13,0.45,29,0.45,ito:ITO_00600,Robotics process,Accuracy\\ \\(CV\\ I\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,LSTM,16.0,55.17,3,0.1,29,0.55,ito:ITO_00600,Robotics process,Accuracy\\ \\(CV\\ I\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-08,SK-CNN,26.0,89.66,10,0.34,29,0.9,ito:ITO_00600,Robotics process,Accuracy\\ \\(CV\\ I\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,29.0,100.0,3,0.1,29,1.0,ito:ITO_00600,Robotics process,Accuracy\\ \\(CV\\ I\\)
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,LSTM,31.0,43.66,31,0.44,71,0.44,ito:ITO_00600,Robotics process,Accuracy\\ \\(CV\\ II\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,33.0,46.48,2,0.03,71,0.46,ito:ITO_00600,Robotics process,Accuracy\\ \\(CV\\ II\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-11,TCN,43.0,60.56,10,0.14,71,0.61,ito:ITO_00600,Robotics process,Accuracy\\ \\(CV\\ II\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-04,Res-TCN,48.0,67.61,5,0.07,71,0.68,ito:ITO_00600,Robotics process,Accuracy\\ \\(CV\\ II\\)
4,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-08,SK-CNN,68.0,95.77,20,0.28,71,0.96,ito:ITO_00600,Robotics process,Accuracy\\ \\(CV\\ II\\)
5,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,71.0,100.0,3,0.04,71,1.0,ito:ITO_00600,Robotics process,Accuracy\\ \\(CV\\ II\\)
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,33.0,57.89,33,0.58,57,0.58,ito:ITO_00600,Robotics process,Accuracy\\ \\(AV\\ I\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-11,TCN,43.0,75.44,10,0.18,57,0.75,ito:ITO_00600,Robotics process,Accuracy\\ \\(AV\\ I\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-04,Res-TCN,48.0,84.21,5,0.09,57,0.84,ito:ITO_00600,Robotics process,Accuracy\\ \\(AV\\ I\\)
3,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2018-01,ST-GCN,53.0,92.98,5,0.09,57,0.93,ito:ITO_00600,Robotics process,Accuracy\\ \\(AV\\ I\\)
4,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2019-04,VS-CNN,57.0,100.0,4,0.07,57,1.0,ito:ITO_00600,Robotics process,Accuracy\\ \\(AV\\ I\\)
0,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,P-LSTM,50.0,64.94,50,0.65,77,0.65,ito:ITO_00600,Robotics process,Accuracy\\ \\(AV\\ II\\)
1,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2016-04,LSTM,68.0,88.31,18,0.23,77,0.88,ito:ITO_00600,Robotics process,Accuracy\\ \\(AV\\ II\\)
2,1,Skeleton Based Action Recognition,Varying-view RGB-D Action-Skeleton,2017-08,SK-CNN,77.0,100.0,9,0.12,77,1.0,ito:ITO_00600,Robotics process,Accuracy\\ \\(AV\\ II\\)
0,1,Playing Game of Doom,ViZDoom Basic Scenario,2016-05,DQN,82.2,100.0,82.2,1.0,82.2,1.0,ito:ITO_00600,Robotics process,Average\\ Score
0,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,BiGAN,0.02,11.11,0.02,0.11,0.18,0.06,ito:ITO_00600,Robotics process,Class\\ IOU
1,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,CoGAN,0.06,33.33,0.0,0.0,0.18,0.19,ito:ITO_00600,Robotics process,Class\\ IOU
2,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-11,pix2pix,0.18,100.0,0.1,0.56,0.18,0.56,ito:ITO_00600,Robotics process,Class\\ IOU
3,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-06,BiGAN,0.07,21.88,0.07,0.22,0.32,0.22,ito:ITO_00600,Robotics process,Class\\ IOU
4,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-06,CoGAN,0.08,25.0,0.0,0.0,0.32,0.25,ito:ITO_00600,Robotics process,Class\\ IOU
5,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-11,pix2pix,0.32,100.0,0.2,0.62,0.32,1.0,ito:ITO_00600,Robotics process,Class\\ IOU
6,1,Image-to-Image Translation,Aerial-to-Map,2016-11,cGAN,0.26,100.0,0.26,1.0,0.26,0.81,ito:ITO_00600,Robotics process,Class\\ IOU
0,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,BiGAN,19.0,23.09,19.0,0.23,82.3,0.21,ito:ITO_00600,Robotics process,Per\\-pixel\\ Accuracy
1,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,CoGAN,40.0,48.6,21.0,0.26,82.3,0.43,ito:ITO_00600,Robotics process,Per\\-pixel\\ Accuracy
2,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-11,pix2pix,71.0,86.27,31.0,0.38,82.3,0.77,ito:ITO_00600,Robotics process,Per\\-pixel\\ Accuracy
3,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2017-07,CRN,77.1,93.68,6.1,0.07,82.3,0.84,ito:ITO_00600,Robotics process,Per\\-pixel\\ Accuracy
4,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2017-11,pix2pixHD,81.4,98.91,4.3,0.05,82.3,0.88,ito:ITO_00600,Robotics process,Per\\-pixel\\ Accuracy
5,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2019-03,SPADE,81.9,99.51,0.5,0.01,82.3,0.89,ito:ITO_00600,Robotics process,Per\\-pixel\\ Accuracy
6,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2019-10,CC-FPSE,82.3,100.0,0.4,0.0,82.3,0.89,ito:ITO_00600,Robotics process,Per\\-pixel\\ Accuracy
7,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-06,BiGAN,41.0,48.24,41,0.48,85,0.45,ito:ITO_00600,Robotics process,Per\\-pixel\\ Accuracy
8,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-06,CoGAN,45.0,52.94,4,0.05,85,0.49,ito:ITO_00600,Robotics process,Per\\-pixel\\ Accuracy
9,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-11,pix2pix,85.0,100.0,40,0.47,85,0.92,ito:ITO_00600,Robotics process,Per\\-pixel\\ Accuracy
10,1,Image-to-Image Translation,Aerial-to-Map,2016-11,cGAN,70.0,100.0,70,1.0,70,0.76,ito:ITO_00600,Robotics process,Per\\-pixel\\ Accuracy
11,1,Image-to-Image Translation,SYNTHIA Fall-to-Winter,2017-11,CyCADA,92.1,100.0,92.1,1.0,92.1,1.0,ito:ITO_00600,Robotics process,Per\\-pixel\\ Accuracy
12,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2017-11,CyCADA pixel+feat,82.3,100.0,82.3,1.0,82.3,0.89,ito:ITO_00600,Robotics process,Per\\-pixel\\ Accuracy
0,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,BiGAN,6.0,24.0,6,0.24,25,0.13,ito:ITO_00600,Robotics process,Per\\-class\\ Accuracy
1,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-06,CoGAN,10.0,40.0,4,0.16,25,0.22,ito:ITO_00600,Robotics process,Per\\-class\\ Accuracy
2,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2016-11,pix2pix,25.0,100.0,15,0.6,25,0.54,ito:ITO_00600,Robotics process,Per\\-class\\ Accuracy
3,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-06,BiGAN,13.0,32.5,13,0.32,40,0.28,ito:ITO_00600,Robotics process,Per\\-class\\ Accuracy
4,1,Image-to-Image Translation,Cityscapes Photo-to-Labels,2016-11,pix2pix,40.0,100.0,27,0.68,40,0.87,ito:ITO_00600,Robotics process,Per\\-class\\ Accuracy
5,1,Image-to-Image Translation,Aerial-to-Map,2016-11,cGAN,46.0,100.0,46,1.0,46,1.0,ito:ITO_00600,Robotics process,Per\\-class\\ Accuracy
0,1,Image Generation,Stanford Dogs,2016-06,InfoGAN,29.34,53.43,29.34,0.53,54.91,0.19,ito:ITO_00600,Robotics process,FID
1,1,Image Generation,Stanford Dogs,2017-03,LR-GAN,54.91,100.0,25.6,0.47,54.91,0.35,ito:ITO_00600,Robotics process,FID
2,1,Image Generation,CUB 128 x 128,2016-06,InfoGAN,13.2,37.81,13.2,0.38,34.91,0.08,ito:ITO_00600,Robotics process,FID
3,1,Image Generation,CUB 128 x 128,2017-03,LR-GAN,34.91,100.0,21.7,0.62,34.91,0.22,ito:ITO_00600,Robotics process,FID
4,1,Image Generation,Stanford Cars,2016-06,InfoGAN,17.63,19.85,17.63,0.2,88.8,0.11,ito:ITO_00600,Robotics process,FID
5,1,Image Generation,Stanford Cars,2017-03,LR-GAN,88.8,100.0,71.2,0.8,88.8,0.57,ito:ITO_00600,Robotics process,FID
6,1,Text-to-Image Generation,CUB,2016-10,GAWWN,67.22,100.0,67.22,1.0,67.22,0.43,ito:ITO_00600,Robotics process,FID
7,1,Fundus to Angiography Generation,Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients,2016-11,pix2pix,48.6,100.0,48.6,1.0,48.6,0.31,ito:ITO_00600,Robotics process,FID
8,1,Image Generation,CAT 256x256,2017-03,WGAN-GP,155.46,100.0,155.46,1.0,155.46,1.0,ito:ITO_00600,Robotics process,FID
9,1,Image Generation,CIFAR-10,2017-03,WGAN-GP,29.3,56.13,29.3,0.56,52.202,0.19,ito:ITO_00600,Robotics process,FID
10,1,Image Generation,CIFAR-10,2019-05,GLF+perceptual loss (ours),44.6,85.44,15.3,0.29,52.202,0.29,ito:ITO_00600,Robotics process,FID
11,1,Image Generation,CIFAR-10,2019-06,Residual Flow,46.37,88.83,1.8,0.03,52.202,0.3,ito:ITO_00600,Robotics process,FID
12,1,Image Generation,CIFAR-10,2019-10,PresGAN,52.202,100.0,5.8,0.11,52.202,0.34,ito:ITO_00600,Robotics process,FID
13,1,Image Generation,LSUN Bedroom 256 x 256,2017-06,WGAN-GP + TT Update Rule,9.5,26.68,9.5,0.27,35.61,0.06,ito:ITO_00600,Robotics process,FID
14,1,Image Generation,LSUN Bedroom 256 x 256,2017-10,StackGAN-v2,35.61,100.0,26.1,0.73,35.61,0.23,ito:ITO_00600,Robotics process,FID
15,1,Image Generation,LSUN Bedroom 64 x 64,2017-06,WGAN-GP + TT Update Rule,9.5,83.33,9.5,0.83,11.4,0.06,ito:ITO_00600,Robotics process,FID
16,1,Image Generation,LSUN Bedroom 64 x 64,2018-02,FOGAN,11.4,100.0,1.9,0.17,11.4,0.07,ito:ITO_00600,Robotics process,FID
17,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2017-07,CRN,73.3,89.61,73.3,0.9,81.8,0.47,ito:ITO_00600,Robotics process,FID
18,1,Image-to-Image Translation,ADE20K Labels-to-Photos,2017-11,pix2pixHD,81.8,100.0,8.5,0.1,81.8,0.53,ito:ITO_00600,Robotics process,FID
19,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2017-07,CRN,70.4,63.14,70.4,0.63,111.5,0.45,ito:ITO_00600,Robotics process,FID
20,1,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,2017-11,pix2pixHD,111.5,100.0,41.1,0.37,111.5,0.72,ito:ITO_00600,Robotics process,FID
21,1,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,2017-07,CRN,99.0,100.0,99.0,1.0,99.0,0.64,ito:ITO_00600,Robotics process,FID
22,1,Image-to-Image Translation,Cityscapes Labels-to-Photo,2017-07,CRN,104.7,100.0,104.7,1.0,104.7,0.67,ito:ITO_00600,Robotics process,FID
23,1,Text-to-Image Generation,COCO,2017-10,StackGAN-v1 ,74.05,90.76,74.05,0.91,81.59,0.48,ito:ITO_00600,Robotics process,FID
24,1,Text-to-Image Generation,COCO,2017-10,StackGAN-v2,81.59,100.0,7.5,0.09,81.59,0.52,ito:ITO_00600,Robotics process,FID
25,1,Text-to-Image Generation,Oxford 102 Flowers,2017-10,StackGAN-v2,48.68,88.06,48.68,0.88,55.28,0.31,ito:ITO_00600,Robotics process,FID
26,1,Text-to-Image Generation,Oxford 102 Flowers,2017-10,StackGAN-v1 ,55.28,100.0,6.6,0.12,55.28,0.36,ito:ITO_00600,Robotics process,FID
27,1,Image Generation,FFHQ,2017-10,PGGAN,8.04,100.0,8.04,1.0,8.04,0.05,ito:ITO_00600,Robotics process,FID
28,1,Image Generation,LSUN Churches 256 x 256,2017-10,PGGAN,6.42,100.0,6.42,1.0,6.42,0.04,ito:ITO_00600,Robotics process,FID
29,1,Image Generation,CelebA-HQ 1024x1024,2017-10,PGGAN,7.3,76.92,7.3,0.77,9.49,0.05,ito:ITO_00600,Robotics process,FID
30,1,Image Generation,CelebA-HQ 1024x1024,2019-03,COCO-GAN,9.49,100.0,2.2,0.23,9.49,0.06,ito:ITO_00600,Robotics process,FID
31,1,Image Generation,LSUN Cat 256 x 256,2017-10,PGGAN,37.52,100.0,37.52,1.0,37.52,0.24,ito:ITO_00600,Robotics process,FID
32,1,Image Generation,CelebA-HQ 256x256,2017-10,PGGAN,8.03,11.65,8.03,0.12,68.93,0.05,ito:ITO_00600,Robotics process,FID
33,1,Image Generation,CelebA-HQ 256x256,2018-07,GLOW,68.93,100.0,60.9,0.88,68.93,0.44,ito:ITO_00600,Robotics process,FID
34,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2017-11,AttnGAN,125.98,96.13,125.98,0.96,131.05,0.81,ito:ITO_00600,Robotics process,FID
35,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2019-04,DM-GAN,131.05,100.0,5.1,0.04,131.05,0.84,ito:ITO_00600,Robotics process,FID
36,1,Conditional Image Generation,CIFAR-10,2018-02,Projection Discriminator,17.5,100.0,17.5,1.0,17.5,0.11,ito:ITO_00600,Robotics process,FID
37,1,Conditional Image Generation,ImageNet 128x128,2018-02,Projection Discriminator,27.62,100.0,27.62,1.0,27.62,0.18,ito:ITO_00600,Robotics process,FID
38,1,Image Generation,STL-10,2018-02,SN-GAN,40.1,85.79,40.1,0.86,46.74,0.26,ito:ITO_00600,Robotics process,FID
39,1,Image Generation,STL-10,2019-05,ProbGAN,46.74,100.0,6.6,0.14,46.74,0.3,ito:ITO_00600,Robotics process,FID
40,1,Layout-to-Image Generation,Visual Genome 64x64,2018-04,SG2Im,74.61,100.0,74.61,1.0,74.61,0.48,ito:ITO_00600,Robotics process,FID
41,1,Layout-to-Image Generation,COCO-Stuff 64x64,2018-04,SG2Im,67.96,100.0,67.96,1.0,67.96,0.44,ito:ITO_00600,Robotics process,FID
42,1,Multimodal Unsupervised Image-To-Image Translation,AFHQ,2018-04,MUNIT,41.5,43.41,41.5,0.43,95.6,0.27,ito:ITO_00600,Robotics process,FID
43,1,Multimodal Unsupervised Image-To-Image Translation,AFHQ,2018-08,DRIT,95.6,100.0,54.1,0.57,95.6,0.61,ito:ITO_00600,Robotics process,FID
44,1,Multimodal Unsupervised Image-To-Image Translation,CelebA-HQ,2018-04,MUNIT,31.4,60.27,31.4,0.6,52.1,0.2,ito:ITO_00600,Robotics process,FID
45,1,Multimodal Unsupervised Image-To-Image Translation,CelebA-HQ,2018-08,DRIT,52.1,100.0,20.7,0.4,52.1,0.34,ito:ITO_00600,Robotics process,FID
46,1,Image Generation,ImageNet 256x256,2018-09,BigGAN-deep,8.1,100.0,8.1,1.0,8.1,0.05,ito:ITO_00600,Robotics process,FID
47,1,Image Generation,ImageNet 128x128,2018-09,BigGAN,14.88,33.92,14.88,0.34,43.87,0.1,ito:ITO_00600,Robotics process,FID
48,1,Image Generation,ImageNet 128x128,2018-11,SS-GAN (sBN),43.87,100.0,29.0,0.66,43.87,0.28,ito:ITO_00600,Robotics process,FID
49,1,Image Generation,CelebA-HQ 128x128,2018-11,SS-GAN (sBN),24.36,100.0,24.36,1.0,24.36,0.16,ito:ITO_00600,Robotics process,FID
50,1,Image Generation,Indian Celebs 256 x 256,2019-03,MSG-StyleGAN,28.44,100.0,28.44,1.0,28.44,0.18,ito:ITO_00600,Robotics process,FID
51,1,Image Generation,Oxford 102 Flowers 256 x 256,2019-03,MSG-StyleGAN,19.6,100.0,19.6,1.0,19.6,0.13,ito:ITO_00600,Robotics process,FID
52,1,Image Generation,CelebA-HQ 64x64,2019-03,COCO-GAN,4.0,100.0,4,1.0,4,0.03,ito:ITO_00600,Robotics process,FID
53,1,Talking Head Generation,VoxCeleb2,2019-05,Few-shot Adversarial Model,48.5,100.0,48.5,1.0,48.5,0.31,ito:ITO_00600,Robotics process,FID
54,1,Talking Head Generation,VoxCeleb1,2019-05,Few-shot Adversarial Model,29.5,100.0,29.5,1.0,29.5,0.19,ito:ITO_00600,Robotics process,FID
55,1,Talking Head Generation,VoxCeleb2,2019-05,Few-shot Adversarial Model,30.6,100.0,30.6,1.0,30.6,0.2,ito:ITO_00600,Robotics process,FID
56,1,Talking Head Generation,VoxCeleb1,2019-05,Few-shot Adversarial Model,43.0,100.0,43,1.0,43,0.28,ito:ITO_00600,Robotics process,FID
57,1,Talking Head Generation,VoxCeleb1,2019-05,Few-shot Adversarial Model,38.0,100.0,38,1.0,38,0.24,ito:ITO_00600,Robotics process,FID
58,1,Talking Head Generation,VoxCeleb2,2019-05,Few-shot Adversarial Model,42.2,100.0,42.2,1.0,42.2,0.27,ito:ITO_00600,Robotics process,FID
59,1,Image Generation,CelebA 256x256,2019-05,GLF+perceptual loss (ours),41.8,100.0,41.8,1.0,41.8,0.27,ito:ITO_00600,Robotics process,FID
60,1,Image Generation,MNIST,2019-05,GLF+perceptual loss (ours),5.8,13.8,5.8,0.14,42.019,0.04,ito:ITO_00600,Robotics process,FID
61,1,Image Generation,MNIST,2019-10,PresGAN,42.019,100.0,36.2,0.86,42.019,0.27,ito:ITO_00600,Robotics process,FID
62,1,Image Generation,Fashion-MNIST,2019-05,GLF+perceptual loss (ours),10.3,100.0,10.3,1.0,10.3,0.07,ito:ITO_00600,Robotics process,FID
63,1,Image Generation,ImageNet 64x64,2019-07,BigBiGAN,15.82,100.0,15.82,1.0,15.82,0.1,ito:ITO_00600,Robotics process,FID
64,1,Layout-to-Image Generation,Visual Genome 128x128,2019-08,LostGAN,29.36,100.0,29.36,1.0,29.36,0.19,ito:ITO_00600,Robotics process,FID
65,1,Layout-to-Image Generation,COCO-Stuff 128x128,2019-08,LostGAN,29.65,49.83,29.65,0.5,59.5,0.19,ito:ITO_00600,Robotics process,FID
66,1,Layout-to-Image Generation,COCO-Stuff 128x128,2019-09,SOARISG,59.5,100.0,29.8,0.5,59.5,0.38,ito:ITO_00600,Robotics process,FID
67,1,Image Generation,Stacked MNIST,2019-10,PresGAN,23.965,100.0,23.965,1.0,23.965,0.15,ito:ITO_00600,Robotics process,FID
68,1,Image Generation,CelebA 128 x 128,2019-10,PresGAN,29.115,100.0,29.115,1.0,29.115,0.19,ito:ITO_00600,Robotics process,FID
69,1,Pose Transfer,Deep-Fashion,2019-10,bFT,12.266,100.0,12.266,1.0,12.266,0.08,ito:ITO_00600,Robotics process,FID
70,1,Image Generation,ImageNet 32x32,2019-11,MSGAN,12.3,100.0,12.3,1.0,12.3,0.08,ito:ITO_00600,Robotics process,FID
71,1,Image Generation,CIFAR-100,2019-11,MSGAN,19.74,100.0,19.74,1.0,19.74,0.13,ito:ITO_00600,Robotics process,FID
72,1,Image Generation,Cityscapes-5K 256x512,2019-11,SB-GAN,65.49,100.0,65.49,1.0,65.49,0.42,ito:ITO_00600,Robotics process,FID
73,1,Image-to-Image Translation,ADE-Indoor Labels-to-Photo,2019-11,SB-GAN,48.15,100.0,48.15,1.0,48.15,0.31,ito:ITO_00600,Robotics process,FID
74,1,Image Generation,Cityscapes-25K 256x512,2019-11,SB-GAN,62.97,100.0,62.97,1.0,62.97,0.41,ito:ITO_00600,Robotics process,FID
75,1,Image Generation,ADE-Indoor,2019-11,SB-GAN,85.27,100.0,85.27,1.0,85.27,0.55,ito:ITO_00600,Robotics process,FID
76,1,Image Generation,LSUN Horse 256 x 256,2019-12,StyleGAN2,3.43,100.0,3.43,1.0,3.43,0.02,ito:ITO_00600,Robotics process,FID
77,1,Image Generation,LSUN Car 256 x 256,2019-12,StyleGAN2,2.32,100.0,2.32,1.0,2.32,0.01,ito:ITO_00600,Robotics process,FID
78,1,Image Generation,LSUN Car 512 x 384,2019-12,StyleGAN2,2.32,100.0,2.32,1.0,2.32,0.01,ito:ITO_00600,Robotics process,FID
79,1,Image-to-Image Translation,AFHQ,2019-12,StarGAN v2,24.4,100.0,24.4,1.0,24.4,0.16,ito:ITO_00600,Robotics process,FID
80,1,Image-to-Image Translation,CelebA-HQ,2019-12,StarGAN v2,18.0,100.0,18.0,1.0,18.0,0.12,ito:ITO_00600,Robotics process,FID
81,1,Image-to-Image Translation,Deep-Fashion,2020-04,CoCosNet,14.4,100.0,14.4,1.0,14.4,0.09,ito:ITO_00600,Robotics process,FID
0,1,Image Generation,ImageNet 64x64,2016-06,"Gated PixelCNN (van den Oord et al., [2016c])",3.57,93.7,3.57,0.94,3.81,0.94,ito:ITO_00600,Robotics process,Bits\\ per\\ byte
1,1,Image Generation,ImageNet 64x64,2017-03,Parallel Multiscale,3.7,97.11,0.1,0.03,3.81,0.97,ito:ITO_00600,Robotics process,Bits\\ per\\ byte
2,1,Image Generation,ImageNet 64x64,2018-07,GLOW,3.81,100.0,0.1,0.03,3.81,1.0,ito:ITO_00600,Robotics process,Bits\\ per\\ byte
0,1,Image Generation,ImageNet 64x64,2016-06,"Gated PixelCNN (van den Oord et al., [2016c])",3.57,93.7,3.57,0.94,3.81,0.94,ito:ITO_00600,Robotics process,Bits\\ per\\ dim
1,1,Image Generation,ImageNet 64x64,2017-03,Parallel Multiscale,3.7,97.11,0.1,0.03,3.81,0.97,ito:ITO_00600,Robotics process,Bits\\ per\\ dim
2,1,Image Generation,ImageNet 64x64,2018-07,"Glow (Kingma and Dhariwal, 2018)",3.81,100.0,0.1,0.03,3.81,1.0,ito:ITO_00600,Robotics process,Bits\\ per\\ dim
0,1,Surgical Skills Evaluation,MISTIC-SIL,2016-06,Bidir. LSTM,19.5,100.0,19.5,1.0,19.5,1.0,ito:ITO_00600,Robotics process,Edit\\ Distance
1,1,Handwritten Word Generation,Handwritten Word Generation,2016-06,Bidir. LSTM,19.5,100.0,19.5,1.0,19.5,1.0,ito:ITO_00600,Robotics process,Edit\\ Distance
2,1,Surgical Skills Evaluation,JIGSAWS,2016-06,Bidir. LSTM,14.6,100.0,14.6,1.0,14.6,0.75,ito:ITO_00600,Robotics process,Edit\\ Distance
3,1,Zero-Shot Text-to-Image Generation,Zero-Shot Text-to-Image Generation,2016-06,Bidir. LSTM,14.6,100.0,14.6,1.0,14.6,0.75,ito:ITO_00600,Robotics process,Edit\\ Distance
0,1,3D Part Segmentation,ShapeNet-Part,2016-06,3D-UNet [Cicek:2016un],84.6,90.87,84.6,0.91,93.1,0.91,ito:ITO_00600,Robotics process,Instance\\ Average\\ IoU
1,1,3D Part Segmentation,ShapeNet-Part,2016-12,SSCNN,84.7,90.98,0.1,0.0,93.1,0.91,ito:ITO_00600,Robotics process,Instance\\ Average\\ IoU
2,1,3D Part Segmentation,ShapeNet-Part,2017-06,SSCN,86.0,92.37,1.3,0.01,93.1,0.92,ito:ITO_00600,Robotics process,Instance\\ Average\\ IoU
3,1,3D Part Segmentation,ShapeNet-Part,2018-01,PointCNN,86.14,92.52,0.1,0.0,93.1,0.93,ito:ITO_00600,Robotics process,Instance\\ Average\\ IoU
4,1,3D Part Segmentation,ShapeNet-Part,2019-04,ConvPoint,93.1,100.0,7.0,0.08,93.1,1.0,ito:ITO_00600,Robotics process,Instance\\ Average\\ IoU
0,1,Image-to-Image Translation,RaFD,2016-10,DIA,4.1,50.81,4.1,0.51,8.07,0.51,ito:ITO_00600,Robotics process,Classification\\ Error
1,1,Image-to-Image Translation,RaFD,2016-11,IcGAN,8.07,100.0,4.0,0.5,8.07,1.0,ito:ITO_00600,Robotics process,Classification\\ Error
0,1,3D Shape Retrieval,Pix3D,2016-10,3D-VAE-GAN,0.02,3.77,0.02,0.04,0.53,0.04,ito:ITO_00600,Robotics process,R\\-at\\-1
1,1,3D Shape Retrieval,Pix3D,2017-11,MarrNet,0.42,79.25,0.4,0.75,0.53,0.79,ito:ITO_00600,Robotics process,R\\-at\\-1
2,1,3D Shape Retrieval,Pix3D,2018-04,MarrNet extension (w/o Pose),0.53,100.0,0.1,0.19,0.53,1.0,ito:ITO_00600,Robotics process,R\\-at\\-1
3,1,3D Shape Classification,Pix3D,2016-10,3D-VAE-GAN,0.02,3.77,0.02,0.04,0.53,0.04,ito:ITO_00600,Robotics process,R\\-at\\-1
4,1,3D Shape Classification,Pix3D,2017-11,MarrNet,0.42,79.25,0.4,0.75,0.53,0.79,ito:ITO_00600,Robotics process,R\\-at\\-1
5,1,3D Shape Classification,Pix3D,2018-04,MarrNet extension (w/o Pose),0.53,100.0,0.1,0.19,0.53,1.0,ito:ITO_00600,Robotics process,R\\-at\\-1
0,1,3D Shape Classification,Pix3D,2016-10,3D-VAE-GAN,0.21,24.71,0.21,0.25,0.85,0.25,ito:ITO_00600,Robotics process,R\\-at\\-16
1,1,3D Shape Classification,Pix3D,2017-11,MarrNet,0.71,83.53,0.5,0.59,0.85,0.84,ito:ITO_00600,Robotics process,R\\-at\\-16
2,1,3D Shape Classification,Pix3D,2018-04,MarrNet extension (w/o Pose),0.85,100.0,0.1,0.12,0.85,1.0,ito:ITO_00600,Robotics process,R\\-at\\-16
3,1,3D Shape Retrieval,Pix3D,2016-10,3D-VAE-GAN,0.21,24.71,0.21,0.25,0.85,0.25,ito:ITO_00600,Robotics process,R\\-at\\-16
4,1,3D Shape Retrieval,Pix3D,2017-11,MarrNet,0.71,83.53,0.5,0.59,0.85,0.84,ito:ITO_00600,Robotics process,R\\-at\\-16
5,1,3D Shape Retrieval,Pix3D,2018-04,MarrNet extension (w/o Pose),0.85,100.0,0.1,0.12,0.85,1.0,ito:ITO_00600,Robotics process,R\\-at\\-16
0,1,3D Shape Retrieval,Pix3D,2016-10,3D-VAE-GAN,0.03,4.84,0.03,0.05,0.62,0.05,ito:ITO_00600,Robotics process,R\\-at\\-2
1,1,3D Shape Retrieval,Pix3D,2017-11,MarrNet,0.51,82.26,0.5,0.81,0.62,0.82,ito:ITO_00600,Robotics process,R\\-at\\-2
2,1,3D Shape Retrieval,Pix3D,2018-04,MarrNet extension (w/o Pose),0.62,100.0,0.1,0.16,0.62,1.0,ito:ITO_00600,Robotics process,R\\-at\\-2
3,1,3D Shape Classification,Pix3D,2016-10,3D-VAE-GAN,0.03,4.84,0.03,0.05,0.62,0.05,ito:ITO_00600,Robotics process,R\\-at\\-2
4,1,3D Shape Classification,Pix3D,2017-11,MarrNet,0.51,82.26,0.5,0.81,0.62,0.82,ito:ITO_00600,Robotics process,R\\-at\\-2
5,1,3D Shape Classification,Pix3D,2018-04,MarrNet extension (w/o Pose),0.62,100.0,0.1,0.16,0.62,1.0,ito:ITO_00600,Robotics process,R\\-at\\-2
0,1,3D Shape Retrieval,Pix3D,2016-10,3D-VAE-GAN,0.34,37.78,0.34,0.38,0.9,0.38,ito:ITO_00600,Robotics process,R\\-at\\-32
1,1,3D Shape Retrieval,Pix3D,2017-11,MarrNet,0.78,86.67,0.4,0.44,0.9,0.87,ito:ITO_00600,Robotics process,R\\-at\\-32
2,1,3D Shape Retrieval,Pix3D,2018-04,MarrNet extension (w/o Pose),0.9,100.0,0.1,0.11,0.9,1.0,ito:ITO_00600,Robotics process,R\\-at\\-32
3,1,3D Shape Classification,Pix3D,2016-10,3D-VAE-GAN,0.34,37.78,0.34,0.38,0.9,0.38,ito:ITO_00600,Robotics process,R\\-at\\-32
4,1,3D Shape Classification,Pix3D,2017-11,MarrNet,0.78,86.67,0.4,0.44,0.9,0.87,ito:ITO_00600,Robotics process,R\\-at\\-32
5,1,3D Shape Classification,Pix3D,2018-04,MarrNet extension (w/o Pose),0.9,100.0,0.1,0.11,0.9,1.0,ito:ITO_00600,Robotics process,R\\-at\\-32
0,1,3D Shape Classification,Pix3D,2016-10,3D-VAE-GAN,0.07,9.86,0.07,0.1,0.71,0.1,ito:ITO_00600,Robotics process,R\\-at\\-4
1,1,3D Shape Classification,Pix3D,2017-11,MarrNet,0.57,80.28,0.5,0.7,0.71,0.8,ito:ITO_00600,Robotics process,R\\-at\\-4
2,1,3D Shape Classification,Pix3D,2018-04,MarrNet extension (w/o Pose),0.71,100.0,0.1,0.14,0.71,1.0,ito:ITO_00600,Robotics process,R\\-at\\-4
3,1,3D Shape Retrieval,Pix3D,2016-10,3D-VAE-GAN,0.07,9.86,0.07,0.1,0.71,0.1,ito:ITO_00600,Robotics process,R\\-at\\-4
4,1,3D Shape Retrieval,Pix3D,2017-11,MarrNet,0.57,80.28,0.5,0.7,0.71,0.8,ito:ITO_00600,Robotics process,R\\-at\\-4
5,1,3D Shape Retrieval,Pix3D,2018-04,MarrNet extension (w/o Pose),0.71,100.0,0.1,0.14,0.71,1.0,ito:ITO_00600,Robotics process,R\\-at\\-4
0,1,3D Shape Classification,Pix3D,2016-10,3D-VAE-GAN,0.12,15.38,0.12,0.15,0.78,0.15,ito:ITO_00600,Robotics process,R\\-at\\-8
1,1,3D Shape Classification,Pix3D,2017-11,MarrNet,0.64,82.05,0.5,0.64,0.78,0.82,ito:ITO_00600,Robotics process,R\\-at\\-8
2,1,3D Shape Classification,Pix3D,2018-04,MarrNet extension (w/o Pose),0.78,100.0,0.1,0.13,0.78,1.0,ito:ITO_00600,Robotics process,R\\-at\\-8
3,1,3D Shape Retrieval,Pix3D,2016-10,3D-VAE-GAN,0.12,15.38,0.12,0.15,0.78,0.15,ito:ITO_00600,Robotics process,R\\-at\\-8
4,1,3D Shape Retrieval,Pix3D,2017-11,MarrNet,0.64,82.05,0.5,0.64,0.78,0.82,ito:ITO_00600,Robotics process,R\\-at\\-8
5,1,3D Shape Retrieval,Pix3D,2018-04,MarrNet extension (w/o Pose),0.78,100.0,0.1,0.13,0.78,1.0,ito:ITO_00600,Robotics process,R\\-at\\-8
0,1,Cross-View Image-to-Image Translation,Ego2Top,2016-11,Pix2pix,0.2213,36.74,0.2213,0.37,0.6024,0.23,ito:ITO_00600,Robotics process,SSIM
1,1,Cross-View Image-to-Image Translation,Ego2Top,2018-03,X-Fork,0.274,45.48,0.1,0.17,0.6024,0.29,ito:ITO_00600,Robotics process,SSIM
2,1,Cross-View Image-to-Image Translation,Ego2Top,2019-04,SelectionGAN,0.6024,100.0,0.3,0.5,0.6024,0.63,ito:ITO_00600,Robotics process,SSIM
3,1,Cross-View Image-to-Image Translation,cvusa,2016-11,Pix2pix,0.3923,73.11,0.3923,0.73,0.5366,0.41,ito:ITO_00600,Robotics process,SSIM
4,1,Cross-View Image-to-Image Translation,cvusa,2016-12,CrossNet,0.4147,77.28,0.0,0.0,0.5366,0.43,ito:ITO_00600,Robotics process,SSIM
5,1,Cross-View Image-to-Image Translation,cvusa,2018-03,X-Fork,0.4356,81.18,0.0,0.0,0.5366,0.45,ito:ITO_00600,Robotics process,SSIM
6,1,Cross-View Image-to-Image Translation,cvusa,2019-04,SelectionGAN,0.5323,99.2,0.1,0.19,0.5366,0.55,ito:ITO_00600,Robotics process,SSIM
7,1,Cross-View Image-to-Image Translation,cvusa,2019-12,UniGAN,0.5366,100.0,0.0,0.0,0.5366,0.56,ito:ITO_00600,Robotics process,SSIM
8,1,Pose Transfer,Deep-Fashion,2017-05,PG Squared,0.762,98.58,0.762,0.99,0.773,0.79,ito:ITO_00600,Robotics process,SSIM
9,1,Pose Transfer,Deep-Fashion,2019-04,Progressive Pose Attention,0.773,100.0,0.0,0.0,0.773,0.81,ito:ITO_00600,Robotics process,SSIM
10,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,0.311,100.0,0.311,1.0,0.311,0.32,ito:ITO_00600,Robotics process,SSIM
11,1,Talking Face Generation,LRW,2019-10,LipGAN,0.96,100.0,0.96,1.0,0.96,1.0,ito:ITO_00600,Robotics process,SSIM
12,1,Facial Inpainting,FFHQ,2020-02,DMFN,0.8985,100.0,0.8985,1.0,0.8985,0.94,ito:ITO_00600,Robotics process,SSIM
0,1,3D Human Pose Estimation,Leeds Sports Pose,2016-11,EDM,4.77,100.0,4.77,1.0,4.77,1.0,ito:ITO_00600,Robotics process,Reprojection\\ Error\\ \\(CPM\\)
0,1,3D Part Segmentation,ShapeNet-Part,2016-12,PointNet,80.4,94.48,80.4,0.94,85.1,0.94,ito:ITO_00600,Robotics process,Class\\ Average\\ IoU
1,1,3D Part Segmentation,ShapeNet-Part,2016-12,SSCNN,82.0,96.36,1.6,0.02,85.1,0.96,ito:ITO_00600,Robotics process,Class\\ Average\\ IoU
2,1,3D Part Segmentation,ShapeNet-Part,2017-11,SGPN,82.8,97.3,0.8,0.01,85.1,0.97,ito:ITO_00600,Robotics process,Class\\ Average\\ IoU
3,1,3D Part Segmentation,ShapeNet-Part,2018-01,PointCNN,84.6,99.41,1.8,0.02,85.1,0.99,ito:ITO_00600,Robotics process,Class\\ Average\\ IoU
4,1,3D Part Segmentation,ShapeNet-Part,2019-04,KPConv,85.1,100.0,0.5,0.01,85.1,1.0,ito:ITO_00600,Robotics process,Class\\ Average\\ IoU
0,1,Semantic Segmentation,S3DIS Area5,2016-12,PointNet,49.0,67.31,49.0,0.67,72.8,0.56,ito:ITO_00600,Robotics process,mAcc
1,1,Semantic Segmentation,S3DIS Area5,2017-10,SegCloud,57.4,78.85,8.4,0.12,72.8,0.66,ito:ITO_00600,Robotics process,mAcc
2,1,Semantic Segmentation,S3DIS Area5,2017-11,SPG,66.5,91.35,9.1,0.12,72.8,0.76,ito:ITO_00600,Robotics process,mAcc
3,1,Semantic Segmentation,S3DIS Area5,2019-04,MinkowskiNet,71.7,98.49,5.2,0.07,72.8,0.82,ito:ITO_00600,Robotics process,mAcc
4,1,Semantic Segmentation,S3DIS Area5,2019-04,KPConv,72.8,100.0,1.1,0.02,72.8,0.84,ito:ITO_00600,Robotics process,mAcc
5,1,Semantic Segmentation,S3DIS,2016-12,PointNet,66.2,80.73,66.2,0.81,82.0,0.76,ito:ITO_00600,Robotics process,mAcc
6,1,Semantic Segmentation,S3DIS,2017-11,SPG,73.0,89.02,6.8,0.08,82.0,0.84,ito:ITO_00600,Robotics process,mAcc
7,1,Semantic Segmentation,S3DIS,2018-12,PointCNN,75.6,92.2,2.6,0.03,82.0,0.87,ito:ITO_00600,Robotics process,mAcc
8,1,Semantic Segmentation,S3DIS,2019-04,KPConv,79.1,96.46,3.5,0.04,82.0,0.91,ito:ITO_00600,Robotics process,mAcc
9,1,Semantic Segmentation,S3DIS,2019-11,RandLA-Net,82.0,100.0,2.9,0.04,82.0,0.94,ito:ITO_00600,Robotics process,mAcc
10,1,3D Semantic Segmentation,S3DIS,2019-07,PVCNN++ (1xC) volumetric,87.12,100.0,87.12,1.0,87.12,1.0,ito:ITO_00600,Robotics process,mAcc
0,1,Semantic Segmentation,S3DIS,2016-12,PointNet,78.5,88.4,78.5,0.88,88.8,0.83,ito:ITO_00600,Robotics process,oAcc
1,1,Semantic Segmentation,S3DIS,2017-11,SPG,85.5,96.28,7.0,0.08,88.8,0.9,ito:ITO_00600,Robotics process,oAcc
2,1,Semantic Segmentation,S3DIS,2018-12,PointCNN,88.1,99.21,2.6,0.03,88.8,0.93,ito:ITO_00600,Robotics process,oAcc
3,1,Semantic Segmentation,S3DIS,2019-04,ConvPoint,88.8,100.0,0.7,0.01,88.8,0.94,ito:ITO_00600,Robotics process,oAcc
4,1,Semantic Segmentation,S3DIS Area5,2017-11,SPG,86.38,100.0,86.38,1.0,86.38,0.91,ito:ITO_00600,Robotics process,oAcc
5,1,Semantic Segmentation,Semantic3D,2017-11,SPG,92.9,98.0,92.9,0.98,94.8,0.98,ito:ITO_00600,Robotics process,oAcc
6,1,Semantic Segmentation,Semantic3D,2019-11,RandLA-Net,94.8,100.0,1.9,0.02,94.8,1.0,ito:ITO_00600,Robotics process,oAcc
0,1,Semantic Segmentation,ADE20K,2016-12,PSPNet,0.5538,0.98,0.5538,0.01,56.41,0.01,ito:ITO_00600,Robotics process,Test\\ Score
1,1,Semantic Segmentation,ADE20K,2016-12,PSPNet,55.38,98.17,54.8,0.97,56.41,0.98,ito:ITO_00600,Robotics process,Test\\ Score
2,1,Semantic Segmentation,ADE20K,2018-03,EncNet,55.67,98.69,0.3,0.01,56.41,0.99,ito:ITO_00600,Robotics process,Test\\ Score
3,1,Semantic Segmentation,ADE20K,2019-03,EncNet + JPU,55.84,98.99,0.2,0.0,56.41,0.99,ito:ITO_00600,Robotics process,Test\\ Score
4,1,Semantic Segmentation,ADE20K,2019-11,LaU-regression-loss,56.32,99.84,0.5,0.01,56.41,1.0,ito:ITO_00600,Robotics process,Test\\ Score
5,1,Semantic Segmentation,ADE20K,2019-11,LaU-offset-loss,56.41,100.0,0.1,0.0,56.41,1.0,ito:ITO_00600,Robotics process,Test\\ Score
0,1,Real-Time Semantic Segmentation,NYU Depth v2,2016-12,PSPNet101,72.0,100.0,72,1.0,72,1.0,ito:ITO_00600,Robotics process,Speed\\(ms/f\\)
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,62.9,80.54,62.9,0.81,78.1,0.81,ito:ITO_00600,Robotics process,PCK\\-at\\-0\\.2
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,69.6,89.12,6.7,0.09,78.1,0.89,ito:ITO_00600,Robotics process,PCK\\-at\\-0\\.2
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,78.1,100.0,8.5,0.11,78.1,1.0,ito:ITO_00600,Robotics process,PCK\\-at\\-0\\.2
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,73.5,85.56,73.5,0.86,85.9,0.86,ito:ITO_00600,Robotics process,PCK\\-at\\-0\\.3
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,80.8,94.06,7.3,0.08,85.9,0.94,ito:ITO_00600,Robotics process,PCK\\-at\\-0\\.3
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,85.9,100.0,5.1,0.06,85.9,1.0,ito:ITO_00600,Robotics process,PCK\\-at\\-0\\.3
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,80.6,89.76,80.6,0.9,89.8,0.9,ito:ITO_00600,Robotics process,PCK\\-at\\-0\\.4
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,87.5,97.44,6.9,0.08,89.8,0.97,ito:ITO_00600,Robotics process,PCK\\-at\\-0\\.4
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,89.8,100.0,2.3,0.03,89.8,1.0,ito:ITO_00600,Robotics process,PCK\\-at\\-0\\.4
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,85.5,92.53,85.5,0.93,92.4,0.93,ito:ITO_00600,Robotics process,PCK\\-at\\-0\\.5
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2018-06,ColorPointer,91.4,98.92,5.9,0.06,92.4,0.99,ito:ITO_00600,Robotics process,PCK\\-at\\-0\\.5
2,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,92.4,100.0,1.0,0.01,92.4,1.0,ito:ITO_00600,Robotics process,PCK\\-at\\-0\\.5
0,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2016-12,FlowNet2,45.2,77.4,45.2,0.77,58.4,0.77,ito:ITO_00600,Robotics process,PCK\\-at\\-0\\.1
1,1,Skeleton Based Action Recognition,JHMDB Pose Tracking,2019-04,mgPFF+ft 1st,58.4,100.0,13.2,0.23,58.4,1.0,ito:ITO_00600,Robotics process,PCK\\-at\\-0\\.1
0,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2016-12,FCNs in the wild,20.2,37.9,20.2,0.38,53.3,0.38,ito:ITO_00600,Robotics process,mIoU\\ \\(13\\ classes\\)
1,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2017-07,CDA,29.0,54.41,8.8,0.17,53.3,0.54,ito:ITO_00600,Robotics process,mIoU\\ \\(13\\ classes\\)
2,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2018-11,ADVENT,48.0,90.06,19.0,0.36,53.3,0.9,ito:ITO_00600,Robotics process,mIoU\\ \\(13\\ classes\\)
3,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-03,SWD,48.1,90.24,0.1,0.0,53.3,0.9,ito:ITO_00600,Robotics process,mIoU\\ \\(13\\ classes\\)
4,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-04,DADA (ResNet-101),49.8,93.43,1.7,0.03,53.3,0.93,ito:ITO_00600,Robotics process,mIoU\\ \\(13\\ classes\\)
5,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-04,Bidirectional Learning (ResNet-101),51.4,96.44,1.6,0.03,53.3,0.96,ito:ITO_00600,Robotics process,mIoU\\ \\(13\\ classes\\)
6,1,Image-to-Image Translation,SYNTHIA-to-Cityscapes,2019-08,PyCDA (ResNet-101),53.3,100.0,1.9,0.04,53.3,1.0,ito:ITO_00600,Robotics process,mIoU\\ \\(13\\ classes\\)
0,1,Weakly-supervised 3D Human Pose Estimation,Human3.6M,2017-01,Tome et al.,1.0,50.0,1,0.5,2,0.5,ito:ITO_00600,Robotics process,Number\\ of\\ Views
1,1,Weakly-supervised 3D Human Pose Estimation,Human3.6M,2019-03,Kocabas et al.,2.0,100.0,1,0.5,2,1.0,ito:ITO_00600,Robotics process,Number\\ of\\ Views
0,1,Weakly-supervised 3D Human Pose Estimation,Human3.6M,2017-01,Tome et al.,1.0,0.41,1,0.0,243,0.0,ito:ITO_00600,Robotics process,Number\\ of\\ Frames\\ Per\\ View
1,1,Weakly-supervised 3D Human Pose Estimation,Human3.6M,2018-11,Pavllo et al.,243.0,100.0,242,1.0,243,1.0,ito:ITO_00600,Robotics process,Number\\ of\\ Frames\\ Per\\ View
0,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2017-03,UNIT,0.023,13.14,0.023,0.13,0.175,0.13,ito:ITO_00600,Robotics process,Diversity
1,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2017-11,BicycleGAN,0.14,80.0,0.1,0.57,0.175,0.8,ito:ITO_00600,Robotics process,Diversity
2,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2018-04,MUNIT,0.175,100.0,0.0,0.0,0.175,1.0,ito:ITO_00600,Robotics process,Diversity
3,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,2017-03,UNIT,0.011,10.09,0.011,0.1,0.109,0.06,ito:ITO_00600,Robotics process,Diversity
4,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,2017-11,BicycleGAN,0.104,95.41,0.1,0.92,0.109,0.59,ito:ITO_00600,Robotics process,Diversity
5,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,2018-04,MUNIT,0.109,100.0,0.0,0.0,0.109,0.62,ito:ITO_00600,Robotics process,Diversity
0,1,Unsupervised Image-To-Image Translation,Freiburg Forest Dataset,2017-03,UNIT,9.42,43.51,9.42,0.44,21.65,0.34,ito:ITO_00600,Robotics process,PSNR
1,1,Unsupervised Image-To-Image Translation,Freiburg Forest Dataset,2017-03,cycGAN,18.57,85.77,9.2,0.42,21.65,0.67,ito:ITO_00600,Robotics process,PSNR
2,1,Unsupervised Image-To-Image Translation,Freiburg Forest Dataset,2017-11,In2I,21.65,100.0,3.1,0.14,21.65,0.78,ito:ITO_00600,Robotics process,PSNR
3,1,Multimodal Unsupervised Image-To-Image Translation,EPFL NIR-VIS,2017-03,UNIT,15.33,66.33,15.33,0.66,23.11,0.55,ito:ITO_00600,Robotics process,PSNR
4,1,Multimodal Unsupervised Image-To-Image Translation,EPFL NIR-VIS,2017-03,cycGAN,17.38,75.21,2.0,0.09,23.11,0.62,ito:ITO_00600,Robotics process,PSNR
5,1,Multimodal Unsupervised Image-To-Image Translation,EPFL NIR-VIS,2017-11,In2I,23.11,100.0,5.7,0.25,23.11,0.83,ito:ITO_00600,Robotics process,PSNR
6,1,Facial Inpainting,VggFace2,2018-12,SymmFCNet (Full),27.81,100.0,27.81,1.0,27.81,1.0,ito:ITO_00600,Robotics process,PSNR
7,1,Facial Inpainting,WebFace,2018-12,SymmFCNet (Full),27.22,100.0,27.22,1.0,27.22,0.98,ito:ITO_00600,Robotics process,PSNR
8,1,Cross-View Image-to-Image Translation,cvusa,2019-12,UniGAN,22.8223,100.0,22.8223,1.0,22.8223,0.82,ito:ITO_00600,Robotics process,PSNR
9,1,Facial Inpainting,FFHQ,2020-02,DMFN,26.49,100.0,26.49,1.0,26.49,0.95,ito:ITO_00600,Robotics process,PSNR
0,1,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,2017-03,UNIT,0.826,78.67,0.826,0.79,1.05,0.01,ito:ITO_00600,Robotics process,IS
1,1,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,2018-04,MUNIT,1.05,100.0,0.2,0.19,1.05,0.01,ito:ITO_00600,Robotics process,IS
2,1,Pose Transfer,Deep-Fashion,2017-05,PG Squared,3.09,89.85,3.09,0.9,3.439,0.02,ito:ITO_00600,Robotics process,IS
3,1,Pose Transfer,Deep-Fashion,2017-12,Disentangled PG,3.228,93.86,0.1,0.03,3.439,0.03,ito:ITO_00600,Robotics process,IS
4,1,Pose Transfer,Deep-Fashion,2017-12,Deformable GAN,3.439,100.0,0.2,0.06,3.439,0.03,ito:ITO_00600,Robotics process,IS
5,1,Image Generation,ImageNet 128x128,2018-09,BigGAN-deep,124.5,100.0,124.5,1.0,124.5,1.0,ito:ITO_00600,Robotics process,IS
6,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,3.323,100.0,3.323,1.0,3.323,0.03,ito:ITO_00600,Robotics process,IS
0,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,2017-03,UNIT,37.4,65.96,37.4,0.66,56.7,0.66,ito:ITO_00600,Robotics process,Quality
1,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,2017-11,BicycleGAN,56.7,100.0,19.3,0.34,56.7,1.0,ito:ITO_00600,Robotics process,Quality
2,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2017-03,UNIT,37.3,72.85,37.3,0.73,51.2,0.66,ito:ITO_00600,Robotics process,Quality
3,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2017-03,CycleGAN,40.8,79.69,3.5,0.07,51.2,0.72,ito:ITO_00600,Robotics process,Quality
4,1,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,2017-11,BicycleGAN,51.2,100.0,10.4,0.2,51.2,0.9,ito:ITO_00600,Robotics process,Quality
0,1,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,2017-03,UNIT,0.115,11.07,0.115,0.11,1.039,0.11,ito:ITO_00600,Robotics process,CIS
1,1,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,2018-04,MUNIT,1.039,100.0,0.9,0.87,1.039,1.0,ito:ITO_00600,Robotics process,CIS
0,1,Panoptic Segmentation,Cityscapes val,2017-03,Mask R-CNN+COCO,54.0,85.44,54.0,0.85,63.2,0.85,ito:ITO_00600,Robotics process,PQth
1,1,Panoptic Segmentation,Cityscapes val,2018-12,TASCNet (ResNet-50),56.0,88.61,2.0,0.03,63.2,0.89,ito:ITO_00600,Robotics process,PQth
2,1,Panoptic Segmentation,Cityscapes val,2018-12,"TASCNet (ResNet-50, multi-scale)",56.1,88.77,0.1,0.0,63.2,0.89,ito:ITO_00600,Robotics process,PQth
3,1,Panoptic Segmentation,Cityscapes val,2019-01,"UPSNet (ResNet-101, multiscale)",57.6,91.14,1.5,0.02,63.2,0.91,ito:ITO_00600,Robotics process,PQth
4,1,Panoptic Segmentation,Cityscapes val,2019-09,AdaptIS (ResNeXt-101),58.7,92.88,1.1,0.02,63.2,0.93,ito:ITO_00600,Robotics process,PQth
5,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS,63.2,100.0,4.5,0.07,63.2,1.0,ito:ITO_00600,Robotics process,PQth
6,1,Panoptic Segmentation,COCO test-dev,2018-09,JSIS-Net (ResNet-50),29.6,53.05,29.6,0.53,55.8,0.47,ito:ITO_00600,Robotics process,PQth
7,1,Panoptic Segmentation,COCO test-dev,2018-12,AUNet (ResNeXt-152-FPN),55.8,100.0,26.2,0.47,55.8,0.88,ito:ITO_00600,Robotics process,PQth
0,1,Panoptic Segmentation,Cityscapes test,2017-04,Dynamically Instantiated Network,55.4,84.07,55.4,0.84,65.9,0.82,ito:ITO_00600,Robotics process,PQ
1,1,Panoptic Segmentation,Cityscapes test,2019-10,Panoptic-Deeplab,65.5,99.39,10.1,0.15,65.9,0.97,ito:ITO_00600,Robotics process,PQ
2,1,Panoptic Segmentation,Cityscapes test,2020-04,EfficientPS,65.9,100.0,0.4,0.01,65.9,0.98,ito:ITO_00600,Robotics process,PQ
3,1,Panoptic Segmentation,Cityscapes val,2018-01,MRCNN + PSPNet (ResNet-101),61.2,90.94,61.2,0.91,67.3,0.91,ito:ITO_00600,Robotics process,PQ
4,1,Panoptic Segmentation,Cityscapes val,2019-01,"UPSNet (ResNet-101, multiscale)",61.8,91.83,0.6,0.01,67.3,0.92,ito:ITO_00600,Robotics process,PQ
5,1,Panoptic Segmentation,Cityscapes val,2019-09,AdaptIS (ResNeXt-101),62.0,92.12,0.2,0.0,67.3,0.92,ito:ITO_00600,Robotics process,PQ
6,1,Panoptic Segmentation,Cityscapes val,2019-11,Panoptic-DeepLab (X71),64.1,95.25,2.1,0.03,67.3,0.95,ito:ITO_00600,Robotics process,PQ
7,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS,67.3,100.0,3.2,0.05,67.3,1.0,ito:ITO_00600,Robotics process,PQ
8,1,Panoptic Segmentation,COCO panoptic,2018-01,MobileNetV2,35.2,81.86,35.2,0.82,43.0,0.52,ito:ITO_00600,Robotics process,PQ
9,1,Panoptic Segmentation,COCO panoptic,2019-01,Panoptic-FPN-ResNet-101,43.0,100.0,7.8,0.18,43.0,0.64,ito:ITO_00600,Robotics process,PQ
10,1,Panoptic Segmentation,Mapillary val,2018-09,JSIS-Net (ResNet-50),35.9,88.64,35.9,0.89,40.5,0.53,ito:ITO_00600,Robotics process,PQ
11,1,Panoptic Segmentation,Mapillary val,2019-09,AdaptIS (ResNeXt-101),40.3,99.51,4.4,0.11,40.5,0.6,ito:ITO_00600,Robotics process,PQ
12,1,Panoptic Segmentation,Mapillary val,2019-11,Panoptic-DeepLab (X71),40.5,100.0,0.2,0.0,40.5,0.6,ito:ITO_00600,Robotics process,PQ
13,1,Panoptic Segmentation,COCO test-dev,2018-09,JSIS-Net (ResNet-50),27.2,56.9,27.2,0.57,47.8,0.4,ito:ITO_00600,Robotics process,PQ
14,1,Panoptic Segmentation,COCO test-dev,2018-12,AUNet (ResNeXt-152-FPN),46.5,97.28,19.3,0.4,47.8,0.69,ito:ITO_00600,Robotics process,PQ
15,1,Panoptic Segmentation,COCO test-dev,2019-01,UPSNet (ResNet-101-FPN),46.6,97.49,0.1,0.0,47.8,0.69,ito:ITO_00600,Robotics process,PQ
16,1,Panoptic Segmentation,COCO test-dev,2019-11,SOGNet (ResNet-101-FPN),47.8,100.0,1.2,0.03,47.8,0.71,ito:ITO_00600,Robotics process,PQ
17,1,Panoptic Segmentation,KITTI Panoptic Segmentation,2019-01,Panoptic FPN,39.3,89.93,39.3,0.9,43.7,0.58,ito:ITO_00600,Robotics process,PQ
18,1,Panoptic Segmentation,KITTI Panoptic Segmentation,2019-01,UPSNet,39.9,91.3,0.6,0.01,43.7,0.59,ito:ITO_00600,Robotics process,PQ
19,1,Panoptic Segmentation,KITTI Panoptic Segmentation,2019-05,Seamless,42.2,96.57,2.3,0.05,43.7,0.63,ito:ITO_00600,Robotics process,PQ
20,1,Panoptic Segmentation,KITTI Panoptic Segmentation,2020-04,EfficientPS,43.7,100.0,1.5,0.03,43.7,0.65,ito:ITO_00600,Robotics process,PQ
21,1,Panoptic Segmentation,Indian Driving Dataset,2019-01,Panoptic FPN,46.7,91.39,46.7,0.91,51.1,0.69,ito:ITO_00600,Robotics process,PQ
22,1,Panoptic Segmentation,Indian Driving Dataset,2019-01,UPSNet,47.1,92.17,0.4,0.01,51.1,0.7,ito:ITO_00600,Robotics process,PQ
23,1,Panoptic Segmentation,Indian Driving Dataset,2019-05,Seamless,48.5,94.91,1.4,0.03,51.1,0.72,ito:ITO_00600,Robotics process,PQ
24,1,Panoptic Segmentation,Indian Driving Dataset,2020-04,EfficientPS,51.1,100.0,2.6,0.05,51.1,0.76,ito:ITO_00600,Robotics process,PQ
0,1,3D Human Pose Estimation,Geometric Pose Affordance ,2017-04,Baseline model,83.6,87.54,83.6,0.88,95.5,0.88,ito:ITO_00600,Robotics process,PCK3D\\ \\(CA\\)
1,1,3D Human Pose Estimation,Geometric Pose Affordance ,2017-05,SIM-G-F,95.5,100.0,11.9,0.12,95.5,1.0,ito:ITO_00600,Robotics process,PCK3D\\ \\(CA\\)
0,1,3D Human Pose Estimation,Geometric Pose Affordance ,2017-04,Baseline model,81.3,86.58,81.3,0.87,93.9,0.87,ito:ITO_00600,Robotics process,PCK3D\\ \\(CS\\)
1,1,3D Human Pose Estimation,Geometric Pose Affordance ,2017-05,SIM-G-F,93.9,100.0,12.6,0.13,93.9,1.0,ito:ITO_00600,Robotics process,PCK3D\\ \\(CS\\)
0,1,3D Human Pose Estimation,Geometric Pose Affordance ,2017-04,Baseline model,99.4,100.0,99.4,1.0,99.4,1.0,ito:ITO_00600,Robotics process,MPJPE\\ \\(CS\\)
0,1,3D Human Pose Estimation,Geometric Pose Affordance ,2017-04,Baseline model,89.2,100.0,89.2,1.0,89.2,1.0,ito:ITO_00600,Robotics process,MPJPE\\ \\(CA\\)
0,1,Skeleton Based Action Recognition,PKU-MMD,2017-04,Li et al. [[Li et al.2017b]],90.4,97.31,90.4,0.97,92.9,0.97,ito:ITO_00600,Robotics process,mAP\\-at\\-0\\.50\\ \\(CS\\)
1,1,Skeleton Based Action Recognition,PKU-MMD,2018-04,HCN,92.6,99.68,2.2,0.02,92.9,1.0,ito:ITO_00600,Robotics process,mAP\\-at\\-0\\.50\\ \\(CS\\)
2,1,Skeleton Based Action Recognition,PKU-MMD,2019-09,RF-Action,92.9,100.0,0.3,0.0,92.9,1.0,ito:ITO_00600,Robotics process,mAP\\-at\\-0\\.50\\ \\(CS\\)
0,1,Skeleton Based Action Recognition,PKU-MMD,2017-04,Li et al. [[Li et al.2017b]],93.7,99.26,93.7,0.99,94.4,0.99,ito:ITO_00600,Robotics process,mAP\\-at\\-0\\.50\\ \\(CV\\)
1,1,Skeleton Based Action Recognition,PKU-MMD,2018-04,HCN,94.2,99.79,0.5,0.01,94.4,1.0,ito:ITO_00600,Robotics process,mAP\\-at\\-0\\.50\\ \\(CV\\)
2,1,Skeleton Based Action Recognition,PKU-MMD,2019-09,RF-Action,94.4,100.0,0.2,0.0,94.4,1.0,ito:ITO_00600,Robotics process,mAP\\-at\\-0\\.50\\ \\(CV\\)
0,1,3D Human Pose Estimation,MPI-INF-3DHP,2017-05,VNect (Augm.),42.0,67.31,42.0,0.67,62.4,0.67,ito:ITO_00600,Robotics process,AUC
1,1,3D Human Pose Estimation,MPI-INF-3DHP,2018-06,"MargiPose (Procrustes alignment, PA)",61.4,98.4,19.4,0.31,62.4,0.98,ito:ITO_00600,Robotics process,AUC
2,1,3D Human Pose Estimation,MPI-INF-3DHP,2018-06,"MargiPose (Procrustes alignment, PA, multi-crop)",62.2,99.68,0.8,0.01,62.4,1.0,ito:ITO_00600,Robotics process,AUC
3,1,3D Human Pose Estimation,MPI-INF-3DHP,2020-02,Explicit Compositional Depth Maps,62.4,100.0,0.2,0.0,62.4,1.0,ito:ITO_00600,Robotics process,AUC
0,1,3D Human Pose Estimation,MPI-INF-3DHP,2017-05,VNect (Augm.),78.1,82.12,78.1,0.82,95.1,0.82,ito:ITO_00600,Robotics process,3DPCK
1,1,3D Human Pose Estimation,MPI-INF-3DHP,2018-06,"MargiPose (Procrustes alignment, PA)",94.8,99.68,16.7,0.18,95.1,1.0,ito:ITO_00600,Robotics process,3DPCK
2,1,3D Human Pose Estimation,MPI-INF-3DHP,2018-06,"MargiPose (Procrustes alignment, PA, multi-crop)",95.1,100.0,0.3,0.0,95.1,1.0,ito:ITO_00600,Robotics process,3DPCK
3,1,3D Multi-Person Pose Estimation,MuPoTS-3D,2019-07,SelecSLS,75.8,100.0,75.8,1.0,75.8,0.8,ito:ITO_00600,Robotics process,3DPCK
0,1,3D Human Pose Estimation,MPI-INF-3DHP,2017-05,VNect (Augm.),119.2,100.0,119.2,1.0,119.2,1.0,ito:ITO_00600,Robotics process,MJPE
0,1,3D Absolute Human Pose Estimation,Human3.6M,2017-10,Fang,60.4,100.0,60.4,1.0,60.4,0.46,ito:ITO_00600,Robotics process,MPJPE
1,1,3D Human Pose Estimation,Surreal,2017-12,self-supervised mocap,64.4,100.0,64.4,1.0,64.4,0.5,ito:ITO_00600,Robotics process,MPJPE
2,1,3D Human Pose Estimation,3DPW,2017-12,HMR,130.0,100.0,130.0,1.0,130.0,1.0,ito:ITO_00600,Robotics process,MPJPE
3,1,3D Human Pose Estimation,CHALL H80K,2018-09,ResNet,55.3,100.0,55.3,1.0,55.3,0.43,ito:ITO_00600,Robotics process,MPJPE
4,1,3D Human Pose Estimation,3D Poses in the Wild Challenge,2019-07,RootNet,84.28,82.18,84.28,0.82,102.56,0.65,ito:ITO_00600,Robotics process,MPJPE
5,1,3D Human Pose Estimation,3D Poses in the Wild Challenge,2019-09,SPIN,102.56,100.0,18.3,0.18,102.56,0.79,ito:ITO_00600,Robotics process,MPJPE
6,1,3D Absolute Human Pose Estimation,Total Capture,2020-03,GeoFuse,24.6,100.0,24.6,1.0,24.6,0.19,ito:ITO_00600,Robotics process,MPJPE
0,1,Skeleton Based Action Recognition,J-HMBD Early Action,2017-10,GAT,58.1,95.87,58.1,0.96,60.6,0.96,ito:ITO_00600,Robotics process,10%
1,1,Skeleton Based Action Recognition,J-HMBD Early Action,2018-02,DR^2N,60.6,100.0,2.5,0.04,60.6,1.0,ito:ITO_00600,Robotics process,10%
0,1,Image-to-Image Translation,SYNTHIA Fall-to-Winter,2017-11,CyCADA,85.7,100.0,85.7,1.0,85.7,1.0,ito:ITO_00600,Robotics process,fwIOU
1,1,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,2017-11,CyCADA pixel+feat,72.4,100.0,72.4,1.0,72.4,0.84,ito:ITO_00600,Robotics process,fwIOU
0,1,Visual Navigation,Room-to-Room,2017-11,Seq2Seq baseline,0.18,35.29,0.18,0.35,0.51,0.2,ito:ITO_00600,Robotics process,spl
1,1,Visual Navigation,Room-to-Room,2018-11,RCM+SIL(no early exploration),0.38,74.51,0.2,0.39,0.51,0.41,ito:ITO_00600,Robotics process,spl
2,1,Visual Navigation,Room-to-Room,2020-02,Prevalent,0.51,100.0,0.1,0.2,0.51,0.56,ito:ITO_00600,Robotics process,spl
3,1,Visual Navigation,R2R,2017-11,Seq2Seq baseline,0.18,35.29,0.18,0.35,0.51,0.2,ito:ITO_00600,Robotics process,spl
4,1,Visual Navigation,R2R,2018-11,RCM+SIL(no early exploration),0.38,74.51,0.2,0.39,0.51,0.41,ito:ITO_00600,Robotics process,spl
5,1,Visual Navigation,R2R,2020-02,Prevalent,0.51,100.0,0.1,0.2,0.51,0.56,ito:ITO_00600,Robotics process,spl
6,1,Vision and Language Navigation,VLN Challenge,2019-03,Tactical Rewind,0.03,6.38,0.03,0.06,0.47,0.03,ito:ITO_00600,Robotics process,spl
7,1,Vision and Language Navigation,VLN Challenge,2019-03,Tactical Rewind,0.41,87.23,0.4,0.85,0.47,0.45,ito:ITO_00600,Robotics process,spl
8,1,Vision and Language Navigation,VLN Challenge,2019-04,Back Translation with Environmental Dropout (no beam search),0.47,100.0,0.1,0.21,0.47,0.51,ito:ITO_00600,Robotics process,spl
9,1,PointGoal Navigation,Gibson PointGoal Navigation,2019-04,Depth PPO,0.79,86.15,0.79,0.86,0.917,0.86,ito:ITO_00600,Robotics process,spl
10,1,PointGoal Navigation,Gibson PointGoal Navigation,2020-01,Depth DDPPO,0.917,100.0,0.1,0.11,0.917,1.0,ito:ITO_00600,Robotics process,spl
11,1,Visual Navigation,Cooperative Vision-and-Dialogue Navigation,2019-07,Seq2Seq Baseline,0.16,100.0,0.16,1.0,0.16,0.17,ito:ITO_00600,Robotics process,spl
0,1,Hand Gesture Recognition,Jester test,2017-11,Multiscale TRN,94.78,98.12,94.78,0.98,96.6,0.98,ito:ITO_00600,Robotics process,Top\\ 1\\ Accuracy
1,1,Hand Gesture Recognition,Jester test,2018-04,DRX3D,96.6,100.0,1.8,0.02,96.6,1.0,ito:ITO_00600,Robotics process,Top\\ 1\\ Accuracy
2,1,Hand Gesture Recognition,Jester val,2018-04,8-MFFs-3f1c (5 crop),96.33,100.0,96.33,1.0,96.33,1.0,ito:ITO_00600,Robotics process,Top\\ 1\\ Accuracy
0,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2017-11,AttnGAN,0.512,94.12,0.512,0.94,0.544,0.94,ito:ITO_00600,Robotics process,LPIPS
1,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2019-04,DM-GAN,0.544,100.0,0.0,0.0,0.544,1.0,ito:ITO_00600,Robotics process,LPIPS
2,1,Pose Transfer,Deep-Fashion,2017-12,Deformable GAN,0.233,100.0,0.233,1.0,0.233,0.43,ito:ITO_00600,Robotics process,LPIPS
3,1,Image-to-Image Translation,AFHQ,2019-12,StarGAN v2,0.524,100.0,0.524,1.0,0.524,0.96,ito:ITO_00600,Robotics process,LPIPS
4,1,Image-to-Image Translation,CelebA-HQ,2019-12,StarGAN v2,0.428,100.0,0.428,1.0,0.428,0.79,ito:ITO_00600,Robotics process,LPIPS
5,1,Facial Inpainting,FFHQ,2020-02,DMFN,0.0457,100.0,0.0457,1.0,0.0457,0.08,ito:ITO_00600,Robotics process,LPIPS
0,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2017-11,AttnGAN,13.0,79.27,13.0,0.79,16.4,0.79,ito:ITO_00600,Robotics process,Acc
1,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2019-04,DM-GAN,16.4,100.0,3.4,0.21,16.4,1.0,ito:ITO_00600,Robotics process,Acc
0,1,Text-to-Image Generation,COCO,2017-11,AttnGAN,25.88,72.19,25.88,0.72,35.85,0.72,ito:ITO_00600,Robotics process,SOA\\-C
1,1,Text-to-Image Generation,COCO,2019-04,DM-GAN,33.44,93.28,7.6,0.21,35.85,0.93,ito:ITO_00600,Robotics process,SOA\\-C
2,1,Text-to-Image Generation,COCO,2019-10,OP-GAN,35.85,100.0,2.4,0.07,35.85,1.0,ito:ITO_00600,Robotics process,SOA\\-C
0,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2017-11,AttnGAN,11.9,70.41,11.9,0.7,16.9,0.7,ito:ITO_00600,Robotics process,Real
1,1,Text-to-Image Generation,Multi-Modal-CelebA-HQ,2019-04,DM-GAN,16.9,100.0,5.0,0.3,16.9,1.0,ito:ITO_00600,Robotics process,Real
0,1,Fundus to Angiography Generation,Fundus Fluorescein Angiogram Photographs & Colour Fundus Images of Diabetic Patients,2017-11,pix2pixHD,0.00258,100.0,0.00258,1.0,0.00258,0.0,ito:ITO_00600,Robotics process,Kernel\\ Inception\\ Distance
1,1,Image-to-Image Translation,anime-to-selfie,2019-07,U-GAT-IT,11.52,100.0,11.52,1.0,11.52,0.99,ito:ITO_00600,Robotics process,Kernel\\ Inception\\ Distance
2,1,Image-to-Image Translation,selfie-to-anime,2019-07,U-GAT-IT,11.61,100.0,11.61,1.0,11.61,1.0,ito:ITO_00600,Robotics process,Kernel\\ Inception\\ Distance
3,1,Image-to-Image Translation,horse2zebra,2019-07,U-GAT-IT,7.06,100.0,7.06,1.0,7.06,0.61,ito:ITO_00600,Robotics process,Kernel\\ Inception\\ Distance
4,1,Image-to-Image Translation,photo2portrait,2019-07,U-GAT-IT,1.79,100.0,1.79,1.0,1.79,0.15,ito:ITO_00600,Robotics process,Kernel\\ Inception\\ Distance
5,1,Image-to-Image Translation,portrait2photo,2019-07,U-GAT-IT,1.69,100.0,1.69,1.0,1.69,0.15,ito:ITO_00600,Robotics process,Kernel\\ Inception\\ Distance
6,1,Image-to-Image Translation,vangogh2photo,2019-07,U-GAT-IT,5.61,100.0,5.61,1.0,5.61,0.48,ito:ITO_00600,Robotics process,Kernel\\ Inception\\ Distance
7,1,Image-to-Image Translation,dog2cat,2019-07,U-GAT-IT,8.15,100.0,8.15,1.0,8.15,0.7,ito:ITO_00600,Robotics process,Kernel\\ Inception\\ Distance
8,1,Image-to-Image Translation,photo2vangogh,2019-07,U-GAT-IT,4.28,100.0,4.28,1.0,4.28,0.37,ito:ITO_00600,Robotics process,Kernel\\ Inception\\ Distance
9,1,Image-to-Image Translation,zebra2horse,2019-07,U-GAT-IT,7.47,100.0,7.47,1.0,7.47,0.64,ito:ITO_00600,Robotics process,Kernel\\ Inception\\ Distance
10,1,Image-to-Image Translation,cat2dog,2019-07,U-GAT-IT,7.07,100.0,7.07,1.0,7.07,0.61,ito:ITO_00600,Robotics process,Kernel\\ Inception\\ Distance
0,1,3D Human Pose Estimation,3DPW,2017-12,HMR,37.4,100.0,37.4,1.0,37.4,1.0,ito:ITO_00600,Robotics process,acceleration\\ error
0,1,3D Human Pose Estimation,3DPW,2017-12,HMR,76.7,94.34,76.7,0.94,81.3,0.94,ito:ITO_00600,Robotics process,PA\\-MPJPE
1,1,3D Human Pose Estimation,3DPW,2017-12,HMR,81.3,100.0,4.6,0.06,81.3,1.0,ito:ITO_00600,Robotics process,PA\\-MPJPE
0,1,Pose Transfer,Deep-Fashion,2017-12,Deformable GAN,30.07,100.0,30.07,1.0,30.07,1.0,ito:ITO_00600,Robotics process,Retrieval\\ Top10\\ Recall
0,1,Panoptic Segmentation,Cityscapes val,2018-01,MRCNN + PSPNet (ResNet-101),66.4,94.45,66.4,0.94,70.3,0.94,ito:ITO_00600,Robotics process,PQst
1,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS,70.3,100.0,3.9,0.06,70.3,1.0,ito:ITO_00600,Robotics process,PQst
2,1,Panoptic Segmentation,COCO test-dev,2018-09,JSIS-Net (ResNet-50),23.4,53.06,23.4,0.53,44.1,0.33,ito:ITO_00600,Robotics process,PQst
3,1,Panoptic Segmentation,COCO test-dev,2018-12,AUNet (ResNeXt-152-FPN),32.5,73.7,9.1,0.21,44.1,0.46,ito:ITO_00600,Robotics process,PQst
4,1,Panoptic Segmentation,COCO test-dev,2019-01,UPSNet (ResNet-101-FPN),36.7,83.22,4.2,0.1,44.1,0.52,ito:ITO_00600,Robotics process,PQst
5,1,Panoptic Segmentation,COCO test-dev,2020-03,EPSNet (ResNet-101-FPN),44.1,100.0,7.4,0.17,44.1,0.63,ito:ITO_00600,Robotics process,PQst
0,1,Panoptic Segmentation,Cityscapes val,2018-01,MRCNN + PSPNet (ResNet-101),36.4,83.68,36.4,0.84,43.5,0.84,ito:ITO_00600,Robotics process,AP
1,1,Panoptic Segmentation,Cityscapes val,2018-12,TASCNet (ResNet-50),37.6,86.44,1.2,0.03,43.5,0.86,ito:ITO_00600,Robotics process,AP
2,1,Panoptic Segmentation,Cityscapes val,2018-12,"TASCNet (ResNet-50, multi-scale)",39.0,89.66,1.4,0.03,43.5,0.9,ito:ITO_00600,Robotics process,AP
3,1,Panoptic Segmentation,Cityscapes val,2020-04,EfficientPS,43.5,100.0,4.5,0.1,43.5,1.0,ito:ITO_00600,Robotics process,AP
0,1,Image Inpainting,Places2 val,2018-01,ContextAttention,8.6,100.0,8.6,1.0,8.6,1.0,ito:ITO_00600,Robotics process,rect\\ mask\\ l1\\ error
0,1,Image Inpainting,Places2 val,2018-01,ContextAttention,2.1,100.0,2.1,1.0,2.1,1.0,ito:ITO_00600,Robotics process,rect\\ mask\\ l2\\ err
0,1,Image Inpainting,Places2 val,2018-01,ContextAttention,17.2,100.0,17.2,1.0,17.2,1.0,ito:ITO_00600,Robotics process,free\\-form\\ mask\\ l1\\ err
0,1,Image Inpainting,Places2 val,2018-01,ContextAttention,4.7,100.0,4.7,1.0,4.7,1.0,ito:ITO_00600,Robotics process,free\\-form\\ mask\\ l2\\ err
0,1,Image-to-Image Translation,Cityscapes-to-Foggy Cityscapes,2018-03,FRCNN in the wild,27.6,74.8,27.6,0.75,36.9,0.75,ito:ITO_00600,Robotics process,mAP
1,1,Image-to-Image Translation,Cityscapes-to-Foggy Cityscapes,2019-05,Diversify & Match,34.6,93.77,7.0,0.19,36.9,0.94,ito:ITO_00600,Robotics process,mAP
2,1,Image-to-Image Translation,Cityscapes-to-Foggy Cityscapes,2019-10,Progressive Domain Adaptation,36.9,100.0,2.3,0.06,36.9,1.0,ito:ITO_00600,Robotics process,mAP
0,1,One-Shot Segmentation,Cluttered Omniglot,2018-03,MaskNet,65.6,100.0,65.6,1.0,65.6,1.0,ito:ITO_00600,Robotics process,IoU\\ \\[32\\ distractors\\]
0,1,One-Shot Segmentation,Cluttered Omniglot,2018-03,MaskNet,95.8,98.66,95.8,0.99,97.1,0.99,ito:ITO_00600,Robotics process,IoU\\ \\[4\\ distractors\\]
1,1,One-Shot Segmentation,Cluttered Omniglot,2018-03,Siamese-U-Net,97.1,100.0,1.3,0.01,97.1,1.0,ito:ITO_00600,Robotics process,IoU\\ \\[4\\ distractors\\]
0,1,One-Shot Segmentation,Cluttered Omniglot,2018-03,MaskNet,43.7,100.0,43.7,1.0,43.7,1.0,ito:ITO_00600,Robotics process,IoU\\ \\[256\\ distractors\\]
0,1,Layout-to-Image Generation,COCO-Stuff 64x64,2018-04,SG2Im,7.3,67.59,7.3,0.68,10.8,0.28,ito:ITO_00600,Robotics process,Inception\\ Score
1,1,Layout-to-Image Generation,COCO-Stuff 64x64,2018-11,Layout2Im,9.1,84.26,1.8,0.17,10.8,0.35,ito:ITO_00600,Robotics process,Inception\\ Score
2,1,Layout-to-Image Generation,COCO-Stuff 64x64,2019-08,LostGAN,9.8,90.74,0.7,0.06,10.8,0.38,ito:ITO_00600,Robotics process,Inception\\ Score
3,1,Layout-to-Image Generation,COCO-Stuff 64x64,2019-09,SOARISG,10.3,95.37,0.5,0.05,10.8,0.4,ito:ITO_00600,Robotics process,Inception\\ Score
4,1,Layout-to-Image Generation,COCO-Stuff 64x64,2020-03,OC-GAN,10.8,100.0,0.5,0.05,10.8,0.42,ito:ITO_00600,Robotics process,Inception\\ Score
5,1,Layout-to-Image Generation,Visual Genome 64x64,2018-04,SG2Im,6.3,67.74,6.3,0.68,9.3,0.24,ito:ITO_00600,Robotics process,Inception\\ Score
6,1,Layout-to-Image Generation,Visual Genome 64x64,2018-11,Layout2Im,8.1,87.1,1.8,0.19,9.3,0.31,ito:ITO_00600,Robotics process,Inception\\ Score
7,1,Layout-to-Image Generation,Visual Genome 64x64,2019-08,LostGAN,8.7,93.55,0.6,0.06,9.3,0.34,ito:ITO_00600,Robotics process,Inception\\ Score
8,1,Layout-to-Image Generation,Visual Genome 64x64,2020-03,OC-GAN,9.3,100.0,0.6,0.06,9.3,0.36,ito:ITO_00600,Robotics process,Inception\\ Score
9,1,Image Generation,ImageNet 64x64,2019-07,BigBiGAN,19.4,74.73,19.4,0.75,25.96,0.75,ito:ITO_00600,Robotics process,Inception\\ Score
10,1,Image Generation,ImageNet 64x64,2020-04,FQ-GAN,25.96,100.0,6.6,0.25,25.96,1.0,ito:ITO_00600,Robotics process,Inception\\ Score
11,1,Layout-to-Image Generation,COCO-Stuff 128x128,2019-08,LostGAN,13.8,94.52,13.8,0.95,14.6,0.53,ito:ITO_00600,Robotics process,Inception\\ Score
12,1,Layout-to-Image Generation,COCO-Stuff 128x128,2020-03,OC-GAN,14.6,100.0,0.8,0.05,14.6,0.56,ito:ITO_00600,Robotics process,Inception\\ Score
13,1,Layout-to-Image Generation,Visual Genome 128x128,2019-08,LostGAN,11.1,90.24,11.1,0.9,12.3,0.43,ito:ITO_00600,Robotics process,Inception\\ Score
14,1,Layout-to-Image Generation,Visual Genome 128x128,2020-03,OC-GAN,12.3,100.0,1.2,0.1,12.3,0.47,ito:ITO_00600,Robotics process,Inception\\ Score
0,1,3D Shape Reconstruction,Pix3D,2018-04,MarrNet extension (w/ Pose),0.119,100.0,0.119,1.0,0.119,1.0,ito:ITO_00600,Robotics process,CD
0,1,3D Shape Reconstruction,Pix3D,2018-04,MarrNet extension (w/ Pose),0.118,100.0,0.118,1.0,0.118,1.0,ito:ITO_00600,Robotics process,EMD
0,1,3D Shape Reconstruction,Pix3D,2018-04,MarrNet extension (w/ Pose),0.282,100.0,0.282,1.0,0.282,1.0,ito:ITO_00600,Robotics process,IoU
0,1,Hand Gesture Recognition,Jester val,2018-04,8-MFFs-3f1c (5 crop),99.86,100.0,99.86,1.0,99.86,1.0,ito:ITO_00600,Robotics process,Top\\ 5\\ Accuracy
0,1,3D Shape Analysis,2017_test set,2018-05,x,10.0,100.0,10,1.0,10,1.0,ito:ITO_00600,Robotics process,1\\ in\\ 10\\ R\\-at\\-1
0,1,Generating 3D Point Clouds,ShapeNet,2018-08,PCN,0.009636,100.0,0.009636,1.0,0.009636,1.0,ito:ITO_00600,Robotics process,Chamfer\\ Distance
0,1,Visual Navigation,Dmlab-30,2018-09,PopArt-IMPALA,72.8,100.0,72.8,1.0,72.8,1.0,ito:ITO_00600,Robotics process,Medium\\ Human\\-Normalized\\ Score
0,1,Music Modeling,JSB Chorales,2018-09,Music Transformer,0.335,100.0,0.335,1.0,0.335,1.0,ito:ITO_00600,Robotics process,NLL
1,1,person reposing,person reposing,2018-09,Music Transformer,0.335,100.0,0.335,1.0,0.335,1.0,ito:ITO_00600,Robotics process,NLL
0,1,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,2018-09,CLAN,47.8,88.85,47.8,0.89,53.8,0.89,ito:ITO_00600,Robotics process,MIoU\\ \\(13\\ classes\\)
1,1,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,2019-10,CAG-UDA,52.6,97.77,4.8,0.09,53.8,0.98,ito:ITO_00600,Robotics process,MIoU\\ \\(13\\ classes\\)
2,1,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,2019-12,MRNet(ResNet-101),53.8,100.0,1.2,0.02,53.8,1.0,ito:ITO_00600,Robotics process,MIoU\\ \\(13\\ classes\\)
0,1,Image Generation,LSUN Bedroom,2018-12,StyleGAN,2.65,100.0,2.65,1.0,2.65,1.0,ito:ITO_00600,Robotics process,FID\\-50k
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,MFA-Net,361.0,100.0,361,1.0,361,1.0,ito:ITO_00600,Robotics process,Speed\\ \\ \\(FPS\\)
1,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet-tiny,98.0,100.0,98,1.0,98,0.27,ito:ITO_00600,Robotics process,Speed\\ \\ \\(FPS\\)
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,MFA-Net,91.3,96.51,91.3,0.97,94.6,0.97,ito:ITO_00600,Robotics process,14\\ gestures\\ accuracy
1,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,STA-Res-TCN,93.6,98.94,2.3,0.02,94.6,0.99,ito:ITO_00600,Robotics process,14\\ gestures\\ accuracy
2,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,94.6,100.0,1.0,0.01,94.6,1.0,ito:ITO_00600,Robotics process,14\\ gestures\\ accuracy
3,1,Hand Gesture Recognition,SHREC 2017,2019-07,DG-STA,94.4,100.0,94.4,1.0,94.4,1.0,ito:ITO_00600,Robotics process,14\\ gestures\\ accuracy
4,1,Hand Gesture Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,94.6,100.0,94.6,1.0,94.6,1.0,ito:ITO_00600,Robotics process,14\\ gestures\\ accuracy
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,MFA-Net,86.6,94.23,86.6,0.94,91.9,0.94,ito:ITO_00600,Robotics process,28\\ gestures\\ accuracy
1,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-01,STA-Res-TCN,90.7,98.69,4.1,0.04,91.9,0.99,ito:ITO_00600,Robotics process,28\\ gestures\\ accuracy
2,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,91.9,100.0,1.2,0.01,91.9,1.0,ito:ITO_00600,Robotics process,28\\ gestures\\ accuracy
3,1,Hand Gesture Recognition,SHREC 2017,2019-07,DG-STA,90.7,100.0,90.7,1.0,90.7,0.99,ito:ITO_00600,Robotics process,28\\ gestures\\ accuracy
0,1,Semantic Segmentation,ADE20K val,2019-01,Auto-DeepLab-L,81.72,100.0,81.72,1.0,81.72,1.0,ito:ITO_00600,Robotics process,Pixel\\ Accuracy
0,1,Semantic Segmentation,38-Cloud,2019-01,Cloud-Net,87.32,98.22,87.32,0.98,88.9,0.98,ito:ITO_00600,Robotics process,Jaccard\\ \\(Mean\\)
1,1,Semantic Segmentation,38-Cloud,2020-01,Cloud-Net+,88.9,100.0,1.6,0.02,88.9,1.0,ito:ITO_00600,Robotics process,Jaccard\\ \\(Mean\\)
0,1,4D Spatio Temporal Semantic Segmentation,4,2019-03,4,7.0,100.0,7,1.0,7,1.0,ito:ITO_00600,Robotics process,4
0,1,Vision and Language Navigation,VLN Challenge,2019-03,Tactical Rewind,0.61,88.41,0.61,0.88,0.69,0.88,ito:ITO_00600,Robotics process,success
1,1,Vision and Language Navigation,VLN Challenge,2019-04,null,0.69,100.0,0.1,0.14,0.69,1.0,ito:ITO_00600,Robotics process,success
0,1,Vision and Language Navigation,VLN Challenge,2019-03,Tactical Rewind,196.53,28.61,196.53,0.29,686.82,0.29,ito:ITO_00600,Robotics process,length
1,1,Vision and Language Navigation,VLN Challenge,2019-04,null,686.82,100.0,490.3,0.71,686.82,1.0,ito:ITO_00600,Robotics process,length
0,1,Vision and Language Navigation,VLN Challenge,2019-03,Tactical Rewind,4.29,82.03,4.29,0.82,5.23,0.82,ito:ITO_00600,Robotics process,error
1,1,Vision and Language Navigation,VLN Challenge,2019-03,Tactical Rewind,5.14,98.28,0.8,0.15,5.23,0.98,ito:ITO_00600,Robotics process,error
2,1,Vision and Language Navigation,VLN Challenge,2019-04,Back Translation with Environmental Dropout (no beam search),5.23,100.0,0.1,0.02,5.23,1.0,ito:ITO_00600,Robotics process,error
0,1,Vision and Language Navigation,VLN Challenge,2019-03,Tactical Rewind,0.9,90.91,0.9,0.91,0.99,0.91,ito:ITO_00600,Robotics process,oracle\\ success
1,1,Vision and Language Navigation,VLN Challenge,2019-04,null,0.99,100.0,0.1,0.1,0.99,1.0,ito:ITO_00600,Robotics process,oracle\\ success
0,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,0.94,100.0,0.94,1.0,0.94,0.98,ito:ITO_00600,Robotics process,PCKh
1,1,Pose Transfer,Deep-Fashion,2019-04,Progressive Pose Attention,0.96,100.0,0.96,1.0,0.96,1.0,ito:ITO_00600,Robotics process,PCKh
0,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,0.811,100.0,0.811,1.0,0.811,1.0,ito:ITO_00600,Robotics process,mask\\-SSIM
0,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,0.74,100.0,0.74,1.0,0.74,0.76,ito:ITO_00600,Robotics process,DS
1,1,Pose Transfer,Deep-Fashion,2019-04,Progressive Pose Attention,0.976,100.0,0.976,1.0,0.976,1.0,ito:ITO_00600,Robotics process,DS
0,1,Pose Transfer,Market-1501,2019-04,Progressive Pose Attention,3.773,100.0,3.773,1.0,3.773,1.0,ito:ITO_00600,Robotics process,mask\\-IS
0,1,Human Grasp Contact Prediction,ContactDB,2019-04,DiverseNet-VoxNet,8.72,29.17,8.72,0.29,29.89,0.29,ito:ITO_00600,Robotics process,Error\\ rate
1,1,Human Grasp Contact Prediction,ContactDB,2019-04,sMCL-VoxNet,17.27,57.78,8.5,0.28,29.89,0.58,ito:ITO_00600,Robotics process,Error\\ rate
2,1,Human Grasp Contact Prediction,ContactDB,2019-04,DiverseNet-PointNet,21.82,73.0,4.6,0.15,29.89,0.73,ito:ITO_00600,Robotics process,Error\\ rate
3,1,Human Grasp Contact Prediction,ContactDB,2019-04,sMCL-PointNet,29.89,100.0,8.1,0.27,29.89,1.0,ito:ITO_00600,Robotics process,Error\\ rate
4,1,Grasp Contact Prediction,ContactDB,2019-04,sMCL-VoxNet,17.27,57.78,17.27,0.58,29.89,0.58,ito:ITO_00600,Robotics process,Error\\ rate
5,1,Grasp Contact Prediction,ContactDB,2019-04,sMCL-PointNet,29.89,100.0,12.6,0.42,29.89,1.0,ito:ITO_00600,Robotics process,Error\\ rate
0,1,Image Inpainting,Paris StreetView,2019-05,Coherent Semantic Attention for Image Inpainting,23.1,100.0,23.1,1.0,23.1,1.0,ito:ITO_00600,Robotics process,40\\-50%\\ Mask\\ PSNR
0,1,Image Inpainting,Paris StreetView,2019-05,Coherent Semantic Attention for Image Inpainting,30.32,100.0,30.32,1.0,30.32,1.0,ito:ITO_00600,Robotics process,20\\-30%\\ Mask\\ PSNR
0,1,Image Inpainting,Paris StreetView,2019-05,Coherent Semantic Attention for Image Inpainting,24.85,100.0,24.85,1.0,24.85,1.0,ito:ITO_00600,Robotics process,30\\-40%\\ Mask\\ PSNR
0,1,3D Shape Modeling,Pix3D S2,2019-06,Mesh R-CNN,72.2,100.0,72.2,1.0,72.2,0.77,ito:ITO_00600,Robotics process,box\\ AP
1,1,UNET Segmentation,UNET Segmentation,2019-06,Mesh R-CNN,72.2,100.0,72.2,1.0,72.2,0.77,ito:ITO_00600,Robotics process,box\\ AP
2,1,3D Shape Modeling,Pix3D S1,2019-06,Mesh R-CNN,94.0,100.0,94,1.0,94,1.0,ito:ITO_00600,Robotics process,box\\ AP
3,1,Road Segementation,Road Segementation,2019-06,Mesh R-CNN,94.0,100.0,94,1.0,94,1.0,ito:ITO_00600,Robotics process,box\\ AP
0,1,3D Shape Modeling,Pix3D S2,2019-06,Mesh R-CNN,63.9,100.0,63.9,1.0,63.9,0.72,ito:ITO_00600,Robotics process,mask\\ AP
1,1,UNET Segmentation,UNET Segmentation,2019-06,Mesh R-CNN,63.9,100.0,63.9,1.0,63.9,0.72,ito:ITO_00600,Robotics process,mask\\ AP
2,1,3D Shape Modeling,Pix3D S1,2019-06,Mesh R-CNN,88.4,100.0,88.4,1.0,88.4,1.0,ito:ITO_00600,Robotics process,mask\\ AP
3,1,Road Segementation,Road Segementation,2019-06,Mesh R-CNN,88.4,100.0,88.4,1.0,88.4,1.0,ito:ITO_00600,Robotics process,mask\\ AP
0,1,3D Shape Modeling,Pix3D S2,2019-06,Mesh R-CNN,28.8,100.0,28.8,1.0,28.8,0.56,ito:ITO_00600,Robotics process,mesh\\ AP
1,1,UNET Segmentation,UNET Segmentation,2019-06,Mesh R-CNN,28.8,100.0,28.8,1.0,28.8,0.56,ito:ITO_00600,Robotics process,mesh\\ AP
2,1,3D Shape Modeling,Pix3D S1,2019-06,Mesh R-CNN,51.1,100.0,51.1,1.0,51.1,1.0,ito:ITO_00600,Robotics process,mesh\\ AP
3,1,Road Segementation,Road Segementation,2019-06,Mesh R-CNN,51.1,100.0,51.1,1.0,51.1,1.0,ito:ITO_00600,Robotics process,mesh\\ AP
0,1,Image Generation,ImageNet 64x64,2019-07,BigBiGAN,47.51,100.0,47.51,1.0,47.51,1.0,ito:ITO_00600,Robotics process,Cls
0,1,Visual Navigation,Cooperative Vision-and-Dialogue Navigation,2019-07,Seq2Seq Baseline,2.35,100.0,2.35,1.0,2.35,1.0,ito:ITO_00600,Robotics process,dist_to_end_reduction
0,1,Visual Navigation,Cooperative Vision-and-Dialogue Navigation,2019-07,Seq2Seq baseline,2.35,96.31,2.35,0.96,2.44,0.96,ito:ITO_00600,Robotics process,Goal\\ Progress
1,1,Visual Navigation,Cooperative Vision-and-Dialogue Navigation,2020-02,Prevalent,2.44,100.0,0.1,0.04,2.44,1.0,ito:ITO_00600,Robotics process,Goal\\ Progress
0,1,Skeleton Based Action Recognition,SHREC 2017 track on 3D Hand Gesture Recognition,2019-07,DD-Net,1820000.0,100.0,1820000,1.0,1820000,1.0,ito:ITO_00600,Robotics process,No\\.\\ parameters
0,1,3D Human Pose Estimation,3D Poses in the Wild Challenge,2019-07,RootNet,21.25,83.6,21.25,0.84,25.42,0.84,ito:ITO_00600,Robotics process,MPJAE
1,1,3D Human Pose Estimation,3D Poses in the Wild Challenge,2019-09,SPIN,25.42,100.0,4.2,0.17,25.42,1.0,ito:ITO_00600,Robotics process,MPJAE
0,1,3D Absolute Human Pose Estimation,Human3.6M,2019-07,RootNet,120.0,100.0,120,1.0,120,1.0,ito:ITO_00600,Robotics process,MRPE
0,1,Layout-to-Image Generation,COCO-Stuff 128x128,2019-08,LostGAN,20.03,59.86,20.03,0.6,33.46,0.6,ito:ITO_00600,Robotics process,SceneFID
1,1,Layout-to-Image Generation,COCO-Stuff 128x128,2019-09,SOARISG,33.46,100.0,13.4,0.4,33.46,1.0,ito:ITO_00600,Robotics process,SceneFID
2,1,Layout-to-Image Generation,Visual Genome 128x128,2019-08,LostGAN,13.17,100.0,13.17,1.0,13.17,0.39,ito:ITO_00600,Robotics process,SceneFID
0,1,3D Pose Estimation,K2HPD,2019-08,A2J,93.78,100.0,93.78,1.0,93.78,1.0,ito:ITO_00600,Robotics process,FPS
0,1,Multiple Object Forecasting,Citywalks,2019-09,STED,26.7,100.0,26.7,1.0,26.7,1.0,ito:ITO_00600,Robotics process,ADE
0,1,Multiple Object Forecasting,Citywalks,2019-09,STED,54.3,100.0,54.3,1.0,54.3,1.0,ito:ITO_00600,Robotics process,AIOU
0,1,3D Human Pose Estimation,3DPW,2019-09,SPIN (SMPL oPtimization IN the loop),116.4,100.0,116.4,1.0,116.4,1.0,ito:ITO_00600,Robotics process,MPVPE
0,1,Talking Face Generation,LRW,2019-10,LipGAN,0.6,100.0,0.6,1.0,0.6,1.0,ito:ITO_00600,Robotics process,LMD
0,1,3D Feature Matching,3DMatch Benchmark,2019-10,FCGF,0.9578,100.0,0.9578,1.0,0.9578,1.0,ito:ITO_00600,Robotics process,Average\\ Recall
0,1,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,2019-10,CAG-UDA,44.5,95.7,44.5,0.96,46.5,0.96,ito:ITO_00600,Robotics process,MIoU\\ \\(16\\ classes\\)
1,1,Synthetic-to-Real Translation,SYNTHIA-to-Cityscapes,2019-12,MRNet(ResNet-101),46.5,100.0,2.0,0.04,46.5,1.0,ito:ITO_00600,Robotics process,MIoU\\ \\(16\\ classes\\)
0,1,Video Reconstruction,Tai-Chi-HD,2019-12,First Order Motion,0.063,100.0,0.063,1.0,0.063,1.0,ito:ITO_00600,Robotics process,L1
1,1,Aerial Video Semantic Segmentation,Aerial Video Semantic Segmentation,2019-12,First Order Motion,0.063,100.0,0.063,1.0,0.063,1.0,ito:ITO_00600,Robotics process,L1
0,1,Visual Odometry,KITTI2015,2019-12,abc,123.0,100.0,123,1.0,123,1.0,ito:ITO_00600,Robotics process,Mean\\ Error\\ Rate
0,1,Cross-View Image-to-Image Translation,cvusa,2019-12,UniGAN,2.6,100.0,2.6,1.0,2.6,1.0,ito:ITO_00600,Robotics process,KL
0,1,Cross-View Image-to-Image Translation,cvusa,2019-12,UniGAN,19.8276,100.0,19.8276,1.0,19.8276,1.0,ito:ITO_00600,Robotics process,SD
0,1,Semantic Segmentation,Cityscapes test,2019-12,LightSeg-DarkNet19,88.29,100.0,88.29,1.0,88.29,1.0,ito:ITO_00600,Robotics process,Category\\ mIoU
0,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet-tiny,0.44,11.08,0.44,0.11,3.97,0.11,ito:ITO_00600,Robotics process,Parameters\\ \\(M\\)
1,1,Real-Time 3D Semantic Segmentation,SemanticKITTI,2020-02,3D-MiniNet,3.97,100.0,3.5,0.88,3.97,1.0,ito:ITO_00600,Robotics process,Parameters\\ \\(M\\)
0,1,3D Human Pose Estimation,Surreal,2020-04,Cross Dataset Generalization,97.3,100.0,97.3,1.0,97.3,1.0,ito:ITO_00600,Robotics process,PCK3D
0,1,Playing Atari Games,Atari 2600 Frostbite,2012-07,UCT,270.5,0.04,270.5,0.0,631378.53,0.0,ito:ITO_00873,Playing Games,Score
1,1,Playing Atari Games,Atari 2600 Frostbite,2015-07,MP-EB,507.0,0.08,236.5,0.0,631378.53,0.0,ito:ITO_00873,Playing Games,Score
2,1,Playing Atari Games,Atari 2600 Frostbite,2015-09,Prior+Duel hs,4038.4,0.64,3531.4,0.01,631378.53,0.0,ito:ITO_00873,Playing Games,Score
3,1,Playing Atari Games,Atari 2600 Frostbite,2015-11,Prior noop,4380.1,0.69,341.7,0.0,631378.53,0.0,ito:ITO_00873,Playing Games,Score
4,1,Playing Atari Games,Atari 2600 Frostbite,2015-11,Duel noop,4672.8,0.74,292.7,0.0,631378.53,0.0,ito:ITO_00873,Playing Games,Score
5,1,Playing Atari Games,Atari 2600 Frostbite,2015-11,Prior+Duel noop,7413.0,1.17,2740.2,0.0,631378.53,0.0,ito:ITO_00873,Playing Games,Score
6,1,Playing Atari Games,Atari 2600 Frostbite,2018-03,Ape-X,9328.6,1.48,1915.6,0.0,631378.53,0.0,ito:ITO_00873,Playing Games,Score
7,1,Playing Atari Games,Atari 2600 Frostbite,2019-05,R2D2,315456.4,49.96,306127.8,0.48,631378.53,0.1,ito:ITO_00873,Playing Games,Score
8,1,Playing Atari Games,Atari 2600 Frostbite,2019-11,MuZero,631378.53,100.0,315922.1,0.5,631378.53,0.2,ito:ITO_00873,Playing Games,Score
9,1,Playing Atari Games,Atari 2600 Gravitar,2012-07,UCT,2850.0,14.83,2850.0,0.15,19213.96,0.0,ito:ITO_00873,Playing Games,Score
10,1,Playing Atari Games,Atari 2600 Gravitar,2018-10,RND,3906.0,20.33,1056.0,0.05,19213.96,0.0,ito:ITO_00873,Playing Games,Score
11,1,Playing Atari Games,Atari 2600 Gravitar,2019-05,R2D2,15680.7,81.61,11774.7,0.61,19213.96,0.01,ito:ITO_00873,Playing Games,Score
12,1,Playing Atari Games,Atari 2600 Gravitar,2020-03,Agent57,19213.96,100.0,3533.3,0.18,19213.96,0.01,ito:ITO_00873,Playing Games,Score
13,1,Playing Atari Games,Atari 2600 Breakout,2012-07,UCT,364.4,42.18,364.4,0.42,864.0,0.0,ito:ITO_00873,Playing Games,Score
14,1,Playing Atari Games,Atari 2600 Breakout,2015-09,DQN noop,385.5,44.62,21.1,0.02,864.0,0.0,ito:ITO_00873,Playing Games,Score
15,1,Playing Atari Games,Atari 2600 Breakout,2015-11,Duel hs,411.6,47.64,26.1,0.03,864.0,0.0,ito:ITO_00873,Playing Games,Score
16,1,Playing Atari Games,Atari 2600 Breakout,2015-11,DDQN (tuned) noop,418.5,48.44,6.9,0.01,864.0,0.0,ito:ITO_00873,Playing Games,Score
17,1,Playing Atari Games,Atari 2600 Breakout,2015-12,Advantage Learning,425.32,49.23,6.8,0.01,864.0,0.0,ito:ITO_00873,Playing Games,Score
18,1,Playing Atari Games,Atari 2600 Breakout,2015-12,Persistent AL,431.89,49.99,6.6,0.01,864.0,0.0,ito:ITO_00873,Playing Games,Score
19,1,Playing Atari Games,Atari 2600 Breakout,2016-02,A3C FF hs,681.9,78.92,250.0,0.29,864.0,0.0,ito:ITO_00873,Playing Games,Score
20,1,Playing Atari Games,Atari 2600 Breakout,2016-02,A3C LSTM hs,766.8,88.75,84.9,0.1,864.0,0.0,ito:ITO_00873,Playing Games,Score
21,1,Playing Atari Games,Atari 2600 Breakout,2016-02,Bootstrapped DQN,855.0,98.96,88.2,0.1,864.0,0.0,ito:ITO_00873,Playing Games,Score
22,1,Playing Atari Games,Atari 2600 Breakout,2019-11,MuZero,864.0,100.0,9.0,0.01,864.0,0.0,ito:ITO_00873,Playing Games,Score
23,1,Playing Atari Games,Atari 2600 Montezuma's Revenge,2012-07,Best Learner,10.7,0.02,10.7,0.0,43791.0,0.0,ito:ITO_00873,Playing Games,Score
24,1,Playing Atari Games,Atari 2600 Montezuma's Revenge,2015-07,MP-EB,142.0,0.32,131.3,0.0,43791.0,0.0,ito:ITO_00873,Playing Games,Score
25,1,Playing Atari Games,Atari 2600 Montezuma's Revenge,2016-06,A3C-CTS,273.7,0.63,131.7,0.0,43791.0,0.0,ito:ITO_00873,Playing Games,Score
26,1,Playing Atari Games,Atari 2600 Montezuma's Revenge,2016-06,DDQN-PC,3459.0,7.9,3185.3,0.07,43791.0,0.0,ito:ITO_00873,Playing Games,Score
27,1,Playing Atari Games,Atari 2600 Montezuma's Revenge,2017-03,DQN-PixelCNN,3705.5,8.46,246.5,0.01,43791.0,0.0,ito:ITO_00873,Playing Games,Score
28,1,Playing Atari Games,Atari 2600 Montezuma's Revenge,2018-10,RND,8152.0,18.62,4446.5,0.1,43791.0,0.0,ito:ITO_00873,Playing Games,Score
29,1,Playing Atari Games,Atari 2600 Montezuma's Revenge,2019-01,Go-Explore,43763.0,99.94,35611.0,0.81,43791.0,0.01,ito:ITO_00873,Playing Games,Score
30,1,Playing Atari Games,Atari 2600 Montezuma's Revenge,2020-04,Go-Explore,43791.0,100.0,28.0,0.0,43791.0,0.01,ito:ITO_00873,Playing Games,Score
31,1,Playing Atari Games,Atari 2600 Krull,2012-07,Best Learner,3371.5,1.25,3371.5,0.01,269358.27,0.0,ito:ITO_00873,Playing Games,Score
32,1,Playing Atari Games,Atari 2600 Krull,2012-07,UCT,5037.0,1.87,1665.5,0.01,269358.27,0.0,ito:ITO_00873,Playing Games,Score
33,1,Playing Atari Games,Atari 2600 Krull,2015-07,Gorila,6363.1,2.36,1326.1,0.0,269358.27,0.0,ito:ITO_00873,Playing Games,Score
34,1,Playing Atari Games,Atari 2600 Krull,2015-09,DQN noop,8422.3,3.13,2059.2,0.01,269358.27,0.0,ito:ITO_00873,Playing Games,Score
35,1,Playing Atari Games,Atari 2600 Krull,2015-11,Prior noop,9728.0,3.61,1305.7,0.0,269358.27,0.0,ito:ITO_00873,Playing Games,Score
36,1,Playing Atari Games,Atari 2600 Krull,2015-11,Prior+Duel noop,10374.4,3.85,646.4,0.0,269358.27,0.0,ito:ITO_00873,Playing Games,Score
37,1,Playing Atari Games,Atari 2600 Krull,2015-11,Duel noop,11451.9,4.25,1077.5,0.0,269358.27,0.0,ito:ITO_00873,Playing Games,Score
38,1,Playing Atari Games,Atari 2600 Krull,2017-07,VPN,15930.0,5.91,4478.1,0.02,269358.27,0.01,ito:ITO_00873,Playing Games,Score
39,1,Playing Atari Games,Atari 2600 Krull,2019-05,R2D2,218448.1,81.1,202518.1,0.75,269358.27,0.07,ito:ITO_00873,Playing Games,Score
40,1,Playing Atari Games,Atari 2600 Krull,2019-11,MuZero,269358.27,100.0,50910.2,0.19,269358.27,0.09,ito:ITO_00873,Playing Games,Score
41,1,Playing Atari Games,Atari 2600 Name This Game,2012-07,Best Learner,2500.1,1.59,2500.1,0.02,157177.85,0.0,ito:ITO_00873,Playing Games,Score
42,1,Playing Atari Games,Atari 2600 Name This Game,2012-07,UCT,15410.0,9.8,12909.9,0.08,157177.85,0.0,ito:ITO_00873,Playing Games,Score
43,1,Playing Atari Games,Atari 2600 Name This Game,2015-11,Prior+Duel noop,15572.5,9.91,162.5,0.0,157177.85,0.01,ito:ITO_00873,Playing Games,Score
44,1,Playing Atari Games,Atari 2600 Name This Game,2016-02,DDQN+Pop-Art noop,15851.2,10.08,278.7,0.0,157177.85,0.01,ito:ITO_00873,Playing Games,Score
45,1,Playing Atari Games,Atari 2600 Name This Game,2017-10,QR-DQN-1,21890.0,13.93,6038.8,0.04,157177.85,0.01,ito:ITO_00873,Playing Games,Score
46,1,Playing Atari Games,Atari 2600 Name This Game,2018-03,Ape-X,25783.3,16.4,3893.3,0.02,157177.85,0.01,ito:ITO_00873,Playing Games,Score
47,1,Playing Atari Games,Atari 2600 Name This Game,2019-05,R2D2,58182.7,37.02,32399.4,0.21,157177.85,0.02,ito:ITO_00873,Playing Games,Score
48,1,Playing Atari Games,Atari 2600 Name This Game,2019-11,MuZero,157177.85,100.0,98995.2,0.63,157177.85,0.05,ito:ITO_00873,Playing Games,Score
49,1,Playing Atari Games,Atari 2600 Battle Zone,2012-07,Best Learner,15819.7,1.69,15819.7,0.02,934134.88,0.01,ito:ITO_00873,Playing Games,Score
50,1,Playing Atari Games,Atari 2600 Battle Zone,2012-07,UCT,70333.3,7.53,54513.6,0.06,934134.88,0.02,ito:ITO_00873,Playing Games,Score
51,1,Playing Atari Games,Atari 2600 Battle Zone,2018-03,Ape-X,98895.0,10.59,28561.7,0.03,934134.88,0.03,ito:ITO_00873,Playing Games,Score
52,1,Playing Atari Games,Atari 2600 Battle Zone,2019-05,R2D2,751880.0,80.49,652985.0,0.7,934134.88,0.24,ito:ITO_00873,Playing Games,Score
53,1,Playing Atari Games,Atari 2600 Battle Zone,2019-11,MuZero,848623.0,90.85,96743.0,0.1,934134.88,0.28,ito:ITO_00873,Playing Games,Score
54,1,Playing Atari Games,Atari 2600 Battle Zone,2020-03,Agent57,934134.88,100.0,85511.9,0.09,934134.88,0.3,ito:ITO_00873,Playing Games,Score
55,1,Playing Atari Games,Atari 2600 Chopper Command,2012-07,Best Learner,1581.5,0.16,1581.5,0.0,999900.0,0.0,ito:ITO_00873,Playing Games,Score
56,1,Playing Atari Games,Atari 2600 Chopper Command,2012-07,UCT,34018.8,3.4,32437.3,0.03,999900.0,0.01,ito:ITO_00873,Playing Games,Score
57,1,Playing Atari Games,Atari 2600 Chopper Command,2017-04,Reactor 500M,107779.0,10.78,73760.2,0.07,999900.0,0.03,ito:ITO_00873,Playing Games,Score
58,1,Playing Atari Games,Atari 2600 Chopper Command,2018-03,Ape-X,721851.0,72.19,614072.0,0.61,999900.0,0.23,ito:ITO_00873,Playing Games,Score
59,1,Playing Atari Games,Atari 2600 Chopper Command,2019-05,R2D2,986652.0,98.68,264801.0,0.26,999900.0,0.32,ito:ITO_00873,Playing Games,Score
60,1,Playing Atari Games,Atari 2600 Chopper Command,2019-11,MuZero,991039.7,99.11,4387.7,0.0,999900.0,0.32,ito:ITO_00873,Playing Games,Score
61,1,Playing Atari Games,Atari 2600 Chopper Command,2020-03,Agent57,999900.0,100.0,8860.3,0.01,999900.0,0.32,ito:ITO_00873,Playing Games,Score
62,1,Playing Atari Games,Atari 2600 Gopher,2012-07,Best Learner,1288.3,0.99,1288.3,0.01,130345.58,0.0,ito:ITO_00873,Playing Games,Score
63,1,Playing Atari Games,Atari 2600 Gopher,2012-07,UCT,20560.0,15.77,19271.7,0.15,130345.58,0.01,ito:ITO_00873,Playing Games,Score
64,1,Playing Atari Games,Atari 2600 Gopher,2015-09,Prior+Duel hs,105148.4,80.67,84588.4,0.65,130345.58,0.03,ito:ITO_00873,Playing Games,Score
65,1,Playing Atari Games,Atari 2600 Gopher,2017-10,QR-DQN-1,113585.0,87.14,8436.6,0.06,130345.58,0.04,ito:ITO_00873,Playing Games,Score
66,1,Playing Atari Games,Atari 2600 Gopher,2018-03,Ape-X,120500.9,92.45,6915.9,0.05,130345.58,0.04,ito:ITO_00873,Playing Games,Score
67,1,Playing Atari Games,Atari 2600 Gopher,2019-05,R2D2,124776.3,95.73,4275.4,0.03,130345.58,0.04,ito:ITO_00873,Playing Games,Score
68,1,Playing Atari Games,Atari 2600 Gopher,2019-11,MuZero,130345.58,100.0,5569.3,0.04,130345.58,0.04,ito:ITO_00873,Playing Games,Score
69,1,Playing Atari Games,Atari 2600 Venture,2012-07,Best Learner,66.0,2.52,66.0,0.03,2623.71,0.0,ito:ITO_00873,Playing Games,Score
70,1,Playing Atari Games,Atari 2600 Venture,2015-07,Gorila,523.4,19.95,457.4,0.17,2623.71,0.0,ito:ITO_00873,Playing Games,Score
71,1,Playing Atari Games,Atari 2600 Venture,2016-02,DDQN+Pop-Art noop,1172.0,44.67,648.6,0.25,2623.71,0.0,ito:ITO_00873,Playing Games,Score
72,1,Playing Atari Games,Atari 2600 Venture,2017-07,C51 noop,1520.0,57.93,348.0,0.13,2623.71,0.0,ito:ITO_00873,Playing Games,Score
73,1,Playing Atari Games,Atari 2600 Venture,2018-03,Ape-X,1813.0,69.1,293.0,0.11,2623.71,0.0,ito:ITO_00873,Playing Games,Score
74,1,Playing Atari Games,Atari 2600 Venture,2018-10,RND,1859.0,70.85,46.0,0.02,2623.71,0.0,ito:ITO_00873,Playing Games,Score
75,1,Playing Atari Games,Atari 2600 Venture,2019-05,R2D2,1970.7,75.11,111.7,0.04,2623.71,0.0,ito:ITO_00873,Playing Games,Score
76,1,Playing Atari Games,Atari 2600 Venture,2020-03,Agent57,2623.71,100.0,653.0,0.25,2623.71,0.0,ito:ITO_00873,Playing Games,Score
77,1,Playing Atari Games,Atari 2600 Ms. Pacman,2012-07,Best Learner,1691.8,0.7,1691.8,0.01,243401.1,0.0,ito:ITO_00873,Playing Games,Score
78,1,Playing Atari Games,Atari 2600 Ms. Pacman,2012-07,UCT,22336.0,9.18,20644.2,0.08,243401.1,0.01,ito:ITO_00873,Playing Games,Score
79,1,Playing Atari Games,Atari 2600 Ms. Pacman,2019-05,R2D2,42281.7,17.37,19945.7,0.08,243401.1,0.01,ito:ITO_00873,Playing Games,Score
80,1,Playing Atari Games,Atari 2600 Ms. Pacman,2019-11,MuZero,243401.1,100.0,201119.4,0.83,243401.1,0.08,ito:ITO_00873,Playing Games,Score
81,1,Playing Atari Games,Atari 2600 HERO,2012-07,Best linear,6459.0,5.63,6459.0,0.06,114736.26,0.0,ito:ITO_00873,Playing Games,Score
82,1,Playing Atari Games,Atari 2600 HERO,2012-07,UCT,12859.5,11.21,6400.5,0.06,114736.26,0.0,ito:ITO_00873,Playing Games,Score
83,1,Playing Atari Games,Atari 2600 HERO,2015-09,DQN noop,20437.8,17.81,7578.3,0.07,114736.26,0.01,ito:ITO_00873,Playing Games,Score
84,1,Playing Atari Games,Atari 2600 HERO,2015-11,Prior noop,23037.7,20.08,2599.9,0.02,114736.26,0.01,ito:ITO_00873,Playing Games,Score
85,1,Playing Atari Games,Atari 2600 HERO,2015-12,Advantage Learning,24788.86,21.61,1751.2,0.02,114736.26,0.01,ito:ITO_00873,Playing Games,Score
86,1,Playing Atari Games,Atari 2600 HERO,2016-02,A3C LSTM hs,28889.5,25.18,4100.6,0.04,114736.26,0.01,ito:ITO_00873,Playing Games,Score
87,1,Playing Atari Games,Atari 2600 HERO,2016-02,A3C FF hs,32464.1,28.29,3574.6,0.03,114736.26,0.01,ito:ITO_00873,Playing Games,Score
88,1,Playing Atari Games,Atari 2600 HERO,2017-07,C51 noop,38874.0,33.88,6409.9,0.06,114736.26,0.01,ito:ITO_00873,Playing Games,Score
89,1,Playing Atari Games,Atari 2600 HERO,2019-05,R2D2,39537.1,34.46,663.1,0.01,114736.26,0.01,ito:ITO_00873,Playing Games,Score
90,1,Playing Atari Games,Atari 2600 HERO,2019-11,MuZero,49244.11,42.92,9707.0,0.08,114736.26,0.02,ito:ITO_00873,Playing Games,Score
91,1,Playing Atari Games,Atari 2600 HERO,2020-03,Agent57,114736.26,100.0,65492.2,0.57,114736.26,0.04,ito:ITO_00873,Playing Games,Score
92,1,Playing Atari Games,Atari 2600 Atlantis,2012-07,Best Learner,62687.0,2.03,62687.0,0.02,3084781.7,0.02,ito:ITO_00873,Playing Games,Score
93,1,Playing Atari Games,Atari 2600 Atlantis,2012-07,UCT,193858.0,6.28,131171.0,0.04,3084781.7,0.06,ito:ITO_00873,Playing Games,Score
94,1,Playing Atari Games,Atari 2600 Atlantis,2015-07,Gorila,629166.5,20.4,435308.5,0.14,3084781.7,0.2,ito:ITO_00873,Playing Games,Score
95,1,Playing Atari Games,Atari 2600 Atlantis,2015-12,Persistent AL,1465250.0,47.5,836083.5,0.27,3084781.7,0.47,ito:ITO_00873,Playing Games,Score
96,1,Playing Atari Games,Atari 2600 Atlantis,2018-06,A2C + SIL,3084781.7,100.0,1619531.7,0.53,3084781.7,1.0,ito:ITO_00873,Playing Games,Score
97,1,Playing Atari Games,Atari 2600 Wizard of Wor,2012-07,Best Learner,1981.3,1.01,1981.3,0.01,197126.0,0.0,ito:ITO_00873,Playing Games,Score
98,1,Playing Atari Games,Atari 2600 Wizard of Wor,2012-07,UCT,105500.0,53.52,103518.7,0.53,197126.0,0.03,ito:ITO_00873,Playing Games,Score
99,1,Playing Atari Games,Atari 2600 Wizard of Wor,2019-05,R2D2,144362.7,73.23,38862.7,0.2,197126.0,0.05,ito:ITO_00873,Playing Games,Score
100,1,Playing Atari Games,Atari 2600 Wizard of Wor,2019-11,MuZero,197126.0,100.0,52763.3,0.27,197126.0,0.06,ito:ITO_00873,Playing Games,Score
101,1,Playing Atari Games,Atari 2600 Up and Down,2012-07,Best Learner,3532.7,0.49,3532.7,0.0,715545.61,0.0,ito:ITO_00873,Playing Games,Score
102,1,Playing Atari Games,Atari 2600 Up and Down,2012-07,UCT,74473.6,10.41,70940.9,0.1,715545.61,0.02,ito:ITO_00873,Playing Games,Score
103,1,Playing Atari Games,Atari 2600 Up and Down,2016-02,A3C LSTM hs,105728.7,14.78,31255.1,0.04,715545.61,0.03,ito:ITO_00873,Playing Games,Score
104,1,Playing Atari Games,Atari 2600 Up and Down,2018-02,IMPALA (deep),332546.75,46.47,226818.0,0.32,715545.61,0.11,ito:ITO_00873,Playing Games,Score
105,1,Playing Atari Games,Atari 2600 Up and Down,2018-03,Ape-X,401884.3,56.16,69337.5,0.1,715545.61,0.13,ito:ITO_00873,Playing Games,Score
106,1,Playing Atari Games,Atari 2600 Up and Down,2019-05,R2D2,589226.9,82.35,187342.6,0.26,715545.61,0.19,ito:ITO_00873,Playing Games,Score
107,1,Playing Atari Games,Atari 2600 Up and Down,2019-11,MuZero,715545.61,100.0,126318.7,0.18,715545.61,0.23,ito:ITO_00873,Playing Games,Score
108,1,Playing Atari Games,Atari 2600 Fishing Derby,2012-07,UCT,37.8,41.47,37.8,0.41,91.16,0.0,ito:ITO_00873,Playing Games,Score
109,1,Playing Atari Games,Atari 2600 Fishing Derby,2015-11,Prior noop,39.5,43.33,1.7,0.02,91.16,0.0,ito:ITO_00873,Playing Games,Score
110,1,Playing Atari Games,Atari 2600 Fishing Derby,2015-11,Prior+Duel noop,41.3,45.3,1.8,0.02,91.16,0.0,ito:ITO_00873,Playing Games,Score
111,1,Playing Atari Games,Atari 2600 Fishing Derby,2015-11,Duel noop,46.4,50.9,5.1,0.06,91.16,0.0,ito:ITO_00873,Playing Games,Score
112,1,Playing Atari Games,Atari 2600 Fishing Derby,2017-06,NoisyNet-Dueling,57.0,62.53,10.6,0.12,91.16,0.0,ito:ITO_00873,Playing Games,Score
113,1,Playing Atari Games,Atari 2600 Fishing Derby,2019-05,R2D2,85.8,94.12,28.8,0.32,91.16,0.0,ito:ITO_00873,Playing Games,Score
114,1,Playing Atari Games,Atari 2600 Fishing Derby,2019-11,MuZero,91.16,100.0,5.4,0.06,91.16,0.0,ito:ITO_00873,Playing Games,Score
115,1,Playing Atari Games,Atari 2600 Video Pinball,2012-07,Best Learner,16871.3,1.69,16871.3,0.02,999383.2,0.01,ito:ITO_00873,Playing Games,Score
116,1,Playing Atari Games,Atari 2600 Video Pinball,2012-07,UCT,254748.0,25.49,237876.7,0.24,999383.2,0.08,ito:ITO_00873,Playing Games,Score
117,1,Playing Atari Games,Atari 2600 Video Pinball,2015-09,Prior+Duel hs,447408.6,44.77,192660.6,0.19,999383.2,0.15,ito:ITO_00873,Playing Games,Score
118,1,Playing Atari Games,Atari 2600 Video Pinball,2015-11,Prior+Duel noop,479197.0,47.95,31788.4,0.03,999383.2,0.16,ito:ITO_00873,Playing Games,Score
119,1,Playing Atari Games,Atari 2600 Video Pinball,2015-12,Advantage Learning,543504.0,54.38,64307.0,0.06,999383.2,0.18,ito:ITO_00873,Playing Games,Score
120,1,Playing Atari Games,Atari 2600 Video Pinball,2016-02,Bootstrapped DQN,811610.0,81.21,268106.0,0.27,999383.2,0.26,ito:ITO_00873,Playing Games,Score
121,1,Playing Atari Games,Atari 2600 Video Pinball,2017-06,NoisyNet-Dueling,870954.0,87.15,59344.0,0.06,999383.2,0.28,ito:ITO_00873,Playing Games,Score
122,1,Playing Atari Games,Atari 2600 Video Pinball,2017-07,C51 noop,949604.0,95.02,78650.0,0.08,999383.2,0.31,ito:ITO_00873,Playing Games,Score
123,1,Playing Atari Games,Atari 2600 Video Pinball,2019-05,R2D2,999383.2,100.0,49779.2,0.05,999383.2,0.32,ito:ITO_00873,Playing Games,Score
124,1,Playing Atari Games,Atari 2600 Boxing,2012-07,Best Learner,44.0,44.0,44.0,0.44,100.0,0.0,ito:ITO_00873,Playing Games,Score
125,1,Playing Atari Games,Atari 2600 Boxing,2012-07,UCT,100.0,100.0,56.0,0.56,100.0,0.0,ito:ITO_00873,Playing Games,Score
126,1,Playing Atari Games,Atari 2600 Asterix,2012-07,Best Learner,987.3,0.1,987.3,0.0,999153.3,0.0,ito:ITO_00873,Playing Games,Score
127,1,Playing Atari Games,Atari 2600 Asterix,2012-07,UCT,290700.0,29.09,289712.7,0.29,999153.3,0.09,ito:ITO_00873,Playing Games,Score
128,1,Playing Atari Games,Atari 2600 Asterix,2015-09,Prior+Duel hs,364200.0,36.45,73500.0,0.07,999153.3,0.12,ito:ITO_00873,Playing Games,Score
129,1,Playing Atari Games,Atari 2600 Asterix,2015-11,Prior+Duel noop,375080.0,37.54,10880.0,0.01,999153.3,0.12,ito:ITO_00873,Playing Games,Score
130,1,Playing Atari Games,Atari 2600 Asterix,2017-07,C51 noop,406211.0,40.66,31131.0,0.03,999153.3,0.13,ito:ITO_00873,Playing Games,Score
131,1,Playing Atari Games,Atari 2600 Asterix,2019-05,R2D2,999153.3,100.0,592942.3,0.59,999153.3,0.32,ito:ITO_00873,Playing Games,Score
132,1,Playing Atari Games,Atari 2600 Space Invaders,2012-07,UCT,2718.0,3.66,2718.0,0.04,74335.3,0.0,ito:ITO_00873,Playing Games,Score
133,1,Playing Atari Games,Atari 2600 Space Invaders,2015-09,Prior+Duel hs,8978.0,12.08,6260.0,0.08,74335.3,0.0,ito:ITO_00873,Playing Games,Score
134,1,Playing Atari Games,Atari 2600 Space Invaders,2015-11,Prior+Duel noop,15311.5,20.6,6333.5,0.09,74335.3,0.0,ito:ITO_00873,Playing Games,Score
135,1,Playing Atari Games,Atari 2600 Space Invaders,2016-02,A3C LSTM hs,23846.0,32.08,8534.5,0.11,74335.3,0.01,ito:ITO_00873,Playing Games,Score
136,1,Playing Atari Games,Atari 2600 Space Invaders,2018-02,IMPALA (deep),43595.78,58.65,19749.8,0.27,74335.3,0.01,ito:ITO_00873,Playing Games,Score
137,1,Playing Atari Games,Atari 2600 Space Invaders,2018-03,Ape-X,54681.0,73.56,11085.2,0.15,74335.3,0.02,ito:ITO_00873,Playing Games,Score
138,1,Playing Atari Games,Atari 2600 Space Invaders,2019-11,MuZero,74335.3,100.0,19654.3,0.26,74335.3,0.02,ito:ITO_00873,Playing Games,Score
139,1,Playing Atari Games,Atari 2600 Zaxxon,2012-07,Best Learner,3365.1,0.46,3365.1,0.0,725853.9,0.0,ito:ITO_00873,Playing Games,Score
140,1,Playing Atari Games,Atari 2600 Zaxxon,2012-07,UCT,22610.0,3.11,19244.9,0.03,725853.9,0.01,ito:ITO_00873,Playing Games,Score
141,1,Playing Atari Games,Atari 2600 Zaxxon,2016-02,A3C LSTM hs,23519.0,3.24,909.0,0.0,725853.9,0.01,ito:ITO_00873,Playing Games,Score
142,1,Playing Atari Games,Atari 2600 Zaxxon,2016-02,A3C FF hs,24622.0,3.39,1103.0,0.0,725853.9,0.01,ito:ITO_00873,Playing Games,Score
143,1,Playing Atari Games,Atari 2600 Zaxxon,2018-02,IMPALA (deep),32935.5,4.54,8313.5,0.01,725853.9,0.01,ito:ITO_00873,Playing Games,Score
144,1,Playing Atari Games,Atari 2600 Zaxxon,2018-03,Ape-X,42285.5,5.83,9350.0,0.01,725853.9,0.01,ito:ITO_00873,Playing Games,Score
145,1,Playing Atari Games,Atari 2600 Zaxxon,2019-05,R2D2,224910.7,30.99,182625.2,0.25,725853.9,0.07,ito:ITO_00873,Playing Games,Score
146,1,Playing Atari Games,Atari 2600 Zaxxon,2019-11,MuZero,725853.9,100.0,500943.2,0.69,725853.9,0.24,ito:ITO_00873,Playing Games,Score
147,1,Playing Atari Games,Atari 2600 Star Gunner,2012-07,Full Tree,1345.0,0.16,1345.0,0.0,839573.53,0.0,ito:ITO_00873,Playing Games,Score
148,1,Playing Atari Games,Atari 2600 Star Gunner,2015-07,Gorila,14919.2,1.78,13574.2,0.02,839573.53,0.0,ito:ITO_00873,Playing Games,Score
149,1,Playing Atari Games,Atari 2600 Star Gunner,2015-09,DDQN (tuned) hs,58365.0,6.95,43445.8,0.05,839573.53,0.02,ito:ITO_00873,Playing Games,Score
150,1,Playing Atari Games,Atari 2600 Star Gunner,2015-09,Prior+Duel hs,127073.0,15.14,68708.0,0.08,839573.53,0.04,ito:ITO_00873,Playing Games,Score
151,1,Playing Atari Games,Atari 2600 Star Gunner,2016-02,A3C LSTM hs,164766.0,19.62,37693.0,0.04,839573.53,0.05,ito:ITO_00873,Playing Games,Score
152,1,Playing Atari Games,Atari 2600 Star Gunner,2018-02,IMPALA (deep),200625.0,23.9,35859.0,0.04,839573.53,0.07,ito:ITO_00873,Playing Games,Score
153,1,Playing Atari Games,Atari 2600 Star Gunner,2018-03,Ape-X,434342.5,51.73,233717.5,0.28,839573.53,0.14,ito:ITO_00873,Playing Games,Score
154,1,Playing Atari Games,Atari 2600 Star Gunner,2019-05,R2D2,717344.0,85.44,283001.5,0.34,839573.53,0.23,ito:ITO_00873,Playing Games,Score
155,1,Playing Atari Games,Atari 2600 Star Gunner,2020-03,Agent57,839573.53,100.0,122229.5,0.15,839573.53,0.27,ito:ITO_00873,Playing Games,Score
156,1,Playing Atari Games,Atari 2600 Kung-Fu Master,2012-07,Best Learner,19544.0,8.37,19544.0,0.08,233413.3,0.01,ito:ITO_00873,Playing Games,Score
157,1,Playing Atari Games,Atari 2600 Kung-Fu Master,2012-07,UCT,48854.5,20.93,29310.5,0.13,233413.3,0.02,ito:ITO_00873,Playing Games,Score
158,1,Playing Atari Games,Atari 2600 Kung-Fu Master,2017-10,QR-DQN-1,76642.0,32.84,27787.5,0.12,233413.3,0.02,ito:ITO_00873,Playing Games,Score
159,1,Playing Atari Games,Atari 2600 Kung-Fu Master,2018-03,Ape-X,97829.5,41.91,21187.5,0.09,233413.3,0.03,ito:ITO_00873,Playing Games,Score
160,1,Playing Atari Games,Atari 2600 Kung-Fu Master,2019-05,R2D2,233413.3,100.0,135583.8,0.58,233413.3,0.08,ito:ITO_00873,Playing Games,Score
161,1,Playing Atari Games,Atari 2600 Assault,2012-07,Best Learner,628.0,0.44,628.0,0.0,143972.03,0.0,ito:ITO_00873,Playing Games,Score
162,1,Playing Atari Games,Atari 2600 Assault,2012-07,UCT,1512.2,1.05,884.2,0.01,143972.03,0.0,ito:ITO_00873,Playing Games,Score
163,1,Playing Atari Games,Atari 2600 Assault,2015-09,DDQN (tuned) hs,6060.8,4.21,4548.6,0.03,143972.03,0.0,ito:ITO_00873,Playing Games,Score
164,1,Playing Atari Games,Atari 2600 Assault,2015-09,Prior+Duel hs,10950.6,7.61,4889.8,0.03,143972.03,0.0,ito:ITO_00873,Playing Games,Score
165,1,Playing Atari Games,Atari 2600 Assault,2015-11,Prior+Duel noop,11477.0,7.97,526.4,0.0,143972.03,0.0,ito:ITO_00873,Playing Games,Score
166,1,Playing Atari Games,Atari 2600 Assault,2016-02,A3C LSTM hs,14497.9,10.07,3020.9,0.02,143972.03,0.0,ito:ITO_00873,Playing Games,Score
167,1,Playing Atari Games,Atari 2600 Assault,2017-10,QR-DQN-1,22012.0,15.29,7514.1,0.05,143972.03,0.01,ito:ITO_00873,Playing Games,Score
168,1,Playing Atari Games,Atari 2600 Assault,2018-03,Ape-X,24559.4,17.06,2547.4,0.02,143972.03,0.01,ito:ITO_00873,Playing Games,Score
169,1,Playing Atari Games,Atari 2600 Assault,2018-06,IQN,29091.0,20.21,4531.6,0.03,143972.03,0.01,ito:ITO_00873,Playing Games,Score
170,1,Playing Atari Games,Atari 2600 Assault,2019-05,R2D2,108197.0,75.15,79106.0,0.55,143972.03,0.04,ito:ITO_00873,Playing Games,Score
171,1,Playing Atari Games,Atari 2600 Assault,2019-11,MuZero,143972.03,100.0,35775.0,0.25,143972.03,0.05,ito:ITO_00873,Playing Games,Score
172,1,Playing Atari Games,Atari 2600 Robotank,2012-07,Best Learner,28.7,21.89,28.7,0.22,131.13,0.0,ito:ITO_00873,Playing Games,Score
173,1,Playing Atari Games,Atari 2600 Robotank,2012-07,UCT,50.4,38.44,21.7,0.17,131.13,0.0,ito:ITO_00873,Playing Games,Score
174,1,Playing Atari Games,Atari 2600 Robotank,2015-07,Gorila,61.8,47.13,11.4,0.09,131.13,0.0,ito:ITO_00873,Playing Games,Score
175,1,Playing Atari Games,Atari 2600 Robotank,2015-09,DQN noop,63.9,48.73,2.1,0.02,131.13,0.0,ito:ITO_00873,Playing Games,Score
176,1,Playing Atari Games,Atari 2600 Robotank,2015-11,Duel noop,65.3,49.8,1.4,0.01,131.13,0.0,ito:ITO_00873,Playing Games,Score
177,1,Playing Atari Games,Atari 2600 Robotank,2015-12,Advantage Learning,69.31,52.86,4.0,0.03,131.13,0.0,ito:ITO_00873,Playing Games,Score
178,1,Playing Atari Games,Atari 2600 Robotank,2018-03,Ape-X,73.8,56.28,4.5,0.03,131.13,0.0,ito:ITO_00873,Playing Games,Score
179,1,Playing Atari Games,Atari 2600 Robotank,2019-05,R2D2,100.4,76.57,26.6,0.2,131.13,0.0,ito:ITO_00873,Playing Games,Score
180,1,Playing Atari Games,Atari 2600 Robotank,2019-11,MuZero,131.13,100.0,30.7,0.23,131.13,0.0,ito:ITO_00873,Playing Games,Score
181,1,Playing Atari Games,Atari 2600 Alien,2012-07,Best Learner,939.2,0.13,939.2,0.0,741812.63,0.0,ito:ITO_00873,Playing Games,Score
182,1,Playing Atari Games,Atari 2600 Alien,2012-07,UCT,7785.0,1.05,6845.8,0.01,741812.63,0.0,ito:ITO_00873,Playing Games,Score
183,1,Playing Atari Games,Atari 2600 Alien,2017-04,Reactor 500M,12689.1,1.71,4904.1,0.01,741812.63,0.0,ito:ITO_00873,Playing Games,Score
184,1,Playing Atari Games,Atari 2600 Alien,2018-02,IMPALA (deep),15962.1,2.15,3273.0,0.0,741812.63,0.01,ito:ITO_00873,Playing Games,Score
185,1,Playing Atari Games,Atari 2600 Alien,2018-03,Ape-X,40804.9,5.5,24842.8,0.03,741812.63,0.01,ito:ITO_00873,Playing Games,Score
186,1,Playing Atari Games,Atari 2600 Alien,2019-05,R2D2,229496.9,30.94,188692.0,0.25,741812.63,0.07,ito:ITO_00873,Playing Games,Score
187,1,Playing Atari Games,Atari 2600 Alien,2019-11,MuZero,741812.63,100.0,512315.7,0.69,741812.63,0.24,ito:ITO_00873,Playing Games,Score
188,1,Playing Atari Games,Atari 2600 Berzerk,2012-07,Best Learner,501.3,0.25,501.3,0.0,197376.0,0.0,ito:ITO_00873,Playing Games,Score
189,1,Playing Atari Games,Atari 2600 Berzerk,2012-07,Best Baseline,670.0,0.34,168.7,0.0,197376.0,0.0,ito:ITO_00873,Playing Games,Score
190,1,Playing Atari Games,Atari 2600 Berzerk,2015-09,DDQN (tuned) hs,1011.1,0.51,341.1,0.0,197376.0,0.0,ito:ITO_00873,Playing Games,Score
191,1,Playing Atari Games,Atari 2600 Berzerk,2015-09,Prior+Duel hs,2178.6,1.1,1167.5,0.01,197376.0,0.0,ito:ITO_00873,Playing Games,Score
192,1,Playing Atari Games,Atari 2600 Berzerk,2015-11,Prior+Duel noop,3409.0,1.73,1230.4,0.01,197376.0,0.0,ito:ITO_00873,Playing Games,Score
193,1,Playing Atari Games,Atari 2600 Berzerk,2018-03,Ape-X,57196.7,28.98,53787.7,0.27,197376.0,0.02,ito:ITO_00873,Playing Games,Score
194,1,Playing Atari Games,Atari 2600 Berzerk,2019-11,MuZero,85932.6,43.54,28735.9,0.15,197376.0,0.03,ito:ITO_00873,Playing Games,Score
195,1,Playing Atari Games,Atari 2600 Berzerk,2020-04,Go-Explore,197376.0,100.0,111443.4,0.56,197376.0,0.06,ito:ITO_00873,Playing Games,Score
196,1,Playing Atari Games,Atari 2600 Amidar,2012-07,Best Learner,103.4,0.35,103.4,0.0,29660.08,0.0,ito:ITO_00873,Playing Games,Score
197,1,Playing Atari Games,Atari 2600 Amidar,2012-07,UCT,180.3,0.61,76.9,0.0,29660.08,0.0,ito:ITO_00873,Playing Games,Score
198,1,Playing Atari Games,Atari 2600 Amidar,2015-07,Gorila,189.2,0.64,8.9,0.0,29660.08,0.0,ito:ITO_00873,Playing Games,Score
199,1,Playing Atari Games,Atari 2600 Amidar,2015-09,DQN noop,978.0,3.3,788.8,0.03,29660.08,0.0,ito:ITO_00873,Playing Games,Score
200,1,Playing Atari Games,Atari 2600 Amidar,2015-11,Prior noop,1838.9,6.2,860.9,0.03,29660.08,0.0,ito:ITO_00873,Playing Games,Score
201,1,Playing Atari Games,Atari 2600 Amidar,2015-11,Prior+Duel noop,2296.8,7.74,457.9,0.02,29660.08,0.0,ito:ITO_00873,Playing Games,Score
202,1,Playing Atari Games,Atari 2600 Amidar,2015-11,Duel noop,2354.5,7.94,57.7,0.0,29660.08,0.0,ito:ITO_00873,Playing Games,Score
203,1,Playing Atari Games,Atari 2600 Amidar,2017-06,NoisyNet-Dueling,3537.0,11.93,1182.5,0.04,29660.08,0.0,ito:ITO_00873,Playing Games,Score
204,1,Playing Atari Games,Atari 2600 Amidar,2018-03,Ape-X,8659.2,29.19,5122.2,0.17,29660.08,0.0,ito:ITO_00873,Playing Games,Score
205,1,Playing Atari Games,Atari 2600 Amidar,2019-05,R2D2,29321.4,98.86,20662.2,0.7,29660.08,0.01,ito:ITO_00873,Playing Games,Score
206,1,Playing Atari Games,Atari 2600 Amidar,2020-03,Agent57,29660.08,100.0,338.7,0.01,29660.08,0.01,ito:ITO_00873,Playing Games,Score
207,1,Playing Atari Games,Atari 2600 Kangaroo,2012-07,Best Learner,1622.1,6.75,1622.1,0.07,24034.16,0.0,ito:ITO_00873,Playing Games,Score
208,1,Playing Atari Games,Atari 2600 Kangaroo,2012-07,UCT,1990.0,8.28,367.9,0.02,24034.16,0.0,ito:ITO_00873,Playing Games,Score
209,1,Playing Atari Games,Atari 2600 Kangaroo,2015-09,DDQN (tuned) hs,11204.0,46.62,9214.0,0.38,24034.16,0.0,ito:ITO_00873,Playing Games,Score
210,1,Playing Atari Games,Atari 2600 Kangaroo,2015-11,Prior hs,12185.0,50.7,981.0,0.04,24034.16,0.0,ito:ITO_00873,Playing Games,Score
211,1,Playing Atari Games,Atari 2600 Kangaroo,2015-11,Prior noop,16200.0,67.4,4015.0,0.17,24034.16,0.01,ito:ITO_00873,Playing Games,Score
212,1,Playing Atari Games,Atari 2600 Kangaroo,2019-11,MuZero,16763.6,69.75,563.6,0.02,24034.16,0.01,ito:ITO_00873,Playing Games,Score
213,1,Playing Atari Games,Atari 2600 Kangaroo,2020-03,Agent57,24034.16,100.0,7270.6,0.3,24034.16,0.01,ito:ITO_00873,Playing Games,Score
214,1,Playing Atari Games,Atari 2600 Ice Hockey,2012-07,UCT,39.4,49.68,39.4,0.5,79.3,0.0,ito:ITO_00873,Playing Games,Score
215,1,Playing Atari Games,Atari 2600 Ice Hockey,2019-05,R2D2,79.3,100.0,39.9,0.5,79.3,0.0,ito:ITO_00873,Playing Games,Score
216,1,Playing Atari Games,Atari 2600 Freeway,2012-07,Best Learner,19.1,56.18,19.1,0.56,34.0,0.0,ito:ITO_00873,Playing Games,Score
217,1,Playing Atari Games,Atari 2600 Freeway,2012-07,Best Baseline,22.5,66.18,3.4,0.1,34.0,0.0,ito:ITO_00873,Playing Games,Score
218,1,Playing Atari Games,Atari 2600 Freeway,2015-07,MP-EB,27.0,79.41,4.5,0.13,34.0,0.0,ito:ITO_00873,Playing Games,Score
219,1,Playing Atari Games,Atari 2600 Freeway,2015-09,DDQN (tuned) hs,28.8,84.71,1.8,0.05,34.0,0.0,ito:ITO_00873,Playing Games,Score
220,1,Playing Atari Games,Atari 2600 Freeway,2015-09,DQN noop,30.8,90.59,2.0,0.06,34.0,0.0,ito:ITO_00873,Playing Games,Score
221,1,Playing Atari Games,Atari 2600 Freeway,2015-11,Prior noop,33.7,99.12,2.9,0.09,34.0,0.0,ito:ITO_00873,Playing Games,Score
222,1,Playing Atari Games,Atari 2600 Freeway,2016-02,Bootstrapped DQN,33.9,99.71,0.2,0.01,34.0,0.0,ito:ITO_00873,Playing Games,Score
223,1,Playing Atari Games,Atari 2600 Freeway,2016-11,TRPO-hash,34.0,100.0,0.1,0.0,34.0,0.0,ito:ITO_00873,Playing Games,Score
224,1,Playing Atari Games,Atari 2600 Private Eye,2012-07,Best Baseline,1947.3,2.03,1947.3,0.02,95756.0,0.0,ito:ITO_00873,Playing Games,Score
225,1,Playing Atari Games,Atari 2600 Private Eye,2015-07,Gorila,2598.6,2.71,651.3,0.01,95756.0,0.0,ito:ITO_00873,Playing Games,Score
226,1,Playing Atari Games,Atari 2600 Private Eye,2015-12,Advantage Learning,5276.16,5.51,2677.6,0.03,95756.0,0.0,ito:ITO_00873,Playing Games,Score
227,1,Playing Atari Games,Atari 2600 Private Eye,2017-03,DQN-PixelCNN,8358.7,8.73,3082.5,0.03,95756.0,0.0,ito:ITO_00873,Playing Games,Score
228,1,Playing Atari Games,Atari 2600 Private Eye,2017-07,C51 noop,15095.0,15.76,6736.3,0.07,95756.0,0.0,ito:ITO_00873,Playing Games,Score
229,1,Playing Atari Games,Atari 2600 Private Eye,2019-11,MuZero,15299.98,15.98,205.0,0.0,95756.0,0.0,ito:ITO_00873,Playing Games,Score
230,1,Playing Atari Games,Atari 2600 Private Eye,2020-03,Agent57,79716.46,83.25,64416.5,0.67,95756.0,0.03,ito:ITO_00873,Playing Games,Score
231,1,Playing Atari Games,Atari 2600 Private Eye,2020-04,Go-Explore,95756.0,100.0,16039.5,0.17,95756.0,0.03,ito:ITO_00873,Playing Games,Score
232,1,Playing Atari Games,Atari 2600 Q_Bert,2012-07,Best Learner,613.5,0.11,613.5,0.0,580328.14,0.0,ito:ITO_00873,Playing Games,Score
233,1,Playing Atari Games,Atari 2600 Q_Bert,2012-07,UCT,17343.4,2.99,16729.9,0.03,580328.14,0.01,ito:ITO_00873,Playing Games,Score
234,1,Playing Atari Games,Atari 2600 Q_Bert,2015-11,Duel noop,19220.3,3.31,1876.9,0.0,580328.14,0.01,ito:ITO_00873,Playing Games,Score
235,1,Playing Atari Games,Atari 2600 Q_Bert,2016-02,A3C LSTM hs,21307.5,3.67,2087.2,0.0,580328.14,0.01,ito:ITO_00873,Playing Games,Score
236,1,Playing Atari Games,Atari 2600 Q_Bert,2017-06,NoisyNet-Dueling,27121.0,4.67,5813.5,0.01,580328.14,0.01,ito:ITO_00873,Playing Games,Score
237,1,Playing Atari Games,Atari 2600 Q_Bert,2017-10,QR-DQN-1,572510.0,98.65,545389.0,0.94,580328.14,0.19,ito:ITO_00873,Playing Games,Score
238,1,Playing Atari Games,Atari 2600 Q_Bert,2020-03,Agent57,580328.14,100.0,7818.1,0.01,580328.14,0.19,ito:ITO_00873,Playing Games,Score
239,1,Playing Atari Games,Atari 2600 Pong,2012-07,UCT,21.0,100.0,21.0,1.0,21.0,0.0,ito:ITO_00873,Playing Games,Score
240,1,Playing Atari Games,Atari 2600 Beam Rider,2012-07,Best Learner,929.4,0.2,929.4,0.0,454993.53,0.0,ito:ITO_00873,Playing Games,Score
241,1,Playing Atari Games,Atari 2600 Beam Rider,2012-07,UCT,6624.6,1.46,5695.2,0.01,454993.53,0.0,ito:ITO_00873,Playing Games,Score
242,1,Playing Atari Games,Atari 2600 Beam Rider,2015-09,DDQN (tuned) hs,17417.2,3.83,10792.6,0.02,454993.53,0.01,ito:ITO_00873,Playing Games,Score
243,1,Playing Atari Games,Atari 2600 Beam Rider,2015-09,Prior+Duel hs,37412.2,8.22,19995.0,0.04,454993.53,0.01,ito:ITO_00873,Playing Games,Score
244,1,Playing Atari Games,Atari 2600 Beam Rider,2018-03,Ape-X,63305.2,13.91,25893.0,0.06,454993.53,0.02,ito:ITO_00873,Playing Games,Score
245,1,Playing Atari Games,Atari 2600 Beam Rider,2019-05,R2D2,188257.4,41.38,124952.2,0.27,454993.53,0.06,ito:ITO_00873,Playing Games,Score
246,1,Playing Atari Games,Atari 2600 Beam Rider,2019-11,MuZero,454993.53,100.0,266736.1,0.59,454993.53,0.15,ito:ITO_00873,Playing Games,Score
247,1,Playing Atari Games,Atari 2600 River Raid,2012-07,Best Learner,1904.3,0.59,1904.3,0.01,323417.18,0.0,ito:ITO_00873,Playing Games,Score
248,1,Playing Atari Games,Atari 2600 River Raid,2012-07,UCT,4449.0,1.38,2544.7,0.01,323417.18,0.0,ito:ITO_00873,Playing Games,Score
249,1,Playing Atari Games,Atari 2600 River Raid,2015-07,Gorila,5310.3,1.64,861.3,0.0,323417.18,0.0,ito:ITO_00873,Playing Games,Score
250,1,Playing Atari Games,Atari 2600 River Raid,2015-09,Prior+Duel hs,16496.8,5.1,11186.5,0.03,323417.18,0.01,ito:ITO_00873,Playing Games,Score
251,1,Playing Atari Games,Atari 2600 River Raid,2015-11,Duel hs,16569.4,5.12,72.6,0.0,323417.18,0.01,ito:ITO_00873,Playing Games,Score
252,1,Playing Atari Games,Atari 2600 River Raid,2015-11,Duel noop,21162.6,6.54,4593.2,0.01,323417.18,0.01,ito:ITO_00873,Playing Games,Score
253,1,Playing Atari Games,Atari 2600 River Raid,2018-02,IMPALA (deep),29608.05,9.15,8445.4,0.03,323417.18,0.01,ito:ITO_00873,Playing Games,Score
254,1,Playing Atari Games,Atari 2600 River Raid,2018-03,Ape-X,63864.4,19.75,34256.4,0.11,323417.18,0.02,ito:ITO_00873,Playing Games,Score
255,1,Playing Atari Games,Atari 2600 River Raid,2019-11,MuZero,323417.18,100.0,259552.8,0.8,323417.18,0.1,ito:ITO_00873,Playing Games,Score
256,1,Playing Atari Games,Atari 2600 Seaquest,2012-07,UCT,5132.4,0.51,5132.4,0.01,999997.63,0.0,ito:ITO_00873,Playing Games,Score
257,1,Playing Atari Games,Atari 2600 Seaquest,2015-07,Gorila,10145.9,1.01,5013.5,0.01,999997.63,0.0,ito:ITO_00873,Playing Games,Score
258,1,Playing Atari Games,Atari 2600 Seaquest,2015-09,DDQN (tuned) hs,14498.0,1.45,4352.1,0.0,999997.63,0.0,ito:ITO_00873,Playing Games,Score
259,1,Playing Atari Games,Atari 2600 Seaquest,2015-11,Prior noop,26357.8,2.64,11859.8,0.01,999997.63,0.01,ito:ITO_00873,Playing Games,Score
260,1,Playing Atari Games,Atari 2600 Seaquest,2015-11,Duel noop,50254.2,5.03,23896.4,0.02,999997.63,0.02,ito:ITO_00873,Playing Games,Score
261,1,Playing Atari Games,Atari 2600 Seaquest,2017-07,C51 noop,266434.0,26.64,216179.8,0.22,999997.63,0.09,ito:ITO_00873,Playing Games,Score
262,1,Playing Atari Games,Atari 2600 Seaquest,2018-03,Ape-X,392952.3,39.3,126518.3,0.13,999997.63,0.13,ito:ITO_00873,Playing Games,Score
263,1,Playing Atari Games,Atari 2600 Seaquest,2019-05,R2D2,999996.7,100.0,607044.4,0.61,999997.63,0.32,ito:ITO_00873,Playing Games,Score
264,1,Playing Atari Games,Atari 2600 Seaquest,2020-03,Agent57,999997.63,100.0,0.9,0.0,999997.63,0.32,ito:ITO_00873,Playing Games,Score
265,1,Playing Atari Games,Atari 2600 Demon Attack,2012-07,Best Learner,520.5,0.23,520.5,0.0,230324.0,0.0,ito:ITO_00873,Playing Games,Score
266,1,Playing Atari Games,Atari 2600 Demon Attack,2012-07,UCT,28158.8,12.23,27638.3,0.12,230324.0,0.01,ito:ITO_00873,Playing Games,Score
267,1,Playing Atari Games,Atari 2600 Demon Attack,2015-09,Prior+Duel hs,73371.3,31.86,45212.5,0.2,230324.0,0.02,ito:ITO_00873,Playing Games,Score
268,1,Playing Atari Games,Atari 2600 Demon Attack,2016-02,A3C LSTM hs,115201.9,50.02,41830.6,0.18,230324.0,0.04,ito:ITO_00873,Playing Games,Score
269,1,Playing Atari Games,Atari 2600 Demon Attack,2017-07,C51 noop,130955.0,56.86,15753.1,0.07,230324.0,0.04,ito:ITO_00873,Playing Games,Score
270,1,Playing Atari Games,Atari 2600 Demon Attack,2018-02,IMPALA (deep),132826.98,57.67,1872.0,0.01,230324.0,0.04,ito:ITO_00873,Playing Games,Score
271,1,Playing Atari Games,Atari 2600 Demon Attack,2018-03,Ape-X,133086.4,57.78,259.4,0.0,230324.0,0.04,ito:ITO_00873,Playing Games,Score
272,1,Playing Atari Games,Atari 2600 Demon Attack,2019-05,R2D2,140002.3,60.78,6915.9,0.03,230324.0,0.05,ito:ITO_00873,Playing Games,Score
273,1,Playing Atari Games,Atari 2600 Demon Attack,2019-11,MuZero,143964.26,62.51,3962.0,0.02,230324.0,0.05,ito:ITO_00873,Playing Games,Score
274,1,Playing Atari Games,Atari 2600 Demon Attack,2020-01,RIMs-PPO,230324.0,100.0,86359.7,0.37,230324.0,0.07,ito:ITO_00873,Playing Games,Score
275,1,Playing Atari Games,Atari 2600 Crazy Climber,2012-07,UCT,98172.2,17.35,98172.2,0.17,565909.85,0.03,ito:ITO_00873,Playing Games,Score
276,1,Playing Atari Games,Atari 2600 Crazy Climber,2015-09,DDQN (tuned) hs,113782.0,20.11,15609.8,0.03,565909.85,0.04,ito:ITO_00873,Playing Games,Score
277,1,Playing Atari Games,Atari 2600 Crazy Climber,2015-09,Prior+Duel hs,127853.0,22.59,14071.0,0.02,565909.85,0.04,ito:ITO_00873,Playing Games,Score
278,1,Playing Atari Games,Atari 2600 Crazy Climber,2015-11,Prior noop,141161.0,24.94,13308.0,0.02,565909.85,0.05,ito:ITO_00873,Playing Games,Score
279,1,Playing Atari Games,Atari 2600 Crazy Climber,2015-11,Duel noop,143570.0,25.37,2409.0,0.0,565909.85,0.05,ito:ITO_00873,Playing Games,Score
280,1,Playing Atari Games,Atari 2600 Crazy Climber,2015-11,Prior+Duel noop,162224.0,28.67,18654.0,0.03,565909.85,0.05,ito:ITO_00873,Playing Games,Score
281,1,Playing Atari Games,Atari 2600 Crazy Climber,2017-04,Reactor 500M,236422.0,41.78,74198.0,0.13,565909.85,0.08,ito:ITO_00873,Playing Games,Score
282,1,Playing Atari Games,Atari 2600 Crazy Climber,2018-03,Ape-X,320426.0,56.62,84004.0,0.15,565909.85,0.1,ito:ITO_00873,Playing Games,Score
283,1,Playing Atari Games,Atari 2600 Crazy Climber,2019-05,R2D2,366690.7,64.8,46264.7,0.08,565909.85,0.12,ito:ITO_00873,Playing Games,Score
284,1,Playing Atari Games,Atari 2600 Crazy Climber,2019-11,MuZero,458315.4,80.99,91624.7,0.16,565909.85,0.15,ito:ITO_00873,Playing Games,Score
285,1,Playing Atari Games,Atari 2600 Crazy Climber,2020-03,Agent57,565909.85,100.0,107594.4,0.19,565909.85,0.18,ito:ITO_00873,Playing Games,Score
286,1,Playing Atari Games,Atari 2600 Double Dunk,2012-07,UCT,24.0,100.0,24.0,1.0,24.0,0.0,ito:ITO_00873,Playing Games,Score
287,1,Playing Atari Games,Atari 2600 Tennis,2012-07,UCT,2.8,11.72,2.8,0.12,23.9,0.0,ito:ITO_00873,Playing Games,Score
288,1,Playing Atari Games,Atari 2600 Tennis,2015-09,DQN hs,11.1,46.44,8.3,0.35,23.9,0.0,ito:ITO_00873,Playing Games,Score
289,1,Playing Atari Games,Atari 2600 Tennis,2015-09,DQN noop,12.2,51.05,1.1,0.05,23.9,0.0,ito:ITO_00873,Playing Games,Score
290,1,Playing Atari Games,Atari 2600 Tennis,2017-07,C51 noop,23.1,96.65,10.9,0.46,23.9,0.0,ito:ITO_00873,Playing Games,Score
291,1,Playing Atari Games,Atari 2600 Tennis,2017-10,QR-DQN-1,23.6,98.74,0.5,0.02,23.9,0.0,ito:ITO_00873,Playing Games,Score
292,1,Playing Atari Games,Atari 2600 Tennis,2018-03,Ape-X,23.9,100.0,0.3,0.01,23.9,0.0,ito:ITO_00873,Playing Games,Score
293,1,Playing Atari Games,Atari 2600 James Bond,2012-07,UCT,330.0,0.24,330.0,0.0,135784.96,0.0,ito:ITO_00873,Playing Games,Score
294,1,Playing Atari Games,Atari 2600 James Bond,2015-07,Gorila,444.0,0.33,114.0,0.0,135784.96,0.0,ito:ITO_00873,Playing Games,Score
295,1,Playing Atari Games,Atari 2600 James Bond,2015-09,DQN noop,768.5,0.57,324.5,0.0,135784.96,0.0,ito:ITO_00873,Playing Games,Score
296,1,Playing Atari Games,Atari 2600 James Bond,2015-11,Prior noop,5148.0,3.79,4379.5,0.03,135784.96,0.0,ito:ITO_00873,Playing Games,Score
297,1,Playing Atari Games,Atari 2600 James Bond,2018-03,Ape-X,21322.5,15.7,16174.5,0.12,135784.96,0.01,ito:ITO_00873,Playing Games,Score
298,1,Playing Atari Games,Atari 2600 James Bond,2018-06,IQN,35108.0,25.86,13785.5,0.1,135784.96,0.01,ito:ITO_00873,Playing Games,Score
299,1,Playing Atari Games,Atari 2600 James Bond,2019-11,FQF,87291.7,64.29,52183.7,0.38,135784.96,0.03,ito:ITO_00873,Playing Games,Score
300,1,Playing Atari Games,Atari 2600 James Bond,2020-03,Agent57,135784.96,100.0,48493.3,0.36,135784.96,0.04,ito:ITO_00873,Playing Games,Score
301,1,Playing Atari Games,Atari 2600 Bank Heist,2012-07,Best Learner,190.8,0.79,190.8,0.01,24235.9,0.0,ito:ITO_00873,Playing Games,Score
302,1,Playing Atari Games,Atari 2600 Bank Heist,2012-07,UCT,497.8,2.05,307.0,0.01,24235.9,0.0,ito:ITO_00873,Playing Games,Score
303,1,Playing Atari Games,Atari 2600 Bank Heist,2015-09,Prior+Duel hs,1004.6,4.15,506.8,0.02,24235.9,0.0,ito:ITO_00873,Playing Games,Score
304,1,Playing Atari Games,Atari 2600 Bank Heist,2015-11,Prior noop,1054.6,4.35,50.0,0.0,24235.9,0.0,ito:ITO_00873,Playing Games,Score
305,1,Playing Atari Games,Atari 2600 Bank Heist,2015-11,Duel hs,1129.3,4.66,74.7,0.0,24235.9,0.0,ito:ITO_00873,Playing Games,Score
306,1,Playing Atari Games,Atari 2600 Bank Heist,2015-11,Duel noop,1611.9,6.65,482.6,0.02,24235.9,0.0,ito:ITO_00873,Playing Games,Score
307,1,Playing Atari Games,Atari 2600 Bank Heist,2018-03,Ape-X,1716.4,7.08,104.5,0.0,24235.9,0.0,ito:ITO_00873,Playing Games,Score
308,1,Playing Atari Games,Atari 2600 Bank Heist,2019-05,R2D2,24235.9,100.0,22519.5,0.93,24235.9,0.01,ito:ITO_00873,Playing Games,Score
309,1,Playing Atari Games,Atari 2600 Enduro,2012-07,UCT,286.3,8.29,286.3,0.08,3454.0,0.0,ito:ITO_00873,Playing Games,Score
310,1,Playing Atari Games,Atari 2600 Enduro,2013-12,DQN Best,661.0,19.14,374.7,0.11,3454.0,0.0,ito:ITO_00873,Playing Games,Score
311,1,Playing Atari Games,Atari 2600 Enduro,2015-09,DDQN (tuned) hs,1216.6,35.22,555.6,0.16,3454.0,0.0,ito:ITO_00873,Playing Games,Score
312,1,Playing Atari Games,Atari 2600 Enduro,2015-09,Prior+Duel hs,2223.9,64.39,1007.3,0.29,3454.0,0.0,ito:ITO_00873,Playing Games,Score
313,1,Playing Atari Games,Atari 2600 Enduro,2015-11,Duel noop,2258.2,65.38,34.3,0.01,3454.0,0.0,ito:ITO_00873,Playing Games,Score
314,1,Playing Atari Games,Atari 2600 Enduro,2015-11,Prior+Duel noop,2306.4,66.77,48.2,0.01,3454.0,0.0,ito:ITO_00873,Playing Games,Score
315,1,Playing Atari Games,Atari 2600 Enduro,2017-07,C51 noop,3454.0,100.0,1147.6,0.33,3454.0,0.0,ito:ITO_00873,Playing Games,Score
316,1,Playing Atari Games,Atari 2600 Asteroids,2012-07,Best Learner,907.3,0.13,907.3,0.0,678558.64,0.0,ito:ITO_00873,Playing Games,Score
317,1,Playing Atari Games,Atari 2600 Asteroids,2012-07,UCT,4660.6,0.69,3753.3,0.01,678558.64,0.0,ito:ITO_00873,Playing Games,Score
318,1,Playing Atari Games,Atari 2600 Asteroids,2016-02,A3C LSTM hs,5093.1,0.75,432.5,0.0,678558.64,0.0,ito:ITO_00873,Playing Games,Score
319,1,Playing Atari Games,Atari 2600 Asteroids,2017-06,NoisyNet-Dueling,86700.0,12.78,81606.9,0.12,678558.64,0.03,ito:ITO_00873,Playing Games,Score
320,1,Playing Atari Games,Atari 2600 Asteroids,2018-02,IMPALA (deep),108590.05,16.0,21890.1,0.03,678558.64,0.04,ito:ITO_00873,Playing Games,Score
321,1,Playing Atari Games,Atari 2600 Asteroids,2018-03,Ape-X,155495.1,22.92,46905.0,0.07,678558.64,0.05,ito:ITO_00873,Playing Games,Score
322,1,Playing Atari Games,Atari 2600 Asteroids,2019-05,R2D2,357867.7,52.74,202372.6,0.3,678558.64,0.12,ito:ITO_00873,Playing Games,Score
323,1,Playing Atari Games,Atari 2600 Asteroids,2019-11,MuZero,678558.64,100.0,320690.9,0.47,678558.64,0.22,ito:ITO_00873,Playing Games,Score
324,1,Playing Atari Games,Atari 2600 Centipede,2012-07,Best Learner,8803.8,0.62,8803.8,0.01,1422628.0,0.0,ito:ITO_00873,Playing Games,Score
325,1,Playing Atari Games,Atari 2600 Centipede,2012-07,Full Tree,125123.0,8.8,116319.2,0.08,1422628.0,0.04,ito:ITO_00873,Playing Games,Score
326,1,Playing Atari Games,Atari 2600 Centipede,2019-05,R2D2,599140.3,42.12,474017.3,0.33,1422628.0,0.19,ito:ITO_00873,Playing Games,Score
327,1,Playing Atari Games,Atari 2600 Centipede,2019-11,MuZero,1159049.27,81.47,559909.0,0.39,1422628.0,0.38,ito:ITO_00873,Playing Games,Score
328,1,Playing Atari Games,Atari 2600 Centipede,2020-04,Go-Explore,1422628.0,100.0,263578.7,0.19,1422628.0,0.46,ito:ITO_00873,Playing Games,Score
329,1,Playing Atari Games,Atari 2600 Tutankham,2012-07,Best Learner,114.3,4.85,114.3,0.05,2354.91,0.0,ito:ITO_00873,Playing Games,Score
330,1,Playing Atari Games,Atari 2600 Tutankham,2012-07,UCT,225.5,9.58,111.2,0.05,2354.91,0.0,ito:ITO_00873,Playing Games,Score
331,1,Playing Atari Games,Atari 2600 Tutankham,2015-11,Prior+Duel noop,245.9,10.44,20.4,0.01,2354.91,0.0,ito:ITO_00873,Playing Games,Score
332,1,Playing Atari Games,Atari 2600 Tutankham,2017-06,NoisyNet-Dueling,269.0,11.42,23.1,0.01,2354.91,0.0,ito:ITO_00873,Playing Games,Score
333,1,Playing Atari Games,Atari 2600 Tutankham,2017-07,C51 noop,280.0,11.89,11.0,0.0,2354.91,0.0,ito:ITO_00873,Playing Games,Score
334,1,Playing Atari Games,Atari 2600 Tutankham,2017-10,QR-DQN-1,297.0,12.61,17.0,0.01,2354.91,0.0,ito:ITO_00873,Playing Games,Score
335,1,Playing Atari Games,Atari 2600 Tutankham,2018-06,A2C + SIL,340.5,14.46,43.5,0.02,2354.91,0.0,ito:ITO_00873,Playing Games,Score
336,1,Playing Atari Games,Atari 2600 Tutankham,2019-05,R2D2,395.3,16.79,54.8,0.02,2354.91,0.0,ito:ITO_00873,Playing Games,Score
337,1,Playing Atari Games,Atari 2600 Tutankham,2019-11,MuZero,491.48,20.87,96.2,0.04,2354.91,0.0,ito:ITO_00873,Playing Games,Score
338,1,Playing Atari Games,Atari 2600 Tutankham,2020-03,Agent57,2354.91,100.0,1863.4,0.79,2354.91,0.0,ito:ITO_00873,Playing Games,Score
339,1,Playing Atari Games,Atari 2600 Bowling,2012-07,Best Learner,43.9,16.88,43.9,0.17,260.13,0.0,ito:ITO_00873,Playing Games,Score
340,1,Playing Atari Games,Atari 2600 Bowling,2015-07,Gorila,54.0,20.76,10.1,0.04,260.13,0.0,ito:ITO_00873,Playing Games,Score
341,1,Playing Atari Games,Atari 2600 Bowling,2015-09,DQN hs,56.5,21.72,2.5,0.01,260.13,0.0,ito:ITO_00873,Playing Games,Score
342,1,Playing Atari Games,Atari 2600 Bowling,2015-09,DDQN (tuned) hs,69.6,26.76,13.1,0.05,260.13,0.0,ito:ITO_00873,Playing Games,Score
343,1,Playing Atari Games,Atari 2600 Bowling,2015-12,Persistent AL,71.59,27.52,2.0,0.01,260.13,0.0,ito:ITO_00873,Playing Games,Score
344,1,Playing Atari Games,Atari 2600 Bowling,2016-02,DDQN+Pop-Art noop,102.1,39.25,30.5,0.12,260.13,0.0,ito:ITO_00873,Playing Games,Score
345,1,Playing Atari Games,Atari 2600 Bowling,2018-06,RUDDER,179.0,68.81,76.9,0.3,260.13,0.0,ito:ITO_00873,Playing Games,Score
346,1,Playing Atari Games,Atari 2600 Bowling,2019-05,R2D2,219.5,84.38,40.5,0.16,260.13,0.0,ito:ITO_00873,Playing Games,Score
347,1,Playing Atari Games,Atari 2600 Bowling,2019-11,MuZero,260.13,100.0,40.6,0.16,260.13,0.0,ito:ITO_00873,Playing Games,Score
348,1,Playing Atari Games,Atari 2600 Pooyan,2012-07,Best Learner,1225.3,6.9,1225.3,0.07,17763.4,0.0,ito:ITO_00873,Playing Games,Score
349,1,Playing Atari Games,Atari 2600 Pooyan,2012-07,UCT,17763.4,100.0,16538.1,0.93,17763.4,0.01,ito:ITO_00873,Playing Games,Score
350,1,Playing Atari Games,Atari 2600 Time Pilot,2012-07,Best Learner,3741.2,0.78,3741.2,0.01,476763.9,0.0,ito:ITO_00873,Playing Games,Score
351,1,Playing Atari Games,Atari 2600 Time Pilot,2012-07,UCT,63854.5,13.39,60113.3,0.13,476763.9,0.02,ito:ITO_00873,Playing Games,Score
352,1,Playing Atari Games,Atari 2600 Time Pilot,2018-03,Ape-X,87085.0,18.27,23230.5,0.05,476763.9,0.03,ito:ITO_00873,Playing Games,Score
353,1,Playing Atari Games,Atari 2600 Time Pilot,2019-05,R2D2,445377.3,93.42,358292.3,0.75,476763.9,0.14,ito:ITO_00873,Playing Games,Score
354,1,Playing Atari Games,Atari 2600 Time Pilot,2019-11,MuZero,476763.9,100.0,31386.6,0.07,476763.9,0.15,ito:ITO_00873,Playing Games,Score
355,1,Playing Atari Games,Atari 2600 Road Runner,2012-07,Best Learner,67.7,0.01,67.7,0.0,613411.8,0.0,ito:ITO_00873,Playing Games,Score
356,1,Playing Atari Games,Atari 2600 Road Runner,2012-07,UCT,38725.0,6.31,38657.3,0.06,613411.8,0.01,ito:ITO_00873,Playing Games,Score
357,1,Playing Atari Games,Atari 2600 Road Runner,2015-07,Gorila,43079.8,7.02,4354.8,0.01,613411.8,0.01,ito:ITO_00873,Playing Games,Score
358,1,Playing Atari Games,Atari 2600 Road Runner,2015-09,Prior+Duel hs,54630.0,8.91,11550.2,0.02,613411.8,0.02,ito:ITO_00873,Playing Games,Score
359,1,Playing Atari Games,Atari 2600 Road Runner,2015-11,Prior noop,57608.0,9.39,2978.0,0.0,613411.8,0.02,ito:ITO_00873,Playing Games,Score
360,1,Playing Atari Games,Atari 2600 Road Runner,2015-11,Duel noop,69524.0,11.33,11916.0,0.02,613411.8,0.02,ito:ITO_00873,Playing Games,Score
361,1,Playing Atari Games,Atari 2600 Road Runner,2016-02,A3C LSTM hs,73949.0,12.06,4425.0,0.01,613411.8,0.02,ito:ITO_00873,Playing Games,Score
362,1,Playing Atari Games,Atari 2600 Road Runner,2017-06,NoisyNet-Dueling,234352.0,38.2,160403.0,0.26,613411.8,0.08,ito:ITO_00873,Playing Games,Score
363,1,Playing Atari Games,Atari 2600 Road Runner,2019-05,R2D2,599246.7,97.69,364894.7,0.59,613411.8,0.19,ito:ITO_00873,Playing Games,Score
364,1,Playing Atari Games,Atari 2600 Road Runner,2019-11,MuZero,613411.8,100.0,14165.1,0.02,613411.8,0.2,ito:ITO_00873,Playing Games,Score
365,1,Playing Atari Games,Atari 2600 Carnival,2012-07,Best Learner,2323.9,45.28,2323.9,0.45,5132.0,0.0,ito:ITO_00873,Playing Games,Score
366,1,Playing Atari Games,Atari 2600 Carnival,2012-07,UCT,5132.0,100.0,2808.1,0.55,5132.0,0.0,ito:ITO_00873,Playing Games,Score
367,1,Playing Atari Games,Atari 2600 Elevator Action,2012-07,UCT,18100.0,62.2,18100.0,0.62,29100.0,0.01,ito:ITO_00873,Playing Games,Score
368,1,Playing Atari Games,Atari 2600 Elevator Action,2015-12,Persistent AL,29100.0,100.0,11000.0,0.38,29100.0,0.01,ito:ITO_00873,Playing Games,Score
369,1,Playing Atari Games,Atari 2600 Journey Escape,2012-07,UCT,7683.3,100.0,7683.3,1.0,7683.3,0.0,ito:ITO_00873,Playing Games,Score
370,1,Playing Atari Games,Atari 2600 Phoenix,2015-11,Prior+Duel hs,63597.0,6.66,63597.0,0.07,955137.84,0.02,ito:ITO_00873,Playing Games,Score
371,1,Playing Atari Games,Atari 2600 Phoenix,2018-02,IMPALA (deep),210996.45,22.09,147399.4,0.15,955137.84,0.07,ito:ITO_00873,Playing Games,Score
372,1,Playing Atari Games,Atari 2600 Phoenix,2018-03,Ape-X,224491.1,23.5,13494.6,0.01,955137.84,0.07,ito:ITO_00873,Playing Games,Score
373,1,Playing Atari Games,Atari 2600 Phoenix,2019-05,R2D2,864020.0,90.46,639528.9,0.67,955137.84,0.28,ito:ITO_00873,Playing Games,Score
374,1,Playing Atari Games,Atari 2600 Phoenix,2019-11,MuZero,955137.84,100.0,91117.8,0.1,955137.84,0.31,ito:ITO_00873,Playing Games,Score
375,1,Playing Atari Games,Atari 2600 Defender,2015-11,Duel noop,42214.0,4.25,42214.0,0.04,993010.0,0.01,ito:ITO_00873,Playing Games,Score
376,1,Playing Atari Games,Atari 2600 Defender,2017-04,Reactor 500M,223025.0,22.46,180811.0,0.18,993010.0,0.07,ito:ITO_00873,Playing Games,Score
377,1,Playing Atari Games,Atari 2600 Defender,2018-03,Ape-X,411943.5,41.48,188918.5,0.19,993010.0,0.13,ito:ITO_00873,Playing Games,Score
378,1,Playing Atari Games,Atari 2600 Defender,2018-06,CGP,993010.0,100.0,581066.5,0.59,993010.0,0.32,ito:ITO_00873,Playing Games,Score
379,1,Playing Atari Games,Atari 2600 Solaris,2015-12,Advantage Learning,4785.16,10.83,4785.16,0.11,44199.93,0.0,ito:ITO_00873,Playing Games,Score
380,1,Playing Atari Games,Atari 2600 Solaris,2017-06,NoisyNet-Dueling,6522.0,14.76,1736.8,0.04,44199.93,0.0,ito:ITO_00873,Playing Games,Score
381,1,Playing Atari Games,Atari 2600 Solaris,2017-10,QR-DQN-1,6740.0,15.25,218.0,0.0,44199.93,0.0,ito:ITO_00873,Playing Games,Score
382,1,Playing Atari Games,Atari 2600 Solaris,2018-06,IQN,8007.0,18.12,1267.0,0.03,44199.93,0.0,ito:ITO_00873,Playing Games,Score
383,1,Playing Atari Games,Atari 2600 Solaris,2018-06,CGP,8324.0,18.83,317.0,0.01,44199.93,0.0,ito:ITO_00873,Playing Games,Score
384,1,Playing Atari Games,Atari 2600 Solaris,2020-03,Agent57,44199.93,100.0,35875.9,0.81,44199.93,0.01,ito:ITO_00873,Playing Games,Score
385,1,Playing Atari Games,Atari 2600 Surround,2015-12,Persistent AL,0.72,7.2,0.72,0.07,10.0,0.0,ito:ITO_00873,Playing Games,Score
386,1,Playing Atari Games,Atari 2600 Surround,2017-06,NoisyNet-Dueling,10.0,100.0,9.3,0.93,10.0,0.0,ito:ITO_00873,Playing Games,Score
387,1,Playing Atari Games,Atari 2600 Yars Revenge,2015-12,Advantage Learning,24240.03,2.43,24240.03,0.02,998532.37,0.01,ito:ITO_00873,Playing Games,Score
388,1,Playing Atari Games,Atari 2600 Yars Revenge,2017-06,NoisyNet-Dueling,86101.0,8.62,61861.0,0.06,998532.37,0.03,ito:ITO_00873,Playing Games,Score
389,1,Playing Atari Games,Atari 2600 Yars Revenge,2018-03,Ape-X,148594.8,14.88,62493.8,0.06,998532.37,0.05,ito:ITO_00873,Playing Games,Score
390,1,Playing Atari Games,Atari 2600 Yars Revenge,2019-05,R2D2,995048.4,99.65,846453.6,0.85,998532.37,0.32,ito:ITO_00873,Playing Games,Score
391,1,Playing Atari Games,Atari 2600 Yars Revenge,2020-03,Agent57,998532.37,100.0,3484.0,0.0,998532.37,0.32,ito:ITO_00873,Playing Games,Score
392,1,Continuous Control,Half-Cheetah,2016-04,TRPO,1914.0,100.0,1914,1.0,1914,0.0,ito:ITO_00873,Playing Games,Score
393,1,Continuous Control,2D Walker,2016-04,TRPO,1353.8,100.0,1353.8,1.0,1353.8,0.0,ito:ITO_00873,Playing Games,Score
394,1,Continuous Control,Simple Humanoid,2016-04,TRPO,269.7,100.0,269.7,1.0,269.7,0.0,ito:ITO_00873,Playing Games,Score
395,1,Continuous Control,Cart-Pole Balancing,2016-04,TRPO,4869.8,100.0,4869.8,1.0,4869.8,0.0,ito:ITO_00873,Playing Games,Score
396,1,Continuous Control,Double Inverted Pendulum,2016-04,TRPO,4412.4,100.0,4412.4,1.0,4412.4,0.0,ito:ITO_00873,Playing Games,Score
397,1,Continuous Control,Hopper,2016-04,TRPO,1183.3,100.0,1183.3,1.0,1183.3,0.0,ito:ITO_00873,Playing Games,Score
398,1,Continuous Control,Swimmer,2016-04,TRPO,96.0,100.0,96,1.0,96,0.0,ito:ITO_00873,Playing Games,Score
399,1,Continuous Control,Ant,2016-04,TRPO,730.2,100.0,730.2,1.0,730.2,0.0,ito:ITO_00873,Playing Games,Score
400,1,Continuous Control,Full Humanoid,2016-04,TRPO,287.0,100.0,287,1.0,287,0.0,ito:ITO_00873,Playing Games,Score
401,1,Continuous Control,Inverted Pendulum,2016-04,TRPO,247.2,100.0,247.2,1.0,247.2,0.0,ito:ITO_00873,Playing Games,Score
402,1,Playing SNES Games,Gradius III,2016-11,Dueling D-DQN,16929.0,100.0,16929,1.0,16929,0.01,ito:ITO_00873,Playing Games,Score
403,1,Playing SNES Games,F-Zero,2016-11,Dueling D-DQN,5161.0,100.0,5161,1.0,5161,0.0,ito:ITO_00873,Playing Games,Score
404,1,Playing SNES Games,Wolfenstein,2016-11,DQN,100.0,100.0,100,1.0,100,0.0,ito:ITO_00873,Playing Games,Score
405,1,Playing SNES Games,Super Mario,2016-11,Dueling D-DQN,20030.0,100.0,20030,1.0,20030,0.01,ito:ITO_00873,Playing Games,Score
406,1,Playing SNES Games,Mortal Kombat,2016-11,Dueling D-DQN,169300.0,100.0,169300,1.0,169300,0.05,ito:ITO_00873,Playing Games,Score
407,1,Playing Atari Games,Atari 2600 Pitfall!,2019-01,Go-Explore,107363.0,100.0,107363.0,1.0,107363.0,0.03,ito:ITO_00873,Playing Games,Score
0,1,Playing Atari Games,Atari 2600 Elevator Action,2012-07,Best Learner,3220.6,100.0,3220.6,1.0,3220.6,1.0,ito:ITO_00873,Playing Games,Action
0,1,Playing Atari Games,Atari-57,2015-11,Prioritized DQN,128.0,6.27,128.0,0.06,2041.1,0.06,ito:ITO_00873,Playing Games,Medium\\ Human\\-Normalized\\ Score
1,1,Playing Atari Games,Atari-57,2015-11,Dueling DQN,172.1,8.43,44.1,0.02,2041.1,0.08,ito:ITO_00873,Playing Games,Medium\\ Human\\-Normalized\\ Score
2,1,Playing Atari Games,Atari-57,2017-04,Reactor,187.0,9.16,14.9,0.01,2041.1,0.09,ito:ITO_00873,Playing Games,Medium\\ Human\\-Normalized\\ Score
3,1,Playing Atari Games,Atari-57,2017-10,Rainbow DQN,223.0,10.93,36.0,0.02,2041.1,0.11,ito:ITO_00873,Playing Games,Medium\\ Human\\-Normalized\\ Score
4,1,Playing Atari Games,Atari-57,2018-03,Ape-X (DQN),434.1,21.27,211.1,0.1,2041.1,0.21,ito:ITO_00873,Playing Games,Medium\\ Human\\-Normalized\\ Score
5,1,Playing Atari Games,Atari-57,2019-05,R2D2,1920.6,94.1,1486.5,0.73,2041.1,0.94,ito:ITO_00873,Playing Games,Medium\\ Human\\-Normalized\\ Score
6,1,Playing Atari Games,Atari-57,2019-11,MuZero,2041.1,100.0,120.5,0.06,2041.1,1.0,ito:ITO_00873,Playing Games,Medium\\ Human\\-Normalized\\ Score
0,1,Playing Game of Doom,ViZDoom Basic Scenario,2016-05,DQN,82.2,100.0,82.2,1.0,82.2,1.0,ito:ITO_00873,Playing Games,Average\\ Score
0,1,Playing Starcraft II,CollectMineralShards,2017-08,FullyConv LSTM,137.0,100.0,137,1.0,137,1.0,ito:ITO_00873,Playing Games,Max\\ Score
1,1,Playing Starcraft II,MoveToBeacon,2017-08,FullyConv LSTM,35.0,100.0,35,1.0,35,0.26,ito:ITO_00873,Playing Games,Max\\ Score
0,1,Playing Montezuma's Revenge,Atari 2600 Montezuma's Revenge,2017-10,Rainbow,384.0,100.0,384,1.0,384,1.0,ito:ITO_00873,Playing Games,Average\\ Return\\ \\(NoOp\\)
0,1,Playing Game of Go,ELO Ratings,2017-12,AlphaGo Zero,5185.0,100.0,5185,1.0,5185,1.0,ito:ITO_00873,Playing Games,ELO\\ Rating
1,1,Playing Game of Shogi,ELO Ratings,2017-12,AlphaZero,4650.0,100.0,4650,1.0,4650,0.9,ito:ITO_00873,Playing Games,ELO\\ Rating
0,1,Steering Control,Comma.ai,2018-11,FM-Net,0.7048,100.0,0.7048,1.0,0.7048,0.43,ito:ITO_00873,Playing Games,MAE
1,1,Steering Control,Udacity,2018-11,FM-Net,1.6236,100.0,1.6236,1.0,1.6236,1.0,ito:ITO_00873,Playing Games,MAE
0,1,Steering Control,BDD100k,2018-11,FM-Net,85.03,100.0,85.03,1.0,85.03,0.87,ito:ITO_00873,Playing Games,Accuracy
1,1,Steering Control,BDD100K,2018-11,FM-Net,85.03,100.0,85.03,1.0,85.03,0.87,ito:ITO_00873,Playing Games,Accuracy
2,1,Playing Game of Suduko,Sudoko 9x9,2019-05,SATNet,98.3,100.0,98.3,1.0,98.3,1.0,ito:ITO_00873,Playing Games,Accuracy
0,1,Music Classification,20NEWS,2016-09,CRNN,10.0,100.0,10,1.0,10,0.16,ito:ITO_01532,Artistic process,Accuracy
1,1,Music Genre Recognition,chords,2019-02,random forest,62.0,100.0,62,1.0,62,1.0,ito:ITO_01532,Artistic process,Accuracy
0,1,Music Transcription,MusicNet,2017-05,Deep Complex Network,8800000.0,88.0,8800000,0.88,10000000,0.88,ito:ITO_01532,Artistic process,Number\\ of\\ params
1,1,Music Transcription,MusicNet,2017-05,Deep Real Network,10000000.0,100.0,1200000,0.12,10000000,1.0,ito:ITO_01532,Artistic process,Number\\ of\\ params
0,1,Music Transcription,MusicNet,2017-05,Deep Complex Network,72.9,100.0,72.9,1.0,72.9,1.0,ito:ITO_01532,Artistic process,APS
0,1,Music Modeling,Nottingham,2018-03,LSTM,3.29,81.23,3.29,0.81,4.05,0.81,ito:ITO_01532,Artistic process,NLL
1,1,Music Modeling,Nottingham,2018-03,RNN,4.05,100.0,0.8,0.2,4.05,1.0,ito:ITO_01532,Artistic process,NLL
2,1,Image Relighting,Image Relighting,2018-03,TCN,3.07,75.8,3.07,0.76,4.05,0.76,ito:ITO_01532,Artistic process,NLL
3,1,Image Relighting,Image Relighting,2018-03,LSTM,3.29,81.23,0.2,0.05,4.05,0.81,ito:ITO_01532,Artistic process,NLL
4,1,Image Relighting,Image Relighting,2018-03,GRU,3.46,85.43,0.2,0.05,4.05,0.85,ito:ITO_01532,Artistic process,NLL
5,1,Image Relighting,Image Relighting,2018-03,RNN,4.05,100.0,0.6,0.15,4.05,1.0,ito:ITO_01532,Artistic process,NLL
6,1,Music Modeling,JSB Chorales,2018-09,Music Transformer,0.335,100.0,0.335,1.0,0.335,0.08,ito:ITO_01532,Artistic process,NLL
7,1,person reposing,person reposing,2018-09,Music Transformer,0.335,100.0,0.335,1.0,0.335,0.08,ito:ITO_01532,Artistic process,NLL
0,1,Music Source Separation,MUSDB18,2018-06,STL2,3.23,47.57,3.23,0.48,6.79,0.48,ito:ITO_01532,Artistic process,SDR\\ \\(avg\\)
1,1,Music Source Separation,MUSDB18,2018-09,Conv-TasNet,5.73,84.39,2.5,0.37,6.79,0.84,ito:ITO_01532,Artistic process,SDR\\ \\(avg\\)
2,1,Music Source Separation,MUSDB18,2018-09,Conv-TasNet (extra),6.32,93.08,0.6,0.09,6.79,0.93,ito:ITO_01532,Artistic process,SDR\\ \\(avg\\)
3,1,Music Source Separation,MUSDB18,2019-09,DEMUCS (extra),6.79,100.0,0.5,0.07,6.79,1.0,ito:ITO_01532,Artistic process,SDR\\ \\(avg\\)
0,1,Music Source Separation,MUSDB18,2018-06,STL2,3.25,44.58,3.25,0.45,7.29,0.45,ito:ITO_01532,Artistic process,SDR\\ \\(vocals\\)
1,1,Music Source Separation,MUSDB18,2018-09,Conv-TasNet,6.81,93.42,3.6,0.49,7.29,0.93,ito:ITO_01532,Artistic process,SDR\\ \\(vocals\\)
2,1,Music Source Separation,MUSDB18,2019-09,DEMUCS (extra),7.29,100.0,0.5,0.07,7.29,1.0,ito:ITO_01532,Artistic process,SDR\\ \\(vocals\\)
0,1,Music Source Separation,MUSDB18,2018-06,STL2,4.22,55.67,4.22,0.56,7.58,0.56,ito:ITO_01532,Artistic process,SDR\\ \\(drums\\)
1,1,Music Source Separation,MUSDB18,2018-09,Conv-TasNet,6.08,80.21,1.9,0.25,7.58,0.8,ito:ITO_01532,Artistic process,SDR\\ \\(drums\\)
2,1,Music Source Separation,MUSDB18,2018-09,Conv-TasNet (extra),7.11,93.8,1.0,0.13,7.58,0.94,ito:ITO_01532,Artistic process,SDR\\ \\(drums\\)
3,1,Music Source Separation,MUSDB18,2019-09,DEMUCS (extra),7.58,100.0,0.5,0.07,7.58,1.0,ito:ITO_01532,Artistic process,SDR\\ \\(drums\\)
0,1,Music Source Separation,MUSDB18,2018-06,STL2,3.21,42.24,3.21,0.42,7.6,0.42,ito:ITO_01532,Artistic process,SDR\\ \\(bass\\)
1,1,Music Source Separation,MUSDB18,2018-09,Conv-TasNet,5.66,74.47,2.4,0.32,7.6,0.74,ito:ITO_01532,Artistic process,SDR\\ \\(bass\\)
2,1,Music Source Separation,MUSDB18,2018-09,Conv-TasNet (extra),7.0,92.11,1.3,0.17,7.6,0.92,ito:ITO_01532,Artistic process,SDR\\ \\(bass\\)
3,1,Music Source Separation,MUSDB18,2019-09,DEMUCS (extra),7.6,100.0,0.6,0.08,7.6,1.0,ito:ITO_01532,Artistic process,SDR\\ \\(bass\\)
0,1,Music Source Separation,MUSDB18,2018-06,STL2,2.25,46.02,2.25,0.46,4.889,0.46,ito:ITO_01532,Artistic process,SDR\\ \\(other\\)
1,1,Music Source Separation,MUSDB18,2018-09,Conv-TasNet,4.37,89.38,2.1,0.43,4.889,0.89,ito:ITO_01532,Artistic process,SDR\\ \\(other\\)
2,1,Music Source Separation,MUSDB18,2018-09,Conv-TasNet (extra),4.44,90.82,0.1,0.02,4.889,0.91,ito:ITO_01532,Artistic process,SDR\\ \\(other\\)
3,1,Music Source Separation,MUSDB18,2019-09,DEMUCS (extra),4.69,95.93,0.2,0.04,4.889,0.96,ito:ITO_01532,Artistic process,SDR\\ \\(other\\)
4,1,Music Source Separation,MUSDB18,2019-09,UMXL,4.889,100.0,0.2,0.04,4.889,1.0,ito:ITO_01532,Artistic process,SDR\\ \\(other\\)
0,1,Aspect Term Extraction and Sentiment Classification,SemEval,2019-06,IMN-BERT,70.72,100.0,70.72,1.0,70.72,1.0,ito:ITO_01532,Artistic process,Restaurant\\ 2014\\ \\(F1\\)
0,1,Aspect Term Extraction and Sentiment Classification,SemEval,2019-06,IMN-BERT,61.73,100.0,61.73,1.0,61.73,1.0,ito:ITO_01532,Artistic process,Laptop\\ 2014\\ \\(F1\\)
0,1,Aspect Term Extraction and Sentiment Classification,SemEval,2019-06,IMN-BERT,60.22,100.0,60.22,1.0,60.22,1.0,ito:ITO_01532,Artistic process,Restaurant\\ 2015\\ \\(F1\\)
0,1,Aspect Term Extraction and Sentiment Classification,SemEval,2019-06,IMN-BERT,64.23,100.0,64.23,1.0,64.23,1.0,ito:ITO_01532,Artistic process,Avg\\ F1
0,1,Cover song identification,YouTube350,2019-10,MOVE,0.885,96.51,0.885,0.97,0.917,0.97,ito:ITO_01532,Artistic process,MAP
1,1,Cover song identification,YouTube350,2019-11,CQT-Net,0.917,100.0,0.0,0.0,0.917,1.0,ito:ITO_01532,Artistic process,MAP
2,1,Cover song identification,Covers80,2019-10,MOVE,0.844,100.0,0.844,1.0,0.844,0.92,ito:ITO_01532,Artistic process,MAP
3,1,Aspect Term Extraction and Sentiment Classification,Aspect Term Extraction and Sentiment Classification,2019-10,MOVE,0.844,100.0,0.844,1.0,0.844,0.92,ito:ITO_01532,Artistic process,MAP
0,1,Cover song identification,SHS100K-TEST,2019-11,CQT-Net,0.655,100.0,0.655,1.0,0.655,1.0,ito:ITO_01532,Artistic process,mAP
